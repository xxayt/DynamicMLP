# 3090
2023-03-16 22:26:04,530 - INFO - --batch_size 128
2023-03-16 22:26:04,530 - INFO - --data inat21_mini
2023-03-16 22:26:04,530 - INFO - --data_dir ./datasets/iNat2021
2023-03-16 22:26:04,530 - INFO - --evaluate False
2023-03-16 22:26:04,530 - INFO - --fold 1
2023-03-16 22:26:04,530 - INFO - --image_only False
2023-03-16 22:26:04,530 - INFO - --metadata geo_temporal
2023-03-16 22:26:04,530 - INFO - --mlp_cin 6
2023-03-16 22:26:04,530 - INFO - --mlp_d 256
2023-03-16 22:26:04,530 - INFO - --mlp_h 64
2023-03-16 22:26:04,530 - INFO - --mlp_n 2
2023-03-16 22:26:04,530 - INFO - --mlp_type c
2023-03-16 22:26:04,530 - INFO - --model_file sk2res2net_dynamic_mlp
2023-03-16 22:26:04,530 - INFO - --model_name sk2res2net101
2023-03-16 22:26:04,530 - INFO - --name sk2_dynamic_mlp
2023-03-16 22:26:04,530 - INFO - --num_classes 10000
2023-03-16 22:26:04,530 - INFO - --num_workers 8
2023-03-16 22:26:04,530 - INFO - --path_log ./outputs/inat21_mini/sk2_dynamic_mlp
2023-03-16 22:26:04,530 - INFO - --pretrained True
2023-03-16 22:26:04,530 - INFO - --random_seed 37
2023-03-16 22:26:04,531 - INFO - --resume Latest
2023-03-16 22:26:04,531 - INFO - --save_dir ./outputs
2023-03-16 22:26:04,531 - INFO - --start_lr 0.04
2023-03-16 22:26:04,531 - INFO - --stop_epoch 90
2023-03-16 22:26:04,531 - INFO - --tencrop False
2023-03-16 22:26:04,531 - INFO - --warmup 2
2023-03-16 22:26:04,531 - INFO - Creating model:sk2res2net_dynamic_mlp -> sk2res2net101
2023-03-16 22:26:05,253 - INFO - type: c, cin: 6, d: 256, h: 64, N: 2
2023-03-16 22:26:05,638 - INFO - Successfully load checkpoints/sk2res2net101_epoch_300.pth !
2023-03-16 22:26:09,726 - INFO - => loading checkpoint './outputs/inat21_mini/sk2_dynamic_mlp/fold1_latest.pth'
2023-03-16 22:26:10,582 - INFO - => loaded checkpoint './outputs/inat21_mini/sk2_dynamic_mlp/fold1_latest.pth' (epoch 5)
2023-03-16 22:26:10,582 - INFO - eval epoch 5
2023-03-16 22:26:22,110 - INFO - Test: [0/782]	Time 11.526 (11.526)	Loss 2.5186 (2.5186)	Acc@1 71.875 (71.875)	Acc@5 92.969 (92.969)
2023-03-16 22:29:00,480 - INFO - Test: [200/782]	Time 0.787 (0.845)	Loss 2.7561 (2.8708)	Acc@1 69.531 (62.815)	Acc@5 85.156 (85.592)
2023-03-16 22:31:36,385 - INFO - Test: [400/782]	Time 0.673 (0.812)	Loss 2.6855 (2.8518)	Acc@1 75.000 (63.412)	Acc@5 85.938 (85.813)
2023-03-16 22:34:10,551 - INFO - Test: [600/782]	Time 0.923 (0.799)	Loss 2.9359 (2.8200)	Acc@1 61.719 (64.164)	Acc@5 84.375 (86.283)
2023-03-16 22:36:27,144 - INFO -  * Acc@1 64.706 Acc@5 86.784
2023-03-16 22:36:27,145 - INFO - Max accuracy: 64.7060%
2023-03-16 22:36:27,145 - INFO - Start training
2023-03-16 22:36:32,893 - INFO - Train: [6/90][0/3907]	eta 6:13:49 lr 0.03969616	time 5.7409 (5.7409)	loss 2.9771 (2.9771)	acc@1: 73.4819	acc@5: 86.7086	
2023-03-16 22:38:40,388 - INFO - Train: [6/90][300/3907]	eta 0:26:36 lr 0.03969616	time 0.3784 (0.4426)	loss 4.9481 (3.9238)	acc@1: 40.1314	acc@5: 54.6038	
2023-03-16 22:40:47,933 - INFO - Train: [6/90][600/3907]	eta 0:23:54 lr 0.03969616	time 0.3991 (0.4339)	loss 3.3603 (3.9036)	acc@1: 61.4250	acc@5: 78.7946	
2023-03-16 22:42:56,222 - INFO - Train: [6/90][900/3907]	eta 0:21:38 lr 0.03969616	time 0.3857 (0.4318)	loss 4.2031 (3.8671)	acc@1: 54.6411	acc@5: 72.8688	
2023-03-16 22:45:04,323 - INFO - Train: [6/90][1200/3907]	eta 0:19:25 lr 0.03969616	time 0.4299 (0.4306)	loss 3.6395 (3.8355)	acc@1: 63.0718	acc@5: 76.6755	
2023-03-16 22:47:12,831 - INFO - Train: [6/90][1500/3907]	eta 0:17:15 lr 0.03969616	time 0.3862 (0.4302)	loss 3.1185 (3.8382)	acc@1: 65.2398	acc@5: 82.2805	
2023-03-16 22:49:21,429 - INFO - Train: [6/90][1800/3907]	eta 0:15:05 lr 0.03969616	time 0.4099 (0.4299)	loss 2.8742 (3.8464)	acc@1: 67.7052	acc@5: 87.2561	
2023-03-16 22:51:30,341 - INFO - Train: [6/90][2100/3907]	eta 0:12:56 lr 0.03969616	time 0.3987 (0.4299)	loss 5.5104 (3.8397)	acc@1: 28.3038	acc@5: 45.2256	
2023-03-16 22:53:38,605 - INFO - Train: [6/90][2400/3907]	eta 0:10:47 lr 0.03969616	time 0.4255 (0.4296)	loss 4.4826 (3.8438)	acc@1: 47.4896	acc@5: 66.6335	
2023-03-16 22:55:47,181 - INFO - Train: [6/90][2700/3907]	eta 0:08:38 lr 0.03969616	time 0.3803 (0.4295)	loss 3.4241 (3.8536)	acc@1: 60.7740	acc@5: 78.3825	
2023-03-16 22:57:55,713 - INFO - Train: [6/90][3000/3907]	eta 0:06:29 lr 0.03969616	time 0.3987 (0.4294)	loss 3.9328 (3.8546)	acc@1: 56.3761	acc@5: 75.0975	
2023-03-16 23:00:04,481 - INFO - Train: [6/90][3300/3907]	eta 0:04:20 lr 0.03969616	time 0.4006 (0.4294)	loss 2.5720 (3.8589)	acc@1: 70.2912	acc@5: 89.8164	
2023-03-16 23:02:12,645 - INFO - Train: [6/90][3600/3907]	eta 0:02:11 lr 0.03969616	time 0.4076 (0.4292)	loss 5.0099 (3.8632)	acc@1: 38.9104	acc@5: 54.9200	
2023-03-16 23:04:19,727 - INFO - Train: [6/90][3900/3907]	eta 0:00:03 lr 0.03969616	time 0.3703 (0.4288)	loss 4.9571 (3.8643)	acc@1: 40.8585	acc@5: 56.2191	
2023-03-16 23:04:23,803 - INFO - EPOCH 6 training takes 0:27:56
2023-03-16 23:04:24,898 - INFO - ./outputs/inat21_mini/sk2_dynamic_mlp/fold1_latest.pth saved !!!
2023-03-16 23:04:24,899 - INFO - **********Latest test***********
2023-03-16 23:04:24,899 - INFO - eval epoch 6
2023-03-16 23:04:25,821 - INFO - Test: [0/782]	Time 0.919 (0.919)	Loss 2.4000 (2.4000)	Acc@1 71.875 (71.875)	Acc@5 91.406 (91.406)
2023-03-16 23:07:04,268 - INFO - Test: [200/782]	Time 0.786 (0.793)	Loss 2.7042 (2.8291)	Acc@1 64.062 (63.130)	Acc@5 84.375 (85.351)
2023-03-16 23:09:42,534 - INFO - Test: [400/782]	Time 0.979 (0.792)	Loss 2.4903 (2.8020)	Acc@1 67.188 (63.874)	Acc@5 92.188 (85.926)
2023-03-16 23:12:22,293 - INFO - Test: [600/782]	Time 0.785 (0.794)	Loss 2.7905 (2.7697)	Acc@1 64.844 (64.653)	Acc@5 83.594 (86.476)
2023-03-16 23:14:39,929 - INFO -  * Acc@1 65.307 Acc@5 86.898
2023-03-16 23:14:39,930 - INFO - Max accuracy: 65.3070%
2023-03-16 23:14:40,832 - INFO - ./outputs/inat21_mini/sk2_dynamic_mlp/fold1_best.pth saved !!!
2023-03-16 23:14:40,833 - INFO - Exp path: ./outputs/inat21_mini/sk2_dynamic_mlp
2023-03-16 23:14:44,043 - INFO - Train: [7/90][0/3907]	eta 3:28:31 lr 0.03956295	time 3.2023 (3.2023)	loss 4.3035 (4.3035)	acc@1: 53.3059	acc@5: 70.2287	
2023-03-16 23:16:52,189 - INFO - Train: [7/90][300/3907]	eta 0:26:13 lr 0.03956295	time 0.4249 (0.4364)	loss 5.3815 (3.6541)	acc@1: 23.8471	acc@5: 44.8419	
2023-03-16 23:19:00,178 - INFO - Train: [7/90][600/3907]	eta 0:23:46 lr 0.03956295	time 0.5469 (0.4315)	loss 5.1633 (3.7069)	acc@1: 22.4808	acc@5: 47.7997	
2023-03-16 23:21:08,584 - INFO - Train: [7/90][900/3907]	eta 0:21:34 lr 0.03956295	time 0.4056 (0.4303)	loss 4.3300 (3.7249)	acc@1: 49.3527	acc@5: 68.6678	
2023-03-16 23:23:17,387 - INFO - Train: [7/90][1200/3907]	eta 0:19:24 lr 0.03956295	time 0.4293 (0.4301)	loss 2.6369 (3.7252)	acc@1: 70.1797	acc@5: 89.4571	
2023-03-16 23:25:26,035 - INFO - Train: [7/90][1500/3907]	eta 0:17:14 lr 0.03956295	time 0.4043 (0.4298)	loss 2.6038 (3.7639)	acc@1: 76.2545	acc@5: 89.9803	
2023-03-16 23:27:34,244 - INFO - Train: [7/90][1800/3907]	eta 0:15:04 lr 0.03956295	time 0.3948 (0.4294)	loss 2.4624 (3.7560)	acc@1: 75.3730	acc@5: 89.3590	
2023-03-16 23:29:42,892 - INFO - Train: [7/90][2100/3907]	eta 0:12:55 lr 0.03956295	time 0.4098 (0.4293)	loss 4.0522 (3.7718)	acc@1: 54.2459	acc@5: 71.3820	
2023-03-16 23:31:51,192 - INFO - Train: [7/90][2400/3907]	eta 0:10:46 lr 0.03956295	time 0.3976 (0.4291)	loss 3.5262 (3.7768)	acc@1: 61.7748	acc@5: 76.7571	
2023-03-16 23:33:59,452 - INFO - Train: [7/90][2700/3907]	eta 0:08:37 lr 0.03956295	time 0.3725 (0.4290)	loss 5.5281 (3.7786)	acc@1: 21.6698	acc@5: 44.5137	
2023-03-16 23:36:08,267 - INFO - Train: [7/90][3000/3907]	eta 0:06:29 lr 0.03956295	time 0.4190 (0.4290)	loss 3.9653 (3.7926)	acc@1: 57.9815	acc@5: 73.8516	
2023-03-16 23:38:16,343 - INFO - Train: [7/90][3300/3907]	eta 0:04:20 lr 0.03956295	time 0.4113 (0.4288)	loss 4.0801 (3.7975)	acc@1: 58.3386	acc@5: 68.8788	
2023-03-16 23:40:24,945 - INFO - Train: [7/90][3600/3907]	eta 0:02:11 lr 0.03956295	time 0.4168 (0.4288)	loss 3.8947 (3.8064)	acc@1: 62.3778	acc@5: 73.4254	
2023-03-16 23:42:32,947 - INFO - Train: [7/90][3900/3907]	eta 0:00:03 lr 0.03956295	time 0.3810 (0.4286)	loss 4.1926 (3.8096)	acc@1: 52.1449	acc@5: 70.8636	
2023-03-16 23:42:35,741 - INFO - EPOCH 7 training takes 0:27:54
2023-03-16 23:42:36,826 - INFO - ./outputs/inat21_mini/sk2_dynamic_mlp/fold1_latest.pth saved !!!
2023-03-16 23:42:36,826 - INFO - **********Latest test***********
2023-03-16 23:42:36,827 - INFO - eval epoch 7
2023-03-16 23:42:37,538 - INFO - Test: [0/782]	Time 0.708 (0.708)	Loss 2.4495 (2.4495)	Acc@1 71.094 (71.094)	Acc@5 92.188 (92.188)
2023-03-16 23:45:11,162 - INFO - Test: [200/782]	Time 0.676 (0.768)	Loss 2.6822 (2.8009)	Acc@1 70.312 (64.350)	Acc@5 86.719 (86.283)
2023-03-16 23:47:41,264 - INFO - Test: [400/782]	Time 0.693 (0.759)	Loss 2.6227 (2.7807)	Acc@1 69.531 (64.855)	Acc@5 88.281 (86.419)
2023-03-16 23:50:05,826 - INFO - Test: [600/782]	Time 0.820 (0.747)	Loss 2.8260 (2.7480)	Acc@1 64.844 (65.690)	Acc@5 87.500 (86.868)
2023-03-16 23:52:14,298 - INFO -  * Acc@1 66.119 Acc@5 87.320
2023-03-16 23:52:14,298 - INFO - Max accuracy: 66.1190%
2023-03-16 23:52:15,377 - INFO - ./outputs/inat21_mini/sk2_dynamic_mlp/fold1_best.pth saved !!!
2023-03-16 23:52:15,378 - INFO - Exp path: ./outputs/inat21_mini/sk2_dynamic_mlp
2023-03-16 23:52:19,215 - INFO - Train: [8/90][0/3907]	eta 4:08:21 lr 0.03940591	time 3.8139 (3.8139)	loss 3.3542 (3.3542)	acc@1: 64.1555	acc@5: 80.7030	
2023-03-16 23:54:31,068 - INFO - Train: [8/90][300/3907]	eta 0:27:05 lr 0.03940591	time 0.4220 (0.4507)	loss 3.7239 (3.9307)	acc@1: 58.2952	acc@5: 76.0681	
2023-03-16 23:56:41,460 - INFO - Train: [8/90][600/3907]	eta 0:24:23 lr 0.03940591	time 0.3872 (0.4427)	loss 3.4692 (3.9166)	acc@1: 63.2046	acc@5: 77.1475	
2023-03-16 23:58:50,426 - INFO - Train: [8/90][900/3907]	eta 0:21:58 lr 0.03940591	time 0.4076 (0.4384)	loss 2.9140 (3.9451)	acc@1: 68.4658	acc@5: 83.5069	
2023-03-17 00:00:59,534 - INFO - Train: [8/90][1200/3907]	eta 0:19:41 lr 0.03940591	time 0.4104 (0.4364)	loss 4.0321 (3.9722)	acc@1: 54.1516	acc@5: 76.4891	
2023-03-17 00:03:07,917 - INFO - Train: [8/90][1500/3907]	eta 0:17:26 lr 0.03940591	time 0.4130 (0.4347)	loss 2.8466 (3.9859)	acc@1: 64.3260	acc@5: 83.6994	
2023-03-17 00:05:15,101 - INFO - Train: [8/90][1800/3907]	eta 0:15:12 lr 0.03940591	time 0.3968 (0.4329)	loss 2.8886 (3.9796)	acc@1: 68.2035	acc@5: 81.3780	
2023-03-17 00:07:22,892 - INFO - Train: [8/90][2100/3907]	eta 0:13:00 lr 0.03940591	time 0.5606 (0.4319)	loss 3.6107 (3.9833)	acc@1: 62.3119	acc@5: 75.1904	
2023-03-17 00:09:34,527 - INFO - Train: [8/90][2400/3907]	eta 0:10:52 lr 0.03940591	time 0.4096 (0.4328)	loss 5.1849 (4.0012)	acc@1: 36.7626	acc@5: 52.6762	
2023-03-17 00:11:45,936 - INFO - Train: [8/90][2700/3907]	eta 0:08:43 lr 0.03940591	time 0.4103 (0.4334)	loss 3.1967 (4.0167)	acc@1: 61.4338	acc@5: 80.9128	
2023-03-17 00:13:57,852 - INFO - Train: [8/90][3000/3907]	eta 0:06:33 lr 0.03940591	time 0.6010 (0.4340)	loss 4.8796 (4.0102)	acc@1: 43.8645	acc@5: 59.5813	
2023-03-17 00:16:09,435 - INFO - Train: [8/90][3300/3907]	eta 0:04:23 lr 0.03940591	time 0.4098 (0.4344)	loss 3.4732 (3.9999)	acc@1: 56.4684	acc@5: 80.7712	
2023-03-17 00:18:21,130 - INFO - Train: [8/90][3600/3907]	eta 0:02:13 lr 0.03940591	time 0.4177 (0.4348)	loss 2.6925 (4.0025)	acc@1: 68.4243	acc@5: 85.5304	
2023-03-17 00:20:31,960 - INFO - Train: [8/90][3900/3907]	eta 0:00:03 lr 0.03940591	time 0.3898 (0.4349)	loss 3.3223 (4.0126)	acc@1: 57.0514	acc@5: 80.0202	
2023-03-17 00:20:34,883 - INFO - EPOCH 8 training takes 0:28:19
2023-03-17 00:20:36,059 - INFO - ./outputs/inat21_mini/sk2_dynamic_mlp/fold1_latest.pth saved !!!
2023-03-17 00:20:36,061 - INFO - **********Latest test***********
2023-03-17 00:20:36,061 - INFO - eval epoch 8
2023-03-17 00:20:36,804 - INFO - Test: [0/782]	Time 0.740 (0.740)	Loss 2.5452 (2.5452)	Acc@1 67.188 (67.188)	Acc@5 93.750 (93.750)
2023-03-17 00:23:02,102 - INFO - Test: [200/782]	Time 0.671 (0.727)	Loss 2.6170 (2.7970)	Acc@1 69.531 (64.665)	Acc@5 85.156 (85.988)
2023-03-17 00:25:25,652 - INFO - Test: [400/782]	Time 0.685 (0.722)	Loss 2.5795 (2.7693)	Acc@1 69.531 (65.282)	Acc@5 89.062 (86.586)
2023-03-17 00:27:48,357 - INFO - Test: [600/782]	Time 0.673 (0.719)	Loss 2.7721 (2.7379)	Acc@1 64.844 (66.075)	Acc@5 87.500 (87.161)
2023-03-17 00:29:56,640 - INFO -  * Acc@1 66.576 Acc@5 87.574
2023-03-17 00:29:56,640 - INFO - Max accuracy: 66.5760%
2023-03-17 00:29:57,679 - INFO - ./outputs/inat21_mini/sk2_dynamic_mlp/fold1_best.pth saved !!!
2023-03-17 00:29:57,680 - INFO - Exp path: ./outputs/inat21_mini/sk2_dynamic_mlp
2023-03-17 00:30:02,097 - INFO - Train: [9/90][0/3907]	eta 4:47:02 lr 0.03922523	time 4.4081 (4.4081)	loss 2.6689 (2.6689)	acc@1: 67.9101	acc@5: 83.5223	
2023-03-17 00:32:10,728 - INFO - Train: [9/90][300/3907]	eta 0:26:34 lr 0.03922523	time 0.3963 (0.4420)	loss 2.9900 (3.8460)	acc@1: 72.5291	acc@5: 85.2284	
2023-03-17 00:34:19,661 - INFO - Train: [9/90][600/3907]	eta 0:24:01 lr 0.03922523	time 0.4015 (0.4359)	loss 5.7020 (3.9264)	acc@1: 23.0142	acc@5: 39.8505	
2023-03-17 00:36:27,996 - INFO - Train: [9/90][900/3907]	eta 0:21:42 lr 0.03922523	time 0.3923 (0.4332)	loss 5.7166 (3.9086)	acc@1: 20.1434	acc@5: 39.8495	
2023-03-17 00:38:36,136 - INFO - Train: [9/90][1200/3907]	eta 0:19:28 lr 0.03922523	time 0.5516 (0.4317)	loss 3.7700 (3.9068)	acc@1: 63.3247	acc@5: 75.1026	
2023-03-17 00:40:44,711 - INFO - Train: [9/90][1500/3907]	eta 0:17:17 lr 0.03922523	time 0.4003 (0.4311)	loss 5.5058 (3.8877)	acc@1: 30.2962	acc@5: 45.3402	
2023-03-17 00:42:52,683 - INFO - Train: [9/90][1800/3907]	eta 0:15:06 lr 0.03922523	time 0.4061 (0.4303)	loss 2.7825 (3.9120)	acc@1: 68.6212	acc@5: 84.2166	
2023-03-17 00:45:01,128 - INFO - Train: [9/90][2100/3907]	eta 0:12:57 lr 0.03922523	time 0.4226 (0.4300)	loss 4.6597 (3.9132)	acc@1: 48.2148	acc@5: 63.3510	
2023-03-17 00:47:09,294 - INFO - Train: [9/90][2400/3907]	eta 0:10:47 lr 0.03922523	time 0.5663 (0.4297)	loss 4.3170 (3.9210)	acc@1: 44.5550	acc@5: 67.4521	
2023-03-17 00:49:17,716 - INFO - Train: [9/90][2700/3907]	eta 0:08:38 lr 0.03922523	time 0.3939 (0.4295)	loss 2.7617 (3.9307)	acc@1: 68.2775	acc@5: 87.4526	
2023-03-17 00:51:26,121 - INFO - Train: [9/90][3000/3907]	eta 0:06:29 lr 0.03922523	time 0.4285 (0.4293)	loss 2.6541 (3.9403)	acc@1: 71.8627	acc@5: 86.7038	
2023-03-17 00:53:34,283 - INFO - Train: [9/90][3300/3907]	eta 0:04:20 lr 0.03922523	time 0.3986 (0.4291)	loss 5.7002 (3.9481)	acc@1: 21.3087	acc@5: 36.9349	
2023-03-17 00:55:42,337 - INFO - Train: [9/90][3600/3907]	eta 0:02:11 lr 0.03922523	time 0.5397 (0.4289)	loss 3.9268 (3.9455)	acc@1: 53.7252	acc@5: 75.0775	
2023-03-17 00:57:49,485 - INFO - Train: [9/90][3900/3907]	eta 0:00:02 lr 0.03922523	time 0.3787 (0.4286)	loss 5.5921 (3.9498)	acc@1: 26.2593	acc@5: 42.3968	
2023-03-17 00:57:52,072 - INFO - EPOCH 9 training takes 0:27:54
2023-03-17 00:57:53,157 - INFO - ./outputs/inat21_mini/sk2_dynamic_mlp/fold1_latest.pth saved !!!
2023-03-17 00:57:53,158 - INFO - **********Latest test***********
2023-03-17 00:57:53,158 - INFO - eval epoch 9
2023-03-17 00:57:53,958 - INFO - Test: [0/782]	Time 0.797 (0.797)	Loss 2.2939 (2.2939)	Acc@1 79.688 (79.688)	Acc@5 96.094 (96.094)
2023-03-17 01:00:20,574 - INFO - Test: [200/782]	Time 0.684 (0.733)	Loss 2.6353 (2.6415)	Acc@1 63.281 (67.615)	Acc@5 89.844 (87.966)
