2023-03-18 01:24:11,173 - INFO - NVIDIA GeForce RTX 3090
2023-03-18 01:24:11,173 - INFO - --batch_size 128
2023-03-18 01:24:11,173 - INFO - --data inat21_mini
2023-03-18 01:24:11,173 - INFO - --data_dir ./datasets/iNat2021
2023-03-18 01:24:11,173 - INFO - --evaluate False
2023-03-18 01:24:11,173 - INFO - --fold 1
2023-03-18 01:24:11,173 - INFO - --image_only False
2023-03-18 01:24:11,173 - INFO - --metadata geo_temporal
2023-03-18 01:24:11,173 - INFO - --mlp_cin 6
2023-03-18 01:24:11,173 - INFO - --mlp_hidden 64
2023-03-18 01:24:11,173 - INFO - --mlp_num_layers 2
2023-03-18 01:24:11,174 - INFO - --mlp_out_channel 256
2023-03-18 01:24:11,174 - INFO - --mlp_type c
2023-03-18 01:24:11,174 - INFO - --model_file resnet_dynamic_mlp
2023-03-18 01:24:11,174 - INFO - --model_name resnet50
2023-03-18 01:24:11,174 - INFO - --name res50_dynamic_mlp
2023-03-18 01:24:11,174 - INFO - --num_classes 10000
2023-03-18 01:24:11,174 - INFO - --num_workers 8
2023-03-18 01:24:11,174 - INFO - --path_log ./outputs/inat21_mini/res50_dynamic_mlp
2023-03-18 01:24:11,174 - INFO - --pretrained True
2023-03-18 01:24:11,174 - INFO - --random_seed 37
2023-03-18 01:24:11,174 - INFO - --resume latest
2023-03-18 01:24:11,174 - INFO - --save_dir ./outputs
2023-03-18 01:24:11,174 - INFO - --start_lr 0.04
2023-03-18 01:24:11,174 - INFO - --stop_epoch 90
2023-03-18 01:24:11,174 - INFO - --tencrop False
2023-03-18 01:24:11,174 - INFO - --warmup 2
2023-03-18 01:24:11,174 - INFO - Creating model:resnet_dynamic_mlp -> resnet50
2023-03-18 01:24:11,174 - INFO - type: c, cin: 6, d: 256, h: 64, N: 2
2023-03-18 01:24:15,936 - INFO - => loading checkpoint './outputs/inat21_mini/res50_dynamic_mlp/fold1_latest.pth'
2023-03-18 01:24:16,306 - INFO - => loaded checkpoint './outputs/inat21_mini/res50_dynamic_mlp/fold1_latest.pth' (epoch 8)
2023-03-18 01:24:16,306 - INFO - eval epoch 8
2023-03-18 01:24:17,460 - INFO - Test: [0/782]	Time 1.152 (1.152)	Loss 5.2672 (5.2672)	Acc@1 22.656 (22.656)	Acc@5 42.969 (42.969)
2023-03-18 01:26:30,197 - INFO - Test: [200/782]	Time 0.656 (0.666)	Loss 5.4084 (5.7762)	Acc@1 15.625 (16.562)	Acc@5 39.844 (35.763)
2023-03-18 01:28:42,698 - INFO - Test: [400/782]	Time 0.665 (0.664)	Loss 5.2188 (5.7279)	Acc@1 24.219 (16.975)	Acc@5 39.062 (36.541)
2023-03-18 01:30:55,801 - INFO - Test: [600/782]	Time 0.646 (0.665)	Loss 5.9459 (5.6745)	Acc@1 14.844 (17.315)	Acc@5 35.156 (37.414)
2023-03-18 01:32:54,258 - INFO -  * Acc@1 16.830 Acc@5 36.894
2023-03-18 01:32:54,258 - INFO - Max accuracy: 50.4520%
2023-03-18 01:32:54,259 - INFO - Start training
2023-03-18 01:32:58,847 - INFO - Train: [9/90][0/3907]	eta 4:58:40 lr 0.03922523	time 4.5869 (4.5869)	loss 5.8674 (5.8674)	acc@1: 16.9008	acc@5: 38.2106	
2023-03-18 01:33:53,230 - INFO - Train: [9/90][300/3907]	eta 0:11:46 lr 0.03922523	time 0.1858 (0.1959)	loss 6.7422 (5.9827)	acc@1: 15.0541	acc@5: 28.3740	
2023-03-18 01:34:47,402 - INFO - Train: [9/90][600/3907]	eta 0:10:22 lr 0.03922523	time 0.1803 (0.1883)	loss 4.4077 (5.5285)	acc@1: 43.9953	acc@5: 66.3536	
2023-03-18 01:35:41,728 - INFO - Train: [9/90][900/3907]	eta 0:09:18 lr 0.03922523	time 0.1756 (0.1859)	loss 5.1974 (5.3201)	acc@1: 34.3095	acc@5: 59.2345	
2023-03-18 01:36:36,285 - INFO - Train: [9/90][1200/3907]	eta 0:08:20 lr 0.03922523	time 0.1919 (0.1849)	loss 4.3542 (5.1829)	acc@1: 49.4029	acc@5: 70.1664	
2023-03-18 01:37:30,593 - INFO - Train: [9/90][1500/3907]	eta 0:07:23 lr 0.03922523	time 0.1774 (0.1841)	loss 4.0264 (5.1191)	acc@1: 47.4178	acc@5: 71.1266	
2023-03-18 01:38:24,865 - INFO - Train: [9/90][1800/3907]	eta 0:06:26 lr 0.03922523	time 0.1764 (0.1836)	loss 4.0308 (5.0768)	acc@1: 46.6505	acc@5: 71.4650	
2023-03-18 01:39:19,785 - INFO - Train: [9/90][2100/3907]	eta 0:05:31 lr 0.03922523	time 0.1755 (0.1835)	loss 6.4217 (5.0341)	acc@1: 15.3433	acc@5: 32.0772	
2023-03-18 01:40:14,518 - INFO - Train: [9/90][2400/3907]	eta 0:04:36 lr 0.03922523	time 0.1759 (0.1834)	loss 5.1344 (5.0102)	acc@1: 37.9917	acc@5: 60.3015	
2023-03-18 01:41:09,124 - INFO - Train: [9/90][2700/3907]	eta 0:03:41 lr 0.03922523	time 0.1916 (0.1832)	loss 4.1128 (4.9957)	acc@1: 49.0184	acc@5: 68.0405	
2023-03-18 01:42:03,897 - INFO - Train: [9/90][3000/3907]	eta 0:02:46 lr 0.03922523	time 0.1763 (0.1831)	loss 4.8643 (4.9790)	acc@1: 37.7496	acc@5: 60.3994	
2023-03-18 01:42:58,414 - INFO - Train: [9/90][3300/3907]	eta 0:01:51 lr 0.03922523	time 0.1866 (0.1830)	loss 3.3307 (4.9680)	acc@1: 57.0137	acc@5: 75.7582	
2023-03-18 01:43:52,801 - INFO - Train: [9/90][3600/3907]	eta 0:00:56 lr 0.03922523	time 0.1819 (0.1829)	loss 6.0464 (4.9582)	acc@1: 27.6523	acc@5: 42.9449	
2023-03-18 01:44:47,523 - INFO - Train: [9/90][3900/3907]	eta 0:00:01 lr 0.03922523	time 0.1745 (0.1828)	loss 6.0364 (4.9479)	acc@1: 28.6488	acc@5: 43.1314	
2023-03-18 01:44:49,260 - INFO - EPOCH 9 training takes 0:11:55
2023-03-18 01:44:50,736 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp/fold1_latest.pth saved !!!
2023-03-18 01:44:50,736 - INFO - **********latest test***********
2023-03-18 01:44:50,737 - INFO - eval epoch 9
2023-03-18 01:44:51,395 - INFO - Test: [0/782]	Time 0.657 (0.657)	Loss 3.0088 (3.0088)	Acc@1 64.844 (64.844)	Acc@5 84.375 (84.375)
2023-03-18 01:47:02,209 - INFO - Test: [200/782]	Time 0.650 (0.654)	Loss 3.5149 (3.5694)	Acc@1 52.344 (49.592)	Acc@5 75.000 (74.386)
2023-03-18 01:49:12,568 - INFO - Test: [400/782]	Time 0.649 (0.653)	Loss 3.3780 (3.5341)	Acc@1 54.688 (50.281)	Acc@5 78.906 (75.386)
2023-03-18 01:51:23,721 - INFO - Test: [600/782]	Time 0.660 (0.654)	Loss 3.5830 (3.5009)	Acc@1 51.562 (51.087)	Acc@5 75.000 (75.968)
2023-03-18 01:53:20,674 - INFO -  * Acc@1 51.598 Acc@5 76.438
2023-03-18 01:53:20,674 - INFO - Max accuracy: 51.5980%
2023-03-18 01:53:22,084 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp/fold1_best.pth saved !!!
2023-03-18 01:53:22,084 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp
2023-03-18 01:53:24,024 - INFO - Train: [10/90][0/3907]	eta 2:06:06 lr 0.03902113	time 1.9365 (1.9365)	loss 5.2238 (5.2238)	acc@1: 39.9923	acc@5: 60.4469	
2023-03-18 01:54:18,881 - INFO - Train: [10/90][300/3907]	eta 0:11:20 lr 0.03902113	time 0.1840 (0.1887)	loss 6.5340 (4.5477)	acc@1: 18.2047	acc@5: 30.4320	
2023-03-18 01:55:13,631 - INFO - Train: [10/90][600/3907]	eta 0:10:13 lr 0.03902113	time 0.1778 (0.1856)	loss 6.5171 (4.5926)	acc@1: 14.2346	acc@5: 28.7595	
2023-03-18 01:56:08,277 - INFO - Train: [10/90][900/3907]	eta 0:09:14 lr 0.03902113	time 0.1811 (0.1844)	loss 5.2503 (4.6119)	acc@1: 36.4286	acc@5: 54.3233	
2023-03-18 01:57:03,053 - INFO - Train: [10/90][1200/3907]	eta 0:08:18 lr 0.03902113	time 0.1769 (0.1840)	loss 3.3526 (4.6099)	acc@1: 53.2157	acc@5: 80.9751	
2023-03-18 01:57:57,672 - INFO - Train: [10/90][1500/3907]	eta 0:07:21 lr 0.03902113	time 0.1774 (0.1836)	loss 3.5963 (4.6580)	acc@1: 52.6156	acc@5: 74.7294	
2023-03-18 01:58:52,213 - INFO - Train: [10/90][1800/3907]	eta 0:06:26 lr 0.03902113	time 0.1883 (0.1833)	loss 3.5626 (4.6496)	acc@1: 52.8358	acc@5: 72.2608	
2023-03-18 01:59:46,928 - INFO - Train: [10/90][2100/3907]	eta 0:05:30 lr 0.03902113	time 0.1762 (0.1832)	loss 4.3280 (4.6659)	acc@1: 46.0206	acc@5: 67.3652	
2023-03-18 02:00:41,814 - INFO - Train: [10/90][2400/3907]	eta 0:04:35 lr 0.03902113	time 0.1753 (0.1831)	loss 4.2886 (4.6727)	acc@1: 47.6449	acc@5: 71.0767	
2023-03-18 02:01:37,147 - INFO - Train: [10/90][2700/3907]	eta 0:03:41 lr 0.03902113	time 0.1765 (0.1833)	loss 6.2999 (4.6750)	acc@1: 20.1073	acc@5: 31.3663	
2023-03-18 02:02:32,357 - INFO - Train: [10/90][3000/3907]	eta 0:02:46 lr 0.03902113	time 0.1874 (0.1834)	loss 5.0819 (4.6895)	acc@1: 42.3619	acc@5: 62.6990	
2023-03-18 02:03:27,161 - INFO - Train: [10/90][3300/3907]	eta 0:01:51 lr 0.03902113	time 0.1819 (0.1833)	loss 4.8405 (4.6952)	acc@1: 40.8433	acc@5: 63.2412	
2023-03-18 02:04:21,919 - INFO - Train: [10/90][3600/3907]	eta 0:00:56 lr 0.03902113	time 0.1749 (0.1832)	loss 4.7337 (4.7037)	acc@1: 43.5193	acc@5: 62.2660	
2023-03-18 02:05:16,303 - INFO - Train: [10/90][3900/3907]	eta 0:00:01 lr 0.03902113	time 0.1743 (0.1831)	loss 4.7933 (4.7060)	acc@1: 44.1226	acc@5: 62.8413	
2023-03-18 02:05:17,498 - INFO - EPOCH 10 training takes 0:11:55
2023-03-18 02:05:18,962 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp/fold1_latest.pth saved !!!
2023-03-18 02:05:18,962 - INFO - **********latest test***********
2023-03-18 02:05:18,962 - INFO - eval epoch 10
2023-03-18 02:05:19,619 - INFO - Test: [0/782]	Time 0.656 (0.656)	Loss 3.1260 (3.1260)	Acc@1 52.344 (52.344)	Acc@5 83.594 (83.594)
2023-03-18 02:07:27,861 - INFO - Test: [200/782]	Time 0.675 (0.641)	Loss 3.2565 (3.4498)	Acc@1 52.344 (51.368)	Acc@5 82.031 (76.143)
2023-03-18 02:09:37,232 - INFO - Test: [400/782]	Time 0.649 (0.644)	Loss 3.1355 (3.4102)	Acc@1 59.375 (52.209)	Acc@5 81.250 (76.970)
2023-03-18 02:11:47,770 - INFO - Test: [600/782]	Time 0.631 (0.647)	Loss 3.5354 (3.3766)	Acc@1 50.000 (52.990)	Acc@5 76.562 (77.541)
2023-03-18 02:13:42,230 - INFO -  * Acc@1 53.647 Acc@5 78.178
2023-03-18 02:13:42,230 - INFO - Max accuracy: 53.6470%
2023-03-18 02:13:43,917 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp/fold1_best.pth saved !!!
2023-03-18 02:13:43,918 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp
2023-03-18 02:13:45,999 - INFO - Train: [11/90][0/3907]	eta 2:15:12 lr 0.03879385	time 2.0765 (2.0765)	loss 3.9464 (3.9464)	acc@1: 47.5461	acc@5: 74.8856	
2023-03-18 02:14:40,087 - INFO - Train: [11/90][300/3907]	eta 0:11:13 lr 0.03879385	time 0.1750 (0.1866)	loss 3.9816 (4.5221)	acc@1: 50.4751	acc@5: 76.0681	
2023-03-18 02:15:34,284 - INFO - Train: [11/90][600/3907]	eta 0:10:07 lr 0.03879385	time 0.1853 (0.1836)	loss 3.9399 (4.5148)	acc@1: 50.6820	acc@5: 74.1647	
2023-03-18 02:16:28,345 - INFO - Train: [11/90][900/3907]	eta 0:09:08 lr 0.03879385	time 0.1805 (0.1825)	loss 3.7061 (4.5464)	acc@1: 50.3874	acc@5: 70.7220	
2023-03-18 02:17:22,148 - INFO - Train: [11/90][1200/3907]	eta 0:08:11 lr 0.03879385	time 0.1793 (0.1817)	loss 4.6219 (4.5768)	acc@1: 46.1332	acc@5: 65.0863	
2023-03-18 02:18:15,827 - INFO - Train: [11/90][1500/3907]	eta 0:07:16 lr 0.03879385	time 0.1755 (0.1811)	loss 3.4056 (4.5920)	acc@1: 51.1584	acc@5: 75.9564	
2023-03-18 02:19:09,839 - INFO - Train: [11/90][1800/3907]	eta 0:06:21 lr 0.03879385	time 0.1857 (0.1810)	loss 3.1822 (4.5888)	acc@1: 62.7725	acc@5: 82.1467	
2023-03-18 02:20:04,029 - INFO - Train: [11/90][2100/3907]	eta 0:05:26 lr 0.03879385	time 0.1808 (0.1809)	loss 4.0283 (4.5941)	acc@1: 50.7985	acc@5: 73.0440	
2023-03-18 02:20:57,686 - INFO - Train: [11/90][2400/3907]	eta 0:04:32 lr 0.03879385	time 0.1819 (0.1807)	loss 5.6806 (4.6143)	acc@1: 35.6523	acc@5: 51.2166	
2023-03-18 02:21:51,489 - INFO - Train: [11/90][2700/3907]	eta 0:03:37 lr 0.03879385	time 0.1865 (0.1805)	loss 3.6846 (4.6319)	acc@1: 50.9451	acc@5: 76.4177	
2023-03-18 02:22:45,258 - INFO - Train: [11/90][3000/3907]	eta 0:02:43 lr 0.03879385	time 0.1951 (0.1804)	loss 5.6136 (4.6274)	acc@1: 30.6523	acc@5: 46.3691	
2023-03-18 02:23:39,021 - INFO - Train: [11/90][3300/3907]	eta 0:01:49 lr 0.03879385	time 0.1814 (0.1803)	loss 4.1917 (4.6207)	acc@1: 47.1761	acc@5: 71.4789	
2023-03-18 02:24:32,965 - INFO - Train: [11/90][3600/3907]	eta 0:00:55 lr 0.03879385	time 0.1774 (0.1802)	loss 3.3241 (4.6237)	acc@1: 53.6509	acc@5: 74.6484	
2023-03-18 02:25:26,756 - INFO - Train: [11/90][3900/3907]	eta 0:00:01 lr 0.03879385	time 0.1756 (0.1802)	loss 4.0945 (4.6352)	acc@1: 43.7147	acc@5: 65.9426	
2023-03-18 02:25:27,977 - INFO - EPOCH 11 training takes 0:11:44
2023-03-18 02:25:29,437 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp/fold1_latest.pth saved !!!
2023-03-18 02:25:29,437 - INFO - **********latest test***********
2023-03-18 02:25:29,438 - INFO - eval epoch 11
2023-03-18 02:25:30,111 - INFO - Test: [0/782]	Time 0.671 (0.671)	Loss 2.9101 (2.9101)	Acc@1 60.938 (60.938)	Acc@5 87.500 (87.500)
2023-03-18 02:27:38,014 - INFO - Test: [200/782]	Time 0.622 (0.640)	Loss 3.2258 (3.4263)	Acc@1 54.688 (51.901)	Acc@5 76.562 (75.898)
2023-03-18 02:29:45,705 - INFO - Test: [400/782]	Time 0.636 (0.639)	Loss 3.1549 (3.3840)	Acc@1 60.938 (52.730)	Acc@5 79.688 (76.991)
2023-03-18 02:31:56,295 - INFO - Test: [600/782]	Time 0.636 (0.644)	Loss 3.4367 (3.3460)	Acc@1 53.906 (53.662)	Acc@5 76.562 (77.762)
2023-03-18 02:33:50,783 - INFO -  * Acc@1 54.163 Acc@5 78.314
2023-03-18 02:33:50,783 - INFO - Max accuracy: 54.1630%
2023-03-18 02:33:52,189 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp/fold1_best.pth saved !!!
2023-03-18 02:33:52,190 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp
2023-03-18 02:33:54,223 - INFO - Train: [12/90][0/3907]	eta 2:12:11 lr 0.03854368	time 2.0302 (2.0302)	loss 3.0231 (3.0231)	acc@1: 64.0079	acc@5: 83.5223	
2023-03-18 02:34:47,924 - INFO - Train: [12/90][300/3907]	eta 0:11:07 lr 0.03854368	time 0.1848 (0.1851)	loss 3.5539 (4.4638)	acc@1: 54.5322	acc@5: 77.6898	
2023-03-18 02:35:41,655 - INFO - Train: [12/90][600/3907]	eta 0:10:02 lr 0.03854368	time 0.1755 (0.1821)	loss 6.5587 (4.5568)	acc@1: 12.2703	acc@5: 24.1895	
2023-03-18 02:36:35,786 - INFO - Train: [12/90][900/3907]	eta 0:09:05 lr 0.03854368	time 0.1766 (0.1816)	loss 6.4745 (4.5409)	acc@1: 16.5869	acc@5: 30.1305	
2023-03-18 02:37:30,017 - INFO - Train: [12/90][1200/3907]	eta 0:08:10 lr 0.03854368	time 0.1770 (0.1814)	loss 4.3105 (4.5380)	acc@1: 47.4231	acc@5: 68.7291	
2023-03-18 02:38:23,986 - INFO - Train: [12/90][1500/3907]	eta 0:07:15 lr 0.03854368	time 0.1748 (0.1811)	loss 6.4905 (4.5245)	acc@1: 17.7883	acc@5: 30.2962	
2023-03-18 02:39:18,470 - INFO - Train: [12/90][1800/3907]	eta 0:06:21 lr 0.03854368	time 0.1754 (0.1812)	loss 3.4440 (4.5544)	acc@1: 50.6851	acc@5: 74.8579	
2023-03-18 02:40:12,601 - INFO - Train: [12/90][2100/3907]	eta 0:05:27 lr 0.03854368	time 0.1807 (0.1811)	loss 5.2039 (4.5570)	acc@1: 36.1993	acc@5: 59.6062	
2023-03-18 02:41:06,398 - INFO - Train: [12/90][2400/3907]	eta 0:04:32 lr 0.03854368	time 0.1829 (0.1808)	loss 4.6441 (4.5644)	acc@1: 43.2082	acc@5: 62.7380	
2023-03-18 02:42:00,279 - INFO - Train: [12/90][2700/3907]	eta 0:03:38 lr 0.03854368	time 0.1888 (0.1807)	loss 3.6355 (4.5736)	acc@1: 49.8695	acc@5: 73.6608	
2023-03-18 02:42:53,933 - INFO - Train: [12/90][3000/3907]	eta 0:02:43 lr 0.03854368	time 0.1757 (0.1805)	loss 3.1787 (4.5822)	acc@1: 60.1456	acc@5: 81.2357	
2023-03-18 02:43:47,306 - INFO - Train: [12/90][3300/3907]	eta 0:01:49 lr 0.03854368	time 0.1753 (0.1803)	loss 6.6954 (4.5884)	acc@1: 15.5550	acc@5: 25.0737	
2023-03-18 02:44:41,365 - INFO - Train: [12/90][3600/3907]	eta 0:00:55 lr 0.03854368	time 0.1796 (0.1803)	loss 4.4491 (4.5832)	acc@1: 47.6186	acc@5: 65.6194	
2023-03-18 02:45:35,509 - INFO - Train: [12/90][3900/3907]	eta 0:00:01 lr 0.03854368	time 0.1741 (0.1803)	loss 6.2547 (4.5874)	acc@1: 23.9693	acc@5: 36.2006	
2023-03-18 02:45:36,704 - INFO - EPOCH 12 training takes 0:11:44
2023-03-18 02:45:38,217 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp/fold1_latest.pth saved !!!
2023-03-18 02:45:38,218 - INFO - **********latest test***********
2023-03-18 02:45:38,218 - INFO - eval epoch 12
2023-03-18 02:45:38,873 - INFO - Test: [0/782]	Time 0.655 (0.655)	Loss 3.0321 (3.0321)	Acc@1 56.250 (56.250)	Acc@5 80.469 (80.469)
2023-03-18 02:47:47,638 - INFO - Test: [200/782]	Time 0.646 (0.644)	Loss 3.1931 (3.4116)	Acc@1 52.344 (52.441)	Acc@5 80.469 (76.963)
2023-03-18 02:49:58,732 - INFO - Test: [400/782]	Time 0.660 (0.650)	Loss 3.2982 (3.3770)	Acc@1 50.781 (53.388)	Acc@5 78.125 (77.774)
2023-03-18 02:52:09,629 - INFO - Test: [600/782]	Time 0.655 (0.651)	Loss 3.4453 (3.3464)	Acc@1 50.000 (54.130)	Acc@5 73.438 (78.372)
2023-03-18 02:54:05,821 - INFO -  * Acc@1 54.801 Acc@5 78.953
2023-03-18 02:54:05,821 - INFO - Max accuracy: 54.8010%
2023-03-18 02:54:07,243 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp/fold1_best.pth saved !!!
2023-03-18 02:54:07,243 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp
2023-03-18 02:54:09,143 - INFO - Train: [13/90][0/3907]	eta 2:03:31 lr 0.03827091	time 1.8971 (1.8971)	loss 3.3216 (3.3216)	acc@1: 56.2142	acc@5: 78.0749	
2023-03-18 02:55:03,323 - INFO - Train: [13/90][300/3907]	eta 0:11:11 lr 0.03827091	time 0.1751 (0.1863)	loss 4.0537 (4.4126)	acc@1: 51.9603	acc@5: 72.3231	
2023-03-18 02:55:56,921 - INFO - Train: [13/90][600/3907]	eta 0:10:03 lr 0.03827091	time 0.1812 (0.1825)	loss 5.1484 (4.4868)	acc@1: 37.2397	acc@5: 57.9834	
2023-03-18 02:56:50,664 - INFO - Train: [13/90][900/3907]	eta 0:09:05 lr 0.03827091	time 0.1827 (0.1814)	loss 3.2032 (4.4758)	acc@1: 60.6806	acc@5: 79.1152	
2023-03-18 02:57:44,300 - INFO - Train: [13/90][1200/3907]	eta 0:08:09 lr 0.03827091	time 0.1803 (0.1807)	loss 2.9574 (4.5028)	acc@1: 64.6911	acc@5: 86.5153	
2023-03-18 02:58:38,046 - INFO - Train: [13/90][1500/3907]	eta 0:07:14 lr 0.03827091	time 0.1764 (0.1804)	loss 6.5066 (4.5106)	acc@1: 16.8127	acc@5: 29.1914	
2023-03-18 02:59:31,618 - INFO - Train: [13/90][1800/3907]	eta 0:06:19 lr 0.03827091	time 0.1762 (0.1801)	loss 4.6429 (4.5114)	acc@1: 43.8803	acc@5: 63.7168	
2023-03-18 03:00:25,356 - INFO - Train: [13/90][2100/3907]	eta 0:05:25 lr 0.03827091	time 0.1826 (0.1800)	loss 6.3941 (4.5215)	acc@1: 21.7977	acc@5: 30.5889	
2023-03-18 03:01:18,694 - INFO - Train: [13/90][2400/3907]	eta 0:04:30 lr 0.03827091	time 0.1826 (0.1797)	loss 3.3070 (4.5363)	acc@1: 58.9397	acc@5: 79.6069	
2023-03-18 03:02:12,646 - INFO - Train: [13/90][2700/3907]	eta 0:03:36 lr 0.03827091	time 0.1898 (0.1797)	loss 3.2739 (4.5388)	acc@1: 59.1201	acc@5: 82.1622	
2023-03-18 03:03:06,890 - INFO - Train: [13/90][3000/3907]	eta 0:02:43 lr 0.03827091	time 0.1759 (0.1798)	loss 4.0413 (4.5411)	acc@1: 46.1290	acc@5: 68.0952	
2023-03-18 03:04:01,196 - INFO - Train: [13/90][3300/3907]	eta 0:01:49 lr 0.03827091	time 0.1790 (0.1799)	loss 2.9904 (4.5596)	acc@1: 64.8366	acc@5: 83.5846	
2023-03-18 03:04:55,688 - INFO - Train: [13/90][3600/3907]	eta 0:00:55 lr 0.03827091	time 0.1785 (0.1801)	loss 3.5464 (4.5571)	acc@1: 55.3721	acc@5: 75.5507	
2023-03-18 03:05:49,948 - INFO - Train: [13/90][3900/3907]	eta 0:00:01 lr 0.03827091	time 0.1761 (0.1801)	loss 3.7843 (4.5613)	acc@1: 50.9835	acc@5: 73.8892	
2023-03-18 03:05:51,114 - INFO - EPOCH 13 training takes 0:11:43
2023-03-18 03:05:52,602 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp/fold1_latest.pth saved !!!
2023-03-18 03:05:52,604 - INFO - **********latest test***********
2023-03-18 03:05:52,604 - INFO - eval epoch 13
2023-03-18 03:05:53,294 - INFO - Test: [0/782]	Time 0.686 (0.686)	Loss 2.9485 (2.9485)	Acc@1 58.594 (58.594)	Acc@5 88.281 (88.281)
2023-03-18 03:08:01,297 - INFO - Test: [200/782]	Time 0.634 (0.640)	Loss 3.1001 (3.3099)	Acc@1 57.812 (54.691)	Acc@5 83.594 (78.129)
2023-03-18 03:10:10,209 - INFO - Test: [400/782]	Time 0.631 (0.642)	Loss 3.1470 (3.2742)	Acc@1 59.375 (55.403)	Acc@5 81.250 (78.791)
2023-03-18 03:12:20,719 - INFO - Test: [600/782]	Time 0.639 (0.646)	Loss 3.3271 (3.2355)	Acc@1 50.781 (56.102)	Acc@5 76.562 (79.584)
2023-03-18 03:14:16,155 - INFO -  * Acc@1 56.669 Acc@5 80.099
2023-03-18 03:14:16,155 - INFO - Max accuracy: 56.6690%
2023-03-18 03:14:17,577 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp/fold1_best.pth saved !!!
2023-03-18 03:14:17,578 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp
2023-03-18 03:14:19,543 - INFO - Train: [14/90][0/3907]	eta 2:07:44 lr 0.03797588	time 1.9618 (1.9618)	loss 3.9095 (3.9095)	acc@1: 58.2619	acc@5: 76.9632	
2023-03-18 03:15:13,479 - INFO - Train: [14/90][300/3907]	eta 0:11:09 lr 0.03797588	time 0.1747 (0.1857)	loss 3.2282 (4.4391)	acc@1: 55.7365	acc@5: 78.9570	
2023-03-18 03:16:07,545 - INFO - Train: [14/90][600/3907]	eta 0:10:05 lr 0.03797588	time 0.1807 (0.1830)	loss 4.4073 (4.4872)	acc@1: 49.5939	acc@5: 73.6390	
2023-03-18 03:17:02,098 - INFO - Train: [14/90][900/3907]	eta 0:09:09 lr 0.03797588	time 0.1781 (0.1826)	loss 6.3974 (4.4964)	acc@1: 19.3010	acc@5: 30.8353	
2023-03-18 03:17:56,206 - INFO - Train: [14/90][1200/3907]	eta 0:08:12 lr 0.03797588	time 0.1792 (0.1820)	loss 4.5229 (4.4916)	acc@1: 47.5632	acc@5: 64.1069	
2023-03-18 03:18:50,117 - INFO - Train: [14/90][1500/3907]	eta 0:07:17 lr 0.03797588	time 0.1803 (0.1816)	loss 3.1572 (4.4850)	acc@1: 57.5515	acc@5: 81.6629	
2023-03-18 03:19:44,642 - INFO - Train: [14/90][1800/3907]	eta 0:06:22 lr 0.03797588	time 0.1770 (0.1816)	loss 4.2934 (4.5004)	acc@1: 51.1493	acc@5: 73.6550	
2023-03-18 03:20:39,079 - INFO - Train: [14/90][2100/3907]	eta 0:05:28 lr 0.03797588	time 0.1762 (0.1816)	loss 4.3795 (4.5068)	acc@1: 45.8357	acc@5: 65.1160	
2023-03-18 03:21:33,398 - INFO - Train: [14/90][2400/3907]	eta 0:04:33 lr 0.03797588	time 0.1756 (0.1815)	loss 4.6033 (4.5237)	acc@1: 48.2237	acc@5: 67.3324	
2023-03-18 03:22:27,938 - INFO - Train: [14/90][2700/3907]	eta 0:03:39 lr 0.03797588	time 0.1828 (0.1815)	loss 4.2088 (4.5205)	acc@1: 52.5851	acc@5: 71.5157	
2023-03-18 03:23:22,829 - INFO - Train: [14/90][3000/3907]	eta 0:02:44 lr 0.03797588	time 0.1772 (0.1817)	loss 4.8638 (4.5246)	acc@1: 46.6545	acc@5: 62.9335	
2023-03-18 03:24:17,551 - INFO - Train: [14/90][3300/3907]	eta 0:01:50 lr 0.03797588	time 0.1760 (0.1817)	loss 4.7131 (4.5256)	acc@1: 41.5930	acc@5: 62.1805	
2023-03-18 03:25:11,838 - INFO - Train: [14/90][3600/3907]	eta 0:00:55 lr 0.03797588	time 0.1755 (0.1817)	loss 6.4236 (4.5261)	acc@1: 15.0376	acc@5: 27.0261	
2023-03-18 03:26:06,117 - INFO - Train: [14/90][3900/3907]	eta 0:00:01 lr 0.03797588	time 0.1810 (0.1816)	loss 6.0367 (4.5368)	acc@1: 21.2954	acc@5: 40.1948	
2023-03-18 03:26:07,315 - INFO - EPOCH 14 training takes 0:11:49
2023-03-18 03:26:08,780 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp/fold1_latest.pth saved !!!
2023-03-18 03:26:08,781 - INFO - **********latest test***********
2023-03-18 03:26:08,781 - INFO - eval epoch 14
2023-03-18 03:26:09,410 - INFO - Test: [0/782]	Time 0.628 (0.628)	Loss 2.9405 (2.9405)	Acc@1 61.719 (61.719)	Acc@5 84.375 (84.375)
2023-03-18 03:28:18,455 - INFO - Test: [200/782]	Time 0.633 (0.645)	Loss 3.1676 (3.3606)	Acc@1 50.781 (53.413)	Acc@5 81.250 (77.705)
2023-03-18 03:30:27,942 - INFO - Test: [400/782]	Time 0.632 (0.646)	Loss 3.1116 (3.3277)	Acc@1 54.688 (54.282)	Acc@5 82.031 (78.361)
2023-03-18 03:32:39,822 - INFO - Test: [600/782]	Time 0.633 (0.651)	Loss 3.3508 (3.2959)	Acc@1 52.344 (55.135)	Acc@5 79.688 (78.983)
2023-03-18 03:34:36,659 - INFO -  * Acc@1 55.620 Acc@5 79.514
2023-03-18 03:34:36,659 - INFO - Max accuracy: 56.6690%
2023-03-18 03:34:36,659 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp
2023-03-18 03:34:38,499 - INFO - Train: [15/90][0/3907]	eta 1:59:39 lr 0.03765895	time 1.8377 (1.8377)	loss 5.4597 (5.4597)	acc@1: 34.0140	acc@5: 49.9348	
2023-03-18 03:35:32,693 - INFO - Train: [15/90][300/3907]	eta 0:11:11 lr 0.03765895	time 0.1811 (0.1861)	loss 3.2801 (4.2485)	acc@1: 59.6363	acc@5: 81.3266	
2023-03-18 03:36:27,471 - INFO - Train: [15/90][600/3907]	eta 0:10:09 lr 0.03765895	time 0.1781 (0.1844)	loss 5.9131 (4.3451)	acc@1: 28.0391	acc@5: 44.8472	
2023-03-18 03:37:22,014 - INFO - Train: [15/90][900/3907]	eta 0:09:11 lr 0.03765895	time 0.1789 (0.1835)	loss 3.0511 (4.3720)	acc@1: 63.9687	acc@5: 81.9112	
2023-03-18 03:38:16,333 - INFO - Train: [15/90][1200/3907]	eta 0:08:15 lr 0.03765895	time 0.1786 (0.1829)	loss 3.0238 (4.4173)	acc@1: 61.7113	acc@5: 83.5837	
2023-03-18 03:39:10,865 - INFO - Train: [15/90][1500/3907]	eta 0:07:19 lr 0.03765895	time 0.1803 (0.1827)	loss 4.0675 (4.4406)	acc@1: 53.6959	acc@5: 74.5833	
2023-03-18 03:40:05,172 - INFO - Train: [15/90][1800/3907]	eta 0:06:24 lr 0.03765895	time 0.1792 (0.1824)	loss 5.2905 (4.4620)	acc@1: 37.6973	acc@5: 57.3272	
2023-03-18 03:40:59,245 - INFO - Train: [15/90][2100/3907]	eta 0:05:29 lr 0.03765895	time 0.1825 (0.1821)	loss 5.6009 (4.4914)	acc@1: 28.4365	acc@5: 50.8816	
2023-03-18 03:41:53,776 - INFO - Train: [15/90][2400/3907]	eta 0:04:34 lr 0.03765895	time 0.1776 (0.1820)	loss 2.8782 (4.4897)	acc@1: 67.8345	acc@5: 88.1069	
2023-03-18 03:42:48,078 - INFO - Train: [15/90][2700/3907]	eta 0:03:39 lr 0.03765895	time 0.1759 (0.1819)	loss 3.6550 (4.4945)	acc@1: 55.4832	acc@5: 76.0044	
2023-03-18 03:43:41,845 - INFO - Train: [15/90][3000/3907]	eta 0:02:44 lr 0.03765895	time 0.1808 (0.1817)	loss 3.5549 (4.4992)	acc@1: 58.8776	acc@5: 80.9567	
2023-03-18 03:44:36,279 - INFO - Train: [15/90][3300/3907]	eta 0:01:50 lr 0.03765895	time 0.2100 (0.1816)	loss 3.3074 (4.4964)	acc@1: 55.3896	acc@5: 81.9148	
2023-03-18 03:45:30,784 - INFO - Train: [15/90][3600/3907]	eta 0:00:55 lr 0.03765895	time 0.1825 (0.1816)	loss 3.3785 (4.5009)	acc@1: 50.2164	acc@5: 77.2561	
2023-03-18 03:46:25,262 - INFO - Train: [15/90][3900/3907]	eta 0:00:01 lr 0.03765895	time 0.1797 (0.1816)	loss 4.5601 (4.5025)	acc@1: 43.7742	acc@5: 65.6613	
2023-03-18 03:46:26,454 - INFO - EPOCH 15 training takes 0:11:49
2023-03-18 03:46:27,940 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp/fold1_latest.pth saved !!!
2023-03-18 03:46:27,940 - INFO - **********latest test***********
2023-03-18 03:46:27,940 - INFO - eval epoch 15
2023-03-18 03:46:28,649 - INFO - Test: [0/782]	Time 0.705 (0.705)	Loss 2.8494 (2.8494)	Acc@1 66.406 (66.406)	Acc@5 86.719 (86.719)
2023-03-18 03:48:37,183 - INFO - Test: [200/782]	Time 0.647 (0.643)	Loss 3.2606 (3.3683)	Acc@1 53.906 (53.739)	Acc@5 77.344 (77.841)
2023-03-18 03:50:48,111 - INFO - Test: [400/782]	Time 0.648 (0.649)	Loss 3.1959 (3.3347)	Acc@1 57.031 (54.578)	Acc@5 79.688 (78.372)
2023-03-18 03:52:59,182 - INFO - Test: [600/782]	Time 0.642 (0.651)	Loss 3.4033 (3.3065)	Acc@1 53.906 (55.324)	Acc@5 78.906 (78.905)
2023-03-18 03:54:55,471 - INFO -  * Acc@1 55.751 Acc@5 79.435
2023-03-18 03:54:55,471 - INFO - Max accuracy: 56.6690%
2023-03-18 03:54:55,472 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp
2023-03-18 03:54:57,371 - INFO - Train: [16/90][0/3907]	eta 2:03:30 lr 0.03732051	time 1.8968 (1.8968)	loss 4.8022 (4.8022)	acc@1: 45.9403	acc@5: 66.2937	
2023-03-18 03:55:51,851 - INFO - Train: [16/90][300/3907]	eta 0:11:15 lr 0.03732051	time 0.1754 (0.1873)	loss 6.1006 (4.3969)	acc@1: 25.8408	acc@5: 38.8965	
2023-03-18 03:56:46,239 - INFO - Train: [16/90][600/3907]	eta 0:10:09 lr 0.03732051	time 0.1810 (0.1843)	loss 3.0307 (4.4038)	acc@1: 64.9703	acc@5: 83.5332	
2023-03-18 03:57:40,740 - INFO - Train: [16/90][900/3907]	eta 0:09:11 lr 0.03732051	time 0.1755 (0.1834)	loss 4.0446 (4.3897)	acc@1: 47.3262	acc@5: 68.4410	
2023-03-18 03:58:35,244 - INFO - Train: [16/90][1200/3907]	eta 0:08:15 lr 0.03732051	time 0.2032 (0.1830)	loss 5.8448 (4.4090)	acc@1: 28.7627	acc@5: 43.3115	
2023-03-18 03:59:29,829 - INFO - Train: [16/90][1500/3907]	eta 0:07:19 lr 0.03732051	time 0.1848 (0.1828)	loss 3.5768 (4.4215)	acc@1: 56.9479	acc@5: 77.9168	
2023-03-18 04:00:23,746 - INFO - Train: [16/90][1800/3907]	eta 0:06:24 lr 0.03732051	time 0.1826 (0.1823)	loss 6.1436 (4.4289)	acc@1: 16.5295	acc@5: 31.1214	
2023-03-18 04:01:17,487 - INFO - Train: [16/90][2100/3907]	eta 0:05:28 lr 0.03732051	time 0.1753 (0.1818)	loss 3.4969 (4.4360)	acc@1: 56.7847	acc@5: 76.2111	
2023-03-18 04:02:11,632 - INFO - Train: [16/90][2400/3907]	eta 0:04:33 lr 0.03732051	time 0.1797 (0.1817)	loss 3.0851 (4.4338)	acc@1: 63.7020	acc@5: 82.3464	
2023-03-18 04:03:05,912 - INFO - Train: [16/90][2700/3907]	eta 0:03:39 lr 0.03732051	time 0.1794 (0.1816)	loss 4.8395 (4.4393)	acc@1: 44.2024	acc@5: 61.7534	
2023-03-18 04:04:00,172 - INFO - Train: [16/90][3000/3907]	eta 0:02:44 lr 0.03732051	time 0.1810 (0.1815)	loss 4.0873 (4.4439)	acc@1: 53.7503	acc@5: 69.3096	
2023-03-18 04:04:54,799 - INFO - Train: [16/90][3300/3907]	eta 0:01:50 lr 0.03732051	time 0.1911 (0.1816)	loss 6.2426 (4.4606)	acc@1: 19.1483	acc@5: 35.8961	
2023-03-18 04:05:49,282 - INFO - Train: [16/90][3600/3907]	eta 0:00:55 lr 0.03732051	time 0.1748 (0.1816)	loss 6.3702 (4.4736)	acc@1: 14.0278	acc@5: 28.2985	
2023-03-18 04:06:43,686 - INFO - Train: [16/90][3900/3907]	eta 0:00:01 lr 0.03732051	time 0.1755 (0.1815)	loss 2.9855 (4.4722)	acc@1: 60.5741	acc@5: 80.7687	
2023-03-18 04:06:44,866 - INFO - EPOCH 16 training takes 0:11:49
2023-03-18 04:06:46,356 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp/fold1_latest.pth saved !!!
2023-03-18 04:06:46,357 - INFO - **********latest test***********
2023-03-18 04:06:46,357 - INFO - eval epoch 16
2023-03-18 04:06:47,035 - INFO - Test: [0/782]	Time 0.677 (0.677)	Loss 2.8774 (2.8774)	Acc@1 64.844 (64.844)	Acc@5 86.719 (86.719)
2023-03-18 04:08:56,324 - INFO - Test: [200/782]	Time 0.650 (0.647)	Loss 3.1899 (3.2920)	Acc@1 56.250 (55.780)	Acc@5 79.688 (79.058)
2023-03-18 04:11:06,113 - INFO - Test: [400/782]	Time 0.646 (0.648)	Loss 3.1366 (3.2635)	Acc@1 57.812 (56.437)	Acc@5 81.250 (79.604)
2023-03-18 04:13:17,959 - INFO - Test: [600/782]	Time 0.633 (0.652)	Loss 3.3375 (3.2314)	Acc@1 55.469 (57.198)	Acc@5 80.469 (80.146)
2023-03-18 04:15:13,608 - INFO -  * Acc@1 57.746 Acc@5 80.698
2023-03-18 04:15:13,608 - INFO - Max accuracy: 57.7460%
2023-03-18 04:15:15,028 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp/fold1_best.pth saved !!!
2023-03-18 04:15:15,029 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp
2023-03-18 04:15:17,052 - INFO - Train: [17/90][0/3907]	eta 2:11:34 lr 0.03696096	time 2.0206 (2.0206)	loss 4.4661 (4.4661)	acc@1: 54.6243	acc@5: 69.0700	
2023-03-18 04:16:11,813 - INFO - Train: [17/90][300/3907]	eta 0:11:20 lr 0.03696096	time 0.1939 (0.1886)	loss 6.2636 (4.2612)	acc@1: 16.1659	acc@5: 29.7877	
2023-03-18 04:17:06,220 - INFO - Train: [17/90][600/3907]	eta 0:10:11 lr 0.03696096	time 0.1913 (0.1850)	loss 5.0423 (4.2999)	acc@1: 34.4695	acc@5: 57.5522	
2023-03-18 04:18:00,048 - INFO - Train: [17/90][900/3907]	eta 0:09:10 lr 0.03696096	time 0.1761 (0.1831)	loss 5.7869 (4.3161)	acc@1: 28.0292	acc@5: 45.7122	
2023-03-18 04:18:54,293 - INFO - Train: [17/90][1200/3907]	eta 0:08:14 lr 0.03696096	time 0.1813 (0.1826)	loss 3.1058 (4.3549)	acc@1: 60.4762	acc@5: 81.4103	
2023-03-18 04:19:49,357 - INFO - Train: [17/90][1500/3907]	eta 0:07:19 lr 0.03696096	time 0.1914 (0.1828)	loss 3.7725 (4.3738)	acc@1: 52.2522	acc@5: 75.8026	
2023-03-18 04:20:44,293 - INFO - Train: [17/90][1800/3907]	eta 0:06:25 lr 0.03696096	time 0.1883 (0.1828)	loss 3.9001 (4.3900)	acc@1: 53.9411	acc@5: 73.6746	
2023-03-18 04:21:39,273 - INFO - Train: [17/90][2100/3907]	eta 0:05:30 lr 0.03696096	time 0.1761 (0.1829)	loss 4.7384 (4.3893)	acc@1: 42.5501	acc@5: 63.1389	
2023-03-18 04:22:33,963 - INFO - Train: [17/90][2400/3907]	eta 0:04:35 lr 0.03696096	time 0.1853 (0.1828)	loss 5.0192 (4.4001)	acc@1: 38.8624	acc@5: 59.5080	
2023-03-18 04:23:28,498 - INFO - Train: [17/90][2700/3907]	eta 0:03:40 lr 0.03696096	time 0.1962 (0.1827)	loss 5.0429 (4.4127)	acc@1: 36.9116	acc@5: 58.3388	
2023-03-18 04:24:23,205 - INFO - Train: [17/90][3000/3907]	eta 0:02:45 lr 0.03696096	time 0.1752 (0.1827)	loss 4.4737 (4.4178)	acc@1: 45.8659	acc@5: 70.8837	
2023-03-18 04:25:17,614 - INFO - Train: [17/90][3300/3907]	eta 0:01:50 lr 0.03696096	time 0.1797 (0.1825)	loss 4.2228 (4.4288)	acc@1: 45.3091	acc@5: 71.1004	
2023-03-18 04:26:11,610 - INFO - Train: [17/90][3600/3907]	eta 0:00:55 lr 0.03696096	time 0.1782 (0.1823)	loss 4.0216 (4.4316)	acc@1: 49.7116	acc@5: 71.3862	
2023-03-18 04:27:05,631 - INFO - Train: [17/90][3900/3907]	eta 0:00:01 lr 0.03696096	time 0.1745 (0.1822)	loss 3.2532 (4.4381)	acc@1: 55.1085	acc@5: 81.4985	
2023-03-18 04:27:06,830 - INFO - EPOCH 17 training takes 0:11:51
2023-03-18 04:27:08,323 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp/fold1_latest.pth saved !!!
2023-03-18 04:27:08,323 - INFO - **********latest test***********
2023-03-18 04:27:08,323 - INFO - eval epoch 17
2023-03-18 04:27:08,996 - INFO - Test: [0/782]	Time 0.672 (0.672)	Loss 2.8439 (2.8439)	Acc@1 63.281 (63.281)	Acc@5 89.062 (89.062)
2023-03-18 04:29:21,235 - INFO - Test: [200/782]	Time 0.665 (0.661)	Loss 3.2224 (3.3048)	Acc@1 57.812 (54.345)	Acc@5 78.906 (78.238)
2023-03-18 04:31:33,932 - INFO - Test: [400/782]	Time 0.663 (0.662)	Loss 3.1718 (3.2646)	Acc@1 60.156 (55.365)	Acc@5 80.469 (79.113)
2023-03-18 04:33:47,147 - INFO - Test: [600/782]	Time 0.649 (0.664)	Loss 3.2480 (3.2293)	Acc@1 54.688 (56.247)	Acc@5 83.594 (79.649)
2023-03-18 04:35:44,561 - INFO -  * Acc@1 56.845 Acc@5 80.221
2023-03-18 04:35:44,561 - INFO - Max accuracy: 57.7460%
2023-03-18 04:35:44,561 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp
2023-03-18 04:35:46,616 - INFO - Train: [18/90][0/3907]	eta 2:13:38 lr 0.03658075	time 2.0523 (2.0523)	loss 5.5675 (5.5675)	acc@1: 32.7943	acc@5: 50.7254	
2023-03-18 04:36:40,925 - INFO - Train: [18/90][300/3907]	eta 0:11:15 lr 0.03658075	time 0.1846 (0.1872)	loss 4.7474 (4.3420)	acc@1: 50.6604	acc@5: 65.6519	
2023-03-18 04:37:36,101 - INFO - Train: [18/90][600/3907]	eta 0:10:13 lr 0.03658075	time 0.1761 (0.1856)	loss 6.3106 (4.3196)	acc@1: 14.1887	acc@5: 27.8816	
2023-03-18 04:38:30,981 - INFO - Train: [18/90][900/3907]	eta 0:09:15 lr 0.03658075	time 0.1817 (0.1847)	loss 4.8196 (4.3388)	acc@1: 45.0056	acc@5: 58.3171	
2023-03-18 04:39:25,976 - INFO - Train: [18/90][1200/3907]	eta 0:08:19 lr 0.03658075	time 0.1752 (0.1844)	loss 6.1453 (4.3477)	acc@1: 19.8815	acc@5: 39.7631	
2023-03-18 04:40:20,942 - INFO - Train: [18/90][1500/3907]	eta 0:07:23 lr 0.03658075	time 0.1776 (0.1841)	loss 6.3603 (4.3646)	acc@1: 16.3160	acc@5: 28.5043	
2023-03-18 04:41:15,977 - INFO - Train: [18/90][1800/3907]	eta 0:06:27 lr 0.03658075	time 0.1883 (0.1840)	loss 5.9742 (4.3711)	acc@1: 28.3395	acc@5: 41.5735	
2023-03-18 04:42:10,819 - INFO - Train: [18/90][2100/3907]	eta 0:05:32 lr 0.03658075	time 0.1911 (0.1838)	loss 3.2200 (4.3723)	acc@1: 56.7189	acc@5: 82.3613	
2023-03-18 04:43:05,513 - INFO - Train: [18/90][2400/3907]	eta 0:04:36 lr 0.03658075	time 0.1806 (0.1836)	loss 3.1406 (4.3778)	acc@1: 53.9056	acc@5: 82.8115	
2023-03-18 04:43:59,791 - INFO - Train: [18/90][2700/3907]	eta 0:03:41 lr 0.03658075	time 0.1765 (0.1833)	loss 5.3035 (4.3888)	acc@1: 36.2149	acc@5: 54.9906	
2023-03-18 04:44:54,219 - INFO - Train: [18/90][3000/3907]	eta 0:02:46 lr 0.03658075	time 0.1764 (0.1832)	loss 6.1320 (4.4025)	acc@1: 22.6171	acc@5: 36.4742	
2023-03-18 04:45:49,404 - INFO - Train: [18/90][3300/3907]	eta 0:01:51 lr 0.03658075	time 0.1758 (0.1832)	loss 5.4409 (4.4096)	acc@1: 37.1292	acc@5: 52.1911	
2023-03-18 04:46:44,370 - INFO - Train: [18/90][3600/3907]	eta 0:00:56 lr 0.03658075	time 0.1916 (0.1832)	loss 4.2928 (4.4231)	acc@1: 52.5904	acc@5: 66.4061	
2023-03-18 04:47:39,193 - INFO - Train: [18/90][3900/3907]	eta 0:00:01 lr 0.03658075	time 0.1753 (0.1832)	loss 5.6071 (4.4293)	acc@1: 29.0697	acc@5: 49.0871	
2023-03-18 04:47:40,384 - INFO - EPOCH 18 training takes 0:11:55
2023-03-18 04:47:41,862 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp/fold1_latest.pth saved !!!
2023-03-18 04:47:41,863 - INFO - **********latest test***********
2023-03-18 04:47:41,863 - INFO - eval epoch 18
2023-03-18 04:47:42,555 - INFO - Test: [0/782]	Time 0.691 (0.691)	Loss 2.8301 (2.8301)	Acc@1 62.500 (62.500)	Acc@5 89.844 (89.844)
2023-03-18 04:49:52,297 - INFO - Test: [200/782]	Time 0.644 (0.649)	Loss 3.2513 (3.3141)	Acc@1 57.812 (54.594)	Acc@5 75.000 (78.203)
2023-03-18 04:52:02,319 - INFO - Test: [400/782]	Time 0.649 (0.650)	Loss 3.1748 (3.2791)	Acc@1 56.250 (55.580)	Acc@5 78.125 (79.011)
2023-03-18 04:54:11,907 - INFO - Test: [600/782]	Time 0.646 (0.649)	Loss 3.3820 (3.2446)	Acc@1 53.906 (56.381)	Acc@5 77.344 (79.649)
2023-03-18 04:56:07,207 - INFO -  * Acc@1 56.773 Acc@5 80.113
2023-03-18 04:56:07,207 - INFO - Max accuracy: 57.7460%
2023-03-18 04:56:07,207 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp
2023-03-18 04:56:09,194 - INFO - Train: [19/90][0/3907]	eta 2:09:12 lr 0.03618034	time 1.9842 (1.9842)	loss 6.1870 (6.1870)	acc@1: 18.2133	acc@5: 31.5353	
2023-03-18 04:57:03,691 - INFO - Train: [19/90][300/3907]	eta 0:11:16 lr 0.03618034	time 0.1866 (0.1876)	loss 3.0953 (4.2989)	acc@1: 61.7106	acc@5: 82.0205	
2023-03-18 04:57:58,153 - INFO - Train: [19/90][600/3907]	eta 0:10:10 lr 0.03618034	time 0.1766 (0.1846)	loss 6.0408 (4.4089)	acc@1: 21.4938	acc@5: 36.0534	
2023-03-18 04:58:52,447 - INFO - Train: [19/90][900/3907]	eta 0:09:11 lr 0.03618034	time 0.1747 (0.1834)	loss 3.2628 (4.3831)	acc@1: 60.7610	acc@5: 82.0925	
2023-03-18 04:59:46,455 - INFO - Train: [19/90][1200/3907]	eta 0:08:14 lr 0.03618034	time 0.1806 (0.1825)	loss 4.5755 (4.3987)	acc@1: 51.0779	acc@5: 65.9089	
2023-03-18 05:00:40,706 - INFO - Train: [19/90][1500/3907]	eta 0:07:18 lr 0.03618034	time 0.1764 (0.1822)	loss 3.7047 (4.4106)	acc@1: 55.7253	acc@5: 76.3036	
2023-03-18 05:01:34,446 - INFO - Train: [19/90][1800/3907]	eta 0:06:22 lr 0.03618034	time 0.1761 (0.1817)	loss 5.1721 (4.4172)	acc@1: 41.2084	acc@5: 56.3502	
2023-03-18 05:02:28,605 - INFO - Train: [19/90][2100/3907]	eta 0:05:28 lr 0.03618034	time 0.1809 (0.1815)	loss 3.6255 (4.4089)	acc@1: 49.7759	acc@5: 73.5077	
2023-03-18 05:03:23,088 - INFO - Train: [19/90][2400/3907]	eta 0:04:33 lr 0.03618034	time 0.1758 (0.1815)	loss 3.0814 (4.4090)	acc@1: 56.2404	acc@5: 82.0173	
2023-03-18 05:04:17,407 - INFO - Train: [19/90][2700/3907]	eta 0:03:39 lr 0.03618034	time 0.1829 (0.1815)	loss 3.2512 (4.4091)	acc@1: 57.7906	acc@5: 80.1363	
2023-03-18 05:05:11,506 - INFO - Train: [19/90][3000/3907]	eta 0:02:44 lr 0.03618034	time 0.1809 (0.1814)	loss 4.2928 (4.4100)	acc@1: 47.4123	acc@5: 66.7462	
2023-03-18 05:06:05,362 - INFO - Train: [19/90][3300/3907]	eta 0:01:49 lr 0.03618034	time 0.1768 (0.1812)	loss 3.1472 (4.4193)	acc@1: 61.3691	acc@5: 82.0953	
2023-03-18 05:06:59,438 - INFO - Train: [19/90][3600/3907]	eta 0:00:55 lr 0.03618034	time 0.1798 (0.1811)	loss 6.1767 (4.4335)	acc@1: 19.9888	acc@5: 35.5640	
2023-03-18 05:07:53,435 - INFO - Train: [19/90][3900/3907]	eta 0:00:01 lr 0.03618034	time 0.1742 (0.1810)	loss 4.7373 (4.4336)	acc@1: 48.5362	acc@5: 63.8178	
2023-03-18 05:07:54,612 - INFO - EPOCH 19 training takes 0:11:47
2023-03-18 05:07:56,080 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp/fold1_latest.pth saved !!!
2023-03-18 05:07:56,080 - INFO - **********latest test***********
2023-03-18 05:07:56,080 - INFO - eval epoch 19
2023-03-18 05:07:56,747 - INFO - Test: [0/782]	Time 0.665 (0.665)	Loss 2.8785 (2.8785)	Acc@1 64.062 (64.062)	Acc@5 85.156 (85.156)
2023-03-18 05:10:05,920 - INFO - Test: [200/782]	Time 0.621 (0.646)	Loss 3.2059 (3.3264)	Acc@1 56.250 (54.890)	Acc@5 78.906 (78.541)
2023-03-18 05:12:16,426 - INFO - Test: [400/782]	Time 0.676 (0.649)	Loss 3.1567 (3.2888)	Acc@1 56.250 (55.630)	Acc@5 78.906 (79.253)
2023-03-18 05:14:27,189 - INFO - Test: [600/782]	Time 0.651 (0.651)	Loss 3.3727 (3.2522)	Acc@1 53.125 (56.338)	Acc@5 78.125 (79.769)
2023-03-18 05:16:23,761 - INFO -  * Acc@1 56.856 Acc@5 80.290
2023-03-18 05:16:23,761 - INFO - Max accuracy: 57.7460%
2023-03-18 05:16:23,761 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp
2023-03-18 05:16:25,754 - INFO - Train: [20/90][0/3907]	eta 2:09:36 lr 0.03576022	time 1.9903 (1.9903)	loss 6.2144 (6.2144)	acc@1: 17.1875	acc@5: 31.2758	
2023-03-18 05:17:20,198 - INFO - Train: [20/90][300/3907]	eta 0:11:16 lr 0.03576022	time 0.1838 (0.1875)	loss 3.1968 (4.2053)	acc@1: 59.3976	acc@5: 80.2352	
2023-03-18 05:18:14,457 - INFO - Train: [20/90][600/3907]	eta 0:10:09 lr 0.03576022	time 0.1766 (0.1842)	loss 3.0032 (4.2217)	acc@1: 65.5513	acc@5: 80.2017	
2023-03-18 05:19:08,569 - INFO - Train: [20/90][900/3907]	eta 0:09:10 lr 0.03576022	time 0.1815 (0.1829)	loss 3.2326 (4.2958)	acc@1: 59.3045	acc@5: 80.8657	
2023-03-18 05:20:02,597 - INFO - Train: [20/90][1200/3907]	eta 0:08:13 lr 0.03576022	time 0.1787 (0.1822)	loss 6.0928 (4.3112)	acc@1: 20.1180	acc@5: 34.7113	
2023-03-18 05:20:56,775 - INFO - Train: [20/90][1500/3907]	eta 0:07:17 lr 0.03576022	time 0.1762 (0.1819)	loss 6.0474 (4.3509)	acc@1: 29.1077	acc@5: 42.3143	
2023-03-18 05:21:51,103 - INFO - Train: [20/90][1800/3907]	eta 0:06:22 lr 0.03576022	time 0.1759 (0.1817)	loss 6.3720 (4.3497)	acc@1: 17.1601	acc@5: 31.0443	
2023-03-18 05:22:45,232 - INFO - Train: [20/90][2100/3907]	eta 0:05:28 lr 0.03576022	time 0.1970 (0.1816)	loss 3.2259 (4.3580)	acc@1: 60.9346	acc@5: 80.4650	
2023-03-18 05:23:39,802 - INFO - Train: [20/90][2400/3907]	eta 0:04:33 lr 0.03576022	time 0.1760 (0.1816)	loss 3.6690 (4.3564)	acc@1: 55.0130	acc@5: 75.8142	
2023-03-18 05:24:34,085 - INFO - Train: [20/90][2700/3907]	eta 0:03:39 lr 0.03576022	time 0.1764 (0.1815)	loss 6.1982 (4.3669)	acc@1: 22.2480	acc@5: 36.1774	
2023-03-18 05:25:28,332 - INFO - Train: [20/90][3000/3907]	eta 0:02:44 lr 0.03576022	time 0.1769 (0.1815)	loss 6.1768 (4.3741)	acc@1: 20.8716	acc@5: 37.9654	
2023-03-18 05:26:22,622 - INFO - Train: [20/90][3300/3907]	eta 0:01:50 lr 0.03576022	time 0.1772 (0.1814)	loss 6.0014 (4.3863)	acc@1: 24.2361	acc@5: 37.1042	
2023-03-18 05:27:16,556 - INFO - Train: [20/90][3600/3907]	eta 0:00:55 lr 0.03576022	time 0.1761 (0.1813)	loss 4.1203 (4.3991)	acc@1: 51.6145	acc@5: 72.1189	
2023-03-18 05:28:10,369 - INFO - Train: [20/90][3900/3907]	eta 0:00:01 lr 0.03576022	time 0.1748 (0.1811)	loss 2.9963 (4.3974)	acc@1: 65.5120	acc@5: 86.3184	
2023-03-18 05:28:11,555 - INFO - EPOCH 20 training takes 0:11:47
2023-03-18 05:28:13,473 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp/fold1_latest.pth saved !!!
2023-03-18 05:28:13,474 - INFO - **********latest test***********
2023-03-18 05:28:13,474 - INFO - eval epoch 20
2023-03-18 05:28:14,144 - INFO - Test: [0/782]	Time 0.669 (0.669)	Loss 2.9629 (2.9629)	Acc@1 55.469 (55.469)	Acc@5 86.719 (86.719)
2023-03-18 05:30:24,117 - INFO - Test: [200/782]	Time 0.637 (0.650)	Loss 3.2829 (3.3122)	Acc@1 56.250 (54.540)	Acc@5 76.562 (78.797)
2023-03-18 05:32:32,755 - INFO - Test: [400/782]	Time 0.647 (0.647)	Loss 3.1673 (3.2744)	Acc@1 54.688 (55.629)	Acc@5 82.812 (79.370)
2023-03-18 05:34:42,765 - INFO - Test: [600/782]	Time 0.630 (0.648)	Loss 3.2834 (3.2399)	Acc@1 56.250 (56.466)	Acc@5 78.125 (80.040)
2023-03-18 05:36:37,033 - INFO -  * Acc@1 56.874 Acc@5 80.442
2023-03-18 05:36:37,033 - INFO - Max accuracy: 57.7460%
2023-03-18 05:36:37,034 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp
2023-03-18 05:36:39,022 - INFO - Train: [21/90][0/3907]	eta 2:09:17 lr 0.03532089	time 1.9856 (1.9856)	loss 2.9733 (2.9733)	acc@1: 63.0530	acc@5: 86.4059	
2023-03-18 05:37:33,893 - INFO - Train: [21/90][300/3907]	eta 0:11:21 lr 0.03532089	time 0.1947 (0.1889)	loss 6.0961 (4.2306)	acc@1: 24.5205	acc@5: 38.7965	
2023-03-18 05:38:28,618 - INFO - Train: [21/90][600/3907]	eta 0:10:13 lr 0.03532089	time 0.1806 (0.1857)	loss 5.3474 (4.2601)	acc@1: 35.9985	acc@5: 55.5107	
2023-03-18 05:39:23,159 - INFO - Train: [21/90][900/3907]	eta 0:09:14 lr 0.03532089	time 0.1856 (0.1844)	loss 5.8508 (4.2876)	acc@1: 24.0237	acc@5: 41.2564	
2023-03-18 05:40:17,509 - INFO - Train: [21/90][1200/3907]	eta 0:08:16 lr 0.03532089	time 0.1760 (0.1836)	loss 3.0509 (4.2887)	acc@1: 60.9056	acc@5: 80.4266	
2023-03-18 05:41:11,506 - INFO - Train: [21/90][1500/3907]	eta 0:07:20 lr 0.03532089	time 0.1826 (0.1829)	loss 3.5082 (4.3156)	acc@1: 58.4708	acc@5: 78.9355	
2023-03-18 05:42:05,771 - INFO - Train: [21/90][1800/3907]	eta 0:06:24 lr 0.03532089	time 0.1818 (0.1825)	loss 3.8781 (4.3087)	acc@1: 59.5429	acc@5: 68.1980	
2023-03-18 05:43:00,051 - INFO - Train: [21/90][2100/3907]	eta 0:05:29 lr 0.03532089	time 0.1818 (0.1823)	loss 3.2676 (4.3196)	acc@1: 59.3392	acc@5: 78.0779	
2023-03-18 05:43:53,834 - INFO - Train: [21/90][2400/3907]	eta 0:04:34 lr 0.03532089	time 0.1774 (0.1819)	loss 4.0264 (4.3210)	acc@1: 53.3784	acc@5: 70.8838	
2023-03-18 05:44:47,775 - INFO - Train: [21/90][2700/3907]	eta 0:03:39 lr 0.03532089	time 0.1776 (0.1817)	loss 3.4663 (4.3269)	acc@1: 65.2401	acc@5: 81.3425	
2023-03-18 05:45:41,962 - INFO - Train: [21/90][3000/3907]	eta 0:02:44 lr 0.03532089	time 0.1899 (0.1816)	loss 2.8616 (4.3301)	acc@1: 63.8302	acc@5: 84.8465	
2023-03-18 05:46:36,173 - INFO - Train: [21/90][3300/3907]	eta 0:01:50 lr 0.03532089	time 0.1817 (0.1815)	loss 4.4225 (4.3473)	acc@1: 46.6836	acc@5: 66.2596	
2023-03-18 05:47:30,348 - INFO - Train: [21/90][3600/3907]	eta 0:00:55 lr 0.03532089	time 0.1882 (0.1814)	loss 6.4053 (4.3430)	acc@1: 13.0964	acc@5: 29.0185	
2023-03-18 05:48:24,826 - INFO - Train: [21/90][3900/3907]	eta 0:00:01 lr 0.03532089	time 0.1749 (0.1814)	loss 2.9513 (4.3563)	acc@1: 68.1709	acc@5: 85.7881	
2023-03-18 05:48:26,013 - INFO - EPOCH 21 training takes 0:11:48
2023-03-18 05:48:27,501 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp/fold1_latest.pth saved !!!
2023-03-18 05:48:27,501 - INFO - **********latest test***********
2023-03-18 05:48:27,501 - INFO - eval epoch 21
2023-03-18 05:48:28,189 - INFO - Test: [0/782]	Time 0.687 (0.687)	Loss 2.8391 (2.8391)	Acc@1 67.188 (67.188)	Acc@5 86.719 (86.719)
2023-03-18 05:50:38,112 - INFO - Test: [200/782]	Time 0.664 (0.650)	Loss 3.1116 (3.2556)	Acc@1 61.719 (56.573)	Acc@5 81.250 (79.777)
2023-03-18 05:52:48,239 - INFO - Test: [400/782]	Time 0.641 (0.650)	Loss 3.0811 (3.2222)	Acc@1 62.500 (57.331)	Acc@5 81.250 (80.344)
2023-03-18 05:55:00,272 - INFO - Test: [600/782]	Time 0.654 (0.654)	Loss 3.2998 (3.1848)	Acc@1 53.906 (58.235)	Acc@5 79.688 (81.063)
2023-03-18 05:56:57,154 - INFO -  * Acc@1 58.803 Acc@5 81.631
2023-03-18 05:56:57,155 - INFO - Max accuracy: 58.8030%
2023-03-18 05:56:58,590 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp/fold1_best.pth saved !!!
2023-03-18 05:56:58,590 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp
2023-03-18 05:57:00,599 - INFO - Train: [22/90][0/3907]	eta 2:10:35 lr 0.03486290	time 2.0054 (2.0054)	loss 2.9613 (2.9613)	acc@1: 69.0252	acc@5: 82.9830	
2023-03-18 05:57:55,234 - INFO - Train: [22/90][300/3907]	eta 0:11:18 lr 0.03486290	time 0.1876 (0.1882)	loss 4.8910 (4.2073)	acc@1: 43.8878	acc@5: 64.2094	
2023-03-18 05:58:49,829 - INFO - Train: [22/90][600/3907]	eta 0:10:12 lr 0.03486290	time 0.1813 (0.1851)	loss 3.1851 (4.2421)	acc@1: 63.6457	acc@5: 81.1197	
2023-03-18 05:59:44,254 - INFO - Train: [22/90][900/3907]	eta 0:09:12 lr 0.03486290	time 0.1751 (0.1839)	loss 6.3928 (4.2676)	acc@1: 18.8029	acc@5: 30.1222	
2023-03-18 06:00:38,318 - INFO - Train: [22/90][1200/3907]	eta 0:08:15 lr 0.03486290	time 0.1797 (0.1829)	loss 2.8103 (4.2783)	acc@1: 68.7274	acc@5: 85.9095	
2023-03-18 06:01:32,393 - INFO - Train: [22/90][1500/3907]	eta 0:07:19 lr 0.03486290	time 0.1950 (0.1824)	loss 2.8699 (4.2663)	acc@1: 65.6062	acc@5: 86.6939	
2023-03-18 06:02:27,072 - INFO - Train: [22/90][1800/3907]	eta 0:06:24 lr 0.03486290	time 0.1875 (0.1824)	loss 4.3666 (4.2984)	acc@1: 47.7680	acc@5: 68.3348	
2023-03-18 06:03:21,828 - INFO - Train: [22/90][2100/3907]	eta 0:05:29 lr 0.03486290	time 0.1827 (0.1824)	loss 4.2957 (4.2984)	acc@1: 49.5259	acc@5: 71.2944	
2023-03-18 06:04:16,436 - INFO - Train: [22/90][2400/3907]	eta 0:04:34 lr 0.03486290	time 0.1808 (0.1824)	loss 3.0739 (4.3178)	acc@1: 61.5493	acc@5: 84.1425	
2023-03-18 06:05:10,837 - INFO - Train: [22/90][2700/3907]	eta 0:03:39 lr 0.03486290	time 0.1821 (0.1822)	loss 5.3062 (4.3404)	acc@1: 40.8014	acc@5: 53.5351	
2023-03-18 06:06:05,352 - INFO - Train: [22/90][3000/3907]	eta 0:02:45 lr 0.03486290	time 0.1828 (0.1822)	loss 3.0801 (4.3461)	acc@1: 63.9753	acc@5: 84.0090	
2023-03-18 06:06:59,729 - INFO - Train: [22/90][3300/3907]	eta 0:01:50 lr 0.03486290	time 0.1818 (0.1821)	loss 3.8512 (4.3428)	acc@1: 56.4450	acc@5: 77.8542	
2023-03-18 06:07:53,967 - INFO - Train: [22/90][3600/3907]	eta 0:00:55 lr 0.03486290	time 0.1756 (0.1820)	loss 6.1739 (4.3528)	acc@1: 19.2172	acc@5: 34.2665	
2023-03-18 06:08:48,277 - INFO - Train: [22/90][3900/3907]	eta 0:00:01 lr 0.03486290	time 0.1752 (0.1819)	loss 3.9767 (4.3674)	acc@1: 53.4187	acc@5: 71.2715	
2023-03-18 06:08:49,488 - INFO - EPOCH 22 training takes 0:11:50
2023-03-18 06:08:50,940 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp/fold1_latest.pth saved !!!
2023-03-18 06:08:50,940 - INFO - **********latest test***********
2023-03-18 06:08:50,940 - INFO - eval epoch 22
2023-03-18 06:08:51,613 - INFO - Test: [0/782]	Time 0.672 (0.672)	Loss 2.8140 (2.8140)	Acc@1 66.406 (66.406)	Acc@5 89.844 (89.844)
2023-03-18 06:11:00,951 - INFO - Test: [200/782]	Time 0.661 (0.647)	Loss 3.1211 (3.2217)	Acc@1 54.688 (57.342)	Acc@5 82.812 (80.477)
2023-03-18 06:13:10,551 - INFO - Test: [400/782]	Time 0.651 (0.647)	Loss 2.9774 (3.1810)	Acc@1 64.844 (58.175)	Acc@5 82.031 (81.172)
2023-03-18 06:15:21,934 - INFO - Test: [600/782]	Time 0.658 (0.651)	Loss 3.1642 (3.1366)	Acc@1 51.562 (59.151)	Acc@5 82.031 (81.835)
2023-03-18 06:17:17,939 - INFO -  * Acc@1 59.631 Acc@5 82.319
2023-03-18 06:17:17,939 - INFO - Max accuracy: 59.6310%
2023-03-18 06:17:19,360 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp/fold1_best.pth saved !!!
2023-03-18 06:17:19,360 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp
2023-03-18 06:17:21,273 - INFO - Train: [23/90][0/3907]	eta 2:04:22 lr 0.03438680	time 1.9100 (1.9100)	loss 6.0372 (6.0372)	acc@1: 22.2849	acc@5: 38.2428	
2023-03-18 06:18:15,872 - INFO - Train: [23/90][300/3907]	eta 0:11:17 lr 0.03438680	time 0.1812 (0.1877)	loss 2.8033 (4.3279)	acc@1: 64.5703	acc@5: 84.0182	
2023-03-18 06:19:09,751 - INFO - Train: [23/90][600/3907]	eta 0:10:07 lr 0.03438680	time 0.1761 (0.1837)	loss 3.0081 (4.3063)	acc@1: 63.8616	acc@5: 83.3292	
2023-03-18 06:20:04,037 - INFO - Train: [23/90][900/3907]	eta 0:09:09 lr 0.03438680	time 0.1763 (0.1828)	loss 5.5281 (4.3377)	acc@1: 34.4010	acc@5: 49.0038	
2023-03-18 06:20:58,386 - INFO - Train: [23/90][1200/3907]	eta 0:08:13 lr 0.03438680	time 0.1803 (0.1824)	loss 4.1796 (4.3199)	acc@1: 55.4630	acc@5: 70.8632	
2023-03-18 06:21:52,786 - INFO - Train: [23/90][1500/3907]	eta 0:07:18 lr 0.03438680	time 0.1811 (0.1822)	loss 3.0531 (4.3225)	acc@1: 60.8611	acc@5: 84.2688	
2023-03-18 06:22:47,136 - INFO - Train: [23/90][1800/3907]	eta 0:06:23 lr 0.03438680	time 0.2078 (0.1820)	loss 2.9346 (4.3270)	acc@1: 63.1076	acc@5: 84.1427	
2023-03-18 06:23:41,356 - INFO - Train: [23/90][2100/3907]	eta 0:05:28 lr 0.03438680	time 0.1843 (0.1818)	loss 3.0144 (4.3306)	acc@1: 57.0210	acc@5: 82.0164	
2023-03-18 06:24:35,657 - INFO - Train: [23/90][2400/3907]	eta 0:04:33 lr 0.03438680	time 0.1781 (0.1817)	loss 2.9149 (4.3383)	acc@1: 64.7683	acc@5: 85.8369	
2023-03-18 06:25:30,070 - INFO - Train: [23/90][2700/3907]	eta 0:03:39 lr 0.03438680	time 0.1892 (0.1817)	loss 3.9787 (4.3302)	acc@1: 55.0861	acc@5: 76.3201	
2023-03-18 06:26:24,784 - INFO - Train: [23/90][3000/3907]	eta 0:02:44 lr 0.03438680	time 0.1823 (0.1817)	loss 6.0511 (4.3424)	acc@1: 21.4986	acc@5: 35.5142	
2023-03-18 06:27:19,158 - INFO - Train: [23/90][3300/3907]	eta 0:01:50 lr 0.03438680	time 0.1755 (0.1817)	loss 6.3085 (4.3368)	acc@1: 14.8879	acc@5: 30.0671	
2023-03-18 06:28:12,904 - INFO - Train: [23/90][3600/3907]	eta 0:00:55 lr 0.03438680	time 0.1754 (0.1815)	loss 3.5086 (4.3482)	acc@1: 56.4187	acc@5: 74.7105	
2023-03-18 06:29:07,819 - INFO - Train: [23/90][3900/3907]	eta 0:00:01 lr 0.03438680	time 0.1749 (0.1816)	loss 4.5807 (4.3541)	acc@1: 45.8954	acc@5: 65.2879	
2023-03-18 06:29:09,023 - INFO - EPOCH 23 training takes 0:11:49
2023-03-18 06:29:10,530 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp/fold1_latest.pth saved !!!
2023-03-18 06:29:10,531 - INFO - **********latest test***********
2023-03-18 06:29:10,531 - INFO - eval epoch 23
2023-03-18 06:29:11,204 - INFO - Test: [0/782]	Time 0.670 (0.670)	Loss 2.8010 (2.8010)	Acc@1 65.625 (65.625)	Acc@5 89.062 (89.062)
2023-03-18 06:31:20,593 - INFO - Test: [200/782]	Time 0.635 (0.647)	Loss 3.3214 (3.3555)	Acc@1 54.688 (54.466)	Acc@5 78.906 (77.573)
2023-03-18 06:33:30,181 - INFO - Test: [400/782]	Time 0.655 (0.647)	Loss 3.2374 (3.3199)	Acc@1 59.375 (55.147)	Acc@5 78.906 (78.458)
2023-03-18 06:35:41,534 - INFO - Test: [600/782]	Time 0.720 (0.651)	Loss 3.4899 (3.2863)	Acc@1 49.219 (55.666)	Acc@5 74.219 (79.048)
2023-03-18 06:37:37,661 - INFO -  * Acc@1 56.197 Acc@5 79.629
2023-03-18 06:37:37,662 - INFO - Max accuracy: 59.6310%
2023-03-18 06:37:37,662 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp
2023-03-18 06:37:39,697 - INFO - Train: [24/90][0/3907]	eta 2:12:21 lr 0.03389317	time 2.0326 (2.0326)	loss 3.8193 (3.8193)	acc@1: 61.9981	acc@5: 76.0710	
2023-03-18 06:38:34,523 - INFO - Train: [24/90][300/3907]	eta 0:11:21 lr 0.03389317	time 0.1774 (0.1889)	loss 3.0181 (4.1981)	acc@1: 72.4047	acc@5: 85.8274	
2023-03-18 06:39:29,057 - INFO - Train: [24/90][600/3907]	eta 0:10:12 lr 0.03389317	time 0.1764 (0.1853)	loss 3.2858 (4.2114)	acc@1: 61.0877	acc@5: 82.6919	
2023-03-18 06:40:23,556 - INFO - Train: [24/90][900/3907]	eta 0:09:13 lr 0.03389317	time 0.1773 (0.1841)	loss 3.5073 (4.2726)	acc@1: 57.5080	acc@5: 80.3637	
2023-03-18 06:41:17,775 - INFO - Train: [24/90][1200/3907]	eta 0:08:16 lr 0.03389317	time 0.1765 (0.1833)	loss 5.5619 (4.2796)	acc@1: 34.7534	acc@5: 48.4343	
2023-03-18 06:42:12,213 - INFO - Train: [24/90][1500/3907]	eta 0:07:20 lr 0.03389317	time 0.1795 (0.1829)	loss 3.3280 (4.2839)	acc@1: 65.9427	acc@5: 80.7522	
2023-03-18 06:43:06,688 - INFO - Train: [24/90][1800/3907]	eta 0:06:24 lr 0.03389317	time 0.1824 (0.1827)	loss 6.1586 (4.2791)	acc@1: 14.9128	acc@5: 35.3981	
2023-03-18 06:44:01,097 - INFO - Train: [24/90][2100/3907]	eta 0:05:29 lr 0.03389317	time 0.1791 (0.1825)	loss 3.2016 (4.2892)	acc@1: 61.9220	acc@5: 80.7926	
2023-03-18 06:44:54,915 - INFO - Train: [24/90][2400/3907]	eta 0:04:34 lr 0.03389317	time 0.1755 (0.1821)	loss 3.1201 (4.2925)	acc@1: 64.4560	acc@5: 83.4136	
2023-03-18 06:45:49,013 - INFO - Train: [24/90][2700/3907]	eta 0:03:39 lr 0.03389317	time 0.1805 (0.1819)	loss 5.9061 (4.3028)	acc@1: 25.1602	acc@5: 43.7024	
2023-03-18 06:46:43,107 - INFO - Train: [24/90][3000/3907]	eta 0:02:44 lr 0.03389317	time 0.1906 (0.1817)	loss 5.7922 (4.2911)	acc@1: 29.8822	acc@5: 45.2965	
2023-03-18 06:47:37,302 - INFO - Train: [24/90][3300/3907]	eta 0:01:50 lr 0.03389317	time 0.1761 (0.1816)	loss 2.8484 (4.2948)	acc@1: 67.1864	acc@5: 82.0299	
2023-03-18 06:48:31,607 - INFO - Train: [24/90][3600/3907]	eta 0:00:55 lr 0.03389317	time 0.1884 (0.1816)	loss 3.7571 (4.3055)	acc@1: 53.5645	acc@5: 77.2000	
2023-03-18 06:49:25,652 - INFO - Train: [24/90][3900/3907]	eta 0:00:01 lr 0.03389317	time 0.1762 (0.1815)	loss 5.2129 (4.3134)	acc@1: 41.8208	acc@5: 55.4652	
2023-03-18 06:49:26,853 - INFO - EPOCH 24 training takes 0:11:49
2023-03-18 06:49:28,311 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp/fold1_latest.pth saved !!!
2023-03-18 06:49:28,313 - INFO - **********latest test***********
2023-03-18 06:49:28,313 - INFO - eval epoch 24
2023-03-18 06:49:28,983 - INFO - Test: [0/782]	Time 0.668 (0.668)	Loss 2.6662 (2.6662)	Acc@1 64.844 (64.844)	Acc@5 91.406 (91.406)
2023-03-18 06:51:37,053 - INFO - Test: [200/782]	Time 0.627 (0.640)	Loss 3.0421 (3.2184)	Acc@1 63.281 (57.043)	Acc@5 78.125 (79.812)
2023-03-18 06:53:44,363 - INFO - Test: [400/782]	Time 0.621 (0.639)	Loss 2.9558 (3.1809)	Acc@1 64.062 (57.980)	Acc@5 83.594 (80.677)
2023-03-18 06:55:52,596 - INFO - Test: [600/782]	Time 0.640 (0.639)	Loss 3.3184 (3.1464)	Acc@1 50.000 (58.702)	Acc@5 81.250 (81.301)
2023-03-18 06:57:47,574 - INFO -  * Acc@1 59.349 Acc@5 81.913
2023-03-18 06:57:47,575 - INFO - Max accuracy: 59.6310%
2023-03-18 06:57:47,575 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp
2023-03-18 06:57:49,629 - INFO - Train: [25/90][0/3907]	eta 2:13:36 lr 0.03338261	time 2.0519 (2.0519)	loss 5.6352 (5.6352)	acc@1: 29.6372	acc@5: 47.2094	
2023-03-18 06:58:43,388 - INFO - Train: [25/90][300/3907]	eta 0:11:08 lr 0.03338261	time 0.1760 (0.1854)	loss 4.2239 (4.1794)	acc@1: 50.6096	acc@5: 72.4521	
2023-03-18 06:59:37,259 - INFO - Train: [25/90][600/3907]	eta 0:10:03 lr 0.03338261	time 0.1744 (0.1825)	loss 4.2778 (4.2054)	acc@1: 53.9070	acc@5: 74.2865	
2023-03-18 07:00:31,191 - INFO - Train: [25/90][900/3907]	eta 0:09:06 lr 0.03338261	time 0.1920 (0.1816)	loss 5.5116 (4.2045)	acc@1: 33.2301	acc@5: 48.0637	
2023-03-18 07:01:24,977 - INFO - Train: [25/90][1200/3907]	eta 0:08:09 lr 0.03338261	time 0.1910 (0.1810)	loss 3.3218 (4.2339)	acc@1: 63.8937	acc@5: 81.7138	
2023-03-18 07:02:18,546 - INFO - Train: [25/90][1500/3907]	eta 0:07:14 lr 0.03338261	time 0.1750 (0.1805)	loss 6.3451 (4.2476)	acc@1: 13.1825	acc@5: 30.5181	
2023-03-18 07:03:12,054 - INFO - Train: [25/90][1800/3907]	eta 0:06:19 lr 0.03338261	time 0.1815 (0.1802)	loss 3.1762 (4.2559)	acc@1: 60.1131	acc@5: 80.4108	
2023-03-18 07:04:06,397 - INFO - Train: [25/90][2100/3907]	eta 0:05:25 lr 0.03338261	time 0.1810 (0.1803)	loss 6.0168 (4.2784)	acc@1: 25.8650	acc@5: 39.7279	
2023-03-18 07:05:00,773 - INFO - Train: [25/90][2400/3907]	eta 0:04:31 lr 0.03338261	time 0.1822 (0.1804)	loss 5.9379 (4.2767)	acc@1: 21.8282	acc@5: 40.6695	
2023-03-18 07:05:54,961 - INFO - Train: [25/90][2700/3907]	eta 0:03:37 lr 0.03338261	time 0.1805 (0.1804)	loss 5.3220 (4.2709)	acc@1: 36.5700	acc@5: 55.2378	
2023-03-18 07:06:49,250 - INFO - Train: [25/90][3000/3907]	eta 0:02:43 lr 0.03338261	time 0.1813 (0.1805)	loss 5.8730 (4.2747)	acc@1: 27.0329	acc@5: 42.1272	
2023-03-18 07:07:43,895 - INFO - Train: [25/90][3300/3907]	eta 0:01:49 lr 0.03338261	time 0.1894 (0.1806)	loss 6.1307 (4.2806)	acc@1: 19.5291	acc@5: 33.9876	
2023-03-18 07:08:38,852 - INFO - Train: [25/90][3600/3907]	eta 0:00:55 lr 0.03338261	time 0.1787 (0.1809)	loss 5.2901 (4.2907)	acc@1: 33.9106	acc@5: 53.4638	
2023-03-18 07:09:33,445 - INFO - Train: [25/90][3900/3907]	eta 0:00:01 lr 0.03338261	time 0.1739 (0.1809)	loss 2.8867 (4.3011)	acc@1: 65.6195	acc@5: 84.3679	
2023-03-18 07:09:34,589 - INFO - EPOCH 25 training takes 0:11:47
2023-03-18 07:09:36,039 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp/fold1_latest.pth saved !!!
2023-03-18 07:09:36,039 - INFO - **********latest test***********
2023-03-18 07:09:36,039 - INFO - eval epoch 25
2023-03-18 07:09:36,679 - INFO - Test: [0/782]	Time 0.638 (0.638)	Loss 2.7023 (2.7023)	Acc@1 63.281 (63.281)	Acc@5 90.625 (90.625)
2023-03-18 07:11:43,233 - INFO - Test: [200/782]	Time 0.624 (0.633)	Loss 2.9821 (3.1564)	Acc@1 60.938 (57.432)	Acc@5 85.156 (80.772)
2023-03-18 07:13:52,371 - INFO - Test: [400/782]	Time 0.654 (0.639)	Loss 2.9286 (3.1250)	Acc@1 63.281 (58.091)	Acc@5 83.594 (81.277)
2023-03-18 07:16:01,009 - INFO - Test: [600/782]	Time 0.627 (0.641)	Loss 3.1391 (3.0876)	Acc@1 52.344 (58.956)	Acc@5 82.812 (81.880)
2023-03-18 07:17:55,787 - INFO -  * Acc@1 59.569 Acc@5 82.410
2023-03-18 07:17:55,787 - INFO - Max accuracy: 59.6310%
2023-03-18 07:17:55,787 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp
2023-03-18 07:17:57,707 - INFO - Train: [26/90][0/3907]	eta 2:04:50 lr 0.03285575	time 1.9171 (1.9171)	loss 4.7849 (4.7849)	acc@1: 48.2546	acc@5: 63.1022	
2023-03-18 07:18:51,400 - INFO - Train: [26/90][300/3907]	eta 0:11:06 lr 0.03285575	time 0.1808 (0.1847)	loss 2.9754 (4.2583)	acc@1: 67.3621	acc@5: 84.9639	
2023-03-18 07:19:44,824 - INFO - Train: [26/90][600/3907]	eta 0:09:59 lr 0.03285575	time 0.1751 (0.1814)	loss 2.9981 (4.2526)	acc@1: 61.7836	acc@5: 84.9420	
2023-03-18 07:20:39,589 - INFO - Train: [26/90][900/3907]	eta 0:09:06 lr 0.03285575	time 0.1807 (0.1818)	loss 4.9676 (4.2835)	acc@1: 42.8366	acc@5: 59.6816	
2023-03-18 07:21:34,089 - INFO - Train: [26/90][1200/3907]	eta 0:08:12 lr 0.03285575	time 0.1823 (0.1818)	loss 3.2380 (4.2550)	acc@1: 60.5581	acc@5: 82.5261	
2023-03-18 07:22:28,316 - INFO - Train: [26/90][1500/3907]	eta 0:07:17 lr 0.03285575	time 0.1848 (0.1816)	loss 5.6722 (4.2560)	acc@1: 29.7797	acc@5: 46.2516	
2023-03-18 07:23:22,450 - INFO - Train: [26/90][1800/3907]	eta 0:06:22 lr 0.03285575	time 0.1752 (0.1814)	loss 4.8114 (4.2587)	acc@1: 43.1256	acc@5: 61.4538	
2023-03-18 07:24:16,232 - INFO - Train: [26/90][2100/3907]	eta 0:05:27 lr 0.03285575	time 0.1761 (0.1811)	loss 5.2543 (4.2683)	acc@1: 36.4608	acc@5: 53.7058	
2023-03-18 07:25:10,368 - INFO - Train: [26/90][2400/3907]	eta 0:04:32 lr 0.03285575	time 0.1801 (0.1810)	loss 3.2889 (4.2798)	acc@1: 65.2577	acc@5: 81.3768	
2023-03-18 07:26:04,356 - INFO - Train: [26/90][2700/3907]	eta 0:03:38 lr 0.03285575	time 0.1802 (0.1809)	loss 3.5853 (4.2794)	acc@1: 57.9264	acc@5: 76.9908	
2023-03-18 07:26:57,988 - INFO - Train: [26/90][3000/3907]	eta 0:02:43 lr 0.03285575	time 0.1818 (0.1807)	loss 2.8911 (4.2732)	acc@1: 66.3055	acc@5: 82.6868	
2023-03-18 07:27:51,719 - INFO - Train: [26/90][3300/3907]	eta 0:01:49 lr 0.03285575	time 0.1827 (0.1805)	loss 5.9973 (4.2827)	acc@1: 23.8119	acc@5: 39.0850	
2023-03-18 07:28:45,866 - INFO - Train: [26/90][3600/3907]	eta 0:00:55 lr 0.03285575	time 0.1759 (0.1805)	loss 3.5341 (4.2833)	acc@1: 54.8302	acc@5: 74.1352	
2023-03-18 07:29:40,607 - INFO - Train: [26/90][3900/3907]	eta 0:00:01 lr 0.03285575	time 0.1747 (0.1807)	loss 6.4909 (4.2864)	acc@1: 16.8648	acc@5: 29.0421	
2023-03-18 07:29:41,793 - INFO - EPOCH 26 training takes 0:11:46
2023-03-18 07:29:43,257 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp/fold1_latest.pth saved !!!
2023-03-18 07:29:43,257 - INFO - **********latest test***********
2023-03-18 07:29:43,257 - INFO - eval epoch 26
2023-03-18 07:29:43,946 - INFO - Test: [0/782]	Time 0.688 (0.688)	Loss 2.8433 (2.8433)	Acc@1 64.062 (64.062)	Acc@5 89.062 (89.062)
2023-03-18 07:31:53,275 - INFO - Test: [200/782]	Time 0.653 (0.647)	Loss 3.1196 (3.2132)	Acc@1 60.156 (57.746)	Acc@5 81.250 (80.403)
2023-03-18 07:34:02,993 - INFO - Test: [400/782]	Time 0.650 (0.648)	Loss 3.1661 (3.1800)	Acc@1 58.594 (58.282)	Acc@5 75.781 (80.890)
2023-03-18 07:36:14,792 - INFO - Test: [600/782]	Time 0.641 (0.651)	Loss 3.1132 (3.1426)	Acc@1 60.156 (59.059)	Acc@5 84.375 (81.506)
2023-03-18 07:38:11,299 - INFO -  * Acc@1 59.544 Acc@5 82.103
2023-03-18 07:38:11,300 - INFO - Max accuracy: 59.6310%
2023-03-18 07:38:11,300 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp
2023-03-18 07:38:13,234 - INFO - Train: [27/90][0/3907]	eta 2:05:47 lr 0.03231323	time 1.9318 (1.9318)	loss 3.1347 (3.1347)	acc@1: 63.3189	acc@5: 83.6714	
2023-03-18 07:39:07,497 - INFO - Train: [27/90][300/3907]	eta 0:11:13 lr 0.03231323	time 0.1906 (0.1867)	loss 2.8139 (4.2037)	acc@1: 63.0850	acc@5: 90.3430	
2023-03-18 07:40:01,564 - INFO - Train: [27/90][600/3907]	eta 0:10:06 lr 0.03231323	time 0.1796 (0.1835)	loss 6.1544 (4.2336)	acc@1: 21.3859	acc@5: 38.8464	
2023-03-18 07:40:55,658 - INFO - Train: [27/90][900/3907]	eta 0:09:08 lr 0.03231323	time 0.1766 (0.1824)	loss 5.9552 (4.2533)	acc@1: 21.8107	acc@5: 38.9175	
2023-03-18 07:41:49,963 - INFO - Train: [27/90][1200/3907]	eta 0:08:12 lr 0.03231323	time 0.1988 (0.1821)	loss 5.6765 (4.2563)	acc@1: 34.0927	acc@5: 45.3858	
2023-03-18 07:42:44,332 - INFO - Train: [27/90][1500/3907]	eta 0:07:17 lr 0.03231323	time 0.1873 (0.1819)	loss 5.9175 (4.2383)	acc@1: 30.6738	acc@5: 43.7127	
2023-03-18 07:43:38,561 - INFO - Train: [27/90][1800/3907]	eta 0:06:22 lr 0.03231323	time 0.1805 (0.1817)	loss 3.4296 (4.2331)	acc@1: 56.9826	acc@5: 74.9566	
2023-03-18 07:44:32,292 - INFO - Train: [27/90][2100/3907]	eta 0:05:27 lr 0.03231323	time 0.1756 (0.1813)	loss 3.2273 (4.2349)	acc@1: 62.4480	acc@5: 77.6943	
2023-03-18 07:45:26,353 - INFO - Train: [27/90][2400/3907]	eta 0:04:33 lr 0.03231323	time 0.1888 (0.1812)	loss 3.6691 (4.2488)	acc@1: 57.3127	acc@5: 79.0556	
2023-03-18 07:46:20,078 - INFO - Train: [27/90][2700/3907]	eta 0:03:38 lr 0.03231323	time 0.1805 (0.1810)	loss 2.9609 (4.2514)	acc@1: 61.5251	acc@5: 86.4466	
2023-03-18 07:47:14,259 - INFO - Train: [27/90][3000/3907]	eta 0:02:44 lr 0.03231323	time 0.1817 (0.1809)	loss 5.6294 (4.2636)	acc@1: 30.8160	acc@5: 45.9419	
2023-03-18 07:48:08,826 - INFO - Train: [27/90][3300/3907]	eta 0:01:49 lr 0.03231323	time 0.1754 (0.1810)	loss 3.8704 (4.2678)	acc@1: 53.0825	acc@5: 69.8072	
2023-03-18 07:49:03,416 - INFO - Train: [27/90][3600/3907]	eta 0:00:55 lr 0.03231323	time 0.1802 (0.1811)	loss 6.0918 (4.2747)	acc@1: 20.2084	acc@5: 39.1273	
2023-03-18 07:49:57,961 - INFO - Train: [27/90][3900/3907]	eta 0:00:01 lr 0.03231323	time 0.1813 (0.1811)	loss 3.1173 (4.2788)	acc@1: 63.0401	acc@5: 80.1643	
2023-03-18 07:49:59,126 - INFO - EPOCH 27 training takes 0:11:47
2023-03-18 07:50:00,618 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp/fold1_latest.pth saved !!!
2023-03-18 07:50:00,619 - INFO - **********latest test***********
2023-03-18 07:50:00,619 - INFO - eval epoch 27
2023-03-18 07:50:01,267 - INFO - Test: [0/782]	Time 0.647 (0.647)	Loss 2.7529 (2.7529)	Acc@1 62.500 (62.500)	Acc@5 87.500 (87.500)
2023-03-18 07:52:09,910 - INFO - Test: [200/782]	Time 0.652 (0.643)	Loss 3.0654 (3.2001)	Acc@1 58.594 (56.876)	Acc@5 83.594 (80.115)
2023-03-18 07:54:19,615 - INFO - Test: [400/782]	Time 0.649 (0.646)	Loss 3.0323 (3.1667)	Acc@1 57.031 (57.766)	Acc@5 81.250 (80.780)
2023-03-18 07:56:30,608 - INFO - Test: [600/782]	Time 0.639 (0.649)	Loss 3.1040 (3.1293)	Acc@1 58.594 (58.643)	Acc@5 78.125 (81.410)
2023-03-18 07:58:27,005 - INFO -  * Acc@1 59.035 Acc@5 81.897
2023-03-18 07:58:27,005 - INFO - Max accuracy: 59.6310%
2023-03-18 07:58:27,005 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp
2023-03-18 07:58:29,005 - INFO - Train: [28/90][0/3907]	eta 2:09:59 lr 0.03175571	time 1.9964 (1.9964)	loss 3.1269 (3.1269)	acc@1: 66.5359	acc@5: 85.2258	
2023-03-18 07:59:23,513 - INFO - Train: [28/90][300/3907]	eta 0:11:17 lr 0.03175571	time 0.1863 (0.1877)	loss 5.0073 (4.1093)	acc@1: 41.0228	acc@5: 58.4408	
2023-03-18 08:00:17,910 - INFO - Train: [28/90][600/3907]	eta 0:10:10 lr 0.03175571	time 0.1837 (0.1845)	loss 3.5040 (4.1399)	acc@1: 58.0340	acc@5: 79.3203	
2023-03-18 08:01:11,636 - INFO - Train: [28/90][900/3907]	eta 0:09:09 lr 0.03175571	time 0.1758 (0.1827)	loss 3.2381 (4.1418)	acc@1: 61.9945	acc@5: 79.1542	
2023-03-18 08:02:05,094 - INFO - Train: [28/90][1200/3907]	eta 0:08:11 lr 0.03175571	time 0.1814 (0.1816)	loss 5.9365 (4.1619)	acc@1: 24.0234	acc@5: 36.2792	
2023-03-18 08:02:58,773 - INFO - Train: [28/90][1500/3907]	eta 0:07:15 lr 0.03175571	time 0.1803 (0.1811)	loss 6.1097 (4.1703)	acc@1: 25.2589	acc@5: 36.9328	
2023-03-18 08:03:53,360 - INFO - Train: [28/90][1800/3907]	eta 0:06:21 lr 0.03175571	time 0.1796 (0.1812)	loss 5.7862 (4.2021)	acc@1: 24.7507	acc@5: 39.5634	
2023-03-18 08:04:47,727 - INFO - Train: [28/90][2100/3907]	eta 0:05:27 lr 0.03175571	time 0.1815 (0.1812)	loss 3.4418 (4.2262)	acc@1: 58.4635	acc@5: 81.4049	
2023-03-18 08:05:41,555 - INFO - Train: [28/90][2400/3907]	eta 0:04:32 lr 0.03175571	time 0.1831 (0.1810)	loss 3.3295 (4.2475)	acc@1: 53.9194	acc@5: 77.7980	
2023-03-18 08:06:35,585 - INFO - Train: [28/90][2700/3907]	eta 0:03:38 lr 0.03175571	time 0.1803 (0.1809)	loss 3.1403 (4.2545)	acc@1: 58.3258	acc@5: 80.8784	
2023-03-18 08:07:29,533 - INFO - Train: [28/90][3000/3907]	eta 0:02:43 lr 0.03175571	time 0.1752 (0.1808)	loss 3.2424 (4.2646)	acc@1: 55.4089	acc@5: 80.8110	
2023-03-18 08:08:24,019 - INFO - Train: [28/90][3300/3907]	eta 0:01:49 lr 0.03175571	time 0.1804 (0.1809)	loss 4.2117 (4.2666)	acc@1: 52.5145	acc@5: 70.4799	
2023-03-18 08:09:18,285 - INFO - Train: [28/90][3600/3907]	eta 0:00:55 lr 0.03175571	time 0.1758 (0.1809)	loss 3.4077 (4.2664)	acc@1: 56.7026	acc@5: 76.3595	
2023-03-18 08:10:12,150 - INFO - Train: [28/90][3900/3907]	eta 0:00:01 lr 0.03175571	time 0.1749 (0.1808)	loss 5.5961 (4.2710)	acc@1: 34.6252	acc@5: 50.1060	
2023-03-18 08:10:13,352 - INFO - EPOCH 28 training takes 0:11:46
2023-03-18 08:10:14,804 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp/fold1_latest.pth saved !!!
2023-03-18 08:10:14,804 - INFO - **********latest test***********
2023-03-18 08:10:14,804 - INFO - eval epoch 28
2023-03-18 08:10:15,468 - INFO - Test: [0/782]	Time 0.662 (0.662)	Loss 2.6852 (2.6852)	Acc@1 67.188 (67.188)	Acc@5 90.625 (90.625)
2023-03-18 08:12:24,124 - INFO - Test: [200/782]	Time 0.640 (0.643)	Loss 2.9960 (3.1598)	Acc@1 63.281 (58.341)	Acc@5 82.812 (81.025)
2023-03-18 08:14:33,204 - INFO - Test: [400/782]	Time 0.642 (0.644)	Loss 3.0186 (3.1212)	Acc@1 60.938 (59.102)	Acc@5 84.375 (81.626)
2023-03-18 08:16:42,783 - INFO - Test: [600/782]	Time 0.667 (0.646)	Loss 3.1705 (3.0826)	Acc@1 54.688 (59.995)	Acc@5 83.594 (82.241)
2023-03-18 08:18:37,563 - INFO -  * Acc@1 60.455 Acc@5 82.683
2023-03-18 08:18:37,564 - INFO - Max accuracy: 60.4550%
2023-03-18 08:18:39,006 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp/fold1_best.pth saved !!!
2023-03-18 08:18:39,006 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp
2023-03-18 08:18:41,068 - INFO - Train: [29/90][0/3907]	eta 2:13:36 lr 0.03118386	time 2.0517 (2.0517)	loss 2.6817 (2.6817)	acc@1: 68.6040	acc@5: 86.5336	
2023-03-18 08:19:35,319 - INFO - Train: [29/90][300/3907]	eta 0:11:14 lr 0.03118386	time 0.1750 (0.1870)	loss 3.3748 (4.1784)	acc@1: 59.2837	acc@5: 77.2939	
2023-03-18 08:20:29,722 - INFO - Train: [29/90][600/3907]	eta 0:10:09 lr 0.03118386	time 0.1822 (0.1842)	loss 6.1050 (4.0894)	acc@1: 22.4669	acc@5: 35.8685	
2023-03-18 08:21:23,746 - INFO - Train: [29/90][900/3907]	eta 0:09:09 lr 0.03118386	time 0.1758 (0.1828)	loss 3.4668 (4.1299)	acc@1: 59.3985	acc@5: 79.8973	
2023-03-18 08:22:17,977 - INFO - Train: [29/90][1200/3907]	eta 0:08:13 lr 0.03118386	time 0.1828 (0.1823)	loss 3.9929 (4.1547)	acc@1: 55.9457	acc@5: 74.3669	
2023-03-18 08:23:12,103 - INFO - Train: [29/90][1500/3907]	eta 0:07:17 lr 0.03118386	time 0.1869 (0.1819)	loss 5.9859 (4.1411)	acc@1: 25.8786	acc@5: 41.9465	
2023-03-18 08:24:06,362 - INFO - Train: [29/90][1800/3907]	eta 0:06:22 lr 0.03118386	time 0.1758 (0.1818)	loss 5.2842 (4.1638)	acc@1: 39.6803	acc@5: 54.9001	
2023-03-18 08:25:00,078 - INFO - Train: [29/90][2100/3907]	eta 0:05:27 lr 0.03118386	time 0.1812 (0.1814)	loss 4.0912 (4.1768)	acc@1: 50.9474	acc@5: 68.7112	
2023-03-18 08:25:53,950 - INFO - Train: [29/90][2400/3907]	eta 0:04:32 lr 0.03118386	time 0.1816 (0.1811)	loss 3.0680 (4.1790)	acc@1: 63.3348	acc@5: 86.2269	
2023-03-18 08:26:47,384 - INFO - Train: [29/90][2700/3907]	eta 0:03:38 lr 0.03118386	time 0.1771 (0.1808)	loss 3.7201 (4.1788)	acc@1: 48.2678	acc@5: 76.7897	
2023-03-18 08:27:40,768 - INFO - Train: [29/90][3000/3907]	eta 0:02:43 lr 0.03118386	time 0.1806 (0.1805)	loss 4.9574 (4.1965)	acc@1: 40.4727	acc@5: 59.7454	
2023-03-18 08:28:34,527 - INFO - Train: [29/90][3300/3907]	eta 0:01:49 lr 0.03118386	time 0.1770 (0.1804)	loss 5.5231 (4.2066)	acc@1: 35.3325	acc@5: 47.2964	
2023-03-18 08:29:28,429 - INFO - Train: [29/90][3600/3907]	eta 0:00:55 lr 0.03118386	time 0.1815 (0.1803)	loss 4.0908 (4.2144)	acc@1: 55.1610	acc@5: 73.1801	
2023-03-18 08:30:22,502 - INFO - Train: [29/90][3900/3907]	eta 0:00:01 lr 0.03118386	time 0.1746 (0.1803)	loss 3.1208 (4.2276)	acc@1: 58.3748	acc@5: 80.1710	
2023-03-18 08:30:23,716 - INFO - EPOCH 29 training takes 0:11:44
2023-03-18 08:30:25,179 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp/fold1_latest.pth saved !!!
2023-03-18 08:30:25,179 - INFO - **********latest test***********
2023-03-18 08:30:25,179 - INFO - eval epoch 29
2023-03-18 08:30:25,884 - INFO - Test: [0/782]	Time 0.702 (0.702)	Loss 2.7087 (2.7087)	Acc@1 60.938 (60.938)	Acc@5 88.281 (88.281)
2023-03-18 08:32:35,054 - INFO - Test: [200/782]	Time 0.656 (0.646)	Loss 3.0485 (3.1273)	Acc@1 60.938 (58.205)	Acc@5 77.344 (81.145)
2023-03-18 08:34:44,927 - INFO - Test: [400/782]	Time 0.655 (0.648)	Loss 2.8793 (3.0908)	Acc@1 67.969 (59.077)	Acc@5 82.812 (81.819)
2023-03-18 08:36:54,609 - INFO - Test: [600/782]	Time 0.616 (0.648)	Loss 3.1652 (3.0556)	Acc@1 58.594 (59.930)	Acc@5 79.688 (82.377)
2023-03-18 08:38:50,155 - INFO -  * Acc@1 60.518 Acc@5 82.869
2023-03-18 08:38:50,156 - INFO - Max accuracy: 60.5180%
2023-03-18 08:38:51,605 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp/fold1_best.pth saved !!!
2023-03-18 08:38:51,605 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp
2023-03-18 08:38:53,678 - INFO - Train: [30/90][0/3907]	eta 2:14:41 lr 0.03059839	time 2.0684 (2.0684)	loss 3.3455 (3.3455)	acc@1: 65.2645	acc@5: 79.9198	
2023-03-18 08:39:48,055 - INFO - Train: [30/90][300/3907]	eta 0:11:16 lr 0.03059839	time 0.1950 (0.1875)	loss 2.3881 (4.0271)	acc@1: 76.5554	acc@5: 89.0542	
2023-03-18 08:40:42,472 - INFO - Train: [30/90][600/3907]	eta 0:10:10 lr 0.03059839	time 0.1804 (0.1845)	loss 3.0091 (4.1487)	acc@1: 65.7824	acc@5: 82.8066	
2023-03-18 08:41:36,878 - INFO - Train: [30/90][900/3907]	eta 0:09:11 lr 0.03059839	time 0.1802 (0.1834)	loss 3.9504 (4.1592)	acc@1: 58.7544	acc@5: 77.2005	
2023-03-18 08:42:31,131 - INFO - Train: [30/90][1200/3907]	eta 0:08:14 lr 0.03059839	time 0.1867 (0.1828)	loss 6.0424 (4.1380)	acc@1: 18.9767	acc@5: 35.4963	
2023-03-18 08:43:25,211 - INFO - Train: [30/90][1500/3907]	eta 0:07:18 lr 0.03059839	time 0.1759 (0.1823)	loss 3.2250 (4.1482)	acc@1: 67.2247	acc@5: 81.4368	
2023-03-18 08:44:19,185 - INFO - Train: [30/90][1800/3907]	eta 0:06:23 lr 0.03059839	time 0.1818 (0.1819)	loss 4.4312 (4.1867)	acc@1: 49.0455	acc@5: 68.2661	
2023-03-18 08:45:13,563 - INFO - Train: [30/90][2100/3907]	eta 0:05:28 lr 0.03059839	time 0.1777 (0.1818)	loss 4.6264 (4.1905)	acc@1: 48.5743	acc@5: 64.9846	
2023-03-18 08:46:07,242 - INFO - Train: [30/90][2400/3907]	eta 0:04:33 lr 0.03059839	time 0.1923 (0.1814)	loss 4.2479 (4.1902)	acc@1: 48.9894	acc@5: 71.0356	
2023-03-18 08:47:01,492 - INFO - Train: [30/90][2700/3907]	eta 0:03:38 lr 0.03059839	time 0.1754 (0.1814)	loss 4.3164 (4.2098)	acc@1: 51.9551	acc@5: 71.3182	
2023-03-18 08:47:55,610 - INFO - Train: [30/90][3000/3907]	eta 0:02:44 lr 0.03059839	time 0.1754 (0.1813)	loss 5.6067 (4.2135)	acc@1: 32.3162	acc@5: 46.3152	
2023-03-18 08:48:49,902 - INFO - Train: [30/90][3300/3907]	eta 0:01:50 lr 0.03059839	time 0.1801 (0.1812)	loss 5.7036 (4.2133)	acc@1: 25.7037	acc@5: 43.2967	
2023-03-18 08:49:44,393 - INFO - Train: [30/90][3600/3907]	eta 0:00:55 lr 0.03059839	time 0.1750 (0.1813)	loss 3.6752 (4.2142)	acc@1: 55.6906	acc@5: 75.9203	
2023-03-18 08:50:38,772 - INFO - Train: [30/90][3900/3907]	eta 0:00:01 lr 0.03059839	time 0.1801 (0.1813)	loss 5.0264 (4.2187)	acc@1: 43.3118	acc@5: 55.0295	
2023-03-18 08:50:40,004 - INFO - EPOCH 30 training takes 0:11:48
2023-03-18 08:50:41,481 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp/fold1_latest.pth saved !!!
2023-03-18 08:50:41,482 - INFO - **********latest test***********
2023-03-18 08:50:41,483 - INFO - eval epoch 30
2023-03-18 08:50:42,132 - INFO - Test: [0/782]	Time 0.647 (0.647)	Loss 2.6271 (2.6271)	Acc@1 70.312 (70.312)	Acc@5 90.625 (90.625)
2023-03-18 08:52:51,726 - INFO - Test: [200/782]	Time 0.621 (0.648)	Loss 3.0308 (3.1313)	Acc@1 59.375 (58.462)	Acc@5 82.031 (81.192)
2023-03-18 08:55:00,967 - INFO - Test: [400/782]	Time 0.663 (0.647)	Loss 2.9586 (3.0927)	Acc@1 59.375 (59.338)	Acc@5 82.031 (81.924)
2023-03-18 08:57:11,478 - INFO - Test: [600/782]	Time 0.647 (0.649)	Loss 3.1019 (3.0594)	Acc@1 60.156 (60.119)	Acc@5 82.812 (82.446)
2023-03-18 08:59:07,606 - INFO -  * Acc@1 60.521 Acc@5 82.958
2023-03-18 08:59:07,607 - INFO - Max accuracy: 60.5210%
2023-03-18 08:59:09,036 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp/fold1_best.pth saved !!!
2023-03-18 08:59:09,036 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp
2023-03-18 08:59:10,952 - INFO - Train: [31/90][0/3907]	eta 2:04:14 lr 0.03000000	time 1.9079 (1.9079)	loss 2.6401 (2.6401)	acc@1: 77.3090	acc@5: 89.0225	
2023-03-18 09:00:05,672 - INFO - Train: [31/90][300/3907]	eta 0:11:18 lr 0.03000000	time 0.1799 (0.1881)	loss 2.6804 (3.9962)	acc@1: 69.3499	acc@5: 89.6083	
2023-03-18 09:00:59,967 - INFO - Train: [31/90][600/3907]	eta 0:10:10 lr 0.03000000	time 0.1750 (0.1846)	loss 4.6600 (4.0689)	acc@1: 52.2798	acc@5: 64.3285	
2023-03-18 09:01:53,902 - INFO - Train: [31/90][900/3907]	eta 0:09:10 lr 0.03000000	time 0.1756 (0.1830)	loss 3.2410 (4.0808)	acc@1: 66.6068	acc@5: 84.1734	
2023-03-18 09:02:47,840 - INFO - Train: [31/90][1200/3907]	eta 0:08:13 lr 0.03000000	time 0.1873 (0.1822)	loss 4.9792 (4.1183)	acc@1: 46.9821	acc@5: 62.9449	
2023-03-18 09:03:41,897 - INFO - Train: [31/90][1500/3907]	eta 0:07:17 lr 0.03000000	time 0.1749 (0.1818)	loss 4.2323 (4.1387)	acc@1: 53.7840	acc@5: 72.2928	
2023-03-18 09:04:35,530 - INFO - Train: [31/90][1800/3907]	eta 0:06:21 lr 0.03000000	time 0.1752 (0.1813)	loss 5.8870 (4.1472)	acc@1: 20.6484	acc@5: 39.6223	
2023-03-18 09:05:29,516 - INFO - Train: [31/90][2100/3907]	eta 0:05:27 lr 0.03000000	time 0.1828 (0.1811)	loss 3.1808 (4.1499)	acc@1: 61.5940	acc@5: 82.8857	
2023-03-18 09:06:23,582 - INFO - Train: [31/90][2400/3907]	eta 0:04:32 lr 0.03000000	time 0.1755 (0.1810)	loss 5.8752 (4.1616)	acc@1: 20.1681	acc@5: 36.2191	
2023-03-18 09:07:17,240 - INFO - Train: [31/90][2700/3907]	eta 0:03:38 lr 0.03000000	time 0.1775 (0.1807)	loss 5.9530 (4.1668)	acc@1: 20.7976	acc@5: 35.8764	
2023-03-18 09:08:11,070 - INFO - Train: [31/90][3000/3907]	eta 0:02:43 lr 0.03000000	time 0.1760 (0.1806)	loss 4.8500 (4.1828)	acc@1: 44.7018	acc@5: 61.0152	
2023-03-18 09:09:05,270 - INFO - Train: [31/90][3300/3907]	eta 0:01:49 lr 0.03000000	time 0.1779 (0.1806)	loss 4.2257 (4.1765)	acc@1: 56.6379	acc@5: 72.6298	
2023-03-18 09:09:59,144 - INFO - Train: [31/90][3600/3907]	eta 0:00:55 lr 0.03000000	time 0.1757 (0.1805)	loss 5.1071 (4.1966)	acc@1: 34.1544	acc@5: 58.1375	
2023-03-18 09:10:52,879 - INFO - Train: [31/90][3900/3907]	eta 0:00:01 lr 0.03000000	time 0.1747 (0.1804)	loss 3.0216 (4.2051)	acc@1: 64.1180	acc@5: 86.5206	
2023-03-18 09:10:54,091 - INFO - EPOCH 31 training takes 0:11:45
2023-03-18 09:10:55,555 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp/fold1_latest.pth saved !!!
2023-03-18 09:10:55,556 - INFO - **********latest test***********
2023-03-18 09:10:55,558 - INFO - eval epoch 31
2023-03-18 09:10:56,237 - INFO - Test: [0/782]	Time 0.677 (0.677)	Loss 2.6815 (2.6815)	Acc@1 65.625 (65.625)	Acc@5 86.719 (86.719)
2023-03-18 09:13:03,489 - INFO - Test: [200/782]	Time 0.633 (0.636)	Loss 2.9320 (3.0821)	Acc@1 56.250 (59.157)	Acc@5 84.375 (81.565)
2023-03-18 09:15:12,532 - INFO - Test: [400/782]	Time 0.661 (0.641)	Loss 2.9545 (3.0513)	Acc@1 60.156 (59.852)	Acc@5 80.469 (82.115)
2023-03-18 09:17:22,815 - INFO - Test: [600/782]	Time 0.649 (0.644)	Loss 3.0798 (3.0138)	Acc@1 54.688 (60.775)	Acc@5 83.594 (82.738)
2023-03-18 09:19:17,416 - INFO -  * Acc@1 61.248 Acc@5 83.231
2023-03-18 09:19:17,417 - INFO - Max accuracy: 61.2480%
2023-03-18 09:19:18,889 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp/fold1_best.pth saved !!!
2023-03-18 09:19:18,890 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp
2023-03-18 09:19:20,944 - INFO - Train: [32/90][0/3907]	eta 2:13:28 lr 0.02938943	time 2.0499 (2.0499)	loss 3.2976 (3.2976)	acc@1: 62.4063	acc@5: 84.6804	
2023-03-18 09:20:15,455 - INFO - Train: [32/90][300/3907]	eta 0:11:17 lr 0.02938943	time 0.1881 (0.1879)	loss 4.1857 (4.1578)	acc@1: 53.8413	acc@5: 70.3795	
2023-03-18 09:21:08,959 - INFO - Train: [32/90][600/3907]	eta 0:10:05 lr 0.02938943	time 0.1763 (0.1831)	loss 5.5129 (4.1309)	acc@1: 26.8044	acc@5: 48.1381	
2023-03-18 09:22:03,105 - INFO - Train: [32/90][900/3907]	eta 0:09:08 lr 0.02938943	time 0.1873 (0.1822)	loss 3.0754 (4.0888)	acc@1: 65.8386	acc@5: 80.3808	
2023-03-18 09:22:57,276 - INFO - Train: [32/90][1200/3907]	eta 0:08:12 lr 0.02938943	time 0.1866 (0.1818)	loss 4.9155 (4.1423)	acc@1: 46.5038	acc@5: 59.6203	
2023-03-18 09:23:51,013 - INFO - Train: [32/90][1500/3907]	eta 0:07:16 lr 0.02938943	time 0.1767 (0.1813)	loss 3.3183 (4.1538)	acc@1: 63.3563	acc@5: 77.0841	
2023-03-18 09:24:44,779 - INFO - Train: [32/90][1800/3907]	eta 0:06:21 lr 0.02938943	time 0.1747 (0.1809)	loss 4.3933 (4.1595)	acc@1: 49.3049	acc@5: 67.2520	
2023-03-18 09:25:38,447 - INFO - Train: [32/90][2100/3907]	eta 0:05:26 lr 0.02938943	time 0.1756 (0.1806)	loss 6.1593 (4.1680)	acc@1: 20.3919	acc@5: 33.6046	
2023-03-18 09:26:32,348 - INFO - Train: [32/90][2400/3907]	eta 0:04:32 lr 0.02938943	time 0.1750 (0.1805)	loss 2.8330 (4.1660)	acc@1: 68.6700	acc@5: 85.8372	
2023-03-18 09:27:26,318 - INFO - Train: [32/90][2700/3907]	eta 0:03:37 lr 0.02938943	time 0.1792 (0.1805)	loss 2.8637 (4.1850)	acc@1: 64.8437	acc@5: 85.9375	
2023-03-18 09:28:19,948 - INFO - Train: [32/90][3000/3907]	eta 0:02:43 lr 0.02938943	time 0.1824 (0.1803)	loss 3.5868 (4.1775)	acc@1: 59.2244	acc@5: 76.0121	
2023-03-18 09:29:13,516 - INFO - Train: [32/90][3300/3907]	eta 0:01:49 lr 0.02938943	time 0.1807 (0.1801)	loss 3.2667 (4.1696)	acc@1: 60.3525	acc@5: 81.9707	
2023-03-18 09:30:07,409 - INFO - Train: [32/90][3600/3907]	eta 0:00:55 lr 0.02938943	time 0.1751 (0.1801)	loss 5.4495 (4.1726)	acc@1: 35.3484	acc@5: 49.5850	
2023-03-18 09:31:01,656 - INFO - Train: [32/90][3900/3907]	eta 0:00:01 lr 0.02938943	time 0.1743 (0.1801)	loss 3.4129 (4.1763)	acc@1: 59.1868	acc@5: 77.9065	
2023-03-18 09:31:02,851 - INFO - EPOCH 32 training takes 0:11:43
2023-03-18 09:31:04,308 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp/fold1_latest.pth saved !!!
2023-03-18 09:31:04,308 - INFO - **********latest test***********
2023-03-18 09:31:04,308 - INFO - eval epoch 32
2023-03-18 09:31:04,998 - INFO - Test: [0/782]	Time 0.689 (0.689)	Loss 2.6930 (2.6930)	Acc@1 64.844 (64.844)	Acc@5 89.844 (89.844)
2023-03-18 09:33:11,997 - INFO - Test: [200/782]	Time 0.638 (0.635)	Loss 2.9347 (3.0834)	Acc@1 62.500 (59.698)	Acc@5 85.156 (81.732)
2023-03-18 09:35:20,045 - INFO - Test: [400/782]	Time 0.629 (0.638)	Loss 2.8980 (3.0477)	Acc@1 61.719 (60.388)	Acc@5 80.469 (82.489)
2023-03-18 09:37:28,660 - INFO - Test: [600/782]	Time 0.628 (0.640)	Loss 3.1037 (3.0104)	Acc@1 60.156 (61.253)	Acc@5 80.469 (83.117)
2023-03-18 09:39:22,863 - INFO -  * Acc@1 61.819 Acc@5 83.627
2023-03-18 09:39:22,863 - INFO - Max accuracy: 61.8190%
2023-03-18 09:39:24,298 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp/fold1_best.pth saved !!!
2023-03-18 09:39:24,298 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp
2023-03-18 09:39:26,285 - INFO - Train: [33/90][0/3907]	eta 2:09:11 lr 0.02876742	time 1.9840 (1.9840)	loss 5.8494 (5.8494)	acc@1: 21.4007	acc@5: 37.9385	
2023-03-18 09:40:20,842 - INFO - Train: [33/90][300/3907]	eta 0:11:17 lr 0.02876742	time 0.1798 (0.1878)	loss 2.8555 (4.1479)	acc@1: 62.3153	acc@5: 86.9363	
2023-03-18 09:41:14,868 - INFO - Train: [33/90][600/3907]	eta 0:10:08 lr 0.02876742	time 0.1969 (0.1840)	loss 3.8167 (4.1181)	acc@1: 60.3479	acc@5: 74.8932	
2023-03-18 09:42:08,825 - INFO - Train: [33/90][900/3907]	eta 0:09:09 lr 0.02876742	time 0.1814 (0.1826)	loss 4.5778 (4.1425)	acc@1: 51.1286	acc@5: 64.5499	
2023-03-18 09:43:02,685 - INFO - Train: [33/90][1200/3907]	eta 0:08:12 lr 0.02876742	time 0.1755 (0.1818)	loss 6.0783 (4.1576)	acc@1: 22.1307	acc@5: 33.9955	
2023-03-18 09:43:56,629 - INFO - Train: [33/90][1500/3907]	eta 0:07:16 lr 0.02876742	time 0.1823 (0.1814)	loss 3.7396 (4.1585)	acc@1: 60.9406	acc@5: 77.0514	
2023-03-18 09:44:49,964 - INFO - Train: [33/90][1800/3907]	eta 0:06:20 lr 0.02876742	time 0.1759 (0.1808)	loss 2.8648 (4.1677)	acc@1: 64.8426	acc@5: 84.3735	
2023-03-18 09:45:43,246 - INFO - Train: [33/90][2100/3907]	eta 0:05:25 lr 0.02876742	time 0.1795 (0.1804)	loss 3.1031 (4.1681)	acc@1: 65.8518	acc@5: 84.9947	
2023-03-18 09:46:37,270 - INFO - Train: [33/90][2400/3907]	eta 0:04:31 lr 0.02876742	time 0.1866 (0.1803)	loss 2.8850 (4.1679)	acc@1: 62.7278	acc@5: 86.7347	
2023-03-18 09:47:31,084 - INFO - Train: [33/90][2700/3907]	eta 0:03:37 lr 0.02876742	time 0.1749 (0.1802)	loss 2.8593 (4.1690)	acc@1: 58.5359	acc@5: 85.0722	
2023-03-18 09:48:25,013 - INFO - Train: [33/90][3000/3907]	eta 0:02:43 lr 0.02876742	time 0.1754 (0.1802)	loss 3.0828 (4.1684)	acc@1: 58.2106	acc@5: 83.0574	
2023-03-18 09:49:19,025 - INFO - Train: [33/90][3300/3907]	eta 0:01:49 lr 0.02876742	time 0.1768 (0.1802)	loss 4.6417 (4.1672)	acc@1: 48.3622	acc@5: 64.2225	
2023-03-18 09:50:13,023 - INFO - Train: [33/90][3600/3907]	eta 0:00:55 lr 0.02876742	time 0.1770 (0.1801)	loss 5.5950 (4.1783)	acc@1: 34.5043	acc@5: 47.4781	
2023-03-18 09:51:07,695 - INFO - Train: [33/90][3900/3907]	eta 0:00:01 lr 0.02876742	time 0.1780 (0.1803)	loss 4.2148 (4.1865)	acc@1: 53.4770	acc@5: 72.3067	
2023-03-18 09:51:08,883 - INFO - EPOCH 33 training takes 0:11:44
2023-03-18 09:51:10,354 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp/fold1_latest.pth saved !!!
2023-03-18 09:51:10,354 - INFO - **********latest test***********
2023-03-18 09:51:10,354 - INFO - eval epoch 33
2023-03-18 09:51:11,044 - INFO - Test: [0/782]	Time 0.688 (0.688)	Loss 2.7281 (2.7281)	Acc@1 60.938 (60.938)	Acc@5 89.844 (89.844)
2023-03-18 09:53:20,844 - INFO - Test: [200/782]	Time 0.641 (0.649)	Loss 3.0416 (3.1389)	Acc@1 63.281 (58.489)	Acc@5 79.688 (81.643)
2023-03-18 09:55:29,692 - INFO - Test: [400/782]	Time 0.659 (0.647)	Loss 3.0447 (3.1040)	Acc@1 62.500 (59.490)	Acc@5 81.250 (82.185)
2023-03-18 09:57:38,528 - INFO - Test: [600/782]	Time 0.629 (0.646)	Loss 3.1339 (3.0756)	Acc@1 57.031 (60.151)	Acc@5 82.812 (82.675)
2023-03-18 09:59:32,788 - INFO -  * Acc@1 60.740 Acc@5 83.168
2023-03-18 09:59:32,788 - INFO - Max accuracy: 61.8190%
2023-03-18 09:59:32,788 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp
2023-03-18 09:59:34,691 - INFO - Train: [34/90][0/3907]	eta 2:03:44 lr 0.02813473	time 1.9004 (1.9004)	loss 3.9580 (3.9580)	acc@1: 54.4641	acc@5: 75.9279	
2023-03-18 10:00:28,917 - INFO - Train: [34/90][300/3907]	eta 0:11:12 lr 0.02813473	time 0.1760 (0.1865)	loss 2.7376 (4.0135)	acc@1: 69.0691	acc@5: 85.3651	
2023-03-18 10:01:23,127 - INFO - Train: [34/90][600/3907]	eta 0:10:07 lr 0.02813473	time 0.1750 (0.1836)	loss 2.9588 (4.0580)	acc@1: 62.2274	acc@5: 81.6724	
2023-03-18 10:02:17,222 - INFO - Train: [34/90][900/3907]	eta 0:09:08 lr 0.02813473	time 0.1771 (0.1825)	loss 3.5027 (4.1167)	acc@1: 61.5729	acc@5: 77.5094	
2023-03-18 10:03:11,241 - INFO - Train: [34/90][1200/3907]	eta 0:08:12 lr 0.02813473	time 0.1754 (0.1819)	loss 4.0395 (4.1267)	acc@1: 57.5206	acc@5: 71.3810	
2023-03-18 10:04:05,283 - INFO - Train: [34/90][1500/3907]	eta 0:07:16 lr 0.02813473	time 0.1759 (0.1815)	loss 4.9546 (4.1049)	acc@1: 42.7306	acc@5: 57.2605	
2023-03-18 10:04:59,730 - INFO - Train: [34/90][1800/3907]	eta 0:06:22 lr 0.02813473	time 0.1768 (0.1815)	loss 3.8151 (4.0970)	acc@1: 59.5679	acc@5: 73.5839	
2023-03-18 10:05:53,681 - INFO - Train: [34/90][2100/3907]	eta 0:05:27 lr 0.02813473	time 0.1757 (0.1813)	loss 3.6574 (4.1038)	acc@1: 63.3174	acc@5: 77.1453	
2023-03-18 10:06:48,104 - INFO - Train: [34/90][2400/3907]	eta 0:04:33 lr 0.02813473	time 0.1923 (0.1813)	loss 5.8654 (4.1078)	acc@1: 29.6667	acc@5: 41.0447	
2023-03-18 10:07:42,210 - INFO - Train: [34/90][2700/3907]	eta 0:03:38 lr 0.02813473	time 0.1768 (0.1812)	loss 2.7429 (4.1153)	acc@1: 68.6746	acc@5: 85.8433	
2023-03-18 10:08:36,441 - INFO - Train: [34/90][3000/3907]	eta 0:02:44 lr 0.02813473	time 0.1830 (0.1812)	loss 3.6554 (4.1135)	acc@1: 57.4160	acc@5: 77.7659	
2023-03-18 10:09:30,777 - INFO - Train: [34/90][3300/3907]	eta 0:01:49 lr 0.02813473	time 0.1887 (0.1811)	loss 6.0460 (4.1325)	acc@1: 21.3079	acc@5: 36.0279	
2023-03-18 10:10:25,458 - INFO - Train: [34/90][3600/3907]	eta 0:00:55 lr 0.02813473	time 0.1887 (0.1812)	loss 6.0161 (4.1332)	acc@1: 16.8429	acc@5: 31.6735	
2023-03-18 10:11:19,819 - INFO - Train: [34/90][3900/3907]	eta 0:00:01 lr 0.02813473	time 0.1749 (0.1812)	loss 4.1623 (4.1341)	acc@1: 51.9357	acc@5: 73.7615	
2023-03-18 10:11:21,084 - INFO - EPOCH 34 training takes 0:11:48
2023-03-18 10:11:22,552 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp/fold1_latest.pth saved !!!
2023-03-18 10:11:22,553 - INFO - **********latest test***********
2023-03-18 10:11:22,553 - INFO - eval epoch 34
2023-03-18 10:11:23,238 - INFO - Test: [0/782]	Time 0.685 (0.685)	Loss 2.7072 (2.7072)	Acc@1 67.969 (67.969)	Acc@5 89.062 (89.062)
2023-03-18 10:13:29,498 - INFO - Test: [200/782]	Time 0.652 (0.632)	Loss 2.9032 (3.0374)	Acc@1 62.500 (60.735)	Acc@5 81.250 (82.840)
2023-03-18 10:15:38,079 - INFO - Test: [400/782]	Time 0.651 (0.637)	Loss 2.9014 (3.0099)	Acc@1 60.938 (61.649)	Acc@5 85.938 (83.251)
2023-03-18 10:17:48,765 - INFO - Test: [600/782]	Time 0.639 (0.643)	Loss 3.0387 (2.9774)	Acc@1 61.719 (62.367)	Acc@5 78.906 (83.722)
2023-03-18 10:19:43,784 - INFO -  * Acc@1 62.908 Acc@5 84.201
2023-03-18 10:19:43,784 - INFO - Max accuracy: 62.9080%
2023-03-18 10:19:45,224 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp/fold1_best.pth saved !!!
2023-03-18 10:19:45,225 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp
2023-03-18 10:19:47,269 - INFO - Train: [35/90][0/3907]	eta 2:12:53 lr 0.02749213	time 2.0409 (2.0409)	loss 2.7683 (2.7683)	acc@1: 74.3232	acc@5: 83.6127	
2023-03-18 10:20:41,652 - INFO - Train: [35/90][300/3907]	eta 0:11:16 lr 0.02749213	time 0.1957 (0.1874)	loss 4.9720 (4.1435)	acc@1: 40.5225	acc@5: 60.3732	
2023-03-18 10:21:36,627 - INFO - Train: [35/90][600/3907]	eta 0:10:12 lr 0.02749213	time 0.1747 (0.1854)	loss 4.6527 (4.1448)	acc@1: 44.5845	acc@5: 59.9619	
2023-03-18 10:22:31,075 - INFO - Train: [35/90][900/3907]	eta 0:09:13 lr 0.02749213	time 0.1750 (0.1841)	loss 3.0218 (4.1439)	acc@1: 65.5044	acc@5: 79.5410	
2023-03-18 10:23:25,377 - INFO - Train: [35/90][1200/3907]	eta 0:08:16 lr 0.02749213	time 0.2023 (0.1833)	loss 2.7410 (4.1208)	acc@1: 67.9060	acc@5: 86.6401	
2023-03-18 10:24:20,195 - INFO - Train: [35/90][1500/3907]	eta 0:07:20 lr 0.02749213	time 0.1913 (0.1832)	loss 3.2995 (4.1056)	acc@1: 58.9931	acc@5: 80.1701	
2023-03-18 10:25:14,789 - INFO - Train: [35/90][1800/3907]	eta 0:06:25 lr 0.02749213	time 0.1817 (0.1830)	loss 2.8184 (4.1142)	acc@1: 64.6984	acc@5: 87.3032	
2023-03-18 10:26:09,824 - INFO - Train: [35/90][2100/3907]	eta 0:05:30 lr 0.02749213	time 0.1762 (0.1830)	loss 5.1167 (4.0979)	acc@1: 41.2292	acc@5: 57.6596	
2023-03-18 10:27:04,132 - INFO - Train: [35/90][2400/3907]	eta 0:04:35 lr 0.02749213	time 0.1750 (0.1828)	loss 5.3267 (4.1131)	acc@1: 28.2485	acc@5: 51.3689	
2023-03-18 10:27:57,901 - INFO - Train: [35/90][2700/3907]	eta 0:03:40 lr 0.02749213	time 0.1762 (0.1824)	loss 5.7951 (4.1230)	acc@1: 22.6497	acc@5: 37.4172	
2023-03-18 10:28:51,682 - INFO - Train: [35/90][3000/3907]	eta 0:02:45 lr 0.02749213	time 0.1749 (0.1821)	loss 4.7275 (4.1312)	acc@1: 46.4826	acc@5: 63.3778	
2023-03-18 10:29:45,551 - INFO - Train: [35/90][3300/3907]	eta 0:01:50 lr 0.02749213	time 0.1772 (0.1819)	loss 6.0506 (4.1394)	acc@1: 17.9168	acc@5: 35.1736	
2023-03-18 10:30:39,201 - INFO - Train: [35/90][3600/3907]	eta 0:00:55 lr 0.02749213	time 0.1750 (0.1816)	loss 2.8952 (4.1459)	acc@1: 66.8977	acc@5: 84.7889	
2023-03-18 10:31:32,863 - INFO - Train: [35/90][3900/3907]	eta 0:00:01 lr 0.02749213	time 0.1747 (0.1814)	loss 2.9231 (4.1569)	acc@1: 62.1571	acc@5: 81.5798	
2023-03-18 10:31:34,066 - INFO - EPOCH 35 training takes 0:11:48
2023-03-18 10:31:35,516 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp/fold1_latest.pth saved !!!
2023-03-18 10:31:35,517 - INFO - **********latest test***********
2023-03-18 10:31:35,517 - INFO - eval epoch 35
2023-03-18 10:31:36,166 - INFO - Test: [0/782]	Time 0.648 (0.648)	Loss 2.6774 (2.6774)	Acc@1 62.500 (62.500)	Acc@5 89.844 (89.844)
2023-03-18 10:33:41,251 - INFO - Test: [200/782]	Time 0.643 (0.626)	Loss 2.9817 (3.0876)	Acc@1 65.625 (59.157)	Acc@5 82.031 (81.868)
2023-03-18 10:35:46,318 - INFO - Test: [400/782]	Time 0.630 (0.625)	Loss 2.9894 (3.0510)	Acc@1 61.719 (60.170)	Acc@5 83.594 (82.501)
2023-03-18 10:37:51,903 - INFO - Test: [600/782]	Time 0.621 (0.626)	Loss 3.0809 (3.0143)	Acc@1 57.812 (61.114)	Acc@5 82.812 (83.132)
2023-03-18 10:39:45,670 - INFO -  * Acc@1 61.636 Acc@5 83.599
2023-03-18 10:39:45,671 - INFO - Max accuracy: 62.9080%
2023-03-18 10:39:45,671 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp
2023-03-18 10:39:47,735 - INFO - Train: [36/90][0/3907]	eta 2:14:12 lr 0.02684040	time 2.0610 (2.0610)	loss 4.9608 (4.9608)	acc@1: 42.0464	acc@5: 58.4994	
2023-03-18 10:40:41,910 - INFO - Train: [36/90][300/3907]	eta 0:11:13 lr 0.02684040	time 0.1833 (0.1868)	loss 6.2133 (4.0073)	acc@1: 14.6648	acc@5: 31.9934	
2023-03-18 10:41:36,324 - INFO - Train: [36/90][600/3907]	eta 0:10:08 lr 0.02684040	time 0.1790 (0.1841)	loss 5.3707 (4.0226)	acc@1: 35.2659	acc@5: 53.2894	
2023-03-18 10:42:30,350 - INFO - Train: [36/90][900/3907]	eta 0:09:09 lr 0.02684040	time 0.1824 (0.1828)	loss 4.8485 (4.0356)	acc@1: 44.7173	acc@5: 62.5301	
2023-03-18 10:43:24,363 - INFO - Train: [36/90][1200/3907]	eta 0:08:12 lr 0.02684040	time 0.1751 (0.1821)	loss 2.5777 (4.0372)	acc@1: 76.2544	acc@5: 90.2603	
2023-03-18 10:44:18,427 - INFO - Train: [36/90][1500/3907]	eta 0:07:17 lr 0.02684040	time 0.1949 (0.1817)	loss 3.7084 (4.0707)	acc@1: 63.0835	acc@5: 79.1157	
2023-03-18 10:45:12,824 - INFO - Train: [36/90][1800/3907]	eta 0:06:22 lr 0.02684040	time 0.1755 (0.1816)	loss 3.0275 (4.0962)	acc@1: 64.0440	acc@5: 78.1024	
2023-03-18 10:46:07,338 - INFO - Train: [36/90][2100/3907]	eta 0:05:28 lr 0.02684040	time 0.1750 (0.1817)	loss 3.2041 (4.0828)	acc@1: 63.6179	acc@5: 81.0370	
2023-03-18 10:47:02,030 - INFO - Train: [36/90][2400/3907]	eta 0:04:33 lr 0.02684040	time 0.1771 (0.1817)	loss 2.8563 (4.0928)	acc@1: 68.1026	acc@5: 87.7695	
2023-03-18 10:47:56,217 - INFO - Train: [36/90][2700/3907]	eta 0:03:39 lr 0.02684040	time 0.1759 (0.1816)	loss 2.9308 (4.0959)	acc@1: 68.4631	acc@5: 85.2092	
2023-03-18 10:48:50,709 - INFO - Train: [36/90][3000/3907]	eta 0:02:44 lr 0.02684040	time 0.1783 (0.1816)	loss 4.1765 (4.1001)	acc@1: 56.9069	acc@5: 70.5802	
2023-03-18 10:49:44,783 - INFO - Train: [36/90][3300/3907]	eta 0:01:50 lr 0.02684040	time 0.1762 (0.1815)	loss 3.0968 (4.0904)	acc@1: 63.1104	acc@5: 80.5809	
2023-03-18 10:50:39,290 - INFO - Train: [36/90][3600/3907]	eta 0:00:55 lr 0.02684040	time 0.1804 (0.1815)	loss 4.5919 (4.0906)	acc@1: 48.9648	acc@5: 63.2758	
2023-03-18 10:51:33,969 - INFO - Train: [36/90][3900/3907]	eta 0:00:01 lr 0.02684040	time 0.1793 (0.1816)	loss 6.0843 (4.1052)	acc@1: 21.4609	acc@5: 34.4840	
2023-03-18 10:51:35,196 - INFO - EPOCH 36 training takes 0:11:49
2023-03-18 10:51:36,659 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp/fold1_latest.pth saved !!!
2023-03-18 10:51:36,660 - INFO - **********latest test***********
2023-03-18 10:51:36,660 - INFO - eval epoch 36
2023-03-18 10:51:37,299 - INFO - Test: [0/782]	Time 0.638 (0.638)	Loss 2.5347 (2.5347)	Acc@1 70.312 (70.312)	Acc@5 89.844 (89.844)
2023-03-18 10:53:45,051 - INFO - Test: [200/782]	Time 0.669 (0.639)	Loss 3.0199 (2.9929)	Acc@1 59.375 (60.751)	Acc@5 81.250 (82.933)
2023-03-18 10:55:52,621 - INFO - Test: [400/782]	Time 0.634 (0.638)	Loss 2.7747 (2.9526)	Acc@1 65.625 (61.758)	Acc@5 85.938 (83.576)
2023-03-18 10:58:02,279 - INFO - Test: [600/782]	Time 0.646 (0.642)	Loss 3.1618 (2.9191)	Acc@1 57.031 (62.504)	Acc@5 79.688 (84.086)
2023-03-18 10:59:56,766 - INFO -  * Acc@1 62.894 Acc@5 84.516
2023-03-18 10:59:56,766 - INFO - Max accuracy: 62.9080%
2023-03-18 10:59:56,766 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp
2023-03-18 10:59:58,801 - INFO - Train: [37/90][0/3907]	eta 2:12:18 lr 0.02618034	time 2.0319 (2.0319)	loss 3.3307 (3.3307)	acc@1: 62.2407	acc@5: 79.4793	
2023-03-18 11:00:53,734 - INFO - Train: [37/90][300/3907]	eta 0:11:22 lr 0.02618034	time 0.1819 (0.1892)	loss 3.2272 (3.9131)	acc@1: 70.1761	acc@5: 81.9144	
2023-03-18 11:01:48,417 - INFO - Train: [37/90][600/3907]	eta 0:10:14 lr 0.02618034	time 0.1798 (0.1858)	loss 5.9780 (3.9168)	acc@1: 20.2234	acc@5: 36.3395	
2023-03-18 11:02:42,358 - INFO - Train: [37/90][900/3907]	eta 0:09:12 lr 0.02618034	time 0.1756 (0.1838)	loss 3.6718 (3.9363)	acc@1: 60.9285	acc@5: 75.9814	
2023-03-18 11:03:35,918 - INFO - Train: [37/90][1200/3907]	eta 0:08:13 lr 0.02618034	time 0.1758 (0.1825)	loss 5.8369 (3.9460)	acc@1: 27.2538	acc@5: 42.6361	
2023-03-18 11:04:30,357 - INFO - Train: [37/90][1500/3907]	eta 0:07:18 lr 0.02618034	time 0.1800 (0.1823)	loss 4.9144 (3.9733)	acc@1: 43.2972	acc@5: 60.5942	
2023-03-18 11:05:25,290 - INFO - Train: [37/90][1800/3907]	eta 0:06:24 lr 0.02618034	time 0.1818 (0.1824)	loss 4.2318 (4.0033)	acc@1: 53.7512	acc@5: 69.1315	
2023-03-18 11:06:20,018 - INFO - Train: [37/90][2100/3907]	eta 0:05:29 lr 0.02618034	time 0.1824 (0.1824)	loss 4.6174 (4.0225)	acc@1: 48.6440	acc@5: 65.8849	
2023-03-18 11:07:14,454 - INFO - Train: [37/90][2400/3907]	eta 0:04:34 lr 0.02618034	time 0.1827 (0.1823)	loss 2.7899 (4.0480)	acc@1: 68.8992	acc@5: 86.7027	
2023-03-18 11:08:08,904 - INFO - Train: [37/90][2700/3907]	eta 0:03:39 lr 0.02618034	time 0.1754 (0.1822)	loss 5.8203 (4.0619)	acc@1: 26.0597	acc@5: 41.2379	
2023-03-18 11:09:03,363 - INFO - Train: [37/90][3000/3907]	eta 0:02:45 lr 0.02618034	time 0.1762 (0.1821)	loss 4.3530 (4.0734)	acc@1: 57.0666	acc@5: 70.6399	
2023-03-18 11:09:57,916 - INFO - Train: [37/90][3300/3907]	eta 0:01:50 lr 0.02618034	time 0.1781 (0.1821)	loss 3.0427 (4.0802)	acc@1: 60.0998	acc@5: 86.6374	
2023-03-18 11:10:52,690 - INFO - Train: [37/90][3600/3907]	eta 0:00:55 lr 0.02618034	time 0.1844 (0.1821)	loss 2.9845 (4.0867)	acc@1: 68.4800	acc@5: 85.9752	
2023-03-18 11:11:44,791 - INFO - Train: [37/90][3900/3907]	eta 0:00:01 lr 0.02618034	time 0.1674 (0.1815)	loss 3.0565 (4.0928)	acc@1: 61.0380	acc@5: 83.9272	
2023-03-18 11:11:45,926 - INFO - EPOCH 37 training takes 0:11:49
2023-03-18 11:11:47,857 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp/fold1_latest.pth saved !!!
2023-03-18 11:11:47,859 - INFO - **********latest test***********
2023-03-18 11:11:47,859 - INFO - eval epoch 37
2023-03-18 11:11:48,549 - INFO - Test: [0/782]	Time 0.687 (0.687)	Loss 2.5208 (2.5208)	Acc@1 65.625 (65.625)	Acc@5 94.531 (94.531)
2023-03-18 11:14:00,977 - INFO - Test: [200/782]	Time 0.652 (0.662)	Loss 2.9503 (3.0609)	Acc@1 63.281 (60.405)	Acc@5 82.812 (82.952)
2023-03-18 11:16:12,302 - INFO - Test: [400/782]	Time 0.636 (0.659)	Loss 2.8695 (3.0259)	Acc@1 62.500 (61.333)	Acc@5 82.812 (83.487)
2023-03-18 11:18:24,745 - INFO - Test: [600/782]	Time 0.637 (0.660)	Loss 3.0805 (2.9855)	Acc@1 58.594 (62.328)	Acc@5 80.469 (84.044)
2023-03-18 11:20:21,167 - INFO -  * Acc@1 62.947 Acc@5 84.510
2023-03-18 11:20:21,167 - INFO - Max accuracy: 62.9470%
2023-03-18 11:20:22,598 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp/fold1_best.pth saved !!!
2023-03-18 11:20:22,598 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp
2023-03-18 11:20:24,628 - INFO - Train: [38/90][0/3907]	eta 2:11:55 lr 0.02551275	time 2.0261 (2.0261)	loss 2.6488 (2.6488)	acc@1: 72.4415	acc@5: 90.1666	
2023-03-18 11:21:19,668 - INFO - Train: [38/90][300/3907]	eta 0:11:23 lr 0.02551275	time 0.1754 (0.1896)	loss 3.7148 (4.0620)	acc@1: 57.6101	acc@5: 77.2997	
2023-03-18 11:22:15,022 - INFO - Train: [38/90][600/3907]	eta 0:10:18 lr 0.02551275	time 0.1947 (0.1871)	loss 4.7654 (4.0079)	acc@1: 46.5212	acc@5: 66.8451	
2023-03-18 11:23:10,540 - INFO - Train: [38/90][900/3907]	eta 0:09:20 lr 0.02551275	time 0.1852 (0.1864)	loss 4.4732 (4.0332)	acc@1: 50.0209	acc@5: 65.1588	
2023-03-18 11:24:05,766 - INFO - Train: [38/90][1200/3907]	eta 0:08:22 lr 0.02551275	time 0.1754 (0.1858)	loss 5.8296 (4.0235)	acc@1: 27.3279	acc@5: 41.2056	
2023-03-18 11:25:01,003 - INFO - Train: [38/90][1500/3907]	eta 0:07:26 lr 0.02551275	time 0.1782 (0.1855)	loss 2.8840 (4.0346)	acc@1: 64.5485	acc@5: 81.6577	
2023-03-18 11:25:56,566 - INFO - Train: [38/90][1800/3907]	eta 0:06:30 lr 0.02551275	time 0.1803 (0.1854)	loss 3.0013 (4.0454)	acc@1: 66.0833	acc@5: 85.2898	
2023-03-18 11:26:51,842 - INFO - Train: [38/90][2100/3907]	eta 0:05:34 lr 0.02551275	time 0.1798 (0.1853)	loss 5.8914 (4.0572)	acc@1: 18.8275	acc@5: 39.3547	
2023-03-18 11:27:46,939 - INFO - Train: [38/90][2400/3907]	eta 0:04:38 lr 0.02551275	time 0.1996 (0.1851)	loss 5.8091 (4.0681)	acc@1: 30.7220	acc@5: 42.1243	
2023-03-18 11:28:42,098 - INFO - Train: [38/90][2700/3907]	eta 0:03:43 lr 0.02551275	time 0.1752 (0.1849)	loss 2.6818 (4.0677)	acc@1: 66.9974	acc@5: 91.1468	
2023-03-18 11:29:37,420 - INFO - Train: [38/90][3000/3907]	eta 0:02:47 lr 0.02551275	time 0.1821 (0.1849)	loss 4.7582 (4.0730)	acc@1: 50.1047	acc@5: 64.7206	
2023-03-18 11:30:32,644 - INFO - Train: [38/90][3300/3907]	eta 0:01:52 lr 0.02551275	time 0.1785 (0.1848)	loss 5.4760 (4.0742)	acc@1: 31.5194	acc@5: 48.0809	
2023-03-18 11:31:27,747 - INFO - Train: [38/90][3600/3907]	eta 0:00:56 lr 0.02551275	time 0.1755 (0.1847)	loss 5.4453 (4.0800)	acc@1: 34.2763	acc@5: 47.4446	
2023-03-18 11:32:22,965 - INFO - Train: [38/90][3900/3907]	eta 0:00:01 lr 0.02551275	time 0.1804 (0.1847)	loss 3.1169 (4.0821)	acc@1: 65.9530	acc@5: 86.4212	
2023-03-18 11:32:24,190 - INFO - EPOCH 38 training takes 0:12:01
2023-03-18 11:32:25,668 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp/fold1_latest.pth saved !!!
2023-03-18 11:32:25,669 - INFO - **********latest test***********
2023-03-18 11:32:25,669 - INFO - eval epoch 38
2023-03-18 11:32:26,331 - INFO - Test: [0/782]	Time 0.661 (0.661)	Loss 2.6007 (2.6007)	Acc@1 67.969 (67.969)	Acc@5 89.062 (89.062)
2023-03-18 11:34:37,062 - INFO - Test: [200/782]	Time 0.657 (0.654)	Loss 2.8565 (3.0199)	Acc@1 61.719 (60.801)	Acc@5 84.375 (82.735)
2023-03-18 11:36:47,432 - INFO - Test: [400/782]	Time 0.657 (0.653)	Loss 2.9627 (2.9840)	Acc@1 61.719 (61.849)	Acc@5 80.469 (83.438)
2023-03-18 11:38:59,530 - INFO - Test: [600/782]	Time 0.692 (0.655)	Loss 3.0508 (2.9458)	Acc@1 58.594 (62.721)	Acc@5 83.594 (84.045)
2023-03-18 11:40:57,057 - INFO -  * Acc@1 63.122 Acc@5 84.458
2023-03-18 11:40:57,057 - INFO - Max accuracy: 63.1220%
2023-03-18 11:40:58,497 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp/fold1_best.pth saved !!!
2023-03-18 11:40:58,497 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp
2023-03-18 11:41:00,525 - INFO - Train: [39/90][0/3907]	eta 2:11:42 lr 0.02483844	time 2.0227 (2.0227)	loss 4.1834 (4.1834)	acc@1: 57.0302	acc@5: 70.9562	
2023-03-18 11:41:55,416 - INFO - Train: [39/90][300/3907]	eta 0:11:21 lr 0.02483844	time 0.1900 (0.1891)	loss 4.4747 (3.9514)	acc@1: 51.2569	acc@5: 67.8217	
2023-03-18 11:42:50,512 - INFO - Train: [39/90][600/3907]	eta 0:10:16 lr 0.02483844	time 0.1857 (0.1864)	loss 2.8638 (3.9761)	acc@1: 73.1084	acc@5: 86.6697	
2023-03-18 11:43:45,642 - INFO - Train: [39/90][900/3907]	eta 0:09:17 lr 0.02483844	time 0.1985 (0.1855)	loss 4.1060 (4.0116)	acc@1: 54.4350	acc@5: 69.8605	
2023-03-18 11:44:40,732 - INFO - Train: [39/90][1200/3907]	eta 0:08:20 lr 0.02483844	time 0.1823 (0.1850)	loss 3.2409 (4.0410)	acc@1: 65.2182	acc@5: 81.3150	
2023-03-18 11:45:35,870 - INFO - Train: [39/90][1500/3907]	eta 0:07:24 lr 0.02483844	time 0.1751 (0.1848)	loss 5.5780 (4.0533)	acc@1: 32.5214	acc@5: 47.2358	
2023-03-18 11:46:30,880 - INFO - Train: [39/90][1800/3907]	eta 0:06:28 lr 0.02483844	time 0.1801 (0.1845)	loss 2.7272 (4.0703)	acc@1: 72.6215	acc@5: 82.7728	
2023-03-18 11:47:25,841 - INFO - Train: [39/90][2100/3907]	eta 0:05:33 lr 0.02483844	time 0.1872 (0.1844)	loss 2.8421 (4.0686)	acc@1: 67.9111	acc@5: 84.1171	
2023-03-18 11:48:21,149 - INFO - Train: [39/90][2400/3907]	eta 0:04:37 lr 0.02483844	time 0.1886 (0.1844)	loss 5.1323 (4.0680)	acc@1: 42.1320	acc@5: 57.6693	
2023-03-18 11:49:16,232 - INFO - Train: [39/90][2700/3907]	eta 0:03:42 lr 0.02483844	time 0.1814 (0.1843)	loss 2.8127 (4.0666)	acc@1: 68.3478	acc@5: 85.2427	
2023-03-18 11:50:11,300 - INFO - Train: [39/90][3000/3907]	eta 0:02:47 lr 0.02483844	time 0.1866 (0.1842)	loss 4.3384 (4.0602)	acc@1: 48.7352	acc@5: 70.2123	
2023-03-18 11:51:06,645 - INFO - Train: [39/90][3300/3907]	eta 0:01:51 lr 0.02483844	time 0.1848 (0.1842)	loss 2.6714 (4.0613)	acc@1: 72.5484	acc@5: 88.7560	
2023-03-18 11:52:02,119 - INFO - Train: [39/90][3600/3907]	eta 0:00:56 lr 0.02483844	time 0.1908 (0.1843)	loss 3.8412 (4.0688)	acc@1: 56.0752	acc@5: 73.0887	
2023-03-18 11:52:57,619 - INFO - Train: [39/90][3900/3907]	eta 0:00:01 lr 0.02483844	time 0.1775 (0.1843)	loss 5.9181 (4.0712)	acc@1: 20.7875	acc@5: 36.4194	
2023-03-18 11:52:58,807 - INFO - EPOCH 39 training takes 0:12:00
2023-03-18 11:53:00,295 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp/fold1_latest.pth saved !!!
2023-03-18 11:53:00,295 - INFO - **********latest test***********
2023-03-18 11:53:00,295 - INFO - eval epoch 39
2023-03-18 11:53:00,977 - INFO - Test: [0/782]	Time 0.681 (0.681)	Loss 2.6130 (2.6130)	Acc@1 71.875 (71.875)	Acc@5 92.188 (92.188)
2023-03-18 11:55:14,283 - INFO - Test: [200/782]	Time 0.642 (0.667)	Loss 3.0163 (3.0410)	Acc@1 60.938 (60.654)	Acc@5 84.375 (82.657)
2023-03-18 11:57:29,635 - INFO - Test: [400/782]	Time 0.717 (0.672)	Loss 2.8541 (3.0046)	Acc@1 66.406 (61.578)	Acc@5 85.938 (83.311)
2023-03-18 11:59:51,505 - INFO - Test: [600/782]	Time 0.719 (0.684)	Loss 3.1138 (2.9683)	Acc@1 63.281 (62.487)	Acc@5 80.469 (83.875)
2023-03-18 12:01:56,325 - INFO -  * Acc@1 62.854 Acc@5 84.339
2023-03-18 12:01:56,326 - INFO - Max accuracy: 63.1220%
2023-03-18 12:01:56,326 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp
2023-03-18 12:01:58,386 - INFO - Train: [40/90][0/3907]	eta 2:13:59 lr 0.02415823	time 2.0577 (2.0577)	loss 3.3829 (3.3829)	acc@1: 65.6726	acc@5: 82.2711	
2023-03-18 12:02:53,457 - INFO - Train: [40/90][300/3907]	eta 0:11:24 lr 0.02415823	time 0.1787 (0.1898)	loss 2.9892 (4.0011)	acc@1: 66.5763	acc@5: 84.7517	
2023-03-18 12:03:48,439 - INFO - Train: [40/90][600/3907]	eta 0:10:16 lr 0.02415823	time 0.1815 (0.1865)	loss 3.7734 (4.0457)	acc@1: 61.4378	acc@5: 78.0052	
2023-03-18 12:04:43,480 - INFO - Train: [40/90][900/3907]	eta 0:09:17 lr 0.02415823	time 0.1833 (0.1855)	loss 6.3443 (4.0393)	acc@1: 16.6008	acc@5: 31.8514	
2023-03-18 12:05:38,758 - INFO - Train: [40/90][1200/3907]	eta 0:08:21 lr 0.02415823	time 0.1836 (0.1852)	loss 4.8058 (4.0266)	acc@1: 45.0631	acc@5: 62.2863	
2023-03-18 12:06:34,161 - INFO - Train: [40/90][1500/3907]	eta 0:07:25 lr 0.02415823	time 0.1793 (0.1851)	loss 5.3560 (4.0434)	acc@1: 36.2686	acc@5: 54.1381	
2023-03-18 12:07:29,824 - INFO - Train: [40/90][1800/3907]	eta 0:06:30 lr 0.02415823	time 0.1903 (0.1852)	loss 5.9213 (4.0481)	acc@1: 19.2357	acc@5: 33.8050	
2023-03-18 12:08:25,782 - INFO - Train: [40/90][2100/3907]	eta 0:05:34 lr 0.02415823	time 0.1790 (0.1854)	loss 4.0647 (4.0574)	acc@1: 53.6792	acc@5: 71.7582	
2023-03-18 12:09:21,394 - INFO - Train: [40/90][2400/3907]	eta 0:04:39 lr 0.02415823	time 0.1766 (0.1854)	loss 3.0207 (4.0668)	acc@1: 65.8093	acc@5: 83.0007	
2023-03-18 12:10:16,852 - INFO - Train: [40/90][2700/3907]	eta 0:03:43 lr 0.02415823	time 0.1774 (0.1853)	loss 5.9520 (4.0736)	acc@1: 19.3598	acc@5: 35.4421	
2023-03-18 12:11:12,390 - INFO - Train: [40/90][3000/3907]	eta 0:02:48 lr 0.02415823	time 0.1924 (0.1853)	loss 3.9375 (4.0668)	acc@1: 60.1954	acc@5: 75.9362	
2023-03-18 12:12:07,966 - INFO - Train: [40/90][3300/3907]	eta 0:01:52 lr 0.02415823	time 0.1829 (0.1853)	loss 6.1231 (4.0750)	acc@1: 22.3063	acc@5: 36.9039	
2023-03-18 12:13:03,493 - INFO - Train: [40/90][3600/3907]	eta 0:00:56 lr 0.02415823	time 0.1757 (0.1853)	loss 5.7160 (4.0792)	acc@1: 25.8545	acc@5: 43.2564	
2023-03-18 12:13:58,890 - INFO - Train: [40/90][3900/3907]	eta 0:00:01 lr 0.02415823	time 0.1751 (0.1852)	loss 3.0473 (4.0822)	acc@1: 65.9346	acc@5: 82.0314	
2023-03-18 12:14:00,113 - INFO - EPOCH 40 training takes 0:12:03
2023-03-18 12:14:01,693 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp/fold1_latest.pth saved !!!
2023-03-18 12:14:01,694 - INFO - **********latest test***********
2023-03-18 12:14:01,694 - INFO - eval epoch 40
2023-03-18 12:14:02,394 - INFO - Test: [0/782]	Time 0.699 (0.699)	Loss 2.5520 (2.5520)	Acc@1 67.188 (67.188)	Acc@5 91.406 (91.406)
2023-03-18 12:16:20,166 - INFO - Test: [200/782]	Time 0.663 (0.689)	Loss 2.8898 (2.9727)	Acc@1 65.625 (62.022)	Acc@5 84.375 (83.656)
2023-03-18 12:18:39,185 - INFO - Test: [400/782]	Time 0.682 (0.692)	Loss 2.8543 (2.9370)	Acc@1 63.281 (62.880)	Acc@5 85.156 (84.317)
2023-03-18 12:21:00,025 - INFO - Test: [600/782]	Time 0.677 (0.696)	Loss 3.0147 (2.9029)	Acc@1 62.500 (63.624)	Acc@5 82.812 (84.901)
2023-03-18 12:23:04,181 - INFO -  * Acc@1 64.149 Acc@5 85.309
2023-03-18 12:23:04,181 - INFO - Max accuracy: 64.1490%
2023-03-18 12:23:05,645 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp/fold1_best.pth saved !!!
2023-03-18 12:23:05,646 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp
2023-03-18 12:23:07,629 - INFO - Train: [41/90][0/3907]	eta 2:08:48 lr 0.02347296	time 1.9782 (1.9782)	loss 2.7241 (2.7241)	acc@1: 67.0661	acc@5: 83.4424	
2023-03-18 12:24:02,587 - INFO - Train: [41/90][300/3907]	eta 0:11:22 lr 0.02347296	time 0.1923 (0.1891)	loss 2.8037 (3.8879)	acc@1: 67.7085	acc@5: 84.0512	
2023-03-18 12:24:57,986 - INFO - Train: [41/90][600/3907]	eta 0:10:18 lr 0.02347296	time 0.1983 (0.1869)	loss 4.0977 (3.9214)	acc@1: 53.5288	acc@5: 72.3760	
2023-03-18 12:25:53,261 - INFO - Train: [41/90][900/3907]	eta 0:09:19 lr 0.02347296	time 0.1960 (0.1860)	loss 2.9260 (3.9634)	acc@1: 67.8695	acc@5: 87.6910	
2023-03-18 12:26:48,608 - INFO - Train: [41/90][1200/3907]	eta 0:08:22 lr 0.02347296	time 0.1784 (0.1856)	loss 5.8293 (3.9470)	acc@1: 26.1383	acc@5: 39.9887	
2023-03-18 12:27:44,105 - INFO - Train: [41/90][1500/3907]	eta 0:07:26 lr 0.02347296	time 0.1830 (0.1855)	loss 5.9651 (3.9556)	acc@1: 22.2593	acc@5: 32.0438	
2023-03-18 12:28:39,865 - INFO - Train: [41/90][1800/3907]	eta 0:06:30 lr 0.02347296	time 0.2009 (0.1856)	loss 5.9718 (3.9660)	acc@1: 22.1992	acc@5: 35.9051	
2023-03-18 12:29:35,216 - INFO - Train: [41/90][2100/3907]	eta 0:05:35 lr 0.02347296	time 0.1769 (0.1854)	loss 2.7387 (3.9766)	acc@1: 61.6064	acc@5: 91.2412	
2023-03-18 12:30:30,686 - INFO - Train: [41/90][2400/3907]	eta 0:04:39 lr 0.02347296	time 0.1780 (0.1853)	loss 2.5967 (3.9948)	acc@1: 73.3237	acc@5: 88.9240	
2023-03-18 12:31:25,929 - INFO - Train: [41/90][2700/3907]	eta 0:03:43 lr 0.02347296	time 0.1814 (0.1852)	loss 5.2306 (4.0037)	acc@1: 34.1122	acc@5: 54.9628	
2023-03-18 12:32:21,437 - INFO - Train: [41/90][3000/3907]	eta 0:02:47 lr 0.02347296	time 0.1827 (0.1852)	loss 2.5706 (4.0027)	acc@1: 75.6545	acc@5: 92.0333	
2023-03-18 12:33:17,178 - INFO - Train: [41/90][3300/3907]	eta 0:01:52 lr 0.02347296	time 0.1952 (0.1852)	loss 4.6178 (4.0069)	acc@1: 49.8624	acc@5: 64.8021	
2023-03-18 12:34:12,847 - INFO - Train: [41/90][3600/3907]	eta 0:00:56 lr 0.02347296	time 0.1763 (0.1853)	loss 5.9995 (4.0283)	acc@1: 20.6949	acc@5: 39.7419	
2023-03-18 12:35:08,291 - INFO - Train: [41/90][3900/3907]	eta 0:00:01 lr 0.02347296	time 0.1755 (0.1852)	loss 3.9301 (4.0372)	acc@1: 59.3049	acc@5: 74.4759	
2023-03-18 12:35:09,516 - INFO - EPOCH 41 training takes 0:12:03
2023-03-18 12:35:11,023 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp/fold1_latest.pth saved !!!
2023-03-18 12:35:11,024 - INFO - **********latest test***********
2023-03-18 12:35:11,025 - INFO - eval epoch 41
2023-03-18 12:35:11,713 - INFO - Test: [0/782]	Time 0.685 (0.685)	Loss 2.3248 (2.3248)	Acc@1 76.562 (76.562)	Acc@5 92.188 (92.188)
2023-03-18 12:37:28,029 - INFO - Test: [200/782]	Time 0.672 (0.682)	Loss 2.8485 (2.9064)	Acc@1 60.938 (63.437)	Acc@5 83.594 (84.025)
2023-03-18 12:39:43,183 - INFO - Test: [400/782]	Time 0.673 (0.679)	Loss 2.6951 (2.8747)	Acc@1 64.062 (64.039)	Acc@5 87.500 (84.597)
2023-03-18 12:42:00,561 - INFO - Test: [600/782]	Time 0.681 (0.681)	Loss 2.9701 (2.8414)	Acc@1 64.062 (64.863)	Acc@5 83.594 (85.085)
2023-03-18 12:44:01,833 - INFO -  * Acc@1 65.179 Acc@5 85.549
2023-03-18 12:44:01,833 - INFO - Max accuracy: 65.1790%
2023-03-18 12:44:03,320 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp/fold1_best.pth saved !!!
2023-03-18 12:44:03,320 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp
2023-03-18 12:44:05,382 - INFO - Train: [42/90][0/3907]	eta 2:14:03 lr 0.02278346	time 2.0586 (2.0586)	loss 2.3816 (2.3816)	acc@1: 81.0364	acc@5: 94.1565	
2023-03-18 12:45:00,128 - INFO - Train: [42/90][300/3907]	eta 0:11:20 lr 0.02278346	time 0.1958 (0.1887)	loss 5.5104 (3.9971)	acc@1: 32.5018	acc@5: 48.5911	
2023-03-18 12:45:55,775 - INFO - Train: [42/90][600/3907]	eta 0:10:18 lr 0.02278346	time 0.1856 (0.1871)	loss 3.4870 (3.9491)	acc@1: 66.5217	acc@5: 79.9371	
2023-03-18 12:46:51,286 - INFO - Train: [42/90][900/3907]	eta 0:09:20 lr 0.02278346	time 0.1772 (0.1864)	loss 2.5169 (3.9273)	acc@1: 77.2350	acc@5: 92.0577	
2023-03-18 12:47:46,803 - INFO - Train: [42/90][1200/3907]	eta 0:08:23 lr 0.02278346	time 0.1783 (0.1861)	loss 2.7713 (3.9390)	acc@1: 76.1779	acc@5: 88.2414	
2023-03-18 12:48:42,373 - INFO - Train: [42/90][1500/3907]	eta 0:07:27 lr 0.02278346	time 0.1850 (0.1859)	loss 2.9866 (3.9519)	acc@1: 67.0823	acc@5: 84.4110	
2023-03-18 12:49:37,770 - INFO - Train: [42/90][1800/3907]	eta 0:06:31 lr 0.02278346	time 0.1966 (0.1857)	loss 5.8065 (3.9679)	acc@1: 28.0910	acc@5: 41.9202	
2023-03-18 12:50:33,696 - INFO - Train: [42/90][2100/3907]	eta 0:05:35 lr 0.02278346	time 0.2005 (0.1858)	loss 3.8319 (3.9720)	acc@1: 61.6054	acc@5: 76.3067	
2023-03-18 12:51:29,380 - INFO - Train: [42/90][2400/3907]	eta 0:04:39 lr 0.02278346	time 0.1826 (0.1858)	loss 2.7805 (3.9740)	acc@1: 71.8413	acc@5: 88.8447	
2023-03-18 12:52:25,041 - INFO - Train: [42/90][2700/3907]	eta 0:03:44 lr 0.02278346	time 0.1894 (0.1857)	loss 5.8882 (3.9832)	acc@1: 25.2002	acc@5: 40.0646	
2023-03-18 12:53:20,809 - INFO - Train: [42/90][3000/3907]	eta 0:02:48 lr 0.02278346	time 0.1849 (0.1858)	loss 5.2705 (3.9958)	acc@1: 40.0547	acc@5: 53.0777	
2023-03-18 12:54:16,339 - INFO - Train: [42/90][3300/3907]	eta 0:01:52 lr 0.02278346	time 0.1946 (0.1857)	loss 5.3670 (4.0076)	acc@1: 39.6779	acc@5: 52.8309	
2023-03-18 12:55:11,954 - INFO - Train: [42/90][3600/3907]	eta 0:00:57 lr 0.02278346	time 0.1956 (0.1857)	loss 4.6631 (4.0166)	acc@1: 46.3385	acc@5: 65.2007	
2023-03-18 12:56:07,652 - INFO - Train: [42/90][3900/3907]	eta 0:00:01 lr 0.02278346	time 0.1755 (0.1857)	loss 5.3647 (4.0246)	acc@1: 38.0414	acc@5: 53.2029	
2023-03-18 12:56:08,857 - INFO - EPOCH 42 training takes 0:12:05
2023-03-18 12:56:10,357 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp/fold1_latest.pth saved !!!
2023-03-18 12:56:10,357 - INFO - **********latest test***********
2023-03-18 12:56:10,357 - INFO - eval epoch 42
2023-03-18 12:56:11,112 - INFO - Test: [0/782]	Time 0.754 (0.754)	Loss 2.4847 (2.4847)	Acc@1 73.438 (73.438)	Acc@5 92.969 (92.969)
2023-03-18 12:58:27,268 - INFO - Test: [200/782]	Time 0.675 (0.681)	Loss 2.9066 (2.9554)	Acc@1 65.625 (62.605)	Acc@5 82.031 (83.850)
2023-03-18 13:00:43,673 - INFO - Test: [400/782]	Time 0.718 (0.682)	Loss 2.7927 (2.9190)	Acc@1 67.969 (63.381)	Acc@5 85.156 (84.550)
2023-03-18 13:03:01,253 - INFO - Test: [600/782]	Time 0.655 (0.684)	Loss 2.9636 (2.8789)	Acc@1 60.938 (64.337)	Acc@5 87.500 (85.119)
2023-03-18 13:05:02,987 - INFO -  * Acc@1 64.879 Acc@5 85.543
2023-03-18 13:05:02,988 - INFO - Max accuracy: 65.1790%
2023-03-18 13:05:02,988 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp
2023-03-18 13:05:05,017 - INFO - Train: [43/90][0/3907]	eta 2:11:55 lr 0.02209057	time 2.0259 (2.0259)	loss 2.6000 (2.6000)	acc@1: 71.8657	acc@5: 89.8321	
2023-03-18 13:06:00,064 - INFO - Train: [43/90][300/3907]	eta 0:11:23 lr 0.02209057	time 0.1841 (0.1896)	loss 3.1417 (3.8669)	acc@1: 68.8004	acc@5: 87.2724	
2023-03-18 13:06:55,499 - INFO - Train: [43/90][600/3907]	eta 0:10:19 lr 0.02209057	time 0.1923 (0.1872)	loss 2.9032 (3.9323)	acc@1: 74.7502	acc@5: 83.9033	
2023-03-18 13:07:51,066 - INFO - Train: [43/90][900/3907]	eta 0:09:20 lr 0.02209057	time 0.1811 (0.1865)	loss 5.6880 (3.9037)	acc@1: 26.5063	acc@5: 41.9301	
2023-03-18 13:08:46,704 - INFO - Train: [43/90][1200/3907]	eta 0:08:24 lr 0.02209057	time 0.1925 (0.1863)	loss 4.7220 (3.9260)	acc@1: 45.8389	acc@5: 64.3841	
2023-03-18 13:09:42,422 - INFO - Train: [43/90][1500/3907]	eta 0:07:28 lr 0.02209057	time 0.1757 (0.1862)	loss 3.0029 (3.9516)	acc@1: 63.8841	acc@5: 86.2051	
2023-03-18 13:10:38,040 - INFO - Train: [43/90][1800/3907]	eta 0:06:31 lr 0.02209057	time 0.1978 (0.1860)	loss 3.1849 (3.9523)	acc@1: 64.6532	acc@5: 81.7141	
2023-03-18 13:11:33,592 - INFO - Train: [43/90][2100/3907]	eta 0:05:35 lr 0.02209057	time 0.1777 (0.1859)	loss 2.7556 (3.9578)	acc@1: 68.8683	acc@5: 88.2112	
2023-03-18 13:12:29,202 - INFO - Train: [43/90][2400/3907]	eta 0:04:40 lr 0.02209057	time 0.1777 (0.1858)	loss 5.3622 (3.9681)	acc@1: 37.2008	acc@5: 51.9962	
2023-03-18 13:13:24,855 - INFO - Train: [43/90][2700/3907]	eta 0:03:44 lr 0.02209057	time 0.1758 (0.1858)	loss 2.5337 (3.9658)	acc@1: 74.0882	acc@5: 88.1257	
2023-03-18 13:14:20,440 - INFO - Train: [43/90][3000/3907]	eta 0:02:48 lr 0.02209057	time 0.1837 (0.1857)	loss 4.2895 (3.9793)	acc@1: 53.2881	acc@5: 70.1422	
2023-03-18 13:15:16,095 - INFO - Train: [43/90][3300/3907]	eta 0:01:52 lr 0.02209057	time 0.1774 (0.1857)	loss 2.9707 (3.9853)	acc@1: 65.6059	acc@5: 81.2263	
2023-03-18 13:16:11,825 - INFO - Train: [43/90][3600/3907]	eta 0:00:57 lr 0.02209057	time 0.1775 (0.1857)	loss 3.7041 (3.9821)	acc@1: 57.0142	acc@5: 78.1799	
2023-03-18 13:17:07,527 - INFO - Train: [43/90][3900/3907]	eta 0:00:01 lr 0.02209057	time 0.1793 (0.1857)	loss 5.5717 (3.9852)	acc@1: 35.0833	acc@5: 47.2062	
2023-03-18 13:17:08,738 - INFO - EPOCH 43 training takes 0:12:05
2023-03-18 13:17:10,220 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp/fold1_latest.pth saved !!!
2023-03-18 13:17:10,220 - INFO - **********latest test***********
2023-03-18 13:17:10,220 - INFO - eval epoch 43
2023-03-18 13:17:10,914 - INFO - Test: [0/782]	Time 0.692 (0.692)	Loss 2.5062 (2.5062)	Acc@1 75.000 (75.000)	Acc@5 92.969 (92.969)
2023-03-18 13:19:27,820 - INFO - Test: [200/782]	Time 0.680 (0.685)	Loss 2.8957 (3.0034)	Acc@1 60.156 (62.383)	Acc@5 85.938 (83.722)
2023-03-18 13:21:45,452 - INFO - Test: [400/782]	Time 0.686 (0.686)	Loss 2.9118 (2.9666)	Acc@1 61.719 (63.049)	Acc@5 82.812 (84.361)
2023-03-18 13:24:06,061 - INFO - Test: [600/782]	Time 0.672 (0.692)	Loss 2.9660 (2.9293)	Acc@1 64.844 (63.857)	Acc@5 85.938 (84.909)
2023-03-18 13:26:09,860 - INFO -  * Acc@1 64.423 Acc@5 85.371
2023-03-18 13:26:09,860 - INFO - Max accuracy: 65.1790%
2023-03-18 13:26:09,860 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp
2023-03-18 13:26:12,117 - INFO - Train: [44/90][0/3907]	eta 2:26:44 lr 0.02139513	time 2.2535 (2.2535)	loss 6.0203 (6.0203)	acc@1: 22.5117	acc@5: 34.8843	
2023-03-18 13:27:07,029 - INFO - Train: [44/90][300/3907]	eta 0:11:25 lr 0.02139513	time 0.1868 (0.1899)	loss 2.4892 (3.9087)	acc@1: 73.4375	acc@5: 92.9687	
2023-03-18 13:28:02,506 - INFO - Train: [44/90][600/3907]	eta 0:10:19 lr 0.02139513	time 0.1807 (0.1874)	loss 5.0940 (3.8397)	acc@1: 41.1473	acc@5: 56.0457	
2023-03-18 13:28:57,910 - INFO - Train: [44/90][900/3907]	eta 0:09:20 lr 0.02139513	time 0.1759 (0.1865)	loss 5.8365 (3.8784)	acc@1: 22.7816	acc@5: 39.8548	
2023-03-18 13:29:53,219 - INFO - Train: [44/90][1200/3907]	eta 0:08:23 lr 0.02139513	time 0.1968 (0.1860)	loss 4.6551 (3.9197)	acc@1: 48.6382	acc@5: 64.3612	
2023-03-18 13:30:48,477 - INFO - Train: [44/90][1500/3907]	eta 0:07:26 lr 0.02139513	time 0.1793 (0.1856)	loss 5.6853 (3.9235)	acc@1: 24.2693	acc@5: 44.4075	
2023-03-18 13:31:44,157 - INFO - Train: [44/90][1800/3907]	eta 0:06:31 lr 0.02139513	time 0.1817 (0.1856)	loss 2.9556 (3.9244)	acc@1: 65.1397	acc@5: 84.8331	
2023-03-18 13:32:39,742 - INFO - Train: [44/90][2100/3907]	eta 0:05:35 lr 0.02139513	time 0.1849 (0.1856)	loss 2.8013 (3.9360)	acc@1: 70.9203	acc@5: 84.9500	
2023-03-18 13:33:35,286 - INFO - Train: [44/90][2400/3907]	eta 0:04:39 lr 0.02139513	time 0.1763 (0.1855)	loss 4.4769 (3.9469)	acc@1: 49.6796	acc@5: 66.6060	
2023-03-18 13:34:30,758 - INFO - Train: [44/90][2700/3907]	eta 0:03:43 lr 0.02139513	time 0.1908 (0.1854)	loss 3.1905 (3.9543)	acc@1: 66.0041	acc@5: 82.8467	
2023-03-18 13:35:26,125 - INFO - Train: [44/90][3000/3907]	eta 0:02:48 lr 0.02139513	time 0.1800 (0.1854)	loss 2.8559 (3.9608)	acc@1: 75.4551	acc@5: 88.2825	
2023-03-18 13:36:21,418 - INFO - Train: [44/90][3300/3907]	eta 0:01:52 lr 0.02139513	time 0.1824 (0.1853)	loss 2.6008 (3.9702)	acc@1: 72.3601	acc@5: 87.9215	
2023-03-18 13:37:17,031 - INFO - Train: [44/90][3600/3907]	eta 0:00:56 lr 0.02139513	time 0.1913 (0.1853)	loss 4.0133 (3.9750)	acc@1: 60.2044	acc@5: 71.1507	
2023-03-18 13:38:12,383 - INFO - Train: [44/90][3900/3907]	eta 0:00:01 lr 0.02139513	time 0.1762 (0.1852)	loss 4.1812 (3.9830)	acc@1: 61.4425	acc@5: 71.0206	
2023-03-18 13:38:13,601 - INFO - EPOCH 44 training takes 0:12:03
2023-03-18 13:38:15,157 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp/fold1_latest.pth saved !!!
2023-03-18 13:38:15,158 - INFO - **********latest test***********
2023-03-18 13:38:15,158 - INFO - eval epoch 44
2023-03-18 13:38:15,874 - INFO - Test: [0/782]	Time 0.714 (0.714)	Loss 2.5337 (2.5337)	Acc@1 69.531 (69.531)	Acc@5 93.750 (93.750)
