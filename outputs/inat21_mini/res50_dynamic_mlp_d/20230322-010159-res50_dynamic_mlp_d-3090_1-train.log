2023-03-22 01:02:03,441 - INFO - --batch_size 128
2023-03-22 01:02:03,442 - INFO - --data inat21_mini
2023-03-22 01:02:03,442 - INFO - --data_dir ./datasets/iNat2021
2023-03-22 01:02:03,442 - INFO - --device_name NVIDIA GeForce RTX 3090
2023-03-22 01:02:03,442 - INFO - --evaluate False
2023-03-22 01:02:03,442 - INFO - --fold 1
2023-03-22 01:02:03,442 - INFO - --image_only False
2023-03-22 01:02:03,442 - INFO - --metadata geo_temporal
2023-03-22 01:02:03,442 - INFO - --mlp_cin 6
2023-03-22 01:02:03,442 - INFO - --mlp_hidden 64
2023-03-22 01:02:03,442 - INFO - --mlp_num_layers 2
2023-03-22 01:02:03,442 - INFO - --mlp_out_channel 256
2023-03-22 01:02:03,442 - INFO - --mlp_type d
2023-03-22 01:02:03,442 - INFO - --model_file resnet_dynamic_mlp
2023-03-22 01:02:03,442 - INFO - --model_name resnet50
2023-03-22 01:02:03,442 - INFO - --name res50_dynamic_mlp_d
2023-03-22 01:02:03,442 - INFO - --num_classes 10000
2023-03-22 01:02:03,442 - INFO - --num_workers 8
2023-03-22 01:02:03,442 - INFO - --path_log ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-22 01:02:03,442 - INFO - --pretrained True
2023-03-22 01:02:03,442 - INFO - --random_seed 37
2023-03-22 01:02:03,442 - INFO - --resume Latest
2023-03-22 01:02:03,442 - INFO - --save_dir ./outputs
2023-03-22 01:02:03,442 - INFO - --start_lr 0.04
2023-03-22 01:02:03,442 - INFO - --stop_epoch 120
2023-03-22 01:02:03,442 - INFO - --storeinfo 3090_1
2023-03-22 01:02:03,443 - INFO - --tencrop False
2023-03-22 01:02:03,443 - INFO - --warmup 2
2023-03-22 01:02:03,443 - INFO - Creating model:resnet_dynamic_mlp -> resnet50
2023-03-22 01:02:03,443 - INFO - type: d, cin: 6, d: 256, h: 64, N: 2
2023-03-22 01:02:08,366 - INFO - => loading checkpoint './outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Latest.pth'
2023-03-22 01:02:08,861 - INFO - => loaded checkpoint './outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Latest.pth' (epoch 90)
2023-03-22 01:02:08,861 - INFO - eval epoch 90
2023-03-22 01:02:09,951 - INFO - Test: [0/782]	Time 1.089 (1.089)	Loss 2.1857 (2.1857)	Acc@1 80.469 (80.469)	Acc@5 95.312 (95.312)
2023-03-22 01:04:07,211 - INFO - Test: [200/782]	Time 0.575 (0.589)	Loss 2.4119 (2.4873)	Acc@1 71.875 (74.911)	Acc@5 88.281 (90.784)
2023-03-22 01:06:04,621 - INFO - Test: [400/782]	Time 0.616 (0.588)	Loss 2.4074 (2.4619)	Acc@1 78.125 (75.676)	Acc@5 90.625 (91.163)
2023-03-22 01:08:03,415 - INFO - Test: [600/782]	Time 0.576 (0.590)	Loss 2.5091 (2.4314)	Acc@1 77.344 (76.482)	Acc@5 88.281 (91.570)
2023-03-22 01:09:48,629 - INFO -  * Acc@1 76.897 Acc@5 91.898
2023-03-22 01:09:48,629 - INFO - Max accuracy: 77.5810%
2023-03-22 01:09:48,629 - INFO - Start training
2023-03-22 01:09:53,307 - INFO - Train: [91/120][0/3907]	eta 5:04:24 lr 0.00585786	time 4.6747 (4.6747)	loss 2.6135 (2.6135)	acc@1: 82.4854	acc@5: 86.1595	
2023-03-22 01:10:47,977 - INFO - Train: [91/120][300/3907]	eta 0:11:51 lr 0.00585786	time 0.1880 (0.1972)	loss 4.8134 (3.3879)	acc@1: 39.4167	acc@5: 56.1996	
2023-03-22 01:11:42,784 - INFO - Train: [91/120][600/3907]	eta 0:10:28 lr 0.00585786	time 0.1799 (0.1899)	loss 2.7299 (3.3785)	acc@1: 80.1171	acc@5: 88.8319	
2023-03-22 01:12:37,571 - INFO - Train: [91/120][900/3907]	eta 0:09:23 lr 0.00585786	time 0.1819 (0.1875)	loss 3.5640 (3.3569)	acc@1: 69.4003	acc@5: 76.5351	
2023-03-22 01:13:32,418 - INFO - Train: [91/120][1200/3907]	eta 0:08:24 lr 0.00585786	time 0.1798 (0.1863)	loss 2.8500 (3.3288)	acc@1: 79.5395	acc@5: 86.6993	
2023-03-22 01:14:27,248 - INFO - Train: [91/120][1500/3907]	eta 0:07:26 lr 0.00585786	time 0.1799 (0.1856)	loss 2.6612 (3.3339)	acc@1: 80.7987	acc@5: 87.4668	
2023-03-22 01:15:22,190 - INFO - Train: [91/120][1800/3907]	eta 0:06:30 lr 0.00585786	time 0.1865 (0.1852)	loss 2.4521 (3.3459)	acc@1: 81.9924	acc@5: 88.0080	
2023-03-22 01:16:16,827 - INFO - Train: [91/120][2100/3907]	eta 0:05:33 lr 0.00585786	time 0.1799 (0.1848)	loss 4.9829 (3.3412)	acc@1: 37.0694	acc@5: 53.0770	
2023-03-22 01:17:10,778 - INFO - Train: [91/120][2400/3907]	eta 0:04:37 lr 0.00585786	time 0.1768 (0.1841)	loss 3.9344 (3.3481)	acc@1: 60.1535	acc@5: 73.8947	
2023-03-22 01:18:03,011 - INFO - Train: [91/120][2700/3907]	eta 0:03:40 lr 0.00585786	time 0.1707 (0.1830)	loss 2.6845 (3.3640)	acc@1: 79.7961	acc@5: 89.3071	
2023-03-22 01:18:55,343 - INFO - Train: [91/120][3000/3907]	eta 0:02:45 lr 0.00585786	time 0.1751 (0.1822)	loss 3.2824 (3.3688)	acc@1: 70.0083	acc@5: 83.1440	
2023-03-22 01:19:47,479 - INFO - Train: [91/120][3300/3907]	eta 0:01:50 lr 0.00585786	time 0.1755 (0.1814)	loss 1.9546 (3.3769)	acc@1: 85.1303	acc@5: 97.6265	
2023-03-22 01:20:39,687 - INFO - Train: [91/120][3600/3907]	eta 0:00:55 lr 0.00585786	time 0.1778 (0.1808)	loss 4.7403 (3.3824)	acc@1: 40.8401	acc@5: 59.2577	
2023-03-22 01:21:31,817 - INFO - Train: [91/120][3900/3907]	eta 0:00:01 lr 0.00585786	time 0.1697 (0.1803)	loss 4.4789 (3.3862)	acc@1: 53.4623	acc@5: 64.6712	
2023-03-22 01:21:33,503 - INFO - EPOCH 91 training takes 0:11:44
2023-03-22 01:21:34,600 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Latest.pth saved !!!
2023-03-22 01:21:34,601 - INFO - **********Latest test***********
2023-03-22 01:21:34,601 - INFO - eval epoch 91
2023-03-22 01:21:35,186 - INFO - Test: [0/782]	Time 0.584 (0.584)	Loss 2.2732 (2.2732)	Acc@1 82.031 (82.031)	Acc@5 94.531 (94.531)
2023-03-22 01:23:30,440 - INFO - Test: [200/782]	Time 0.573 (0.576)	Loss 2.6572 (2.6627)	Acc@1 68.750 (70.243)	Acc@5 88.281 (88.476)
2023-03-22 01:25:25,978 - INFO - Test: [400/782]	Time 0.586 (0.577)	Loss 2.5971 (2.6291)	Acc@1 73.438 (71.230)	Acc@5 88.281 (89.010)
2023-03-22 01:27:22,244 - INFO - Test: [600/782]	Time 0.566 (0.578)	Loss 2.6705 (2.6019)	Acc@1 71.094 (71.953)	Acc@5 88.281 (89.452)
2023-03-22 01:29:05,220 - INFO -  * Acc@1 72.498 Acc@5 89.855
2023-03-22 01:29:05,220 - INFO - Max accuracy: 77.5810%
2023-03-22 01:29:06,257 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Best.pth saved !!!
2023-03-22 01:29:06,258 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-22 01:29:08,260 - INFO - Train: [92/120][0/3907]	eta 2:10:07 lr 0.00549251	time 1.9984 (1.9984)	loss 3.9716 (3.9716)	acc@1: 61.5252	acc@5: 74.7031	
2023-03-22 01:30:02,772 - INFO - Train: [92/120][300/3907]	eta 0:11:17 lr 0.00549251	time 0.1838 (0.1877)	loss 4.7883 (3.2511)	acc@1: 38.2694	acc@5: 56.7219	
2023-03-22 01:30:57,473 - INFO - Train: [92/120][600/3907]	eta 0:10:11 lr 0.00549251	time 0.1855 (0.1850)	loss 5.5391 (3.2885)	acc@1: 26.0107	acc@5: 42.0407	
2023-03-22 01:31:52,316 - INFO - Train: [92/120][900/3907]	eta 0:09:14 lr 0.00549251	time 0.1798 (0.1843)	loss 3.6968 (3.2988)	acc@1: 62.6316	acc@5: 77.7573	
2023-03-22 01:32:47,008 - INFO - Train: [92/120][1200/3907]	eta 0:08:17 lr 0.00549251	time 0.1803 (0.1838)	loss 2.1843 (3.2919)	acc@1: 82.5071	acc@5: 94.0735	
2023-03-22 01:33:41,893 - INFO - Train: [92/120][1500/3907]	eta 0:07:21 lr 0.00549251	time 0.1877 (0.1836)	loss 2.2273 (3.3349)	acc@1: 85.4238	acc@5: 92.3054	
2023-03-22 01:34:36,760 - INFO - Train: [92/120][1800/3907]	eta 0:06:26 lr 0.00549251	time 0.1848 (0.1835)	loss 1.9950 (3.3240)	acc@1: 87.8135	acc@5: 95.5835	
2023-03-22 01:35:31,796 - INFO - Train: [92/120][2100/3907]	eta 0:05:31 lr 0.00549251	time 0.1857 (0.1835)	loss 3.2263 (3.3359)	acc@1: 74.8092	acc@5: 82.3491	
2023-03-22 01:36:24,770 - INFO - Train: [92/120][2400/3907]	eta 0:04:35 lr 0.00549251	time 0.1746 (0.1826)	loss 3.0194 (3.3441)	acc@1: 76.0471	acc@5: 83.8577	
2023-03-22 01:37:16,890 - INFO - Train: [92/120][2700/3907]	eta 0:03:39 lr 0.00549251	time 0.1730 (0.1816)	loss 5.0904 (3.3489)	acc@1: 33.7726	acc@5: 53.8218	
2023-03-22 01:38:09,115 - INFO - Train: [92/120][3000/3907]	eta 0:02:44 lr 0.00549251	time 0.1714 (0.1809)	loss 3.5682 (3.3654)	acc@1: 66.3847	acc@5: 78.9746	
2023-03-22 01:39:01,626 - INFO - Train: [92/120][3300/3907]	eta 0:01:49 lr 0.00549251	time 0.1779 (0.1804)	loss 3.5692 (3.3722)	acc@1: 66.6575	acc@5: 77.4427	
2023-03-22 01:39:53,780 - INFO - Train: [92/120][3600/3907]	eta 0:00:55 lr 0.00549251	time 0.1731 (0.1798)	loss 3.5154 (3.3807)	acc@1: 65.7254	acc@5: 81.1245	
2023-03-22 01:40:45,978 - INFO - Train: [92/120][3900/3907]	eta 0:00:01 lr 0.00549251	time 0.1719 (0.1794)	loss 3.6316 (3.3839)	acc@1: 67.8591	acc@5: 80.7865	
2023-03-22 01:40:47,172 - INFO - EPOCH 92 training takes 0:11:40
2023-03-22 01:40:48,260 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Latest.pth saved !!!
2023-03-22 01:40:48,260 - INFO - **********Latest test***********
2023-03-22 01:40:48,260 - INFO - eval epoch 92
2023-03-22 01:40:48,890 - INFO - Test: [0/782]	Time 0.629 (0.629)	Loss 2.3825 (2.3825)	Acc@1 75.781 (75.781)	Acc@5 94.531 (94.531)
2023-03-22 01:42:45,098 - INFO - Test: [200/782]	Time 0.577 (0.581)	Loss 2.6724 (2.6523)	Acc@1 71.094 (71.024)	Acc@5 85.938 (88.969)
2023-03-22 01:44:41,405 - INFO - Test: [400/782]	Time 0.592 (0.581)	Loss 2.4953 (2.6241)	Acc@1 76.562 (71.822)	Acc@5 89.844 (89.298)
2023-03-22 01:46:39,673 - INFO - Test: [600/782]	Time 0.581 (0.585)	Loss 2.7076 (2.5945)	Acc@1 71.094 (72.616)	Acc@5 86.719 (89.706)
2023-03-22 01:48:23,769 - INFO -  * Acc@1 73.081 Acc@5 90.093
2023-03-22 01:48:23,769 - INFO - Max accuracy: 77.5810%
2023-03-22 01:48:24,819 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Best.pth saved !!!
2023-03-22 01:48:24,820 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-22 01:48:26,780 - INFO - Train: [93/120][0/3907]	eta 2:07:23 lr 0.00513710	time 1.9562 (1.9562)	loss 2.9663 (2.9663)	acc@1: 72.1313	acc@5: 83.7045	
2023-03-22 01:49:21,318 - INFO - Train: [93/120][300/3907]	eta 0:11:16 lr 0.00513710	time 0.1789 (0.1877)	loss 2.9852 (3.2845)	acc@1: 76.9197	acc@5: 83.3883	
2023-03-22 01:50:15,800 - INFO - Train: [93/120][600/3907]	eta 0:10:10 lr 0.00513710	time 0.1800 (0.1846)	loss 2.6339 (3.2704)	acc@1: 82.9233	acc@5: 89.5278	
2023-03-22 01:51:10,522 - INFO - Train: [93/120][900/3907]	eta 0:09:12 lr 0.00513710	time 0.1799 (0.1839)	loss 2.4530 (3.2961)	acc@1: 81.2215	acc@5: 90.9982	
2023-03-22 01:52:05,513 - INFO - Train: [93/120][1200/3907]	eta 0:08:17 lr 0.00513710	time 0.1881 (0.1838)	loss 3.2412 (3.3198)	acc@1: 73.2090	acc@5: 80.7592	
2023-03-22 01:53:00,298 - INFO - Train: [93/120][1500/3907]	eta 0:07:21 lr 0.00513710	time 0.1857 (0.1835)	loss 2.1278 (3.3271)	acc@1: 84.4681	acc@5: 93.0050	
2023-03-22 01:53:55,058 - INFO - Train: [93/120][1800/3907]	eta 0:06:26 lr 0.00513710	time 0.1797 (0.1834)	loss 2.1183 (3.3184)	acc@1: 82.1592	acc@5: 93.0088	
2023-03-22 01:54:49,924 - INFO - Train: [93/120][2100/3907]	eta 0:05:31 lr 0.00513710	time 0.1822 (0.1833)	loss 2.9525 (3.3190)	acc@1: 78.1180	acc@5: 82.4767	
2023-03-22 01:55:44,355 - INFO - Train: [93/120][2400/3907]	eta 0:04:35 lr 0.00513710	time 0.1708 (0.1831)	loss 4.5789 (3.3362)	acc@1: 49.0787	acc@5: 61.8673	
2023-03-22 01:56:36,350 - INFO - Train: [93/120][2700/3907]	eta 0:03:39 lr 0.00513710	time 0.1708 (0.1820)	loss 2.6384 (3.3530)	acc@1: 77.1669	acc@5: 89.1539	
2023-03-22 01:57:28,607 - INFO - Train: [93/120][3000/3907]	eta 0:02:44 lr 0.00513710	time 0.1707 (0.1812)	loss 4.4529 (3.3468)	acc@1: 50.5970	acc@5: 65.2109	
2023-03-22 01:58:20,536 - INFO - Train: [93/120][3300/3907]	eta 0:01:49 lr 0.00513710	time 0.1709 (0.1805)	loss 2.8927 (3.3370)	acc@1: 76.5489	acc@5: 87.2708	
2023-03-22 01:59:12,564 - INFO - Train: [93/120][3600/3907]	eta 0:00:55 lr 0.00513710	time 0.1774 (0.1799)	loss 2.1608 (3.3391)	acc@1: 81.6464	acc@5: 93.3096	
2023-03-22 02:00:04,700 - INFO - Train: [93/120][3900/3907]	eta 0:00:01 lr 0.00513710	time 0.1725 (0.1794)	loss 2.6289 (3.3489)	acc@1: 80.0202	acc@5: 88.1704	
2023-03-22 02:00:05,877 - INFO - EPOCH 93 training takes 0:11:41
2023-03-22 02:00:06,950 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Latest.pth saved !!!
2023-03-22 02:00:06,951 - INFO - **********Latest test***********
2023-03-22 02:00:06,951 - INFO - eval epoch 93
2023-03-22 02:00:07,542 - INFO - Test: [0/782]	Time 0.590 (0.590)	Loss 2.3089 (2.3089)	Acc@1 78.906 (78.906)	Acc@5 93.750 (93.750)
2023-03-22 02:02:03,775 - INFO - Test: [200/782]	Time 0.565 (0.581)	Loss 2.6185 (2.5965)	Acc@1 71.875 (71.887)	Acc@5 85.938 (89.160)
2023-03-22 02:03:59,209 - INFO - Test: [400/782]	Time 0.591 (0.579)	Loss 2.4914 (2.5689)	Acc@1 75.781 (72.549)	Acc@5 91.406 (89.668)
2023-03-22 02:05:57,330 - INFO - Test: [600/782]	Time 0.579 (0.583)	Loss 2.6022 (2.5372)	Acc@1 71.094 (73.232)	Acc@5 90.625 (90.049)
2023-03-22 02:07:41,200 - INFO -  * Acc@1 73.611 Acc@5 90.389
2023-03-22 02:07:41,200 - INFO - Max accuracy: 77.5810%
2023-03-22 02:07:42,247 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Best.pth saved !!!
2023-03-22 02:07:42,248 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-22 02:07:44,382 - INFO - Train: [94/120][0/3907]	eta 2:18:42 lr 0.00479188	time 2.1300 (2.1300)	loss 2.0973 (2.0973)	acc@1: 83.5230	acc@5: 93.6705	
2023-03-22 02:08:38,686 - INFO - Train: [94/120][300/3907]	eta 0:11:16 lr 0.00479188	time 0.1794 (0.1875)	loss 2.5837 (3.2639)	acc@1: 77.7924	acc@5: 88.9977	
2023-03-22 02:09:33,303 - INFO - Train: [94/120][600/3907]	eta 0:10:11 lr 0.00479188	time 0.1855 (0.1848)	loss 5.1258 (3.3471)	acc@1: 29.8091	acc@5: 51.5332	
2023-03-22 02:10:28,165 - INFO - Train: [94/120][900/3907]	eta 0:09:13 lr 0.00479188	time 0.1881 (0.1841)	loss 5.1877 (3.3236)	acc@1: 31.6901	acc@5: 48.4461	
2023-03-22 02:11:23,003 - INFO - Train: [94/120][1200/3907]	eta 0:08:17 lr 0.00479188	time 0.1802 (0.1838)	loss 3.3725 (3.3137)	acc@1: 69.5103	acc@5: 78.5391	
2023-03-22 02:12:17,882 - INFO - Train: [94/120][1500/3907]	eta 0:07:21 lr 0.00479188	time 0.1841 (0.1836)	loss 4.9962 (3.2875)	acc@1: 38.4091	acc@5: 54.8193	
2023-03-22 02:13:12,675 - INFO - Train: [94/120][1800/3907]	eta 0:06:26 lr 0.00479188	time 0.1801 (0.1835)	loss 1.9491 (3.3061)	acc@1: 89.6750	acc@5: 96.6930	
2023-03-22 02:14:07,525 - INFO - Train: [94/120][2100/3907]	eta 0:05:31 lr 0.00479188	time 0.1802 (0.1834)	loss 4.0420 (3.3012)	acc@1: 62.1027	acc@5: 72.5601	
2023-03-22 02:15:00,366 - INFO - Train: [94/120][2400/3907]	eta 0:04:34 lr 0.00479188	time 0.1704 (0.1825)	loss 3.4005 (3.3111)	acc@1: 70.8193	acc@5: 79.1162	
2023-03-22 02:15:52,354 - INFO - Train: [94/120][2700/3907]	eta 0:03:39 lr 0.00479188	time 0.1795 (0.1814)	loss 2.3315 (3.3247)	acc@1: 82.0694	acc@5: 92.8074	
2023-03-22 02:16:44,418 - INFO - Train: [94/120][3000/3907]	eta 0:02:43 lr 0.00479188	time 0.1758 (0.1807)	loss 2.1315 (3.3354)	acc@1: 84.3602	acc@5: 95.2957	
2023-03-22 02:17:36,480 - INFO - Train: [94/120][3300/3907]	eta 0:01:49 lr 0.00479188	time 0.1749 (0.1800)	loss 5.3623 (3.3444)	acc@1: 28.8374	acc@5: 45.8124	
2023-03-22 02:18:28,626 - INFO - Train: [94/120][3600/3907]	eta 0:00:55 lr 0.00479188	time 0.1789 (0.1795)	loss 3.1253 (3.3423)	acc@1: 75.8587	acc@5: 84.8130	
2023-03-22 02:19:20,607 - INFO - Train: [94/120][3900/3907]	eta 0:00:01 lr 0.00479188	time 0.1701 (0.1790)	loss 5.2340 (3.3477)	acc@1: 38.4906	acc@5: 49.4377	
2023-03-22 02:19:21,781 - INFO - EPOCH 94 training takes 0:11:39
2023-03-22 02:19:22,707 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Latest.pth saved !!!
2023-03-22 02:19:22,708 - INFO - **********Latest test***********
2023-03-22 02:19:22,708 - INFO - eval epoch 94
2023-03-22 02:19:23,287 - INFO - Test: [0/782]	Time 0.578 (0.578)	Loss 2.2774 (2.2774)	Acc@1 81.250 (81.250)	Acc@5 93.750 (93.750)
2023-03-22 02:21:18,115 - INFO - Test: [200/782]	Time 0.574 (0.574)	Loss 2.6215 (2.6617)	Acc@1 71.875 (70.845)	Acc@5 85.156 (88.577)
2023-03-22 02:23:12,678 - INFO - Test: [400/782]	Time 0.574 (0.573)	Loss 2.5315 (2.6323)	Acc@1 75.000 (71.645)	Acc@5 89.062 (89.154)
2023-03-22 02:25:08,927 - INFO - Test: [600/782]	Time 0.567 (0.576)	Loss 2.6561 (2.5992)	Acc@1 71.875 (72.452)	Acc@5 89.062 (89.585)
2023-03-22 02:26:52,034 - INFO -  * Acc@1 72.963 Acc@5 89.923
2023-03-22 02:26:52,034 - INFO - Max accuracy: 77.5810%
2023-03-22 02:26:52,034 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-22 02:26:54,059 - INFO - Train: [95/120][0/3907]	eta 2:11:37 lr 0.00445708	time 2.0213 (2.0213)	loss 1.8256 (1.8256)	acc@1: 92.9079	acc@5: 98.3731	
2023-03-22 02:27:48,611 - INFO - Train: [95/120][300/3907]	eta 0:11:17 lr 0.00445708	time 0.1852 (0.1879)	loss 3.1214 (3.2158)	acc@1: 75.1318	acc@5: 82.9347	
2023-03-22 02:28:43,313 - INFO - Train: [95/120][600/3907]	eta 0:10:12 lr 0.00445708	time 0.1805 (0.1851)	loss 3.5504 (3.2800)	acc@1: 71.9651	acc@5: 78.3857	
2023-03-22 02:29:37,995 - INFO - Train: [95/120][900/3907]	eta 0:09:13 lr 0.00445708	time 0.1858 (0.1842)	loss 2.1616 (3.2626)	acc@1: 82.2008	acc@5: 95.2586	
2023-03-22 02:30:32,836 - INFO - Train: [95/120][1200/3907]	eta 0:08:17 lr 0.00445708	time 0.1803 (0.1838)	loss 2.0183 (3.2863)	acc@1: 87.2890	acc@5: 96.6414	
2023-03-22 02:31:27,660 - INFO - Train: [95/120][1500/3907]	eta 0:07:21 lr 0.00445708	time 0.1801 (0.1836)	loss 4.9582 (3.2866)	acc@1: 30.2207	acc@5: 53.3467	
2023-03-22 02:32:22,387 - INFO - Train: [95/120][1800/3907]	eta 0:06:26 lr 0.00445708	time 0.1797 (0.1834)	loss 3.5120 (3.2799)	acc@1: 66.9029	acc@5: 78.8048	
2023-03-22 02:33:17,077 - INFO - Train: [95/120][2100/3907]	eta 0:05:31 lr 0.00445708	time 0.1802 (0.1833)	loss 4.9435 (3.2844)	acc@1: 31.7307	acc@5: 51.7513	
2023-03-22 02:34:10,082 - INFO - Train: [95/120][2400/3907]	eta 0:04:34 lr 0.00445708	time 0.1786 (0.1824)	loss 2.2164 (3.2970)	acc@1: 84.9808	acc@5: 94.9317	
2023-03-22 02:35:02,086 - INFO - Train: [95/120][2700/3907]	eta 0:03:38 lr 0.00445708	time 0.1772 (0.1814)	loss 2.2412 (3.2994)	acc@1: 82.9162	acc@5: 92.1276	
2023-03-22 02:35:54,073 - INFO - Train: [95/120][3000/3907]	eta 0:02:43 lr 0.00445708	time 0.1791 (0.1806)	loss 2.8320 (3.3039)	acc@1: 73.2206	acc@5: 85.6682	
2023-03-22 02:36:46,614 - INFO - Train: [95/120][3300/3907]	eta 0:01:49 lr 0.00445708	time 0.1705 (0.1801)	loss 1.8465 (3.3227)	acc@1: 92.9584	acc@5: 97.6453	
2023-03-22 02:37:38,592 - INFO - Train: [95/120][3600/3907]	eta 0:00:55 lr 0.00445708	time 0.1713 (0.1795)	loss 2.5085 (3.3207)	acc@1: 81.4957	acc@5: 92.7060	
2023-03-22 02:38:30,715 - INFO - Train: [95/120][3900/3907]	eta 0:00:01 lr 0.00445708	time 0.1710 (0.1791)	loss 2.6250 (3.3262)	acc@1: 80.5392	acc@5: 88.6670	
2023-03-22 02:38:31,870 - INFO - EPOCH 95 training takes 0:11:39
2023-03-22 02:38:32,965 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Latest.pth saved !!!
2023-03-22 02:38:32,965 - INFO - **********Latest test***********
2023-03-22 02:38:32,965 - INFO - eval epoch 95
2023-03-22 02:38:33,582 - INFO - Test: [0/782]	Time 0.615 (0.615)	Loss 2.2359 (2.2359)	Acc@1 76.562 (76.562)	Acc@5 94.531 (94.531)
2023-03-22 02:40:29,771 - INFO - Test: [200/782]	Time 0.558 (0.581)	Loss 2.5558 (2.5406)	Acc@1 68.750 (72.792)	Acc@5 89.062 (89.743)
2023-03-22 02:42:25,317 - INFO - Test: [400/782]	Time 0.596 (0.579)	Loss 2.4598 (2.5170)	Acc@1 78.125 (73.432)	Acc@5 88.281 (90.175)
2023-03-22 02:44:22,399 - INFO - Test: [600/782]	Time 0.574 (0.581)	Loss 2.5177 (2.4848)	Acc@1 74.219 (74.215)	Acc@5 90.625 (90.593)
2023-03-22 02:46:05,509 - INFO -  * Acc@1 74.677 Acc@5 90.958
2023-03-22 02:46:05,509 - INFO - Max accuracy: 77.5810%
2023-03-22 02:46:06,575 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Best.pth saved !!!
2023-03-22 02:46:06,575 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-22 02:46:08,607 - INFO - Train: [96/120][0/3907]	eta 2:12:01 lr 0.00413293	time 2.0276 (2.0276)	loss 2.8234 (2.8234)	acc@1: 81.3409	acc@5: 86.3759	
2023-03-22 02:47:03,026 - INFO - Train: [96/120][300/3907]	eta 0:11:16 lr 0.00413293	time 0.1853 (0.1875)	loss 2.1015 (3.2822)	acc@1: 88.2452	acc@5: 94.4374	
2023-03-22 02:47:57,523 - INFO - Train: [96/120][600/3907]	eta 0:10:10 lr 0.00413293	time 0.1809 (0.1846)	loss 3.4005 (3.3119)	acc@1: 69.6715	acc@5: 79.0490	
2023-03-22 02:48:52,204 - INFO - Train: [96/120][900/3907]	eta 0:09:12 lr 0.00413293	time 0.1870 (0.1838)	loss 5.0118 (3.3080)	acc@1: 30.4218	acc@5: 52.2498	
2023-03-22 02:49:46,892 - INFO - Train: [96/120][1200/3907]	eta 0:08:16 lr 0.00413293	time 0.1800 (0.1834)	loss 3.1243 (3.2957)	acc@1: 78.0771	acc@5: 85.7516	
2023-03-22 02:50:41,668 - INFO - Train: [96/120][1500/3907]	eta 0:07:21 lr 0.00413293	time 0.1813 (0.1833)	loss 2.0317 (3.2854)	acc@1: 87.8808	acc@5: 94.1021	
2023-03-22 02:51:36,503 - INFO - Train: [96/120][1800/3907]	eta 0:06:25 lr 0.00413293	time 0.1858 (0.1832)	loss 3.1473 (3.2913)	acc@1: 71.1256	acc@5: 84.0834	
2023-03-22 02:52:31,323 - INFO - Train: [96/120][2100/3907]	eta 0:05:30 lr 0.00413293	time 0.1907 (0.1831)	loss 2.8834 (3.2938)	acc@1: 79.3306	acc@5: 87.8996	
2023-03-22 02:53:26,207 - INFO - Train: [96/120][2400/3907]	eta 0:04:35 lr 0.00413293	time 0.1801 (0.1831)	loss 3.4857 (3.3045)	acc@1: 71.9449	acc@5: 78.6564	
2023-03-22 02:54:20,882 - INFO - Train: [96/120][2700/3907]	eta 0:03:40 lr 0.00413293	time 0.1723 (0.1830)	loss 3.1023 (3.2974)	acc@1: 76.5038	acc@5: 84.9174	
2023-03-22 02:55:12,893 - INFO - Train: [96/120][3000/3907]	eta 0:02:45 lr 0.00413293	time 0.1754 (0.1820)	loss 3.7887 (3.3000)	acc@1: 66.4916	acc@5: 75.1958	
2023-03-22 02:56:04,829 - INFO - Train: [96/120][3300/3907]	eta 0:01:50 lr 0.00413293	time 0.1797 (0.1812)	loss 3.4662 (3.2982)	acc@1: 68.1223	acc@5: 81.4475	
2023-03-22 02:56:57,109 - INFO - Train: [96/120][3600/3907]	eta 0:00:55 lr 0.00413293	time 0.1703 (0.1806)	loss 5.1009 (3.2967)	acc@1: 35.0185	acc@5: 52.8214	
2023-03-22 02:57:49,109 - INFO - Train: [96/120][3900/3907]	eta 0:00:01 lr 0.00413293	time 0.1700 (0.1801)	loss 4.6039 (3.3046)	acc@1: 44.5624	acc@5: 60.5596	
2023-03-22 02:57:50,288 - INFO - EPOCH 96 training takes 0:11:43
2023-03-22 02:57:51,347 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Latest.pth saved !!!
2023-03-22 02:57:51,347 - INFO - **********Latest test***********
2023-03-22 02:57:51,347 - INFO - eval epoch 96
2023-03-22 02:57:51,939 - INFO - Test: [0/782]	Time 0.591 (0.591)	Loss 2.2763 (2.2763)	Acc@1 78.125 (78.125)	Acc@5 96.094 (96.094)
2023-03-22 02:59:47,769 - INFO - Test: [200/782]	Time 0.572 (0.579)	Loss 2.5533 (2.5811)	Acc@1 70.312 (72.097)	Acc@5 89.844 (89.303)
2023-03-22 03:01:44,058 - INFO - Test: [400/782]	Time 0.584 (0.580)	Loss 2.5290 (2.5525)	Acc@1 73.438 (72.960)	Acc@5 88.281 (89.744)
2023-03-22 03:03:42,363 - INFO - Test: [600/782]	Time 0.574 (0.584)	Loss 2.5766 (2.5180)	Acc@1 74.219 (73.805)	Acc@5 89.844 (90.239)
2023-03-22 03:05:26,073 - INFO -  * Acc@1 74.294 Acc@5 90.640
2023-03-22 03:05:26,073 - INFO - Max accuracy: 77.5810%
2023-03-22 03:05:26,073 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-22 03:05:28,082 - INFO - Train: [97/120][0/3907]	eta 2:10:33 lr 0.00381966	time 2.0049 (2.0049)	loss 4.4277 (4.4277)	acc@1: 48.8107	acc@5: 64.2263	
2023-03-22 03:06:22,738 - INFO - Train: [97/120][300/3907]	eta 0:11:18 lr 0.00381966	time 0.1793 (0.1882)	loss 1.9834 (3.1002)	acc@1: 88.2826	acc@5: 95.2523	
2023-03-22 03:07:17,455 - INFO - Train: [97/120][600/3907]	eta 0:10:12 lr 0.00381966	time 0.1813 (0.1853)	loss 4.8884 (3.1860)	acc@1: 39.1542	acc@5: 55.5679	
2023-03-22 03:08:12,354 - INFO - Train: [97/120][900/3907]	eta 0:09:14 lr 0.00381966	time 0.1876 (0.1845)	loss 1.9172 (3.2032)	acc@1: 87.3731	acc@5: 95.9543	
2023-03-22 03:09:06,951 - INFO - Train: [97/120][1200/3907]	eta 0:08:17 lr 0.00381966	time 0.1794 (0.1839)	loss 1.9494 (3.2425)	acc@1: 89.0519	acc@5: 96.0823	
2023-03-22 03:10:01,534 - INFO - Train: [97/120][1500/3907]	eta 0:07:21 lr 0.00381966	time 0.1793 (0.1835)	loss 3.1420 (3.2541)	acc@1: 71.8833	acc@5: 85.1970	
2023-03-22 03:10:56,417 - INFO - Train: [97/120][1800/3907]	eta 0:06:26 lr 0.00381966	time 0.1880 (0.1834)	loss 4.1938 (3.2677)	acc@1: 60.3932	acc@5: 69.2890	
2023-03-22 03:11:50,902 - INFO - Train: [97/120][2100/3907]	eta 0:05:30 lr 0.00381966	time 0.1873 (0.1832)	loss 4.3054 (3.2896)	acc@1: 53.0947	acc@5: 66.1174	
2023-03-22 03:12:44,023 - INFO - Train: [97/120][2400/3907]	eta 0:04:34 lr 0.00381966	time 0.1711 (0.1824)	loss 2.0392 (3.2805)	acc@1: 84.9881	acc@5: 95.9039	
2023-03-22 03:13:35,575 - INFO - Train: [97/120][2700/3907]	eta 0:03:38 lr 0.00381966	time 0.1704 (0.1812)	loss 2.2444 (3.2800)	acc@1: 86.6662	acc@5: 94.2879	
2023-03-22 03:14:27,794 - INFO - Train: [97/120][3000/3907]	eta 0:02:43 lr 0.00381966	time 0.1784 (0.1805)	loss 2.6351 (3.2828)	acc@1: 81.7832	acc@5: 87.6710	
2023-03-22 03:15:19,992 - INFO - Train: [97/120][3300/3907]	eta 0:01:49 lr 0.00381966	time 0.1708 (0.1799)	loss 2.2482 (3.2776)	acc@1: 81.9159	acc@5: 89.7171	
2023-03-22 03:16:12,143 - INFO - Train: [97/120][3600/3907]	eta 0:00:55 lr 0.00381966	time 0.1706 (0.1794)	loss 2.1427 (3.2835)	acc@1: 82.6727	acc@5: 94.2611	
2023-03-22 03:17:04,314 - INFO - Train: [97/120][3900/3907]	eta 0:00:01 lr 0.00381966	time 0.1750 (0.1790)	loss 3.3995 (3.2879)	acc@1: 69.7652	acc@5: 77.3861	
2023-03-22 03:17:05,444 - INFO - EPOCH 97 training takes 0:11:39
2023-03-22 03:17:06,523 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Latest.pth saved !!!
2023-03-22 03:17:06,524 - INFO - **********Latest test***********
2023-03-22 03:17:06,524 - INFO - eval epoch 97
2023-03-22 03:17:07,127 - INFO - Test: [0/782]	Time 0.602 (0.602)	Loss 2.2158 (2.2158)	Acc@1 77.344 (77.344)	Acc@5 94.531 (94.531)
2023-03-22 03:19:03,238 - INFO - Test: [200/782]	Time 0.569 (0.581)	Loss 2.5088 (2.5417)	Acc@1 70.312 (72.866)	Acc@5 86.719 (89.782)
2023-03-22 03:20:59,579 - INFO - Test: [400/782]	Time 0.594 (0.581)	Loss 2.4477 (2.5140)	Acc@1 74.219 (73.599)	Acc@5 91.406 (90.230)
2023-03-22 03:22:56,370 - INFO - Test: [600/782]	Time 0.570 (0.582)	Loss 2.5639 (2.4813)	Acc@1 71.875 (74.414)	Acc@5 89.844 (90.637)
2023-03-22 03:24:39,375 - INFO -  * Acc@1 74.862 Acc@5 90.914
2023-03-22 03:24:39,375 - INFO - Max accuracy: 77.5810%
2023-03-22 03:24:40,294 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Best.pth saved !!!
2023-03-22 03:24:40,294 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-22 03:24:42,325 - INFO - Train: [98/120][0/3907]	eta 2:11:58 lr 0.00351748	time 2.0267 (2.0267)	loss 3.7976 (3.7976)	acc@1: 63.7496	acc@5: 76.6157	
2023-03-22 03:25:36,658 - INFO - Train: [98/120][300/3907]	eta 0:11:15 lr 0.00351748	time 0.1797 (0.1872)	loss 4.6309 (3.2396)	acc@1: 46.1628	acc@5: 60.1802	
2023-03-22 03:26:31,250 - INFO - Train: [98/120][600/3907]	eta 0:10:10 lr 0.00351748	time 0.1797 (0.1846)	loss 1.9373 (3.2392)	acc@1: 90.4943	acc@5: 97.4554	
2023-03-22 03:27:25,727 - INFO - Train: [98/120][900/3907]	eta 0:09:12 lr 0.00351748	time 0.1798 (0.1836)	loss 2.7062 (3.2124)	acc@1: 80.8718	acc@5: 88.1527	
2023-03-22 03:28:20,253 - INFO - Train: [98/120][1200/3907]	eta 0:08:15 lr 0.00351748	time 0.1821 (0.1831)	loss 4.3386 (3.2275)	acc@1: 48.7324	acc@5: 66.1192	
2023-03-22 03:29:14,915 - INFO - Train: [98/120][1500/3907]	eta 0:07:20 lr 0.00351748	time 0.1801 (0.1830)	loss 2.2757 (3.2319)	acc@1: 86.9035	acc@5: 94.3924	
2023-03-22 03:30:09,547 - INFO - Train: [98/120][1800/3907]	eta 0:06:25 lr 0.00351748	time 0.1796 (0.1828)	loss 5.0278 (3.2328)	acc@1: 28.3099	acc@5: 48.6533	
2023-03-22 03:31:04,275 - INFO - Train: [98/120][2100/3907]	eta 0:05:30 lr 0.00351748	time 0.1727 (0.1828)	loss 2.2846 (3.2345)	acc@1: 88.2339	acc@5: 93.4981	
2023-03-22 03:31:56,766 - INFO - Train: [98/120][2400/3907]	eta 0:04:33 lr 0.00351748	time 0.1729 (0.1818)	loss 1.9414 (3.2276)	acc@1: 89.3469	acc@5: 97.1155	
2023-03-22 03:32:48,635 - INFO - Train: [98/120][2700/3907]	eta 0:03:38 lr 0.00351748	time 0.1710 (0.1808)	loss 3.6569 (3.2331)	acc@1: 66.9537	acc@5: 77.3542	
2023-03-22 03:33:40,831 - INFO - Train: [98/120][3000/3907]	eta 0:02:43 lr 0.00351748	time 0.1862 (0.1801)	loss 2.9275 (3.2391)	acc@1: 76.5300	acc@5: 86.5054	
2023-03-22 03:34:32,869 - INFO - Train: [98/120][3300/3907]	eta 0:01:48 lr 0.00351748	time 0.1743 (0.1795)	loss 4.7208 (3.2548)	acc@1: 44.6932	acc@5: 57.2582	
2023-03-22 03:35:24,998 - INFO - Train: [98/120][3600/3907]	eta 0:00:54 lr 0.00351748	time 0.1706 (0.1790)	loss 5.0665 (3.2655)	acc@1: 30.4078	acc@5: 53.8800	
2023-03-22 03:36:17,289 - INFO - Train: [98/120][3900/3907]	eta 0:00:01 lr 0.00351748	time 0.1763 (0.1787)	loss 2.0589 (3.2652)	acc@1: 86.9762	acc@5: 95.5180	
2023-03-22 03:36:18,450 - INFO - EPOCH 98 training takes 0:11:38
2023-03-22 03:36:19,552 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Latest.pth saved !!!
2023-03-22 03:36:19,552 - INFO - **********Latest test***********
2023-03-22 03:36:19,552 - INFO - eval epoch 98
2023-03-22 03:36:20,144 - INFO - Test: [0/782]	Time 0.591 (0.591)	Loss 2.2402 (2.2402)	Acc@1 78.906 (78.906)	Acc@5 96.875 (96.875)
2023-03-22 03:38:15,510 - INFO - Test: [200/782]	Time 0.580 (0.577)	Loss 2.4866 (2.5554)	Acc@1 75.000 (72.866)	Acc@5 89.844 (89.782)
2023-03-22 03:40:12,152 - INFO - Test: [400/782]	Time 0.603 (0.580)	Loss 2.4714 (2.5260)	Acc@1 73.438 (73.621)	Acc@5 89.844 (90.212)
2023-03-22 03:42:10,274 - INFO - Test: [600/782]	Time 0.571 (0.584)	Loss 2.5792 (2.4962)	Acc@1 75.000 (74.386)	Acc@5 89.062 (90.617)
2023-03-22 03:43:54,220 - INFO -  * Acc@1 74.827 Acc@5 90.932
2023-03-22 03:43:54,220 - INFO - Max accuracy: 77.5810%
2023-03-22 03:43:54,220 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-22 03:43:56,328 - INFO - Train: [99/120][0/3907]	eta 2:16:59 lr 0.00322659	time 2.1037 (2.1037)	loss 3.2636 (3.2636)	acc@1: 75.6362	acc@5: 83.5156	
2023-03-22 03:44:50,981 - INFO - Train: [99/120][300/3907]	eta 0:11:20 lr 0.00322659	time 0.1797 (0.1886)	loss 4.9210 (3.1360)	acc@1: 31.0431	acc@5: 49.8264	
2023-03-22 03:45:45,758 - INFO - Train: [99/120][600/3907]	eta 0:10:13 lr 0.00322659	time 0.1797 (0.1856)	loss 3.9322 (3.1742)	acc@1: 59.4238	acc@5: 73.4634	
2023-03-22 03:46:40,332 - INFO - Train: [99/120][900/3907]	eta 0:09:14 lr 0.00322659	time 0.1847 (0.1844)	loss 4.7482 (3.1857)	acc@1: 43.0086	acc@5: 55.3386	
2023-03-22 03:47:35,104 - INFO - Train: [99/120][1200/3907]	eta 0:08:17 lr 0.00322659	time 0.1872 (0.1839)	loss 2.0542 (3.2156)	acc@1: 86.8495	acc@5: 96.9288	
2023-03-22 03:48:29,702 - INFO - Train: [99/120][1500/3907]	eta 0:07:21 lr 0.00322659	time 0.1795 (0.1835)	loss 2.5162 (3.2235)	acc@1: 83.1620	acc@5: 92.7293	
2023-03-22 03:49:24,484 - INFO - Train: [99/120][1800/3907]	eta 0:06:26 lr 0.00322659	time 0.1813 (0.1834)	loss 2.4657 (3.2318)	acc@1: 86.7431	acc@5: 92.5745	
2023-03-22 03:50:19,150 - INFO - Train: [99/120][2100/3907]	eta 0:05:31 lr 0.00322659	time 0.1878 (0.1832)	loss 3.1334 (3.2286)	acc@1: 76.9597	acc@5: 85.2902	
2023-03-22 03:51:13,084 - INFO - Train: [99/120][2400/3907]	eta 0:04:35 lr 0.00322659	time 0.1752 (0.1828)	loss 4.0813 (3.2385)	acc@1: 56.4719	acc@5: 71.5673	
2023-03-22 03:52:05,120 - INFO - Train: [99/120][2700/3907]	eta 0:03:39 lr 0.00322659	time 0.1705 (0.1817)	loss 3.7425 (3.2540)	acc@1: 62.8551	acc@5: 74.8766	
2023-03-22 03:52:57,221 - INFO - Train: [99/120][3000/3907]	eta 0:02:44 lr 0.00322659	time 0.1712 (0.1809)	loss 3.1691 (3.2623)	acc@1: 73.0549	acc@5: 84.1739	
2023-03-22 03:53:49,474 - INFO - Train: [99/120][3300/3907]	eta 0:01:49 lr 0.00322659	time 0.1740 (0.1803)	loss 3.0565 (3.2752)	acc@1: 77.4582	acc@5: 85.1259	
2023-03-22 03:54:41,583 - INFO - Train: [99/120][3600/3907]	eta 0:00:55 lr 0.00322659	time 0.1708 (0.1798)	loss 2.7338 (3.2786)	acc@1: 79.9709	acc@5: 85.8561	
2023-03-22 03:55:33,857 - INFO - Train: [99/120][3900/3907]	eta 0:00:01 lr 0.00322659	time 0.1694 (0.1793)	loss 1.9586 (3.2841)	acc@1: 87.7079	acc@5: 97.0221	
2023-03-22 03:55:34,984 - INFO - EPOCH 99 training takes 0:11:40
2023-03-22 03:55:36,069 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Latest.pth saved !!!
2023-03-22 03:55:36,070 - INFO - **********Latest test***********
2023-03-22 03:55:36,070 - INFO - eval epoch 99
2023-03-22 03:55:36,695 - INFO - Test: [0/782]	Time 0.624 (0.624)	Loss 2.1976 (2.1976)	Acc@1 81.250 (81.250)	Acc@5 96.094 (96.094)
2023-03-22 03:57:32,505 - INFO - Test: [200/782]	Time 0.572 (0.579)	Loss 2.4837 (2.5094)	Acc@1 73.438 (73.908)	Acc@5 89.844 (90.190)
2023-03-22 03:59:29,392 - INFO - Test: [400/782]	Time 0.578 (0.582)	Loss 2.3969 (2.4833)	Acc@1 77.344 (74.542)	Acc@5 90.625 (90.570)
2023-03-22 04:01:26,464 - INFO - Test: [600/782]	Time 0.579 (0.583)	Loss 2.5769 (2.4544)	Acc@1 71.875 (75.295)	Acc@5 87.500 (90.942)
2023-03-22 04:03:09,698 - INFO -  * Acc@1 75.646 Acc@5 91.222
2023-03-22 04:03:09,698 - INFO - Max accuracy: 77.5810%
2023-03-22 04:03:10,748 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Best.pth saved !!!
2023-03-22 04:03:10,749 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-22 04:03:12,619 - INFO - Train: [100/120][0/3907]	eta 2:01:32 lr 0.00294720	time 1.8666 (1.8666)	loss 4.2174 (4.2174)	acc@1: 56.4992	acc@5: 67.0558	
2023-03-22 04:04:07,136 - INFO - Train: [100/120][300/3907]	eta 0:11:15 lr 0.00294720	time 0.1793 (0.1873)	loss 3.5740 (3.2205)	acc@1: 69.9864	acc@5: 77.7295	
2023-03-22 04:05:01,864 - INFO - Train: [100/120][600/3907]	eta 0:10:11 lr 0.00294720	time 0.1875 (0.1849)	loss 5.1895 (3.2037)	acc@1: 30.1833	acc@5: 50.6641	
2023-03-22 04:05:56,548 - INFO - Train: [100/120][900/3907]	eta 0:09:13 lr 0.00294720	time 0.1856 (0.1840)	loss 3.6624 (3.2110)	acc@1: 64.1694	acc@5: 78.0704	
2023-03-22 04:06:51,527 - INFO - Train: [100/120][1200/3907]	eta 0:08:17 lr 0.00294720	time 0.1800 (0.1838)	loss 4.8442 (3.2125)	acc@1: 34.4532	acc@5: 57.1225	
2023-03-22 04:07:46,231 - INFO - Train: [100/120][1500/3907]	eta 0:07:21 lr 0.00294720	time 0.1806 (0.1835)	loss 4.9005 (3.2213)	acc@1: 35.1111	acc@5: 55.3785	
2023-03-22 04:08:40,989 - INFO - Train: [100/120][1800/3907]	eta 0:06:26 lr 0.00294720	time 0.1842 (0.1834)	loss 4.6029 (3.2227)	acc@1: 47.4093	acc@5: 63.1215	
2023-03-22 04:09:35,536 - INFO - Train: [100/120][2100/3907]	eta 0:05:30 lr 0.00294720	time 0.1799 (0.1831)	loss 2.2111 (3.2217)	acc@1: 80.8075	acc@5: 92.4655	
2023-03-22 04:10:30,451 - INFO - Train: [100/120][2400/3907]	eta 0:04:35 lr 0.00294720	time 0.1883 (0.1831)	loss 1.9653 (3.2219)	acc@1: 90.6239	acc@5: 94.5301	
2023-03-22 04:11:22,696 - INFO - Train: [100/120][2700/3907]	eta 0:03:39 lr 0.00294720	time 0.1750 (0.1821)	loss 4.4873 (3.2290)	acc@1: 52.3370	acc@5: 63.2551	
2023-03-22 04:12:14,763 - INFO - Train: [100/120][3000/3907]	eta 0:02:44 lr 0.00294720	time 0.1797 (0.1813)	loss 4.9445 (3.2390)	acc@1: 37.9853	acc@5: 56.3636	
2023-03-22 04:13:06,948 - INFO - Train: [100/120][3300/3907]	eta 0:01:49 lr 0.00294720	time 0.1708 (0.1806)	loss 4.5277 (3.2413)	acc@1: 47.3525	acc@5: 60.9359	
2023-03-22 04:13:59,090 - INFO - Train: [100/120][3600/3907]	eta 0:00:55 lr 0.00294720	time 0.1752 (0.1800)	loss 3.2928 (3.2503)	acc@1: 73.2235	acc@5: 80.1314	
2023-03-22 04:14:51,195 - INFO - Train: [100/120][3900/3907]	eta 0:00:01 lr 0.00294720	time 0.1695 (0.1796)	loss 4.3679 (3.2579)	acc@1: 52.6972	acc@5: 63.1230	
2023-03-22 04:14:52,347 - INFO - EPOCH 100 training takes 0:11:41
2023-03-22 04:14:53,416 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Latest.pth saved !!!
2023-03-22 04:14:53,416 - INFO - **********Latest test***********
2023-03-22 04:14:53,416 - INFO - eval epoch 100
2023-03-22 04:14:54,016 - INFO - Test: [0/782]	Time 0.598 (0.598)	Loss 2.2883 (2.2883)	Acc@1 76.562 (76.562)	Acc@5 93.750 (93.750)
2023-03-22 04:16:49,719 - INFO - Test: [200/782]	Time 0.572 (0.579)	Loss 2.4842 (2.5310)	Acc@1 71.875 (73.371)	Acc@5 92.188 (90.050)
2023-03-22 04:18:45,569 - INFO - Test: [400/782]	Time 0.594 (0.579)	Loss 2.4714 (2.5052)	Acc@1 78.125 (74.045)	Acc@5 89.844 (90.428)
2023-03-22 04:20:42,073 - INFO - Test: [600/782]	Time 0.566 (0.580)	Loss 2.5617 (2.4736)	Acc@1 74.219 (74.873)	Acc@5 87.500 (90.867)
2023-03-22 04:22:25,290 - INFO -  * Acc@1 75.292 Acc@5 91.176
2023-03-22 04:22:25,291 - INFO - Max accuracy: 77.5810%
2023-03-22 04:22:25,291 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-22 04:22:27,370 - INFO - Train: [101/120][0/3907]	eta 2:15:09 lr 0.00267949	time 2.0755 (2.0755)	loss 5.1049 (5.1049)	acc@1: 29.3988	acc@5: 51.3961	
2023-03-22 04:23:21,790 - INFO - Train: [101/120][300/3907]	eta 0:11:16 lr 0.00267949	time 0.1788 (0.1877)	loss 2.1083 (3.2091)	acc@1: 83.5826	acc@5: 91.3941	
2023-03-22 04:24:16,473 - INFO - Train: [101/120][600/3907]	eta 0:10:11 lr 0.00267949	time 0.1798 (0.1850)	loss 4.7827 (3.3150)	acc@1: 41.2508	acc@5: 57.0244	
2023-03-22 04:25:11,086 - INFO - Train: [101/120][900/3907]	eta 0:09:13 lr 0.00267949	time 0.1870 (0.1840)	loss 2.3391 (3.2842)	acc@1: 83.5463	acc@5: 90.3819	
2023-03-22 04:26:05,695 - INFO - Train: [101/120][1200/3907]	eta 0:08:16 lr 0.00267949	time 0.1794 (0.1835)	loss 3.6439 (3.2868)	acc@1: 66.5537	acc@5: 77.2803	
2023-03-22 04:27:00,407 - INFO - Train: [101/120][1500/3907]	eta 0:07:21 lr 0.00267949	time 0.1807 (0.1833)	loss 2.5839 (3.2897)	acc@1: 80.7030	acc@5: 89.5017	
2023-03-22 04:27:55,172 - INFO - Train: [101/120][1800/3907]	eta 0:06:25 lr 0.00267949	time 0.1853 (0.1832)	loss 3.7216 (3.2855)	acc@1: 65.2483	acc@5: 74.6170	
2023-03-22 04:28:49,856 - INFO - Train: [101/120][2100/3907]	eta 0:05:30 lr 0.00267949	time 0.1807 (0.1830)	loss 2.2114 (3.2692)	acc@1: 82.6942	acc@5: 93.4118	
2023-03-22 04:29:43,326 - INFO - Train: [101/120][2400/3907]	eta 0:04:34 lr 0.00267949	time 0.1710 (0.1824)	loss 1.9862 (3.2618)	acc@1: 88.2663	acc@5: 95.2964	
2023-03-22 04:30:35,221 - INFO - Train: [101/120][2700/3907]	eta 0:03:38 lr 0.00267949	time 0.1765 (0.1814)	loss 2.2105 (3.2553)	acc@1: 84.0104	acc@5: 94.0275	
2023-03-22 04:31:27,143 - INFO - Train: [101/120][3000/3907]	eta 0:02:43 lr 0.00267949	time 0.1708 (0.1806)	loss 3.1214 (3.2513)	acc@1: 75.6790	acc@5: 83.9246	
2023-03-22 04:32:18,974 - INFO - Train: [101/120][3300/3907]	eta 0:01:49 lr 0.00267949	time 0.1706 (0.1798)	loss 2.2906 (3.2595)	acc@1: 82.1094	acc@5: 91.3148	
2023-03-22 04:33:11,080 - INFO - Train: [101/120][3600/3907]	eta 0:00:55 lr 0.00267949	time 0.1708 (0.1793)	loss 4.8512 (3.2725)	acc@1: 41.5307	acc@5: 57.0188	
2023-03-22 04:34:03,330 - INFO - Train: [101/120][3900/3907]	eta 0:00:01 lr 0.00267949	time 0.1694 (0.1789)	loss 3.7483 (3.2724)	acc@1: 67.2905	acc@5: 76.4938	
2023-03-22 04:34:04,522 - INFO - EPOCH 101 training takes 0:11:39
2023-03-22 04:34:05,596 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Latest.pth saved !!!
2023-03-22 04:34:05,596 - INFO - **********Latest test***********
2023-03-22 04:34:05,596 - INFO - eval epoch 101
2023-03-22 04:34:06,199 - INFO - Test: [0/782]	Time 0.601 (0.601)	Loss 2.2169 (2.2169)	Acc@1 78.906 (78.906)	Acc@5 96.094 (96.094)
2023-03-22 04:36:01,796 - INFO - Test: [200/782]	Time 0.573 (0.578)	Loss 2.4866 (2.5131)	Acc@1 75.000 (73.690)	Acc@5 88.281 (90.120)
2023-03-22 04:37:58,078 - INFO - Test: [400/782]	Time 0.595 (0.580)	Loss 2.4085 (2.4874)	Acc@1 78.906 (74.451)	Acc@5 90.625 (90.496)
2023-03-22 04:39:56,139 - INFO - Test: [600/782]	Time 0.562 (0.583)	Loss 2.5645 (2.4591)	Acc@1 76.562 (75.260)	Acc@5 87.500 (90.903)
2023-03-22 04:41:39,839 - INFO -  * Acc@1 75.766 Acc@5 91.242
2023-03-22 04:41:39,839 - INFO - Max accuracy: 77.5810%
2023-03-22 04:41:40,899 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Best.pth saved !!!
2023-03-22 04:41:40,899 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-22 04:41:42,825 - INFO - Train: [102/120][0/3907]	eta 2:05:07 lr 0.00242366	time 1.9216 (1.9216)	loss 5.1175 (5.1175)	acc@1: 28.9062	acc@5: 48.0662	
2023-03-22 04:42:37,279 - INFO - Train: [102/120][300/3907]	eta 0:11:15 lr 0.00242366	time 0.1786 (0.1873)	loss 2.0941 (3.1353)	acc@1: 85.6448	acc@5: 92.5972	
2023-03-22 04:43:31,958 - INFO - Train: [102/120][600/3907]	eta 0:10:11 lr 0.00242366	time 0.1801 (0.1848)	loss 2.0452 (3.1311)	acc@1: 85.5992	acc@5: 94.0810	
2023-03-22 04:44:26,779 - INFO - Train: [102/120][900/3907]	eta 0:09:13 lr 0.00242366	time 0.1858 (0.1841)	loss 2.0785 (3.1922)	acc@1: 83.9458	acc@5: 93.9564	
2023-03-22 04:45:21,543 - INFO - Train: [102/120][1200/3907]	eta 0:08:17 lr 0.00242366	time 0.1861 (0.1837)	loss 4.9988 (3.1999)	acc@1: 32.1170	acc@5: 51.1736	
2023-03-22 04:46:16,210 - INFO - Train: [102/120][1500/3907]	eta 0:07:21 lr 0.00242366	time 0.1860 (0.1834)	loss 4.8365 (3.2300)	acc@1: 40.0424	acc@5: 56.9427	
2023-03-22 04:47:10,793 - INFO - Train: [102/120][1800/3907]	eta 0:06:25 lr 0.00242366	time 0.1823 (0.1832)	loss 5.0871 (3.2215)	acc@1: 35.7833	acc@5: 48.9891	
2023-03-22 04:48:05,250 - INFO - Train: [102/120][2100/3907]	eta 0:05:30 lr 0.00242366	time 0.1788 (0.1829)	loss 1.9172 (3.2224)	acc@1: 88.2771	acc@5: 95.3080	
2023-03-22 04:48:57,288 - INFO - Train: [102/120][2400/3907]	eta 0:04:33 lr 0.00242366	time 0.1705 (0.1817)	loss 2.4820 (3.2155)	acc@1: 82.4619	acc@5: 90.6722	
2023-03-22 04:49:49,408 - INFO - Train: [102/120][2700/3907]	eta 0:03:38 lr 0.00242366	time 0.1762 (0.1809)	loss 4.8828 (3.2203)	acc@1: 37.5979	acc@5: 53.3916	
2023-03-22 04:50:41,456 - INFO - Train: [102/120][3000/3907]	eta 0:02:43 lr 0.00242366	time 0.1782 (0.1801)	loss 4.7684 (3.2237)	acc@1: 41.6148	acc@5: 60.0384	
2023-03-22 04:51:33,638 - INFO - Train: [102/120][3300/3907]	eta 0:01:48 lr 0.00242366	time 0.1704 (0.1796)	loss 4.8747 (3.2294)	acc@1: 37.5854	acc@5: 55.4976	
2023-03-22 04:52:25,906 - INFO - Train: [102/120][3600/3907]	eta 0:00:54 lr 0.00242366	time 0.1819 (0.1791)	loss 2.8451 (3.2368)	acc@1: 79.9706	acc@5: 86.3340	
2023-03-22 04:53:18,108 - INFO - Train: [102/120][3900/3907]	eta 0:00:01 lr 0.00242366	time 0.1710 (0.1787)	loss 2.0577 (3.2369)	acc@1: 86.3184	acc@5: 95.5656	
2023-03-22 04:53:19,270 - INFO - EPOCH 102 training takes 0:11:38
2023-03-22 04:53:20,235 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Latest.pth saved !!!
2023-03-22 04:53:20,236 - INFO - **********Latest test***********
2023-03-22 04:53:20,236 - INFO - eval epoch 102
2023-03-22 04:53:20,821 - INFO - Test: [0/782]	Time 0.584 (0.584)	Loss 2.2591 (2.2591)	Acc@1 78.906 (78.906)	Acc@5 96.094 (96.094)
2023-03-22 04:55:16,593 - INFO - Test: [200/782]	Time 0.567 (0.579)	Loss 2.5333 (2.5463)	Acc@1 71.875 (73.527)	Acc@5 89.844 (90.104)
2023-03-22 04:57:11,983 - INFO - Test: [400/782]	Time 0.575 (0.578)	Loss 2.4083 (2.5194)	Acc@1 78.125 (74.176)	Acc@5 89.844 (90.528)
2023-03-22 04:59:08,748 - INFO - Test: [600/782]	Time 0.572 (0.580)	Loss 2.5455 (2.4906)	Acc@1 75.781 (74.875)	Acc@5 87.500 (90.875)
2023-03-22 05:00:52,129 - INFO -  * Acc@1 75.306 Acc@5 91.204
2023-03-22 05:00:52,129 - INFO - Max accuracy: 77.5810%
2023-03-22 05:00:52,129 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-22 05:00:54,139 - INFO - Train: [103/120][0/3907]	eta 2:10:38 lr 0.00217987	time 2.0063 (2.0063)	loss 1.9385 (1.9385)	acc@1: 87.9684	acc@5: 96.5312	
2023-03-22 05:01:48,723 - INFO - Train: [103/120][300/3907]	eta 0:11:18 lr 0.00217987	time 0.1867 (0.1880)	loss 4.6021 (3.1404)	acc@1: 46.2256	acc@5: 58.9615	
2023-03-22 05:02:43,407 - INFO - Train: [103/120][600/3907]	eta 0:10:12 lr 0.00217987	time 0.1847 (0.1851)	loss 4.4267 (3.1692)	acc@1: 53.6218	acc@5: 66.2903	
2023-03-22 05:03:37,978 - INFO - Train: [103/120][900/3907]	eta 0:09:13 lr 0.00217987	time 0.1796 (0.1841)	loss 4.9448 (3.1849)	acc@1: 37.9211	acc@5: 59.0600	
2023-03-22 05:04:32,613 - INFO - Train: [103/120][1200/3907]	eta 0:08:16 lr 0.00217987	time 0.1798 (0.1836)	loss 1.9932 (3.1760)	acc@1: 90.5779	acc@5: 95.2634	
2023-03-22 05:05:27,323 - INFO - Train: [103/120][1500/3907]	eta 0:07:21 lr 0.00217987	time 0.1799 (0.1833)	loss 2.6920 (3.1921)	acc@1: 76.7429	acc@5: 86.2444	
2023-03-22 05:06:22,164 - INFO - Train: [103/120][1800/3907]	eta 0:06:26 lr 0.00217987	time 0.1801 (0.1832)	loss 2.7339 (3.1739)	acc@1: 83.8803	acc@5: 87.4593	
2023-03-22 05:07:16,163 - INFO - Train: [103/120][2100/3907]	eta 0:05:30 lr 0.00217987	time 0.1763 (0.1828)	loss 1.9971 (3.1810)	acc@1: 86.6669	acc@5: 94.4747	
2023-03-22 05:08:08,093 - INFO - Train: [103/120][2400/3907]	eta 0:04:33 lr 0.00217987	time 0.1720 (0.1816)	loss 2.9354 (3.1831)	acc@1: 77.8049	acc@5: 85.5883	
2023-03-22 05:09:00,220 - INFO - Train: [103/120][2700/3907]	eta 0:03:38 lr 0.00217987	time 0.1709 (0.1807)	loss 2.4793 (3.1911)	acc@1: 87.1486	acc@5: 91.5402	
2023-03-22 05:09:52,210 - INFO - Train: [103/120][3000/3907]	eta 0:02:43 lr 0.00217987	time 0.1706 (0.1800)	loss 2.0124 (3.1937)	acc@1: 87.1788	acc@5: 94.9655	
2023-03-22 05:10:44,190 - INFO - Train: [103/120][3300/3907]	eta 0:01:48 lr 0.00217987	time 0.1717 (0.1794)	loss 3.3421 (3.2118)	acc@1: 69.8472	acc@5: 79.4040	
2023-03-22 05:11:36,155 - INFO - Train: [103/120][3600/3907]	eta 0:00:54 lr 0.00217987	time 0.1722 (0.1788)	loss 5.1621 (3.2066)	acc@1: 33.4089	acc@5: 49.4433	
2023-03-22 05:12:28,210 - INFO - Train: [103/120][3900/3907]	eta 0:00:01 lr 0.00217987	time 0.1733 (0.1784)	loss 2.0755 (3.2193)	acc@1: 86.5540	acc@5: 94.9797	
2023-03-22 05:12:29,360 - INFO - EPOCH 103 training takes 0:11:37
2023-03-22 05:12:30,469 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Latest.pth saved !!!
2023-03-22 05:12:30,470 - INFO - **********Latest test***********
2023-03-22 05:12:30,470 - INFO - eval epoch 103
2023-03-22 05:12:31,062 - INFO - Test: [0/782]	Time 0.591 (0.591)	Loss 2.2727 (2.2727)	Acc@1 78.125 (78.125)	Acc@5 94.531 (94.531)
2023-03-22 05:14:25,745 - INFO - Test: [200/782]	Time 0.567 (0.574)	Loss 2.4999 (2.5419)	Acc@1 70.312 (73.570)	Acc@5 89.844 (90.011)
2023-03-22 05:16:20,851 - INFO - Test: [400/782]	Time 0.578 (0.575)	Loss 2.4581 (2.5140)	Acc@1 76.562 (74.310)	Acc@5 91.406 (90.422)
2023-03-22 05:18:16,969 - INFO - Test: [600/782]	Time 0.561 (0.577)	Loss 2.5481 (2.4857)	Acc@1 74.219 (75.026)	Acc@5 89.844 (90.790)
2023-03-22 05:19:59,788 - INFO -  * Acc@1 75.439 Acc@5 91.150
2023-03-22 05:19:59,788 - INFO - Max accuracy: 77.5810%
2023-03-22 05:19:59,788 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-22 05:20:01,916 - INFO - Train: [104/120][0/3907]	eta 2:18:18 lr 0.00194829	time 2.1241 (2.1241)	loss 1.8551 (1.8551)	acc@1: 91.5127	acc@5: 96.9408	
2023-03-22 05:20:56,246 - INFO - Train: [104/120][300/3907]	eta 0:11:16 lr 0.00194829	time 0.1795 (0.1875)	loss 3.6722 (3.1365)	acc@1: 68.5201	acc@5: 74.1083	
2023-03-22 05:21:50,685 - INFO - Train: [104/120][600/3907]	eta 0:10:10 lr 0.00194829	time 0.1796 (0.1845)	loss 2.0296 (3.1534)	acc@1: 92.4614	acc@5: 95.4921	
2023-03-22 05:22:45,611 - INFO - Train: [104/120][900/3907]	eta 0:09:13 lr 0.00194829	time 0.1810 (0.1840)	loss 4.9622 (3.1683)	acc@1: 30.5216	acc@5: 49.6710	
2023-03-22 05:23:40,300 - INFO - Train: [104/120][1200/3907]	eta 0:08:17 lr 0.00194829	time 0.1822 (0.1836)	loss 2.0012 (3.1700)	acc@1: 87.4715	acc@5: 95.2815	
2023-03-22 05:24:35,082 - INFO - Train: [104/120][1500/3907]	eta 0:07:21 lr 0.00194829	time 0.1809 (0.1834)	loss 1.8041 (3.1501)	acc@1: 90.5991	acc@5: 98.4093	
2023-03-22 05:25:29,530 - INFO - Train: [104/120][1800/3907]	eta 0:06:25 lr 0.00194829	time 0.1876 (0.1831)	loss 3.4018 (3.1733)	acc@1: 70.3251	acc@5: 78.6399	
2023-03-22 05:26:24,377 - INFO - Train: [104/120][2100/3907]	eta 0:05:30 lr 0.00194829	time 0.1799 (0.1830)	loss 3.2623 (3.1664)	acc@1: 73.1169	acc@5: 81.3452	
2023-03-22 05:27:19,253 - INFO - Train: [104/120][2400/3907]	eta 0:04:35 lr 0.00194829	time 0.1817 (0.1830)	loss 2.1021 (3.1885)	acc@1: 84.9216	acc@5: 93.4914	
2023-03-22 05:28:14,090 - INFO - Train: [104/120][2700/3907]	eta 0:03:40 lr 0.00194829	time 0.1823 (0.1830)	loss 4.0267 (3.2130)	acc@1: 55.7857	acc@5: 71.6444	
2023-03-22 05:29:08,680 - INFO - Train: [104/120][3000/3907]	eta 0:02:45 lr 0.00194829	time 0.1800 (0.1829)	loss 2.0589 (3.2192)	acc@1: 87.8402	acc@5: 95.5454	
2023-03-22 05:30:01,719 - INFO - Train: [104/120][3300/3907]	eta 0:01:50 lr 0.00194829	time 0.1743 (0.1823)	loss 2.7738 (3.2169)	acc@1: 79.9275	acc@5: 87.0639	
2023-03-22 05:30:53,786 - INFO - Train: [104/120][3600/3907]	eta 0:00:55 lr 0.00194829	time 0.1710 (0.1816)	loss 4.9290 (3.2255)	acc@1: 33.0503	acc@5: 53.1333	
2023-03-22 05:31:45,826 - INFO - Train: [104/120][3900/3907]	eta 0:00:01 lr 0.00194829	time 0.1701 (0.1810)	loss 2.7953 (3.2399)	acc@1: 80.4487	acc@5: 88.9845	
2023-03-22 05:31:46,997 - INFO - EPOCH 104 training takes 0:11:47
2023-03-22 05:31:48,061 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Latest.pth saved !!!
2023-03-22 05:31:48,061 - INFO - **********Latest test***********
2023-03-22 05:31:48,061 - INFO - eval epoch 104
2023-03-22 05:31:48,644 - INFO - Test: [0/782]	Time 0.582 (0.582)	Loss 2.1586 (2.1586)	Acc@1 79.688 (79.688)	Acc@5 96.094 (96.094)
2023-03-22 05:33:43,933 - INFO - Test: [200/782]	Time 0.572 (0.576)	Loss 2.4224 (2.4873)	Acc@1 75.781 (74.359)	Acc@5 90.625 (90.454)
2023-03-22 05:35:39,183 - INFO - Test: [400/782]	Time 0.575 (0.576)	Loss 2.4057 (2.4614)	Acc@1 76.562 (75.023)	Acc@5 91.406 (90.867)
2023-03-22 05:37:35,350 - INFO - Test: [600/782]	Time 0.569 (0.578)	Loss 2.5163 (2.4298)	Acc@1 73.438 (75.835)	Acc@5 88.281 (91.296)
2023-03-22 05:39:18,399 - INFO -  * Acc@1 76.290 Acc@5 91.622
2023-03-22 05:39:18,399 - INFO - Max accuracy: 77.5810%
2023-03-22 05:39:19,457 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Best.pth saved !!!
2023-03-22 05:39:19,457 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-22 05:39:21,464 - INFO - Train: [105/120][0/3907]	eta 2:10:24 lr 0.00172909	time 2.0027 (2.0027)	loss 5.1345 (5.1345)	acc@1: 30.1359	acc@5: 50.0385	
2023-03-22 05:40:15,778 - INFO - Train: [105/120][300/3907]	eta 0:11:14 lr 0.00172909	time 0.1789 (0.1871)	loss 1.8379 (3.2654)	acc@1: 91.0161	acc@5: 94.9057	
2023-03-22 05:41:10,462 - INFO - Train: [105/120][600/3907]	eta 0:10:10 lr 0.00172909	time 0.1836 (0.1847)	loss 1.9692 (3.2284)	acc@1: 85.6654	acc@5: 95.0098	
2023-03-22 05:42:05,221 - INFO - Train: [105/120][900/3907]	eta 0:09:13 lr 0.00172909	time 0.1848 (0.1840)	loss 4.3731 (3.2431)	acc@1: 50.0905	acc@5: 64.1177	
2023-03-22 05:42:59,989 - INFO - Train: [105/120][1200/3907]	eta 0:08:17 lr 0.00172909	time 0.1801 (0.1836)	loss 2.9082 (3.2175)	acc@1: 77.7820	acc@5: 84.1633	
2023-03-22 05:43:54,666 - INFO - Train: [105/120][1500/3907]	eta 0:07:21 lr 0.00172909	time 0.1824 (0.1833)	loss 1.7329 (3.2142)	acc@1: 93.6319	acc@5: 99.8739	
2023-03-22 05:44:49,335 - INFO - Train: [105/120][1800/3907]	eta 0:06:25 lr 0.00172909	time 0.1799 (0.1832)	loss 1.8182 (3.2096)	acc@1: 92.7126	acc@5: 96.6080	
2023-03-22 05:45:44,320 - INFO - Train: [105/120][2100/3907]	eta 0:05:30 lr 0.00172909	time 0.1877 (0.1832)	loss 1.8989 (3.2072)	acc@1: 89.8276	acc@5: 97.6387	
2023-03-22 05:46:39,086 - INFO - Train: [105/120][2400/3907]	eta 0:04:35 lr 0.00172909	time 0.1807 (0.1831)	loss 1.8360 (3.2105)	acc@1: 89.7366	acc@5: 96.7595	
2023-03-22 05:47:32,539 - INFO - Train: [105/120][2700/3907]	eta 0:03:40 lr 0.00172909	time 0.1709 (0.1825)	loss 3.0023 (3.1965)	acc@1: 76.9088	acc@5: 86.4983	
2023-03-22 05:48:24,595 - INFO - Train: [105/120][3000/3907]	eta 0:02:44 lr 0.00172909	time 0.1757 (0.1816)	loss 5.0273 (3.2073)	acc@1: 31.1092	acc@5: 51.9113	
2023-03-22 05:49:16,652 - INFO - Train: [105/120][3300/3907]	eta 0:01:49 lr 0.00172909	time 0.1782 (0.1809)	loss 5.0512 (3.2011)	acc@1: 34.1499	acc@5: 49.7308	
2023-03-22 05:50:08,635 - INFO - Train: [105/120][3600/3907]	eta 0:00:55 lr 0.00172909	time 0.1706 (0.1803)	loss 2.0691 (3.2119)	acc@1: 88.4484	acc@5: 94.5457	
2023-03-22 05:51:00,700 - INFO - Train: [105/120][3900/3907]	eta 0:00:01 lr 0.00172909	time 0.1699 (0.1798)	loss 3.7869 (3.2177)	acc@1: 63.9950	acc@5: 72.2914	
2023-03-22 05:51:01,887 - INFO - EPOCH 105 training takes 0:11:42
2023-03-22 05:51:02,940 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Latest.pth saved !!!
2023-03-22 05:51:02,940 - INFO - **********Latest test***********
2023-03-22 05:51:02,940 - INFO - eval epoch 105
2023-03-22 05:51:03,544 - INFO - Test: [0/782]	Time 0.603 (0.603)	Loss 2.2185 (2.2185)	Acc@1 78.125 (78.125)	Acc@5 96.875 (96.875)
2023-03-22 05:52:59,961 - INFO - Test: [200/782]	Time 0.577 (0.582)	Loss 2.4443 (2.4975)	Acc@1 74.219 (74.300)	Acc@5 89.062 (90.271)
2023-03-22 05:54:56,335 - INFO - Test: [400/782]	Time 0.586 (0.582)	Loss 2.3750 (2.4714)	Acc@1 79.688 (74.945)	Acc@5 91.406 (90.769)
2023-03-22 05:56:53,556 - INFO - Test: [600/782]	Time 0.583 (0.583)	Loss 2.5807 (2.4398)	Acc@1 74.219 (75.721)	Acc@5 89.062 (91.210)
2023-03-22 05:58:37,903 - INFO -  * Acc@1 76.197 Acc@5 91.494
2023-03-22 05:58:37,904 - INFO - Max accuracy: 77.5810%
2023-03-22 05:58:37,904 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-22 05:58:40,054 - INFO - Train: [106/120][0/3907]	eta 2:19:45 lr 0.00152241	time 2.1462 (2.1462)	loss 2.8809 (2.8809)	acc@1: 81.6225	acc@5: 86.5480	
2023-03-22 05:59:34,769 - INFO - Train: [106/120][300/3907]	eta 0:11:21 lr 0.00152241	time 0.1794 (0.1889)	loss 2.3364 (3.1180)	acc@1: 84.3716	acc@5: 93.3201	
2023-03-22 06:00:29,867 - INFO - Train: [106/120][600/3907]	eta 0:10:16 lr 0.00152241	time 0.1831 (0.1863)	loss 2.4622 (3.1290)	acc@1: 82.8007	acc@5: 90.2504	
2023-03-22 06:01:24,866 - INFO - Train: [106/120][900/3907]	eta 0:09:17 lr 0.00152241	time 0.1800 (0.1853)	loss 2.5247 (3.1838)	acc@1: 84.1820	acc@5: 90.0803	
2023-03-22 06:02:19,771 - INFO - Train: [106/120][1200/3907]	eta 0:08:20 lr 0.00152241	time 0.1797 (0.1847)	loss 4.2992 (3.1822)	acc@1: 54.5034	acc@5: 66.4821	
2023-03-22 06:03:15,198 - INFO - Train: [106/120][1500/3907]	eta 0:07:24 lr 0.00152241	time 0.1897 (0.1847)	loss 2.5894 (3.1800)	acc@1: 81.4519	acc@5: 88.8566	
2023-03-22 06:04:11,884 - INFO - Train: [106/120][1800/3907]	eta 0:06:30 lr 0.00152241	time 0.2047 (0.1854)	loss 5.0153 (3.1669)	acc@1: 34.9211	acc@5: 50.9194	
2023-03-22 06:05:08,286 - INFO - Train: [106/120][2100/3907]	eta 0:05:35 lr 0.00152241	time 0.1907 (0.1858)	loss 2.1862 (3.1733)	acc@1: 86.8312	acc@5: 92.1150	
2023-03-22 06:06:03,785 - INFO - Train: [106/120][2400/3907]	eta 0:04:39 lr 0.00152241	time 0.1795 (0.1857)	loss 2.2094 (3.1784)	acc@1: 86.4927	acc@5: 94.8341	
2023-03-22 06:06:58,450 - INFO - Train: [106/120][2700/3907]	eta 0:03:43 lr 0.00152241	time 0.1792 (0.1853)	loss 4.7180 (3.1881)	acc@1: 47.1367	acc@5: 55.9811	
2023-03-22 06:07:53,263 - INFO - Train: [106/120][3000/3907]	eta 0:02:47 lr 0.00152241	time 0.1735 (0.1851)	loss 4.3400 (3.1765)	acc@1: 53.3943	acc@5: 63.5279	
2023-03-22 06:08:45,702 - INFO - Train: [106/120][3300/3907]	eta 0:01:51 lr 0.00152241	time 0.1711 (0.1841)	loss 1.8831 (3.1805)	acc@1: 92.9672	acc@5: 95.3109	
2023-03-22 06:09:38,813 - INFO - Train: [106/120][3600/3907]	eta 0:00:56 lr 0.00152241	time 0.1921 (0.1835)	loss 2.8139 (3.1896)	acc@1: 76.5528	acc@5: 87.2657	
2023-03-22 06:10:32,036 - INFO - Train: [106/120][3900/3907]	eta 0:00:01 lr 0.00152241	time 0.1740 (0.1831)	loss 3.9079 (3.1951)	acc@1: 64.0406	acc@5: 72.0035	
2023-03-22 06:10:33,228 - INFO - EPOCH 106 training takes 0:11:55
2023-03-22 06:10:34,297 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Latest.pth saved !!!
2023-03-22 06:10:34,298 - INFO - **********Latest test***********
2023-03-22 06:10:34,298 - INFO - eval epoch 106
2023-03-22 06:10:34,887 - INFO - Test: [0/782]	Time 0.588 (0.588)	Loss 2.1956 (2.1956)	Acc@1 77.344 (77.344)	Acc@5 96.875 (96.875)
2023-03-22 06:12:36,868 - INFO - Test: [200/782]	Time 0.594 (0.610)	Loss 2.4018 (2.4634)	Acc@1 71.875 (74.712)	Acc@5 91.406 (90.563)
2023-03-22 06:14:51,679 - INFO - Test: [400/782]	Time 0.596 (0.642)	Loss 2.3585 (2.4365)	Acc@1 77.344 (75.417)	Acc@5 90.625 (91.020)
2023-03-22 06:16:57,567 - INFO - Test: [600/782]	Time 0.588 (0.638)	Loss 2.5041 (2.4058)	Acc@1 76.562 (76.199)	Acc@5 90.625 (91.435)
2023-03-22 06:19:33,907 - INFO -  * Acc@1 76.631 Acc@5 91.734
2023-03-22 06:19:33,907 - INFO - Max accuracy: 77.5810%
2023-03-22 06:19:35,237 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Best.pth saved !!!
2023-03-22 06:19:35,239 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-22 06:19:38,621 - INFO - Train: [107/120][0/3907]	eta 3:39:27 lr 0.00132839	time 3.3701 (3.3701)	loss 4.6403 (4.6403)	acc@1: 47.4784	acc@5: 60.7854	
2023-03-22 06:20:38,544 - INFO - Train: [107/120][300/3907]	eta 0:12:38 lr 0.00132839	time 0.2011 (0.2103)	loss 3.0675 (3.1124)	acc@1: 77.1315	acc@5: 86.1037	
2023-03-22 06:21:38,545 - INFO - Train: [107/120][600/3907]	eta 0:11:18 lr 0.00132839	time 0.2076 (0.2051)	loss 3.3844 (3.1376)	acc@1: 71.7807	acc@5: 80.4508	
2023-03-22 06:22:38,162 - INFO - Train: [107/120][900/3907]	eta 0:10:10 lr 0.00132839	time 0.1954 (0.2030)	loss 4.2722 (3.1255)	acc@1: 53.1508	acc@5: 64.9362	
2023-03-22 06:23:37,951 - INFO - Train: [107/120][1200/3907]	eta 0:09:07 lr 0.00132839	time 0.1992 (0.2021)	loss 2.4162 (3.1482)	acc@1: 85.4262	acc@5: 89.8812	
2023-03-22 06:24:37,830 - INFO - Train: [107/120][1500/3907]	eta 0:08:05 lr 0.00132839	time 0.1916 (0.2016)	loss 4.8763 (3.1519)	acc@1: 39.9425	acc@5: 53.5526	
2023-03-22 06:25:37,484 - INFO - Train: [107/120][1800/3907]	eta 0:07:03 lr 0.00132839	time 0.1932 (0.2011)	loss 1.7681 (3.1481)	acc@1: 95.2444	acc@5: 98.3677	
2023-03-22 06:26:37,460 - INFO - Train: [107/120][2100/3907]	eta 0:06:03 lr 0.00132839	time 0.1903 (0.2009)	loss 4.7366 (3.1617)	acc@1: 42.9490	acc@5: 56.9129	
2023-03-22 06:27:37,460 - INFO - Train: [107/120][2400/3907]	eta 0:05:02 lr 0.00132839	time 0.1937 (0.2008)	loss 4.5821 (3.1544)	acc@1: 44.0089	acc@5: 64.0379	
2023-03-22 06:28:36,342 - INFO - Train: [107/120][2700/3907]	eta 0:04:01 lr 0.00132839	time 0.2023 (0.2003)	loss 4.0504 (3.1479)	acc@1: 61.1362	acc@5: 70.1440	
2023-03-22 06:29:31,431 - INFO - Train: [107/120][3000/3907]	eta 0:03:00 lr 0.00132839	time 0.1778 (0.1987)	loss 4.6587 (3.1523)	acc@1: 44.0343	acc@5: 60.5346	
2023-03-22 06:30:23,887 - INFO - Train: [107/120][3300/3907]	eta 0:01:59 lr 0.00132839	time 0.1732 (0.1965)	loss 5.0365 (3.1596)	acc@1: 30.4622	acc@5: 49.9978	
2023-03-22 06:31:16,457 - INFO - Train: [107/120][3600/3907]	eta 0:00:59 lr 0.00132839	time 0.1703 (0.1947)	loss 3.7462 (3.1682)	acc@1: 66.5317	acc@5: 73.8171	
2023-03-22 06:32:09,015 - INFO - Train: [107/120][3900/3907]	eta 0:00:01 lr 0.00132839	time 0.1717 (0.1932)	loss 1.8374 (3.1777)	acc@1: 91.3987	acc@5: 97.6481	
2023-03-22 06:32:10,246 - INFO - EPOCH 107 training takes 0:12:34
2023-03-22 06:32:11,339 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Latest.pth saved !!!
2023-03-22 06:32:11,339 - INFO - **********Latest test***********
2023-03-22 06:32:11,339 - INFO - eval epoch 107
2023-03-22 06:32:11,929 - INFO - Test: [0/782]	Time 0.589 (0.589)	Loss 2.1267 (2.1267)	Acc@1 80.469 (80.469)	Acc@5 96.875 (96.875)
2023-03-22 06:34:16,262 - INFO - Test: [200/782]	Time 0.825 (0.622)	Loss 2.4113 (2.4386)	Acc@1 71.094 (75.334)	Acc@5 91.406 (90.932)
2023-03-22 06:36:38,624 - INFO - Test: [400/782]	Time 0.886 (0.667)	Loss 2.3602 (2.4131)	Acc@1 78.125 (75.968)	Acc@5 90.625 (91.307)
2023-03-22 06:39:14,364 - INFO - Test: [600/782]	Time 0.735 (0.704)	Loss 2.4924 (2.3834)	Acc@1 74.219 (76.783)	Acc@5 90.625 (91.681)
2023-03-22 06:41:32,495 - INFO -  * Acc@1 77.171 Acc@5 91.968
2023-03-22 06:41:32,495 - INFO - Max accuracy: 77.5810%
2023-03-22 06:41:33,951 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Best.pth saved !!!
2023-03-22 06:41:33,951 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-22 06:41:37,059 - INFO - Train: [108/120][0/3907]	eta 3:22:10 lr 0.00114717	time 3.1047 (3.1047)	loss 3.7913 (3.7913)	acc@1: 66.3581	acc@5: 74.2697	
2023-03-22 06:42:34,620 - INFO - Train: [108/120][300/3907]	eta 0:12:06 lr 0.00114717	time 0.1906 (0.2015)	loss 1.9119 (3.1882)	acc@1: 94.1634	acc@5: 96.4753	
2023-03-22 06:43:32,524 - INFO - Train: [108/120][600/3907]	eta 0:10:52 lr 0.00114717	time 0.1893 (0.1973)	loss 1.9096 (3.1808)	acc@1: 88.0111	acc@5: 97.2745	
2023-03-22 06:44:29,850 - INFO - Train: [108/120][900/3907]	eta 0:09:47 lr 0.00114717	time 0.1929 (0.1952)	loss 4.0300 (3.2018)	acc@1: 58.6780	acc@5: 69.1287	
2023-03-22 06:45:28,967 - INFO - Train: [108/120][1200/3907]	eta 0:08:49 lr 0.00114717	time 0.2091 (0.1957)	loss 2.1144 (3.1704)	acc@1: 89.3116	acc@5: 94.6082	
2023-03-22 06:46:27,718 - INFO - Train: [108/120][1500/3907]	eta 0:07:51 lr 0.00114717	time 0.1881 (0.1957)	loss 4.2964 (3.1641)	acc@1: 50.5617	acc@5: 67.1245	
2023-03-22 06:47:25,983 - INFO - Train: [108/120][1800/3907]	eta 0:06:51 lr 0.00114717	time 0.1819 (0.1955)	loss 3.6510 (3.1595)	acc@1: 67.7739	acc@5: 78.1844	
2023-03-22 06:48:23,649 - INFO - Train: [108/120][2100/3907]	eta 0:05:52 lr 0.00114717	time 0.1802 (0.1950)	loss 3.9327 (3.1637)	acc@1: 58.8712	acc@5: 71.0678	
2023-03-22 06:49:18,331 - INFO - Train: [108/120][2400/3907]	eta 0:04:51 lr 0.00114717	time 0.1834 (0.1934)	loss 2.5400 (3.1689)	acc@1: 85.0402	acc@5: 89.4363	
2023-03-22 06:50:13,142 - INFO - Train: [108/120][2700/3907]	eta 0:03:51 lr 0.00114717	time 0.1761 (0.1922)	loss 2.6599 (3.1618)	acc@1: 79.1905	acc@5: 86.5230	
2023-03-22 06:51:07,628 - INFO - Train: [108/120][3000/3907]	eta 0:02:53 lr 0.00114717	time 0.1781 (0.1912)	loss 1.7812 (3.1563)	acc@1: 91.2676	acc@5: 98.2881	
2023-03-22 06:52:01,943 - INFO - Train: [108/120][3300/3907]	eta 0:01:55 lr 0.00114717	time 0.1831 (0.1902)	loss 4.6839 (3.1645)	acc@1: 42.9583	acc@5: 56.7018	
2023-03-22 06:52:56,646 - INFO - Train: [108/120][3600/3907]	eta 0:00:58 lr 0.00114717	time 0.1754 (0.1896)	loss 2.6410 (3.1641)	acc@1: 77.7996	acc@5: 88.9139	
2023-03-22 06:53:51,378 - INFO - Train: [108/120][3900/3907]	eta 0:00:01 lr 0.00114717	time 0.1735 (0.1890)	loss 5.4762 (3.1678)	acc@1: 25.9714	acc@5: 42.3505	
2023-03-22 06:53:52,757 - INFO - EPOCH 108 training takes 0:12:18
2023-03-22 06:53:54,157 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Latest.pth saved !!!
2023-03-22 06:53:54,158 - INFO - **********Latest test***********
2023-03-22 06:53:54,158 - INFO - eval epoch 108
2023-03-22 06:53:55,069 - INFO - Test: [0/782]	Time 0.909 (0.909)	Loss 2.2332 (2.2332)	Acc@1 80.469 (80.469)	Acc@5 96.094 (96.094)
2023-03-22 06:56:36,864 - INFO - Test: [200/782]	Time 0.719 (0.809)	Loss 2.4973 (2.5520)	Acc@1 71.875 (73.698)	Acc@5 90.625 (90.104)
2023-03-22 06:59:23,624 - INFO - Test: [400/782]	Time 0.775 (0.822)	Loss 2.4605 (2.5247)	Acc@1 78.125 (74.417)	Acc@5 89.844 (90.522)
2023-03-22 07:02:14,760 - INFO - Test: [600/782]	Time 0.889 (0.833)	Loss 2.5817 (2.4942)	Acc@1 76.562 (75.263)	Acc@5 86.719 (90.928)
2023-03-22 07:04:46,061 - INFO -  * Acc@1 75.662 Acc@5 91.257
2023-03-22 07:04:46,062 - INFO - Max accuracy: 77.5810%
2023-03-22 07:04:46,062 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-22 07:04:49,145 - INFO - Train: [109/120][0/3907]	eta 3:20:31 lr 0.00097887	time 3.0796 (3.0796)	loss 2.4996 (2.4996)	acc@1: 79.9299	acc@5: 90.4830	
2023-03-22 07:05:47,013 - INFO - Train: [109/120][300/3907]	eta 0:12:10 lr 0.00097887	time 0.1898 (0.2025)	loss 2.0784 (3.1722)	acc@1: 88.7829	acc@5: 91.1193	
2023-03-22 07:06:45,709 - INFO - Train: [109/120][600/3907]	eta 0:10:58 lr 0.00097887	time 0.1860 (0.1991)	loss 4.7633 (3.1838)	acc@1: 41.0335	acc@5: 55.5745	
2023-03-22 07:07:44,127 - INFO - Train: [109/120][900/3907]	eta 0:09:54 lr 0.00097887	time 0.1824 (0.1976)	loss 4.8477 (3.1905)	acc@1: 39.0803	acc@5: 55.0474	
2023-03-22 07:08:42,585 - INFO - Train: [109/120][1200/3907]	eta 0:08:53 lr 0.00097887	time 0.1815 (0.1969)	loss 4.1725 (3.1876)	acc@1: 52.7493	acc@5: 68.9189	
2023-03-22 07:09:41,037 - INFO - Train: [109/120][1500/3907]	eta 0:07:52 lr 0.00097887	time 0.1857 (0.1965)	loss 4.5855 (3.1614)	acc@1: 45.2913	acc@5: 60.1350	
2023-03-22 07:10:39,255 - INFO - Train: [109/120][1800/3907]	eta 0:06:53 lr 0.00097887	time 0.1881 (0.1961)	loss 2.2580 (3.1476)	acc@1: 87.6236	acc@5: 92.8984	
2023-03-22 07:11:37,845 - INFO - Train: [109/120][2100/3907]	eta 0:05:54 lr 0.00097887	time 0.2115 (0.1960)	loss 2.1246 (3.1425)	acc@1: 87.5516	acc@5: 93.6421	
2023-03-22 07:12:35,366 - INFO - Train: [109/120][2400/3907]	eta 0:04:54 lr 0.00097887	time 0.1777 (0.1955)	loss 2.5759 (3.1500)	acc@1: 85.5784	acc@5: 89.2022	
2023-03-22 07:13:30,373 - INFO - Train: [109/120][2700/3907]	eta 0:03:54 lr 0.00097887	time 0.1722 (0.1941)	loss 1.7811 (3.1484)	acc@1: 91.1194	acc@5: 97.3522	
2023-03-22 07:14:25,208 - INFO - Train: [109/120][3000/3907]	eta 0:02:55 lr 0.00097887	time 0.1824 (0.1930)	loss 4.4162 (3.1550)	acc@1: 46.1656	acc@5: 59.6155	
2023-03-22 07:15:20,186 - INFO - Train: [109/120][3300/3907]	eta 0:01:56 lr 0.00097887	time 0.1879 (0.1921)	loss 2.6788 (3.1553)	acc@1: 79.2602	acc@5: 87.9861	
2023-03-22 07:16:14,667 - INFO - Train: [109/120][3600/3907]	eta 0:00:58 lr 0.00097887	time 0.1863 (0.1912)	loss 4.4946 (3.1568)	acc@1: 50.3092	acc@5: 61.2467	
2023-03-22 07:17:09,779 - INFO - Train: [109/120][3900/3907]	eta 0:00:01 lr 0.00097887	time 0.1730 (0.1906)	loss 1.9275 (3.1568)	acc@1: 90.2754	acc@5: 96.5042	
2023-03-22 07:17:11,118 - INFO - EPOCH 109 training takes 0:12:25
2023-03-22 07:17:12,526 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Latest.pth saved !!!
2023-03-22 07:17:12,527 - INFO - **********Latest test***********
2023-03-22 07:17:12,527 - INFO - eval epoch 109
2023-03-22 07:17:13,454 - INFO - Test: [0/782]	Time 0.925 (0.925)	Loss 2.2363 (2.2363)	Acc@1 81.250 (81.250)	Acc@5 96.875 (96.875)
2023-03-22 07:20:02,264 - INFO - Test: [200/782]	Time 0.886 (0.844)	Loss 2.4964 (2.5292)	Acc@1 71.094 (74.238)	Acc@5 89.062 (90.454)
2023-03-22 07:22:50,779 - INFO - Test: [400/782]	Time 0.786 (0.844)	Loss 2.4324 (2.5025)	Acc@1 80.469 (75.094)	Acc@5 89.844 (90.781)
2023-03-22 07:25:38,057 - INFO - Test: [600/782]	Time 0.908 (0.841)	Loss 2.5392 (2.4721)	Acc@1 75.000 (75.833)	Acc@5 88.281 (91.146)
2023-03-22 07:28:02,807 - INFO -  * Acc@1 76.268 Acc@5 91.480
2023-03-22 07:28:02,808 - INFO - Max accuracy: 77.5810%
2023-03-22 07:28:02,808 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-22 07:28:05,622 - INFO - Train: [110/120][0/3907]	eta 3:02:55 lr 0.00082361	time 2.8091 (2.8091)	loss 2.5438 (2.5438)	acc@1: 80.0263	acc@5: 88.9974	
2023-03-22 07:29:04,029 - INFO - Train: [110/120][300/3907]	eta 0:12:13 lr 0.00082361	time 0.1931 (0.2034)	loss 3.7666 (3.0676)	acc@1: 65.2283	acc@5: 75.1407	
2023-03-22 07:30:02,850 - INFO - Train: [110/120][600/3907]	eta 0:11:00 lr 0.00082361	time 0.1912 (0.1997)	loss 2.5090 (3.0878)	acc@1: 86.0209	acc@5: 89.6910	
2023-03-22 07:31:01,766 - INFO - Train: [110/120][900/3907]	eta 0:09:57 lr 0.00082361	time 0.2061 (0.1986)	loss 2.3880 (3.0848)	acc@1: 84.3767	acc@5: 88.8531	
2023-03-22 07:32:00,683 - INFO - Train: [110/120][1200/3907]	eta 0:08:56 lr 0.00082361	time 0.2041 (0.1981)	loss 4.6980 (3.0957)	acc@1: 37.0055	acc@5: 56.2926	
2023-03-22 07:32:59,675 - INFO - Train: [110/120][1500/3907]	eta 0:07:56 lr 0.00082361	time 0.2114 (0.1978)	loss 4.7594 (3.0959)	acc@1: 41.7149	acc@5: 59.2010	
2023-03-22 07:33:58,728 - INFO - Train: [110/120][1800/3907]	eta 0:06:56 lr 0.00082361	time 0.2128 (0.1976)	loss 4.6066 (3.1172)	acc@1: 45.4387	acc@5: 62.0013	
2023-03-22 07:34:57,743 - INFO - Train: [110/120][2100/3907]	eta 0:05:56 lr 0.00082361	time 0.1874 (0.1975)	loss 2.3830 (3.1336)	acc@1: 85.1463	acc@5: 91.8479	
2023-03-22 07:35:56,405 - INFO - Train: [110/120][2400/3907]	eta 0:04:57 lr 0.00082361	time 0.1879 (0.1972)	loss 1.9229 (3.1502)	acc@1: 93.2035	acc@5: 97.0549	
2023-03-22 07:36:51,560 - INFO - Train: [110/120][2700/3907]	eta 0:03:56 lr 0.00082361	time 0.1815 (0.1958)	loss 1.9624 (3.1548)	acc@1: 87.8811	acc@5: 96.4355	
2023-03-22 07:37:46,501 - INFO - Train: [110/120][3000/3907]	eta 0:02:56 lr 0.00082361	time 0.1764 (0.1945)	loss 2.1315 (3.1647)	acc@1: 83.1074	acc@5: 95.4297	
2023-03-22 07:38:41,174 - INFO - Train: [110/120][3300/3907]	eta 0:01:57 lr 0.00082361	time 0.1827 (0.1934)	loss 3.1937 (3.1667)	acc@1: 71.9522	acc@5: 80.9349	
2023-03-22 07:39:35,744 - INFO - Train: [110/120][3600/3907]	eta 0:00:59 lr 0.00082361	time 0.1937 (0.1924)	loss 2.3381 (3.1640)	acc@1: 83.2394	acc@5: 90.0438	
2023-03-22 07:40:30,388 - INFO - Train: [110/120][3900/3907]	eta 0:00:01 lr 0.00082361	time 0.1765 (0.1916)	loss 4.4854 (3.1679)	acc@1: 49.0315	acc@5: 64.7072	
2023-03-22 07:40:31,774 - INFO - EPOCH 110 training takes 0:12:28
2023-03-22 07:40:33,221 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Latest.pth saved !!!
2023-03-22 07:40:33,222 - INFO - **********Latest test***********
2023-03-22 07:40:33,222 - INFO - eval epoch 110
2023-03-22 07:40:34,004 - INFO - Test: [0/782]	Time 0.781 (0.781)	Loss 2.1600 (2.1600)	Acc@1 78.906 (78.906)	Acc@5 96.094 (96.094)
2023-03-22 07:43:21,692 - INFO - Test: [200/782]	Time 0.892 (0.838)	Loss 2.4236 (2.4727)	Acc@1 71.094 (75.237)	Acc@5 90.625 (90.757)
2023-03-22 07:46:08,143 - INFO - Test: [400/782]	Time 0.728 (0.835)	Loss 2.3657 (2.4485)	Acc@1 78.125 (75.807)	Acc@5 92.969 (91.137)
2023-03-22 07:48:54,240 - INFO - Test: [600/782]	Time 0.881 (0.834)	Loss 2.5019 (2.4174)	Acc@1 75.000 (76.581)	Acc@5 89.844 (91.592)
2023-03-22 07:51:27,235 - INFO -  * Acc@1 77.005 Acc@5 91.899
2023-03-22 07:51:27,235 - INFO - Max accuracy: 77.5810%
2023-03-22 07:51:27,235 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-22 07:51:30,121 - INFO - Train: [111/120][0/3907]	eta 3:07:35 lr 0.00068148	time 2.8808 (2.8808)	loss 1.8868 (1.8868)	acc@1: 88.8689	acc@5: 95.1053	
2023-03-22 07:52:28,659 - INFO - Train: [111/120][300/3907]	eta 0:12:15 lr 0.00068148	time 0.2103 (0.2040)	loss 2.1701 (3.1633)	acc@1: 88.5811	acc@5: 94.5845	
2023-03-22 07:53:27,722 - INFO - Train: [111/120][600/3907]	eta 0:11:02 lr 0.00068148	time 0.2004 (0.2005)	loss 4.8559 (3.0697)	acc@1: 33.9498	acc@5: 56.4489	
2023-03-22 07:54:26,653 - INFO - Train: [111/120][900/3907]	eta 0:09:58 lr 0.00068148	time 0.2056 (0.1991)	loss 2.4788 (3.0961)	acc@1: 84.3390	acc@5: 90.2450	
2023-03-22 07:55:25,638 - INFO - Train: [111/120][1200/3907]	eta 0:08:57 lr 0.00068148	time 0.1953 (0.1985)	loss 3.2890 (3.1109)	acc@1: 72.3201	acc@5: 77.4919	
2023-03-22 07:56:24,770 - INFO - Train: [111/120][1500/3907]	eta 0:07:57 lr 0.00068148	time 0.2013 (0.1982)	loss 4.6881 (3.0894)	acc@1: 43.3637	acc@5: 60.0605	
2023-03-22 07:57:22,862 - INFO - Train: [111/120][1800/3907]	eta 0:06:56 lr 0.00068148	time 0.1838 (0.1974)	loss 4.0427 (3.1053)	acc@1: 58.1616	acc@5: 69.7796	
2023-03-22 07:58:21,299 - INFO - Train: [111/120][2100/3907]	eta 0:05:56 lr 0.00068148	time 0.1940 (0.1971)	loss 2.6980 (3.1086)	acc@1: 82.1556	acc@5: 87.1825	
2023-03-22 07:59:18,632 - INFO - Train: [111/120][2400/3907]	eta 0:04:55 lr 0.00068148	time 0.1780 (0.1963)	loss 2.2130 (3.1037)	acc@1: 89.3338	acc@5: 93.1491	
2023-03-22 08:00:13,384 - INFO - Train: [111/120][2700/3907]	eta 0:03:55 lr 0.00068148	time 0.1753 (0.1948)	loss 2.4512 (3.0964)	acc@1: 84.9342	acc@5: 90.0535	
2023-03-22 08:01:08,476 - INFO - Train: [111/120][3000/3907]	eta 0:02:55 lr 0.00068148	time 0.1808 (0.1937)	loss 3.5235 (3.1064)	acc@1: 70.0242	acc@5: 77.0037	
2023-03-22 08:02:03,342 - INFO - Train: [111/120][3300/3907]	eta 0:01:56 lr 0.00068148	time 0.1792 (0.1927)	loss 4.4114 (3.1098)	acc@1: 47.9627	acc@5: 65.1656	
2023-03-22 08:02:58,208 - INFO - Train: [111/120][3600/3907]	eta 0:00:58 lr 0.00068148	time 0.1804 (0.1919)	loss 3.0357 (3.1169)	acc@1: 80.0752	acc@5: 82.9250	
2023-03-22 08:03:53,168 - INFO - Train: [111/120][3900/3907]	eta 0:00:01 lr 0.00068148	time 0.1763 (0.1912)	loss 2.0263 (3.1293)	acc@1: 88.7326	acc@5: 94.1839	
2023-03-22 08:03:54,453 - INFO - EPOCH 111 training takes 0:12:27
2023-03-22 08:03:55,815 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Latest.pth saved !!!
2023-03-22 08:03:55,816 - INFO - **********Latest test***********
2023-03-22 08:03:55,816 - INFO - eval epoch 111
2023-03-22 08:03:56,605 - INFO - Test: [0/782]	Time 0.788 (0.788)	Loss 2.1597 (2.1597)	Acc@1 82.031 (82.031)	Acc@5 96.094 (96.094)
2023-03-22 08:06:48,823 - INFO - Test: [200/782]	Time 0.797 (0.861)	Loss 2.4186 (2.4528)	Acc@1 73.438 (75.381)	Acc@5 91.406 (90.955)
2023-03-22 08:09:34,168 - INFO - Test: [400/782]	Time 0.912 (0.844)	Loss 2.3397 (2.4275)	Acc@1 79.688 (76.011)	Acc@5 92.969 (91.358)
2023-03-22 08:12:30,265 - INFO - Test: [600/782]	Time 0.899 (0.856)	Loss 2.4791 (2.3971)	Acc@1 77.344 (76.695)	Acc@5 89.844 (91.759)
2023-03-22 08:15:06,477 - INFO -  * Acc@1 77.104 Acc@5 92.058
2023-03-22 08:15:06,477 - INFO - Max accuracy: 77.5810%
2023-03-22 08:15:06,477 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-22 08:15:09,188 - INFO - Train: [112/120][0/3907]	eta 2:56:15 lr 0.00055260	time 2.7067 (2.7067)	loss 2.4414 (2.4414)	acc@1: 85.7819	acc@5: 90.9112	
2023-03-22 08:16:08,134 - INFO - Train: [112/120][300/3907]	eta 0:12:18 lr 0.00055260	time 0.1903 (0.2048)	loss 1.9717 (3.0437)	acc@1: 86.7107	acc@5: 96.0848	
2023-03-22 08:17:07,259 - INFO - Train: [112/120][600/3907]	eta 0:11:04 lr 0.00055260	time 0.1922 (0.2010)	loss 2.0163 (3.1322)	acc@1: 90.5374	acc@5: 95.1803	
2023-03-22 08:18:05,860 - INFO - Train: [112/120][900/3907]	eta 0:09:58 lr 0.00055260	time 0.1883 (0.1991)	loss 2.9386 (3.1357)	acc@1: 80.0313	acc@5: 85.1078	
2023-03-22 08:19:04,554 - INFO - Train: [112/120][1200/3907]	eta 0:08:56 lr 0.00055260	time 0.1979 (0.1982)	loss 4.8258 (3.1033)	acc@1: 32.1224	acc@5: 57.1224	
2023-03-22 08:20:03,829 - INFO - Train: [112/120][1500/3907]	eta 0:07:56 lr 0.00055260	time 0.2145 (0.1981)	loss 2.2944 (3.1003)	acc@1: 86.5898	acc@5: 92.5591	
2023-03-22 08:21:02,934 - INFO - Train: [112/120][1800/3907]	eta 0:06:56 lr 0.00055260	time 0.1935 (0.1979)	loss 3.2237 (3.1272)	acc@1: 76.3379	acc@5: 80.0072	
2023-03-22 08:22:02,353 - INFO - Train: [112/120][2100/3907]	eta 0:05:57 lr 0.00055260	time 0.1926 (0.1979)	loss 3.3879 (3.1243)	acc@1: 72.3299	acc@5: 79.1437	
2023-03-22 08:23:01,656 - INFO - Train: [112/120][2400/3907]	eta 0:04:58 lr 0.00055260	time 0.1936 (0.1979)	loss 2.9787 (3.1166)	acc@1: 81.0392	acc@5: 85.8410	
2023-03-22 08:24:00,086 - INFO - Train: [112/120][2700/3907]	eta 0:03:58 lr 0.00055260	time 0.1756 (0.1976)	loss 3.0092 (3.1334)	acc@1: 76.8505	acc@5: 85.9302	
2023-03-22 08:24:55,058 - INFO - Train: [112/120][3000/3907]	eta 0:02:57 lr 0.00055260	time 0.1776 (0.1961)	loss 4.1256 (3.1379)	acc@1: 56.6414	acc@5: 68.8358	
2023-03-22 08:25:50,100 - INFO - Train: [112/120][3300/3907]	eta 0:01:58 lr 0.00055260	time 0.1836 (0.1950)	loss 4.7391 (3.1365)	acc@1: 40.8456	acc@5: 56.4527	
2023-03-22 08:26:45,088 - INFO - Train: [112/120][3600/3907]	eta 0:00:59 lr 0.00055260	time 0.1742 (0.1940)	loss 2.7653 (3.1362)	acc@1: 79.4740	acc@5: 85.9765	
2023-03-22 08:27:40,358 - INFO - Train: [112/120][3900/3907]	eta 0:00:01 lr 0.00055260	time 0.1746 (0.1932)	loss 3.7809 (3.1381)	acc@1: 65.2718	acc@5: 71.8686	
2023-03-22 08:27:41,650 - INFO - EPOCH 112 training takes 0:12:35
2023-03-22 08:27:42,986 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Latest.pth saved !!!
2023-03-22 08:27:42,987 - INFO - **********Latest test***********
2023-03-22 08:27:42,987 - INFO - eval epoch 112
2023-03-22 08:27:43,902 - INFO - Test: [0/782]	Time 0.914 (0.914)	Loss 2.1632 (2.1632)	Acc@1 80.469 (80.469)	Acc@5 96.875 (96.875)
2023-03-22 08:30:33,191 - INFO - Test: [200/782]	Time 0.752 (0.847)	Loss 2.4204 (2.4530)	Acc@1 72.656 (75.544)	Acc@5 89.062 (91.014)
2023-03-22 08:33:25,460 - INFO - Test: [400/782]	Time 0.940 (0.854)	Loss 2.3508 (2.4273)	Acc@1 80.469 (76.276)	Acc@5 92.969 (91.412)
2023-03-22 08:36:20,816 - INFO - Test: [600/782]	Time 0.728 (0.862)	Loss 2.4600 (2.3972)	Acc@1 77.344 (77.038)	Acc@5 89.844 (91.790)
2023-03-22 08:38:51,583 - INFO -  * Acc@1 77.415 Acc@5 92.088
2023-03-22 08:38:51,583 - INFO - Max accuracy: 77.5810%
2023-03-22 08:38:53,274 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Best.pth saved !!!
2023-03-22 08:38:53,275 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-22 08:38:56,259 - INFO - Train: [113/120][0/3907]	eta 3:14:02 lr 0.00043705	time 2.9799 (2.9799)	loss 1.8821 (1.8821)	acc@1: 91.3655	acc@5: 96.0509	
2023-03-22 08:39:55,847 - INFO - Train: [113/120][300/3907]	eta 0:12:29 lr 0.00043705	time 0.1915 (0.2079)	loss 1.8833 (3.0157)	acc@1: 89.6083	acc@5: 95.8416	
2023-03-22 08:40:55,057 - INFO - Train: [113/120][600/3907]	eta 0:11:10 lr 0.00043705	time 0.1905 (0.2026)	loss 3.8093 (3.0635)	acc@1: 65.4205	acc@5: 73.0542	
2023-03-22 08:41:53,950 - INFO - Train: [113/120][900/3907]	eta 0:10:02 lr 0.00043705	time 0.1943 (0.2005)	loss 2.4970 (3.0646)	acc@1: 85.6373	acc@5: 89.2970	
2023-03-22 08:42:53,167 - INFO - Train: [113/120][1200/3907]	eta 0:09:00 lr 0.00043705	time 0.1921 (0.1997)	loss 3.8904 (3.0884)	acc@1: 64.5637	acc@5: 71.8888	
2023-03-22 08:43:52,040 - INFO - Train: [113/120][1500/3907]	eta 0:07:59 lr 0.00043705	time 0.2030 (0.1990)	loss 3.2062 (3.0987)	acc@1: 73.4947	acc@5: 82.7491	
2023-03-22 08:44:50,960 - INFO - Train: [113/120][1800/3907]	eta 0:06:58 lr 0.00043705	time 0.1934 (0.1986)	loss 4.5608 (3.0957)	acc@1: 41.5379	acc@5: 60.4367	
2023-03-22 08:45:49,847 - INFO - Train: [113/120][2100/3907]	eta 0:05:58 lr 0.00043705	time 0.1894 (0.1983)	loss 2.2860 (3.0933)	acc@1: 85.9274	acc@5: 92.7711	
2023-03-22 08:46:48,790 - INFO - Train: [113/120][2400/3907]	eta 0:04:58 lr 0.00043705	time 0.1814 (0.1980)	loss 4.8706 (3.0993)	acc@1: 34.7274	acc@5: 52.4117	
2023-03-22 08:47:47,774 - INFO - Train: [113/120][2700/3907]	eta 0:03:58 lr 0.00043705	time 0.1876 (0.1979)	loss 4.8476 (3.0997)	acc@1: 34.5113	acc@5: 52.8289	
2023-03-22 08:48:46,845 - INFO - Train: [113/120][3000/3907]	eta 0:02:59 lr 0.00043705	time 0.2076 (0.1978)	loss 3.6335 (3.1067)	acc@1: 68.5444	acc@5: 75.4341	
2023-03-22 08:49:45,041 - INFO - Train: [113/120][3300/3907]	eta 0:01:59 lr 0.00043705	time 0.1964 (0.1974)	loss 3.3547 (3.0950)	acc@1: 70.0794	acc@5: 80.0743	
2023-03-22 08:50:42,059 - INFO - Train: [113/120][3600/3907]	eta 0:01:00 lr 0.00043705	time 0.1790 (0.1968)	loss 4.0499 (3.1127)	acc@1: 59.7801	acc@5: 74.0428	
2023-03-22 08:51:36,973 - INFO - Train: [113/120][3900/3907]	eta 0:00:01 lr 0.00043705	time 0.1831 (0.1958)	loss 1.8322 (3.1205)	acc@1: 93.4819	acc@5: 98.8894	
2023-03-22 08:51:38,373 - INFO - EPOCH 113 training takes 0:12:45
2023-03-22 08:51:39,752 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Latest.pth saved !!!
2023-03-22 08:51:39,753 - INFO - **********Latest test***********
2023-03-22 08:51:39,753 - INFO - eval epoch 113
2023-03-22 08:51:40,674 - INFO - Test: [0/782]	Time 0.919 (0.919)	Loss 2.1512 (2.1512)	Acc@1 79.688 (79.688)	Acc@5 96.875 (96.875)
2023-03-22 08:54:37,190 - INFO - Test: [200/782]	Time 0.881 (0.883)	Loss 2.3823 (2.4393)	Acc@1 73.438 (75.595)	Acc@5 91.406 (91.115)
2023-03-22 08:57:32,075 - INFO - Test: [400/782]	Time 0.916 (0.879)	Loss 2.3288 (2.4146)	Acc@1 78.906 (76.292)	Acc@5 92.188 (91.478)
2023-03-22 09:00:23,163 - INFO - Test: [600/782]	Time 0.836 (0.871)	Loss 2.4811 (2.3835)	Acc@1 74.219 (77.088)	Acc@5 89.844 (91.874)
2023-03-22 09:03:02,255 - INFO -  * Acc@1 77.509 Acc@5 92.174
2023-03-22 09:03:02,255 - INFO - Max accuracy: 77.5810%
2023-03-22 09:03:03,821 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Best.pth saved !!!
2023-03-22 09:03:03,821 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-22 09:03:06,628 - INFO - Train: [114/120][0/3907]	eta 3:02:27 lr 0.00033490	time 2.8021 (2.8021)	loss 2.3557 (2.3557)	acc@1: 86.1654	acc@5: 93.5901	
2023-03-22 09:04:05,419 - INFO - Train: [114/120][300/3907]	eta 0:12:18 lr 0.00033490	time 0.1944 (0.2046)	loss 3.0516 (3.1837)	acc@1: 77.8674	acc@5: 82.9675	
2023-03-22 09:05:04,800 - INFO - Train: [114/120][600/3907]	eta 0:11:05 lr 0.00033490	time 0.1830 (0.2013)	loss 4.6181 (3.1412)	acc@1: 44.2318	acc@5: 59.5514	
2023-03-22 09:06:04,156 - INFO - Train: [114/120][900/3907]	eta 0:10:01 lr 0.00033490	time 0.2088 (0.2001)	loss 2.2127 (3.0927)	acc@1: 83.4423	acc@5: 92.6269	
2023-03-22 09:07:03,264 - INFO - Train: [114/120][1200/3907]	eta 0:08:59 lr 0.00033490	time 0.1891 (0.1994)	loss 3.8303 (3.1319)	acc@1: 63.9788	acc@5: 72.6136	
2023-03-22 09:08:02,655 - INFO - Train: [114/120][1500/3907]	eta 0:07:59 lr 0.00033490	time 0.1862 (0.1991)	loss 2.1076 (3.1323)	acc@1: 87.7241	acc@5: 95.3506	
2023-03-22 09:09:01,964 - INFO - Train: [114/120][1800/3907]	eta 0:06:58 lr 0.00033490	time 0.2078 (0.1988)	loss 3.2005 (3.1306)	acc@1: 75.7766	acc@5: 81.4439	
2023-03-22 09:10:01,639 - INFO - Train: [114/120][2100/3907]	eta 0:05:59 lr 0.00033490	time 0.2051 (0.1989)	loss 4.7408 (3.1292)	acc@1: 38.4346	acc@5: 59.6709	
2023-03-22 09:11:00,259 - INFO - Train: [114/120][2400/3907]	eta 0:04:59 lr 0.00033490	time 0.1901 (0.1984)	loss 1.7804 (3.1214)	acc@1: 92.0808	acc@5: 98.3234	
2023-03-22 09:12:00,048 - INFO - Train: [114/120][2700/3907]	eta 0:03:59 lr 0.00033490	time 0.1848 (0.1985)	loss 1.6714 (3.1328)	acc@1: 92.9687	acc@5: 96.8750	
2023-03-22 09:12:59,560 - INFO - Train: [114/120][3000/3907]	eta 0:03:00 lr 0.00033490	time 0.1897 (0.1985)	loss 2.4471 (3.1249)	acc@1: 86.1279	acc@5: 91.2372	
2023-03-22 09:13:59,242 - INFO - Train: [114/120][3300/3907]	eta 0:02:00 lr 0.00033490	time 0.1847 (0.1985)	loss 2.2480 (3.1157)	acc@1: 89.3383	acc@5: 93.8404	
2023-03-22 09:14:58,864 - INFO - Train: [114/120][3600/3907]	eta 0:01:00 lr 0.00033490	time 0.1969 (0.1986)	loss 4.1424 (3.1159)	acc@1: 56.7902	acc@5: 69.1516	
2023-03-22 09:15:58,183 - INFO - Train: [114/120][3900/3907]	eta 0:00:01 lr 0.00033490	time 0.1883 (0.1985)	loss 2.3187 (3.1180)	acc@1: 86.1108	acc@5: 92.8499	
2023-03-22 09:15:59,568 - INFO - EPOCH 114 training takes 0:12:55
2023-03-22 09:16:01,074 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Latest.pth saved !!!
2023-03-22 09:16:01,074 - INFO - **********Latest test***********
2023-03-22 09:16:01,074 - INFO - eval epoch 114
2023-03-22 09:16:02,124 - INFO - Test: [0/782]	Time 1.048 (1.048)	Loss 2.1714 (2.1714)	Acc@1 79.688 (79.688)	Acc@5 96.094 (96.094)
2023-03-22 09:18:54,063 - INFO - Test: [200/782]	Time 0.839 (0.861)	Loss 2.3838 (2.4403)	Acc@1 75.000 (75.680)	Acc@5 91.406 (91.115)
2023-03-22 09:21:45,044 - INFO - Test: [400/782]	Time 0.873 (0.858)	Loss 2.3404 (2.4153)	Acc@1 79.688 (76.352)	Acc@5 92.188 (91.508)
2023-03-22 09:24:39,606 - INFO - Test: [600/782]	Time 0.920 (0.863)	Loss 2.4839 (2.3857)	Acc@1 77.344 (77.147)	Acc@5 89.844 (91.886)
2023-03-22 09:27:14,593 - INFO -  * Acc@1 77.550 Acc@5 92.164
2023-03-22 09:27:14,594 - INFO - Max accuracy: 77.5810%
2023-03-22 09:27:16,057 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Best.pth saved !!!
2023-03-22 09:27:16,058 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-22 09:27:18,927 - INFO - Train: [115/120][0/3907]	eta 3:06:27 lr 0.00024623	time 2.8633 (2.8633)	loss 4.9541 (4.9541)	acc@1: 35.7880	acc@5: 51.0443	
2023-03-22 09:28:18,044 - INFO - Train: [115/120][300/3907]	eta 0:12:22 lr 0.00024623	time 0.1929 (0.2059)	loss 1.9445 (3.1646)	acc@1: 89.9879	acc@5: 96.9091	
2023-03-22 09:29:17,724 - INFO - Train: [115/120][600/3907]	eta 0:11:09 lr 0.00024623	time 0.1952 (0.2024)	loss 2.9159 (3.1273)	acc@1: 79.6531	acc@5: 83.8975	
2023-03-22 09:30:17,761 - INFO - Train: [115/120][900/3907]	eta 0:10:06 lr 0.00024623	time 0.2219 (0.2017)	loss 3.6641 (3.1481)	acc@1: 66.1124	acc@5: 73.9954	
2023-03-22 09:31:17,558 - INFO - Train: [115/120][1200/3907]	eta 0:09:04 lr 0.00024623	time 0.1920 (0.2011)	loss 5.1958 (3.1569)	acc@1: 27.8257	acc@5: 47.8389	
2023-03-22 09:32:16,058 - INFO - Train: [115/120][1500/3907]	eta 0:08:01 lr 0.00024623	time 0.1931 (0.1999)	loss 2.8135 (3.1508)	acc@1: 82.1970	acc@5: 85.7801	
2023-03-22 09:33:15,856 - INFO - Train: [115/120][1800/3907]	eta 0:07:00 lr 0.00024623	time 0.1894 (0.1998)	loss 1.8464 (3.1498)	acc@1: 90.6233	acc@5: 97.6545	
2023-03-22 09:34:15,848 - INFO - Train: [115/120][2100/3907]	eta 0:06:01 lr 0.00024623	time 0.1951 (0.1998)	loss 2.1361 (3.1435)	acc@1: 86.5417	acc@5: 94.9646	
2023-03-22 09:35:15,769 - INFO - Train: [115/120][2400/3907]	eta 0:05:01 lr 0.00024623	time 0.2171 (0.1998)	loss 1.9870 (3.1368)	acc@1: 89.8324	acc@5: 93.7045	
2023-03-22 09:36:15,656 - INFO - Train: [115/120][2700/3907]	eta 0:04:01 lr 0.00024623	time 0.1940 (0.1998)	loss 1.9324 (3.1297)	acc@1: 90.5379	acc@5: 92.8793	
2023-03-22 09:37:15,678 - INFO - Train: [115/120][3000/3907]	eta 0:03:01 lr 0.00024623	time 0.2153 (0.1998)	loss 1.8791 (3.1227)	acc@1: 90.8086	acc@5: 96.2416	
2023-03-22 09:38:15,441 - INFO - Train: [115/120][3300/3907]	eta 0:02:01 lr 0.00024623	time 0.1939 (0.1997)	loss 3.3705 (3.1142)	acc@1: 75.6419	acc@5: 80.3294	
2023-03-22 09:39:15,347 - INFO - Train: [115/120][3600/3907]	eta 0:01:01 lr 0.00024623	time 0.1911 (0.1997)	loss 4.5627 (3.1200)	acc@1: 47.7187	acc@5: 60.7445	
2023-03-22 09:40:15,249 - INFO - Train: [115/120][3900/3907]	eta 0:00:01 lr 0.00024623	time 0.1918 (0.1997)	loss 3.3174 (3.1213)	acc@1: 74.5377	acc@5: 79.9981	
2023-03-22 09:40:16,697 - INFO - EPOCH 115 training takes 0:13:00
2023-03-22 09:40:18,208 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Latest.pth saved !!!
2023-03-22 09:40:18,210 - INFO - **********Latest test***********
2023-03-22 09:40:18,210 - INFO - eval epoch 115
2023-03-22 09:40:19,124 - INFO - Test: [0/782]	Time 0.912 (0.912)	Loss 2.2346 (2.2346)	Acc@1 80.469 (80.469)	Acc@5 96.094 (96.094)
2023-03-22 09:43:13,510 - INFO - Test: [200/782]	Time 0.916 (0.872)	Loss 2.4425 (2.5035)	Acc@1 73.438 (74.992)	Acc@5 91.406 (90.734)
2023-03-22 09:46:12,366 - INFO - Test: [400/782]	Time 0.906 (0.883)	Loss 2.3963 (2.4786)	Acc@1 77.344 (75.727)	Acc@5 92.188 (91.095)
2023-03-22 09:49:12,728 - INFO - Test: [600/782]	Time 0.878 (0.889)	Loss 2.5340 (2.4485)	Acc@1 74.219 (76.526)	Acc@5 89.062 (91.505)
2023-03-22 09:51:51,995 - INFO -  * Acc@1 76.899 Acc@5 91.819
2023-03-22 09:51:51,996 - INFO - Max accuracy: 77.5810%
2023-03-22 09:51:51,996 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-22 09:51:54,928 - INFO - Train: [116/120][0/3907]	eta 3:10:39 lr 0.00017110	time 2.9279 (2.9279)	loss 3.0794 (3.0794)	acc@1: 75.8361	acc@5: 82.8221	
2023-03-22 09:52:54,334 - INFO - Train: [116/120][300/3907]	eta 0:12:26 lr 0.00017110	time 0.1895 (0.2071)	loss 1.8961 (3.0420)	acc@1: 90.0211	acc@5: 96.2291	
2023-03-22 09:53:52,959 - INFO - Train: [116/120][600/3907]	eta 0:11:05 lr 0.00017110	time 0.2120 (0.2013)	loss 1.9195 (3.0750)	acc@1: 91.0060	acc@5: 96.4540	
2023-03-22 09:54:52,762 - INFO - Train: [116/120][900/3907]	eta 0:10:03 lr 0.00017110	time 0.1912 (0.2006)	loss 2.7261 (3.1078)	acc@1: 79.7394	acc@5: 85.5345	
2023-03-22 09:55:52,745 - INFO - Train: [116/120][1200/3907]	eta 0:09:02 lr 0.00017110	time 0.1909 (0.2004)	loss 3.0096 (3.1080)	acc@1: 77.6182	acc@5: 83.3388	
2023-03-22 09:56:52,424 - INFO - Train: [116/120][1500/3907]	eta 0:08:01 lr 0.00017110	time 0.1921 (0.2001)	loss 3.6938 (3.0855)	acc@1: 69.1930	acc@5: 76.0484	
2023-03-22 09:57:52,472 - INFO - Train: [116/120][1800/3907]	eta 0:07:01 lr 0.00017110	time 0.2233 (0.2001)	loss 2.8392 (3.0725)	acc@1: 79.8911	acc@5: 87.0600	
2023-03-22 09:58:52,350 - INFO - Train: [116/120][2100/3907]	eta 0:06:01 lr 0.00017110	time 0.1965 (0.2001)	loss 2.4086 (3.0738)	acc@1: 87.3878	acc@5: 91.7545	
2023-03-22 09:59:52,163 - INFO - Train: [116/120][2400/3907]	eta 0:05:01 lr 0.00017110	time 0.1995 (0.2000)	loss 4.5024 (3.0719)	acc@1: 44.9967	acc@5: 59.1423	
2023-03-22 10:00:52,151 - INFO - Train: [116/120][2700/3907]	eta 0:04:01 lr 0.00017110	time 0.1980 (0.2000)	loss 2.0300 (3.0739)	acc@1: 86.6246	acc@5: 92.8677	
2023-03-22 10:01:51,771 - INFO - Train: [116/120][3000/3907]	eta 0:03:01 lr 0.00017110	time 0.2147 (0.1998)	loss 2.5717 (3.0672)	acc@1: 81.4543	acc@5: 90.2302	
2023-03-22 10:02:51,282 - INFO - Train: [116/120][3300/3907]	eta 0:02:01 lr 0.00017110	time 0.2118 (0.1997)	loss 4.8566 (3.0842)	acc@1: 38.6914	acc@5: 56.5184	
2023-03-22 10:03:50,882 - INFO - Train: [116/120][3600/3907]	eta 0:01:01 lr 0.00017110	time 0.1808 (0.1996)	loss 4.7820 (3.0851)	acc@1: 35.9770	acc@5: 54.3166	
2023-03-22 10:04:49,566 - INFO - Train: [116/120][3900/3907]	eta 0:00:01 lr 0.00017110	time 0.1873 (0.1993)	loss 3.0001 (3.0852)	acc@1: 77.7547	acc@5: 86.0386	
2023-03-22 10:04:50,999 - INFO - EPOCH 116 training takes 0:12:58
2023-03-22 10:04:52,629 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Latest.pth saved !!!
2023-03-22 10:04:52,631 - INFO - **********Latest test***********
2023-03-22 10:04:52,631 - INFO - eval epoch 116
2023-03-22 10:04:53,534 - INFO - Test: [0/782]	Time 0.900 (0.900)	Loss 2.1378 (2.1378)	Acc@1 80.469 (80.469)	Acc@5 96.094 (96.094)
2023-03-22 10:07:49,051 - INFO - Test: [200/782]	Time 0.885 (0.878)	Loss 2.3631 (2.4097)	Acc@1 75.000 (76.166)	Acc@5 92.188 (91.391)
2023-03-22 10:10:45,962 - INFO - Test: [400/782]	Time 0.915 (0.881)	Loss 2.3201 (2.3855)	Acc@1 80.469 (76.812)	Acc@5 91.406 (91.708)
2023-03-22 10:13:47,741 - INFO - Test: [600/782]	Time 0.923 (0.890)	Loss 2.4577 (2.3553)	Acc@1 75.000 (77.570)	Acc@5 90.625 (92.102)
2023-03-22 10:16:22,027 - INFO -  * Acc@1 77.955 Acc@5 92.409
2023-03-22 10:16:22,028 - INFO - Max accuracy: 77.9550%
2023-03-22 10:16:23,436 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Best.pth saved !!!
2023-03-22 10:16:23,437 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-22 10:16:26,275 - INFO - Train: [117/120][0/3907]	eta 3:04:20 lr 0.00010956	time 2.8308 (2.8308)	loss 1.8398 (1.8398)	acc@1: 94.4504	acc@5: 96.7728	
2023-03-22 10:17:25,328 - INFO - Train: [117/120][300/3907]	eta 0:12:21 lr 0.00010956	time 0.1937 (0.2056)	loss 3.8194 (3.1841)	acc@1: 60.9691	acc@5: 74.5954	
2023-03-22 10:18:24,961 - INFO - Train: [117/120][600/3907]	eta 0:11:08 lr 0.00010956	time 0.1919 (0.2022)	loss 3.5491 (3.1823)	acc@1: 68.1253	acc@5: 76.4272	
2023-03-22 10:19:24,758 - INFO - Train: [117/120][900/3907]	eta 0:10:05 lr 0.00010956	time 0.2018 (0.2012)	loss 1.8538 (3.1741)	acc@1: 90.4599	acc@5: 97.4782	
2023-03-22 10:20:24,451 - INFO - Train: [117/120][1200/3907]	eta 0:09:03 lr 0.00010956	time 0.1994 (0.2007)	loss 1.8372 (3.1423)	acc@1: 89.7607	acc@5: 97.5667	
2023-03-22 10:21:24,032 - INFO - Train: [117/120][1500/3907]	eta 0:08:02 lr 0.00010956	time 0.1940 (0.2003)	loss 2.1617 (3.1207)	acc@1: 92.3461	acc@5: 93.8587	
2023-03-22 10:22:23,528 - INFO - Train: [117/120][1800/3907]	eta 0:07:01 lr 0.00010956	time 0.1993 (0.1999)	loss 1.7274 (3.1214)	acc@1: 94.3185	acc@5: 98.2159	
2023-03-22 10:23:23,044 - INFO - Train: [117/120][2100/3907]	eta 0:06:00 lr 0.00010956	time 0.1895 (0.1997)	loss 4.0964 (3.0977)	acc@1: 55.0098	acc@5: 70.6187	
2023-03-22 10:24:19,284 - INFO - Train: [117/120][2400/3907]	eta 0:04:58 lr 0.00010956	time 0.1756 (0.1982)	loss 4.4115 (3.1057)	acc@1: 47.5097	acc@5: 61.6192	
2023-03-22 10:25:14,057 - INFO - Train: [117/120][2700/3907]	eta 0:03:57 lr 0.00010956	time 0.1712 (0.1964)	loss 4.6702 (3.1127)	acc@1: 40.6374	acc@5: 59.3874	
2023-03-22 10:26:08,774 - INFO - Train: [117/120][3000/3907]	eta 0:02:56 lr 0.00010956	time 0.1997 (0.1950)	loss 3.8094 (3.1177)	acc@1: 64.3206	acc@5: 70.5444	
2023-03-22 10:27:04,155 - INFO - Train: [117/120][3300/3907]	eta 0:01:57 lr 0.00010956	time 0.2002 (0.1941)	loss 5.0273 (3.1232)	acc@1: 32.8385	acc@5: 53.9322	
2023-03-22 10:27:59,275 - INFO - Train: [117/120][3600/3907]	eta 0:00:59 lr 0.00010956	time 0.1874 (0.1932)	loss 1.8493 (3.1277)	acc@1: 91.7932	acc@5: 97.2384	
2023-03-22 10:28:54,433 - INFO - Train: [117/120][3900/3907]	eta 0:00:01 lr 0.00010956	time 0.1824 (0.1925)	loss 1.9689 (3.1351)	acc@1: 88.5720	acc@5: 93.2335	
2023-03-22 10:28:55,718 - INFO - EPOCH 117 training takes 0:12:32
2023-03-22 10:28:57,209 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Latest.pth saved !!!
2023-03-22 10:28:57,210 - INFO - **********Latest test***********
2023-03-22 10:28:57,211 - INFO - eval epoch 117
2023-03-22 10:28:58,129 - INFO - Test: [0/782]	Time 0.916 (0.916)	Loss 2.1743 (2.1743)	Acc@1 80.469 (80.469)	Acc@5 96.875 (96.875)
2023-03-22 10:31:46,398 - INFO - Test: [200/782]	Time 0.880 (0.842)	Loss 2.4007 (2.4525)	Acc@1 73.438 (75.517)	Acc@5 92.188 (91.053)
2023-03-22 10:34:36,599 - INFO - Test: [400/782]	Time 0.922 (0.846)	Loss 2.3640 (2.4278)	Acc@1 79.688 (76.249)	Acc@5 92.188 (91.397)
2023-03-22 10:37:24,799 - INFO - Test: [600/782]	Time 0.827 (0.845)	Loss 2.4981 (2.3976)	Acc@1 72.656 (77.023)	Acc@5 89.844 (91.813)
2023-03-22 10:39:55,396 - INFO -  * Acc@1 77.432 Acc@5 92.120
2023-03-22 10:39:55,396 - INFO - Max accuracy: 77.9550%
2023-03-22 10:39:55,396 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-22 10:39:58,008 - INFO - Train: [118/120][0/3907]	eta 2:49:47 lr 0.00006165	time 2.6074 (2.6074)	loss 3.8961 (3.8961)	acc@1: 60.4994	acc@5: 73.2024	
2023-03-22 10:40:56,749 - INFO - Train: [118/120][300/3907]	eta 0:12:15 lr 0.00006165	time 0.2165 (0.2038)	loss 5.0391 (3.0739)	acc@1: 29.2826	acc@5: 51.6188	
2023-03-22 10:41:55,659 - INFO - Train: [118/120][600/3907]	eta 0:11:01 lr 0.00006165	time 0.1880 (0.2001)	loss 4.3506 (3.0809)	acc@1: 50.8621	acc@5: 65.3243	
2023-03-22 10:42:54,350 - INFO - Train: [118/120][900/3907]	eta 0:09:57 lr 0.00006165	time 0.2091 (0.1986)	loss 3.8834 (3.0846)	acc@1: 64.1563	acc@5: 71.4306	
2023-03-22 10:43:53,505 - INFO - Train: [118/120][1200/3907]	eta 0:08:56 lr 0.00006165	time 0.1893 (0.1982)	loss 1.8353 (3.0795)	acc@1: 90.2635	acc@5: 97.2664	
2023-03-22 10:44:52,619 - INFO - Train: [118/120][1500/3907]	eta 0:07:56 lr 0.00006165	time 0.1912 (0.1980)	loss 2.7725 (3.1013)	acc@1: 84.8376	acc@5: 87.6105	
2023-03-22 10:45:51,440 - INFO - Train: [118/120][1800/3907]	eta 0:06:56 lr 0.00006165	time 0.2045 (0.1977)	loss 1.7151 (3.1183)	acc@1: 92.1603	acc@5: 99.1895	
2023-03-22 10:46:49,245 - INFO - Train: [118/120][2100/3907]	eta 0:05:55 lr 0.00006165	time 0.2021 (0.1970)	loss 2.2489 (3.0995)	acc@1: 87.8532	acc@5: 92.3974	
2023-03-22 10:47:48,345 - INFO - Train: [118/120][2400/3907]	eta 0:04:56 lr 0.00006165	time 0.1860 (0.1970)	loss 2.0466 (3.1037)	acc@1: 91.5267	acc@5: 95.3088	
2023-03-22 10:48:45,493 - INFO - Train: [118/120][2700/3907]	eta 0:03:56 lr 0.00006165	time 0.1827 (0.1962)	loss 2.1224 (3.1029)	acc@1: 87.4479	acc@5: 93.5298	
2023-03-22 10:49:40,542 - INFO - Train: [118/120][3000/3907]	eta 0:02:56 lr 0.00006165	time 0.1928 (0.1950)	loss 3.4054 (3.1020)	acc@1: 68.3666	acc@5: 77.8725	
2023-03-22 10:50:35,430 - INFO - Train: [118/120][3300/3907]	eta 0:01:57 lr 0.00006165	time 0.1989 (0.1939)	loss 2.0565 (3.0878)	acc@1: 88.1117	acc@5: 94.9480	
2023-03-22 10:51:30,257 - INFO - Train: [118/120][3600/3907]	eta 0:00:59 lr 0.00006165	time 0.1776 (0.1930)	loss 3.5768 (3.0883)	acc@1: 66.6342	acc@5: 77.2165	
2023-03-22 10:52:25,061 - INFO - Train: [118/120][3900/3907]	eta 0:00:01 lr 0.00006165	time 0.1805 (0.1922)	loss 5.0274 (3.0986)	acc@1: 31.1823	acc@5: 49.3278	
2023-03-22 10:52:26,337 - INFO - EPOCH 118 training takes 0:12:30
2023-03-22 10:52:27,732 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Latest.pth saved !!!
2023-03-22 10:52:27,733 - INFO - **********Latest test***********
2023-03-22 10:52:27,733 - INFO - eval epoch 118
2023-03-22 10:52:28,700 - INFO - Test: [0/782]	Time 0.966 (0.966)	Loss 2.1588 (2.1588)	Acc@1 80.469 (80.469)	Acc@5 96.094 (96.094)
2023-03-22 10:55:20,057 - INFO - Test: [200/782]	Time 0.892 (0.857)	Loss 2.3917 (2.4365)	Acc@1 74.219 (75.867)	Acc@5 92.969 (91.192)
2023-03-22 10:58:06,447 - INFO - Test: [400/782]	Time 0.885 (0.845)	Loss 2.3418 (2.4127)	Acc@1 80.469 (76.502)	Acc@5 92.188 (91.548)
2023-03-22 11:00:57,204 - INFO - Test: [600/782]	Time 0.735 (0.848)	Loss 2.4846 (2.3825)	Acc@1 75.000 (77.287)	Acc@5 89.844 (91.974)
2023-03-22 11:03:30,853 - INFO -  * Acc@1 77.695 Acc@5 92.284
2023-03-22 11:03:30,854 - INFO - Max accuracy: 77.9550%
2023-03-22 11:03:30,854 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-22 11:03:33,569 - INFO - Train: [119/120][0/3907]	eta 2:56:20 lr 0.00002741	time 2.7080 (2.7080)	loss 2.1888 (2.1888)	acc@1: 90.7218	acc@5: 94.4694	
2023-03-22 11:04:31,784 - INFO - Train: [119/120][300/3907]	eta 0:12:10 lr 0.00002741	time 0.1956 (0.2024)	loss 2.4538 (3.0063)	acc@1: 85.4652	acc@5: 91.3090	
2023-03-22 11:05:30,844 - INFO - Train: [119/120][600/3907]	eta 0:11:00 lr 0.00002741	time 0.1945 (0.1996)	loss 4.8096 (2.9996)	acc@1: 35.8038	acc@5: 55.1286	
2023-03-22 11:06:29,941 - INFO - Train: [119/120][900/3907]	eta 0:09:57 lr 0.00002741	time 0.1992 (0.1988)	loss 2.8284 (3.0085)	acc@1: 81.7159	acc@5: 85.2999	
2023-03-22 11:07:27,756 - INFO - Train: [119/120][1200/3907]	eta 0:08:53 lr 0.00002741	time 0.1876 (0.1972)	loss 4.8635 (3.0112)	acc@1: 39.1254	acc@5: 53.0782	
2023-03-22 11:08:26,842 - INFO - Train: [119/120][1500/3907]	eta 0:07:54 lr 0.00002741	time 0.1973 (0.1972)	loss 3.6061 (3.0270)	acc@1: 71.0251	acc@5: 76.6148	
2023-03-22 11:09:25,939 - INFO - Train: [119/120][1800/3907]	eta 0:06:55 lr 0.00002741	time 0.1895 (0.1971)	loss 3.2921 (3.0474)	acc@1: 73.6590	acc@5: 79.8667	
2023-03-22 11:10:25,063 - INFO - Train: [119/120][2100/3907]	eta 0:05:56 lr 0.00002741	time 0.1934 (0.1971)	loss 3.6905 (3.0567)	acc@1: 64.0840	acc@5: 75.3792	
2023-03-22 11:11:24,107 - INFO - Train: [119/120][2400/3907]	eta 0:04:57 lr 0.00002741	time 0.1895 (0.1971)	loss 1.8347 (3.0769)	acc@1: 92.1140	acc@5: 97.5325	
2023-03-22 11:12:22,760 - INFO - Train: [119/120][2700/3907]	eta 0:03:57 lr 0.00002741	time 0.2040 (0.1969)	loss 4.6648 (3.0880)	acc@1: 43.5814	acc@5: 59.4855	
2023-03-22 11:13:21,774 - INFO - Train: [119/120][3000/3907]	eta 0:02:58 lr 0.00002741	time 0.2071 (0.1969)	loss 3.6026 (3.0970)	acc@1: 67.3003	acc@5: 76.5380	
2023-03-22 11:14:20,816 - INFO - Train: [119/120][3300/3907]	eta 0:01:59 lr 0.00002741	time 0.1947 (0.1969)	loss 1.8367 (3.1016)	acc@1: 90.5407	acc@5: 96.7849	
2023-03-22 11:15:20,042 - INFO - Train: [119/120][3600/3907]	eta 0:01:00 lr 0.00002741	time 0.1911 (0.1969)	loss 2.0805 (3.1043)	acc@1: 89.7580	acc@5: 93.5613	
2023-03-22 11:16:19,004 - INFO - Train: [119/120][3900/3907]	eta 0:00:01 lr 0.00002741	time 0.1949 (0.1969)	loss 1.9528 (3.1050)	acc@1: 92.3200	acc@5: 96.8978	
2023-03-22 11:16:20,328 - INFO - EPOCH 119 training takes 0:12:49
2023-03-22 11:16:21,683 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Latest.pth saved !!!
2023-03-22 11:16:21,684 - INFO - **********Latest test***********
2023-03-22 11:16:21,684 - INFO - eval epoch 119
2023-03-22 11:16:22,442 - INFO - Test: [0/782]	Time 0.757 (0.757)	Loss 2.1318 (2.1318)	Acc@1 80.469 (80.469)	Acc@5 96.875 (96.875)
2023-03-22 11:19:06,370 - INFO - Test: [200/782]	Time 0.762 (0.819)	Loss 2.3656 (2.4119)	Acc@1 75.000 (76.166)	Acc@5 92.188 (91.356)
2023-03-22 11:21:54,239 - INFO - Test: [400/782]	Time 0.858 (0.829)	Loss 2.3261 (2.3881)	Acc@1 79.688 (76.863)	Acc@5 92.188 (91.708)
2023-03-22 11:24:44,294 - INFO - Test: [600/782]	Time 0.850 (0.836)	Loss 2.4718 (2.3576)	Acc@1 76.562 (77.621)	Acc@5 90.625 (92.104)
2023-03-22 11:27:14,809 - INFO -  * Acc@1 77.999 Acc@5 92.370
2023-03-22 11:27:14,810 - INFO - Max accuracy: 77.9990%
2023-03-22 11:27:16,152 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Best.pth saved !!!
2023-03-22 11:27:16,153 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-22 11:27:18,740 - INFO - Train: [120/120][0/3907]	eta 2:48:13 lr 0.00000685	time 2.5834 (2.5834)	loss 2.0746 (2.0746)	acc@1: 90.1772	acc@5: 94.0304	
2023-03-22 11:28:16,534 - INFO - Train: [120/120][300/3907]	eta 0:12:03 lr 0.00000685	time 0.1885 (0.2006)	loss 2.5145 (3.1663)	acc@1: 86.2066	acc@5: 90.5820	
2023-03-22 11:29:15,456 - INFO - Train: [120/120][600/3907]	eta 0:10:56 lr 0.00000685	time 0.1926 (0.1985)	loss 3.7145 (3.1100)	acc@1: 64.9974	acc@5: 75.1822	
2023-03-22 11:30:14,748 - INFO - Train: [120/120][900/3907]	eta 0:09:56 lr 0.00000685	time 0.1913 (0.1982)	loss 3.3874 (3.1164)	acc@1: 74.4962	acc@5: 80.0077	
2023-03-22 11:31:13,739 - INFO - Train: [120/120][1200/3907]	eta 0:08:55 lr 0.00000685	time 0.2167 (0.1978)	loss 4.8423 (3.1032)	acc@1: 37.5369	acc@5: 54.3021	
2023-03-22 11:32:12,525 - INFO - Train: [120/120][1500/3907]	eta 0:07:55 lr 0.00000685	time 0.1951 (0.1974)	loss 1.9503 (3.1073)	acc@1: 84.7756	acc@5: 96.4446	
2023-03-22 11:33:11,527 - INFO - Train: [120/120][1800/3907]	eta 0:06:55 lr 0.00000685	time 0.1901 (0.1973)	loss 2.0278 (3.1116)	acc@1: 90.6546	acc@5: 95.2642	
2023-03-22 11:34:10,307 - INFO - Train: [120/120][2100/3907]	eta 0:05:56 lr 0.00000685	time 0.1903 (0.1971)	loss 5.0263 (3.1146)	acc@1: 34.4078	acc@5: 53.5872	
2023-03-22 11:35:09,325 - INFO - Train: [120/120][2400/3907]	eta 0:04:56 lr 0.00000685	time 0.1913 (0.1971)	loss 4.3219 (3.1196)	acc@1: 53.4124	acc@5: 65.1749	
2023-03-22 11:36:08,823 - INFO - Train: [120/120][2700/3907]	eta 0:03:58 lr 0.00000685	time 0.1888 (0.1972)	loss 1.8289 (3.1133)	acc@1: 91.1445	acc@5: 95.8186	
2023-03-22 11:37:04,672 - INFO - Train: [120/120][3000/3907]	eta 0:02:57 lr 0.00000685	time 0.1918 (0.1961)	loss 3.8310 (3.1161)	acc@1: 60.5101	acc@5: 70.6111	
2023-03-22 11:37:59,633 - INFO - Train: [120/120][3300/3907]	eta 0:01:58 lr 0.00000685	time 0.1992 (0.1949)	loss 4.3407 (3.1138)	acc@1: 50.4247	acc@5: 62.4221	
2023-03-22 11:38:54,054 - INFO - Train: [120/120][3600/3907]	eta 0:00:59 lr 0.00000685	time 0.1746 (0.1938)	loss 4.2704 (3.1153)	acc@1: 53.7605	acc@5: 64.1568	
2023-03-22 11:39:49,184 - INFO - Train: [120/120][3900/3907]	eta 0:00:01 lr 0.00000685	time 0.1747 (0.1930)	loss 2.2303 (3.1154)	acc@1: 87.2024	acc@5: 92.5090	
2023-03-22 11:39:50,426 - INFO - EPOCH 120 training takes 0:12:34
2023-03-22 11:39:51,642 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Latest.pth saved !!!
2023-03-22 11:39:51,643 - INFO - **********Latest test***********
2023-03-22 11:39:51,643 - INFO - eval epoch 120
2023-03-22 11:39:52,526 - INFO - Test: [0/782]	Time 0.882 (0.882)	Loss 2.1803 (2.1803)	Acc@1 81.250 (81.250)	Acc@5 96.094 (96.094)
2023-03-22 11:42:48,100 - INFO - Test: [200/782]	Time 0.761 (0.878)	Loss 2.3922 (2.4536)	Acc@1 73.438 (75.649)	Acc@5 92.188 (91.056)
2023-03-22 11:45:42,095 - INFO - Test: [400/782]	Time 0.929 (0.874)	Loss 2.3568 (2.4294)	Acc@1 79.688 (76.374)	Acc@5 92.188 (91.465)
2023-03-22 11:48:39,016 - INFO - Test: [600/782]	Time 0.812 (0.877)	Loss 2.4985 (2.3993)	Acc@1 75.000 (77.162)	Acc@5 90.625 (91.876)
2023-03-22 11:51:12,707 - INFO -  * Acc@1 77.562 Acc@5 92.176
2023-03-22 11:51:12,708 - INFO - Max accuracy: 77.9990%
2023-03-22 11:51:12,708 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-22 11:51:12,708 - INFO - Training time 10:41:24
