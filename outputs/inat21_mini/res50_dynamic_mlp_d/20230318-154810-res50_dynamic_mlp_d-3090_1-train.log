2023-03-18 15:48:15,098 - INFO - --batch_size 128
2023-03-18 15:48:15,098 - INFO - --data inat21_mini
2023-03-18 15:48:15,098 - INFO - --data_dir ./datasets/iNat2021
2023-03-18 15:48:15,098 - INFO - --device_name NVIDIA GeForce RTX 3090
2023-03-18 15:48:15,098 - INFO - --evaluate False
2023-03-18 15:48:15,098 - INFO - --fold 1
2023-03-18 15:48:15,098 - INFO - --image_only False
2023-03-18 15:48:15,098 - INFO - --metadata geo_temporal
2023-03-18 15:48:15,098 - INFO - --mlp_cin 6
2023-03-18 15:48:15,098 - INFO - --mlp_hidden 64
2023-03-18 15:48:15,098 - INFO - --mlp_num_layers 2
2023-03-18 15:48:15,098 - INFO - --mlp_out_channel 256
2023-03-18 15:48:15,098 - INFO - --mlp_type d
2023-03-18 15:48:15,098 - INFO - --model_file resnet_dynamic_mlp
2023-03-18 15:48:15,098 - INFO - --model_name resnet50
2023-03-18 15:48:15,098 - INFO - --name res50_dynamic_mlp_d
2023-03-18 15:48:15,098 - INFO - --num_classes 10000
2023-03-18 15:48:15,098 - INFO - --num_workers 8
2023-03-18 15:48:15,098 - INFO - --path_log ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-18 15:48:15,098 - INFO - --pretrained True
2023-03-18 15:48:15,098 - INFO - --random_seed 37
2023-03-18 15:48:15,098 - INFO - --resume Latest
2023-03-18 15:48:15,098 - INFO - --save_dir ./outputs
2023-03-18 15:48:15,098 - INFO - --start_lr 0.04
2023-03-18 15:48:15,099 - INFO - --stop_epoch 90
2023-03-18 15:48:15,099 - INFO - --storeinfo 3090_1
2023-03-18 15:48:15,099 - INFO - --tencrop False
2023-03-18 15:48:15,099 - INFO - --warmup 2
2023-03-18 15:48:15,099 - INFO - Creating model:resnet_dynamic_mlp -> resnet50
2023-03-18 15:48:15,099 - INFO - type: d, cin: 6, d: 256, h: 64, N: 2
2023-03-18 15:48:20,190 - INFO - => loading checkpoint './outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Latest.pth'
2023-03-18 15:48:20,703 - INFO - => loaded checkpoint './outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Latest.pth' (epoch 41)
2023-03-18 15:48:20,703 - INFO - eval epoch 41
2023-03-18 15:48:21,797 - INFO - Test: [0/782]	Time 1.093 (1.093)	Loss 2.5437 (2.5437)	Acc@1 71.875 (71.875)	Acc@5 92.188 (92.188)
2023-03-18 15:50:19,853 - INFO - Test: [200/782]	Time 0.584 (0.593)	Loss 2.8242 (2.9061)	Acc@1 67.188 (62.710)	Acc@5 82.812 (84.080)
2023-03-18 15:52:18,558 - INFO - Test: [400/782]	Time 0.589 (0.593)	Loss 2.7982 (2.8744)	Acc@1 64.844 (63.369)	Acc@5 85.156 (84.696)
2023-03-18 15:54:18,973 - INFO - Test: [600/782]	Time 0.581 (0.596)	Loss 2.9301 (2.8399)	Acc@1 63.281 (64.222)	Acc@5 84.375 (85.217)
2023-03-18 15:56:04,731 - INFO -  * Acc@1 64.701 Acc@5 85.608
2023-03-18 15:56:04,732 - INFO - Max accuracy: 64.7010%
2023-03-18 15:56:04,732 - INFO - Start training
2023-03-18 15:56:09,492 - INFO - Train: [42/90][0/3907]	eta 5:09:42 lr 0.02278346	time 4.7563 (4.7563)	loss 3.2071 (3.2071)	acc@1: 67.7426	acc@5: 81.0158	
2023-03-18 15:57:04,805 - INFO - Train: [42/90][300/3907]	eta 0:11:59 lr 0.02278346	time 0.1844 (0.1996)	loss 5.4817 (4.0160)	acc@1: 28.7120	acc@5: 46.4146	
2023-03-18 15:57:59,616 - INFO - Train: [42/90][600/3907]	eta 0:10:32 lr 0.02278346	time 0.1846 (0.1911)	loss 3.1840 (3.9977)	acc@1: 67.1348	acc@5: 82.3408	
2023-03-18 15:58:54,510 - INFO - Train: [42/90][900/3907]	eta 0:09:26 lr 0.02278346	time 0.1957 (0.1884)	loss 4.2231 (3.9712)	acc@1: 55.4223	acc@5: 70.8169	
2023-03-18 15:59:49,312 - INFO - Train: [42/90][1200/3907]	eta 0:08:26 lr 0.02278346	time 0.1850 (0.1870)	loss 3.4700 (3.9421)	acc@1: 63.0718	acc@5: 79.5395	
2023-03-18 16:00:44,228 - INFO - Train: [42/90][1500/3907]	eta 0:07:28 lr 0.02278346	time 0.1872 (0.1862)	loss 3.2029 (3.9472)	acc@1: 63.7580	acc@5: 80.0578	
2023-03-18 16:01:39,067 - INFO - Train: [42/90][1800/3907]	eta 0:06:31 lr 0.02278346	time 0.1882 (0.1856)	loss 2.9907 (3.9590)	acc@1: 67.7052	acc@5: 82.7443	
2023-03-18 16:02:33,972 - INFO - Train: [42/90][2100/3907]	eta 0:05:34 lr 0.02278346	time 0.1810 (0.1853)	loss 5.8010 (3.9547)	acc@1: 24.1478	acc@5: 41.7959	
2023-03-18 16:03:29,211 - INFO - Train: [42/90][2400/3907]	eta 0:04:38 lr 0.02278346	time 0.1872 (0.1851)	loss 4.5243 (3.9625)	acc@1: 48.2708	acc@5: 64.7339	
2023-03-18 16:04:24,418 - INFO - Train: [42/90][2700/3907]	eta 0:03:43 lr 0.02278346	time 0.1815 (0.1850)	loss 3.1919 (3.9782)	acc@1: 66.6269	acc@5: 83.4541	
2023-03-18 16:05:19,415 - INFO - Train: [42/90][3000/3907]	eta 0:02:47 lr 0.02278346	time 0.1810 (0.1848)	loss 3.8307 (3.9829)	acc@1: 56.9676	acc@5: 74.8128	
2023-03-18 16:06:14,529 - INFO - Train: [42/90][3300/3907]	eta 0:01:52 lr 0.02278346	time 0.1883 (0.1847)	loss 2.4765 (3.9923)	acc@1: 72.6342	acc@5: 89.0354	
2023-03-18 16:07:09,940 - INFO - Train: [42/90][3600/3907]	eta 0:00:56 lr 0.02278346	time 0.1806 (0.1847)	loss 5.4380 (3.9993)	acc@1: 30.6024	acc@5: 47.5215	
2023-03-18 16:08:05,197 - INFO - Train: [42/90][3900/3907]	eta 0:00:01 lr 0.02278346	time 0.1809 (0.1847)	loss 5.1378 (4.0045)	acc@1: 42.3502	acc@5: 56.3937	
2023-03-18 16:08:06,981 - INFO - EPOCH 42 training takes 0:12:02
2023-03-18 16:08:08,054 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Latest.pth saved !!!
2023-03-18 16:08:08,055 - INFO - **********Latest test***********
2023-03-18 16:08:08,055 - INFO - eval epoch 42
2023-03-18 16:08:08,647 - INFO - Test: [0/782]	Time 0.591 (0.591)	Loss 2.5211 (2.5211)	Acc@1 68.750 (68.750)	Acc@5 92.969 (92.969)
2023-03-18 16:10:06,624 - INFO - Test: [200/782]	Time 0.571 (0.590)	Loss 3.0068 (3.0501)	Acc@1 60.938 (59.911)	Acc@5 82.031 (81.985)
2023-03-18 16:12:03,741 - INFO - Test: [400/782]	Time 0.588 (0.588)	Loss 3.0072 (3.0142)	Acc@1 57.812 (60.897)	Acc@5 80.469 (82.772)
