2023-03-18 15:48:15,098 - INFO - --batch_size 128
2023-03-18 15:48:15,098 - INFO - --data inat21_mini
2023-03-18 15:48:15,098 - INFO - --data_dir ./datasets/iNat2021
2023-03-18 15:48:15,098 - INFO - --device_name NVIDIA GeForce RTX 3090
2023-03-18 15:48:15,098 - INFO - --evaluate False
2023-03-18 15:48:15,098 - INFO - --fold 1
2023-03-18 15:48:15,098 - INFO - --image_only False
2023-03-18 15:48:15,098 - INFO - --metadata geo_temporal
2023-03-18 15:48:15,098 - INFO - --mlp_cin 6
2023-03-18 15:48:15,098 - INFO - --mlp_hidden 64
2023-03-18 15:48:15,098 - INFO - --mlp_num_layers 2
2023-03-18 15:48:15,098 - INFO - --mlp_out_channel 256
2023-03-18 15:48:15,098 - INFO - --mlp_type d
2023-03-18 15:48:15,098 - INFO - --model_file resnet_dynamic_mlp
2023-03-18 15:48:15,098 - INFO - --model_name resnet50
2023-03-18 15:48:15,098 - INFO - --name res50_dynamic_mlp_d
2023-03-18 15:48:15,098 - INFO - --num_classes 10000
2023-03-18 15:48:15,098 - INFO - --num_workers 8
2023-03-18 15:48:15,098 - INFO - --path_log ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-18 15:48:15,098 - INFO - --pretrained True
2023-03-18 15:48:15,098 - INFO - --random_seed 37
2023-03-18 15:48:15,098 - INFO - --resume Latest
2023-03-18 15:48:15,098 - INFO - --save_dir ./outputs
2023-03-18 15:48:15,098 - INFO - --start_lr 0.04
2023-03-18 15:48:15,099 - INFO - --stop_epoch 90
2023-03-18 15:48:15,099 - INFO - --storeinfo 3090_1
2023-03-18 15:48:15,099 - INFO - --tencrop False
2023-03-18 15:48:15,099 - INFO - --warmup 2
2023-03-18 15:48:15,099 - INFO - Creating model:resnet_dynamic_mlp -> resnet50
2023-03-18 15:48:15,099 - INFO - type: d, cin: 6, d: 256, h: 64, N: 2
2023-03-18 15:48:20,190 - INFO - => loading checkpoint './outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Latest.pth'
2023-03-18 15:48:20,703 - INFO - => loaded checkpoint './outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Latest.pth' (epoch 41)
2023-03-18 15:48:20,703 - INFO - eval epoch 41
2023-03-18 15:48:21,797 - INFO - Test: [0/782]	Time 1.093 (1.093)	Loss 2.5437 (2.5437)	Acc@1 71.875 (71.875)	Acc@5 92.188 (92.188)
2023-03-18 15:50:19,853 - INFO - Test: [200/782]	Time 0.584 (0.593)	Loss 2.8242 (2.9061)	Acc@1 67.188 (62.710)	Acc@5 82.812 (84.080)
2023-03-18 15:52:18,558 - INFO - Test: [400/782]	Time 0.589 (0.593)	Loss 2.7982 (2.8744)	Acc@1 64.844 (63.369)	Acc@5 85.156 (84.696)
2023-03-18 15:54:18,973 - INFO - Test: [600/782]	Time 0.581 (0.596)	Loss 2.9301 (2.8399)	Acc@1 63.281 (64.222)	Acc@5 84.375 (85.217)
2023-03-18 15:56:04,731 - INFO -  * Acc@1 64.701 Acc@5 85.608
2023-03-18 15:56:04,732 - INFO - Max accuracy: 64.7010%
2023-03-18 15:56:04,732 - INFO - Start training
2023-03-18 15:56:09,492 - INFO - Train: [42/90][0/3907]	eta 5:09:42 lr 0.02278346	time 4.7563 (4.7563)	loss 3.2071 (3.2071)	acc@1: 67.7426	acc@5: 81.0158	
2023-03-18 15:57:04,805 - INFO - Train: [42/90][300/3907]	eta 0:11:59 lr 0.02278346	time 0.1844 (0.1996)	loss 5.4817 (4.0160)	acc@1: 28.7120	acc@5: 46.4146	
2023-03-18 15:57:59,616 - INFO - Train: [42/90][600/3907]	eta 0:10:32 lr 0.02278346	time 0.1846 (0.1911)	loss 3.1840 (3.9977)	acc@1: 67.1348	acc@5: 82.3408	
2023-03-18 15:58:54,510 - INFO - Train: [42/90][900/3907]	eta 0:09:26 lr 0.02278346	time 0.1957 (0.1884)	loss 4.2231 (3.9712)	acc@1: 55.4223	acc@5: 70.8169	
2023-03-18 15:59:49,312 - INFO - Train: [42/90][1200/3907]	eta 0:08:26 lr 0.02278346	time 0.1850 (0.1870)	loss 3.4700 (3.9421)	acc@1: 63.0718	acc@5: 79.5395	
2023-03-18 16:00:44,228 - INFO - Train: [42/90][1500/3907]	eta 0:07:28 lr 0.02278346	time 0.1872 (0.1862)	loss 3.2029 (3.9472)	acc@1: 63.7580	acc@5: 80.0578	
2023-03-18 16:01:39,067 - INFO - Train: [42/90][1800/3907]	eta 0:06:31 lr 0.02278346	time 0.1882 (0.1856)	loss 2.9907 (3.9590)	acc@1: 67.7052	acc@5: 82.7443	
2023-03-18 16:02:33,972 - INFO - Train: [42/90][2100/3907]	eta 0:05:34 lr 0.02278346	time 0.1810 (0.1853)	loss 5.8010 (3.9547)	acc@1: 24.1478	acc@5: 41.7959	
2023-03-18 16:03:29,211 - INFO - Train: [42/90][2400/3907]	eta 0:04:38 lr 0.02278346	time 0.1872 (0.1851)	loss 4.5243 (3.9625)	acc@1: 48.2708	acc@5: 64.7339	
2023-03-18 16:04:24,418 - INFO - Train: [42/90][2700/3907]	eta 0:03:43 lr 0.02278346	time 0.1815 (0.1850)	loss 3.1919 (3.9782)	acc@1: 66.6269	acc@5: 83.4541	
2023-03-18 16:05:19,415 - INFO - Train: [42/90][3000/3907]	eta 0:02:47 lr 0.02278346	time 0.1810 (0.1848)	loss 3.8307 (3.9829)	acc@1: 56.9676	acc@5: 74.8128	
2023-03-18 16:06:14,529 - INFO - Train: [42/90][3300/3907]	eta 0:01:52 lr 0.02278346	time 0.1883 (0.1847)	loss 2.4765 (3.9923)	acc@1: 72.6342	acc@5: 89.0354	
2023-03-18 16:07:09,940 - INFO - Train: [42/90][3600/3907]	eta 0:00:56 lr 0.02278346	time 0.1806 (0.1847)	loss 5.4380 (3.9993)	acc@1: 30.6024	acc@5: 47.5215	
2023-03-18 16:08:05,197 - INFO - Train: [42/90][3900/3907]	eta 0:00:01 lr 0.02278346	time 0.1809 (0.1847)	loss 5.1378 (4.0045)	acc@1: 42.3502	acc@5: 56.3937	
2023-03-18 16:08:06,981 - INFO - EPOCH 42 training takes 0:12:02
2023-03-18 16:08:08,054 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Latest.pth saved !!!
2023-03-18 16:08:08,055 - INFO - **********Latest test***********
2023-03-18 16:08:08,055 - INFO - eval epoch 42
2023-03-18 16:08:08,647 - INFO - Test: [0/782]	Time 0.591 (0.591)	Loss 2.5211 (2.5211)	Acc@1 68.750 (68.750)	Acc@5 92.969 (92.969)
2023-03-18 16:10:06,624 - INFO - Test: [200/782]	Time 0.571 (0.590)	Loss 3.0068 (3.0501)	Acc@1 60.938 (59.911)	Acc@5 82.031 (81.985)
2023-03-18 16:12:03,741 - INFO - Test: [400/782]	Time 0.588 (0.588)	Loss 3.0072 (3.0142)	Acc@1 57.812 (60.897)	Acc@5 80.469 (82.772)
2023-03-18 16:14:03,209 - INFO - Test: [600/782]        Time 0.593 (0.591)      Loss 3.0162 (2.9771)    Acc@1 60.156 (61.706)   Acc@5 83.594 (83.318)                              
2023-03-18 16:15:49,953 - INFO -  * Acc@1 62.247 Acc@5 83.809                   
2023-03-18 16:15:49,954 - INFO - Max accuracy: 64.7010%                         
2023-03-18 16:15:50,984 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Best.pth saved !!!
2023-03-18 16:15:50,985 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d                             
2023-03-18 16:15:53,318 - INFO - Train: [43/90][0/3907] eta 2:31:39 lr 0.02209057       time 2.3291 (2.3291)    loss 4.4473 (4.4473)    acc@1: 55.9466  acc@5: 68.5048             
2023-03-18 16:16:47,641 - INFO - Train: [43/90][300/3907]       eta 0:11:18 lr 0.02209057       time 0.1799 (0.1882)    loss 5.5242 (3.8123)    acc@1: 28.0758  acc@5: 44.5194     
2023-03-18 16:17:42,272 - INFO - Train: [43/90][600/3907]       eta 0:10:12 lr 0.02209057       time 0.1803 (0.1852)    loss 6.2016 (3.8563)    acc@1: 18.5172  acc@5: 31.4508     
2023-03-18 16:18:36,839 - INFO - Train: [43/90][900/3907]       eta 0:09:13 lr 0.02209057       time 0.1804 (0.1841)    loss 4.2120 (3.8714)    acc@1: 53.0452  acc@5: 69.8039     
2023-03-18 16:19:32,048 - INFO - Train: [43/90][1200/3907]      eta 0:08:18 lr 0.02209057       time 0.1841 (0.1841)    loss 2.7947 (3.8681)    acc@1: 65.5430  acc@5: 84.8204     
2023-03-18 16:20:27,181 - INFO - Train: [43/90][1500/3907]      eta 0:07:22 lr 0.02209057       time 0.1879 (0.1840)    loss 2.7687 (3.9169)    acc@1: 66.3601  acc@5: 86.2050     
2023-03-18 16:21:22,550 - INFO - Train: [43/90][1800/3907]      eta 0:06:27 lr 0.02209057       time 0.1810 (0.1841)    loss 2.6105 (3.9094)    acc@1: 69.9426  acc@5: 89.3675     
2023-03-18 16:22:17,693 - INFO - Train: [43/90][2100/3907]      eta 0:05:32 lr 0.02209057       time 0.1823 (0.1841)    loss 3.7554 (3.9249)    acc@1: 61.1003  acc@5: 74.8092     
2023-03-18 16:23:11,224 - INFO - Train: [43/90][2400/3907]      eta 0:04:36 lr 0.02209057       time 0.1805 (0.1834)    loss 3.5977 (3.9368)    acc@1: 66.8164  acc@5: 76.7571     
2023-03-18 16:24:03,981 - INFO - Train: [43/90][2700/3907]      eta 0:03:40 lr 0.02209057       time 0.1750 (0.1825)    loss 5.8882 (3.9440)    acc@1: 22.1878  acc@5: 39.9557     
2023-03-18 16:24:56,733 - INFO - Train: [43/90][3000/3907]      eta 0:02:44 lr 0.02209057       time 0.1763 (0.1818)    loss 4.0678 (3.9628)    acc@1: 55.2321  acc@5: 72.9451     
2023-03-18 16:25:49,018 - INFO - Train: [43/90][3300/3907]      eta 0:01:49 lr 0.02209057       time 0.1864 (0.1812)    loss 4.1419 (3.9709)    acc@1: 54.6773  acc@5: 71.2689     
2023-03-18 16:26:41,463 - INFO - Train: [43/90][3600/3907]      eta 0:00:55 lr 0.02209057       time 0.1766 (0.1806)    loss 4.0867 (3.9812)    acc@1: 55.6825  acc@5: 69.0730     
2023-03-18 16:27:34,177 - INFO - Train: [43/90][3900/3907]      eta 0:00:01 lr 0.02209057       time 0.1735 (0.1803)    loss 4.3362 (3.9853)    acc@1: 48.2465  acc@5: 70.4205     
2023-03-18 16:27:35,343 - INFO - EPOCH 43 training takes 0:11:44                
2023-03-18 16:27:36,446 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Latest.pth saved !!! 
2023-03-18 16:27:36,446 - INFO - **********Latest test***********               
2023-03-18 16:27:36,447 - INFO - eval epoch 43 
2023-03-18 16:27:37,055 - INFO - Test: [0/782]  Time 0.607 (0.607)      Loss 2.6018 (2.6018)    Acc@1 65.625 (65.625)   Acc@5 89.062 (89.062)     
2023-03-18 16:29:39,253 - INFO - Test: [200/782]        Time 0.578 (0.611)      Loss 2.8362 (2.9039)    Acc@1 66.406 (62.924)   Acc@5 85.156 (84.239)                              
2023-03-18 16:31:43,556 - INFO - Test: [400/782]        Time 0.665 (0.616)      Loss 2.6166 (2.8675)    Acc@1 70.312 (63.611)   Acc@5 88.281 (84.856)                              
2023-03-18 16:33:43,343 - INFO - Test: [600/782]        Time 0.593 (0.610)      Loss 2.8956 (2.8322)    Acc@1 58.594 (64.511)   Acc@5 85.938 (85.373)                              
2023-03-18 16:35:29,795 - INFO -  * Acc@1 65.093 Acc@5 85.848                   
2023-03-18 16:35:29,795 - INFO - Max accuracy: 65.0930%                         
2023-03-18 16:35:30,739 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Best.pth saved !!!
2023-03-18 16:35:30,740 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d                             
2023-03-18 16:35:33,133 - INFO - Train: [44/90][0/3907] eta 2:35:34 lr 0.02139513       time 2.3891 (2.3891)    loss 3.5232 (3.5232)    acc@1: 60.5582  acc@5: 77.9488             
2023-03-18 16:36:28,353 - INFO - Train: [44/90][300/3907]       eta 0:11:30 lr 0.02139513       time 0.1797 (0.1914)    loss 3.5273 (3.8490)    acc@1: 63.3420  acc@5: 76.1385     
2023-03-18 16:37:23,227 - INFO - Train: [44/90][600/3907]       eta 0:10:18 lr 0.02139513       time 0.1883 (0.1872)    loss 3.2369 (3.8369)    acc@1: 66.7789  acc@5: 82.9233     
2023-03-18 16:38:17,819 - INFO - Train: [44/90][900/3907]       eta 0:09:17 lr 0.02139513       time 0.1812 (0.1854)    loss 2.9629 (3.8669)    acc@1: 69.1887  acc@5: 84.9818     
2023-03-18 16:39:13,011 - INFO - Train: [44/90][1200/3907]      eta 0:08:20 lr 0.02139513       time 0.1819 (0.1851)    loss 3.7806 (3.8970)    acc@1: 59.6711  acc@5: 77.9473     
2023-03-18 16:40:08,153 - INFO - Train: [44/90][1500/3907]      eta 0:07:24 lr 0.02139513       time 0.1814 (0.1848)    loss 2.6730 (3.9084)    acc@1: 71.2941  acc@5: 86.7992     
2023-03-18 16:41:03,029 - INFO - Train: [44/90][1800/3907]      eta 0:06:28 lr 0.02139513       time 0.1848 (0.1845)    loss 2.5654 (3.9029)    acc@1: 69.7597  acc@5: 89.1340     
2023-03-18 16:41:57,922 - INFO - Train: [44/90][2100/3907]      eta 0:05:32 lr 0.02139513       time 0.1897 (0.1843)    loss 3.5048 (3.9078)    acc@1: 63.0931  acc@5: 77.4026     
2023-03-18 16:42:53,128 - INFO - Train: [44/90][2400/3907]      eta 0:04:37 lr 0.02139513       time 0.1808 (0.1842)    loss 5.1947 (3.9304)    acc@1: 37.1946  acc@5: 54.6301     
2023-03-18 16:43:48,204 - INFO - Train: [44/90][2700/3907]      eta 0:03:42 lr 0.02139513       time 0.1820 (0.1842)    loss 3.1632 (3.9493)    acc@1: 60.6846  acc@5: 82.4112     
2023-03-18 16:44:43,158 - INFO - Train: [44/90][3000/3907]      eta 0:02:46 lr 0.02139513       time 0.1904 (0.1841)    loss 5.1771 (3.9436)    acc@1: 38.1201  acc@5: 55.6061     
2023-03-18 16:45:38,100 - INFO - Train: [44/90][3300/3907]      eta 0:01:51 lr 0.02139513       time 0.1891 (0.1840)    loss 3.6409 (3.9358)    acc@1: 59.3940  acc@5: 77.2637     
2023-03-18 16:46:33,389 - INFO - Train: [44/90][3600/3907]      eta 0:00:56 lr 0.02139513       time 0.1811 (0.1840)    loss 2.8826 (3.9398)    acc@1: 62.2076  acc@5: 86.3117     
2023-03-18 16:47:28,608 - INFO - Train: [44/90][3900/3907]      eta 0:00:01 lr 0.02139513       time 0.1797 (0.1840)    loss 3.0438 (3.9523)    acc@1: 68.1653  acc@5: 85.2067     
2023-03-18 16:47:29,826 - INFO - EPOCH 44 training takes 0:11:59                
2023-03-18 16:47:30,904 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Latest.pth saved !!!
 2023-03-18 16:47:30,904 - INFO - **********Latest test***********               
2023-03-18 16:47:30,904 - INFO - eval epoch 44 
2023-03-18 16:47:31,506 - INFO - Test: [0/782]  Time 0.601 (0.601)      Loss 2.5898 (2.5898)    Acc@1 70.312 (70.312)   Acc@5 92.188 (92.188)     
2023-03-18 16:49:28,772 - INFO - Test: [200/782]        Time 0.581 (0.586)      Loss 2.7553 (2.9183)    Acc@1 66.406 (62.737)   Acc@5 88.281 (84.235)                              
2023-03-18 16:51:26,911 - INFO - Test: [400/782]        Time 0.586 (0.589)      Loss 2.8499 (2.8872)    Acc@1 61.719 (63.611)   Acc@5 85.156 (84.936)                              
2023-03-18 16:53:25,931 - INFO - Test: [600/782]        Time 0.624 (0.591)      Loss 2.9424 (2.8529)    Acc@1 59.375 (64.411)   Acc@5 82.812 (85.463)                              
2023-03-18 16:55:12,135 - INFO -  * Acc@1 64.969 Acc@5 85.824                   
2023-03-18 16:55:12,135 - INFO - Max accuracy: 65.0930%                         
2023-03-18 16:55:12,135 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d                             
2023-03-18 16:55:14,494 - INFO - Train: [45/90][0/3907] eta 2:33:24 lr 0.02069799       time 2.3559 (2.3559)    loss 2.4960 (2.4960)    acc@1: 73.3755  acc@5: 90.5482             
2023-03-18 16:56:09,460 - INFO - Train: [45/90][300/3907]       eta 0:11:26 lr 0.02069799       time 0.1850 (0.1904)    loss 3.1472 (3.8164)    acc@1: 66.5530  acc@5: 81.5275     
2023-03-18 16:57:04,520 - INFO - Train: [45/90][600/3907]       eta 0:10:18 lr 0.02069799       time 0.1847 (0.1870)    loss 5.8019 (3.9115)    acc@1: 20.5917  acc@5: 41.2982     
2023-03-18 16:57:59,560 - INFO - Train: [45/90][900/3907]       eta 0:09:18 lr 0.02069799       time 0.1898 (0.1858)    loss 5.9529 (3.8928)    acc@1: 23.4461  acc@5: 37.5115     
2023-03-18 16:58:54,661 - INFO - Train: [45/90][1200/3907]      eta 0:08:21 lr 0.02069799       time 0.1851 (0.1853)    loss 3.8749 (3.8906)    acc@1: 58.5137  acc@5: 70.8849     
2023-03-18 16:59:49,576 - INFO - Train: [45/90][1500/3907]      eta 0:07:24 lr 0.02069799       time 0.1820 (0.1848)    loss 5.7513 (3.8673)    acc@1: 23.3611  acc@5: 42.7079     
2023-03-18 17:00:44,398 - INFO - Train: [45/90][1800/3907]      eta 0:06:28 lr 0.02069799       time 0.1833 (0.1845)    loss 2.4809 (3.8914)    acc@1: 73.2999  acc@5: 94.3536     
2023-03-18 17:01:39,291 - INFO - Train: [45/90][2100/3907]      eta 0:05:32 lr 0.02069799       time 0.1802 (0.1843)    loss 4.7285 (3.8911)    acc@1: 46.3424  acc@5: 62.1027     
2023-03-18 17:02:33,887 - INFO - Train: [45/90][2400/3907]      eta 0:04:37 lr 0.02069799       time 0.1808 (0.1840)    loss 3.8443 (3.8996)    acc@1: 61.3911  acc@5: 74.1865     
2023-03-18 17:03:28,717 - INFO - Train: [45/90][2700/3907]      eta 0:03:41 lr 0.02069799       time 0.1852 (0.1838)    loss 2.8693 (3.9101)    acc@1: 65.1953  acc@5: 87.4384     
2023-03-18 17:04:23,070 - INFO - Train: [45/90][3000/3907]      eta 0:02:46 lr 0.02069799       time 0.1724 (0.1836)    loss 2.7280 (3.9192)    acc@1: 65.6135  acc@5: 85.1413     
2023-03-18 17:05:15,424 - INFO - Train: [45/90][3300/3907]      eta 0:01:50 lr 0.02069799       time 0.1732 (0.1828)    loss 5.9348 (3.9268)    acc@1: 23.8662  acc@5: 37.5037     
2023-03-18 17:06:07,584 - INFO - Train: [45/90][3600/3907]      eta 0:00:55 lr 0.02069799       time 0.1712 (0.1820)    loss 3.5858 (3.9225)    acc@1: 62.7718  acc@5: 78.6139     
2023-03-18 17:06:59,815 - INFO - Train: [45/90][3900/3907]      eta 0:00:01 lr 0.02069799       time 0.1712 (0.1814)    loss 5.8774 (3.9267)    acc@1: 29.5014  acc@5: 43.5198     
2023-03-18 17:07:01,010 - INFO - EPOCH 45 training takes 0:11:48                
2023-03-18 17:07:02,087 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Latest.pth saved !!!
2023-03-18 17:07:02,087 - INFO - **********Latest test***********               
2023-03-18 17:07:02,087 - INFO - eval epoch 45 
2023-03-18 17:07:02,679 - INFO - Test: [0/782]  Time 0.591 (0.591)      Loss 2.5498 (2.5498)    Acc@1 68.750 (68.750)   Acc@5 91.406 (91.406)     
2023-03-18 17:08:59,048 - INFO - Test: [200/782]        Time 0.577 (0.582)      Loss 2.7036 (2.8881)    Acc@1 70.312 (64.000)   Acc@5 85.156 (84.639)                              
2023-03-18 17:10:55,820 - INFO - Test: [400/782]        Time 0.589 (0.583)      Loss 2.6748 (2.8550)    Acc@1 67.969 (64.737)   Acc@5 88.281 (85.156)                              
2023-03-18 17:12:53,933 - INFO - Test: [600/782]        Time 0.570 (0.585)      Loss 2.8303 (2.8168)    Acc@1 60.938 (65.534)   Acc@5 84.375 (85.800)                              
2023-03-18 17:14:38,391 - INFO -  * Acc@1 66.012 Acc@5 86.242                   
2023-03-18 17:14:38,392 - INFO - Max accuracy: 66.0120%                         
2023-03-18 17:14:39,547 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Best.pth saved !!!
2023-03-18 17:14:39,548 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d                             
2023-03-18 17:14:41,971 - INFO - Train: [46/90][0/3907] eta 2:37:30 lr 0.02000000       time 2.4190 (2.4190)    loss 2.2931 (2.2931)    acc@1: 85.8813  acc@5: 92.9079             
2023-03-18 17:15:36,615 - INFO - Train: [46/90][300/3907]       eta 0:11:23 lr 0.02000000       time 0.1804 (0.1896)    loss 3.5933 (3.7758)    acc@1: 59.6841  acc@5: 76.5361     
2023-03-18 17:16:31,654 - INFO - Train: [46/90][600/3907]       eta 0:10:16 lr 0.02000000       time 0.1804 (0.1865)    loss 4.1005 (3.8472)    acc@1: 61.1263  acc@5: 70.7079     
2023-03-18 17:17:26,530 - INFO - Train: [46/90][900/3907]       eta 0:09:17 lr 0.02000000       time 0.1802 (0.1853)    loss 2.6351 (3.8317)    acc@1: 72.2154  acc@5: 88.3457     
2023-03-18 17:18:21,314 - INFO - Train: [46/90][1200/3907]      eta 0:08:19 lr 0.02000000       time 0.1881 (0.1846)    loss 2.6187 (3.8648)    acc@1: 67.8048  acc@5: 87.2890     
2023-03-18 17:19:16,133 - INFO - Train: [46/90][1500/3907]      eta 0:07:23 lr 0.02000000       time 0.1888 (0.1843)    loss 5.8155 (3.8700)    acc@1: 18.8134  acc@5: 37.3153     
2023-03-18 17:20:10,924 - INFO - Train: [46/90][1800/3907]      eta 0:06:27 lr 0.02000000       time 0.1811 (0.1840)    loss 4.1715 (3.8675)    acc@1: 55.0010  acc@5: 71.5314     
2023-03-18 17:21:05,940 - INFO - Train: [46/90][2100/3907]      eta 0:05:32 lr 0.02000000       time 0.1813 (0.1839)    loss 5.6435 (3.8770)    acc@1: 22.9395  acc@5: 38.4357     
2023-03-18 17:22:00,896 - INFO - Train: [46/90][2400/3907]      eta 0:04:37 lr 0.02000000       time 0.1869 (0.1838)    loss 2.8213 (3.8930)    acc@1: 65.0791  acc@5: 83.4499     
2023-03-18 17:22:55,837 - INFO - Train: [46/90][2700/3907]      eta 0:03:41 lr 0.02000000       time 0.1809 (0.1837)    loss 2.7509 (3.8924)    acc@1: 72.1696  acc@5: 85.2191     
2023-03-18 17:23:50,670 - INFO - Train: [46/90][3000/3907]      eta 0:02:46 lr 0.02000000       time 0.1805 (0.1836)    loss 3.4937 (3.8946)    acc@1: 57.8443  acc@5: 75.4173     
2023-03-18 17:24:45,853 - INFO - Train: [46/90][3300/3907]      eta 0:01:51 lr 0.02000000       time 0.1807 (0.1837)    loss 2.4620 (3.9134)    acc@1: 71.0858  acc@5: 92.1772     
2023-03-18 17:25:40,711 - INFO - Train: [46/90][3600/3907]      eta 0:00:56 lr 0.02000000       time 0.1806 (0.1836)    loss 3.1064 (3.9110)    acc@1: 62.0644  acc@5: 85.9798     
2023-03-18 17:26:35,683 - INFO - Train: [46/90][3900/3907]      eta 0:00:01 lr 0.02000000       time 0.1798 (0.1836)    loss 3.0857 (3.9173)    acc@1: 70.1947  acc@5: 84.9725     
2023-03-18 17:26:36,905 - INFO - EPOCH 46 training takes 0:11:57                
2023-03-18 17:26:37,981 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Latest.pth saved !!! 
2023-03-18 17:26:37,982 - INFO - **********Latest test***********               
2023-03-18 17:26:37,982 - INFO - eval epoch 46 
2023-03-18 17:26:38,604 - INFO - Test: [0/782]  Time 0.621 (0.621)      Loss 2.4007 (2.4007)    Acc@1 71.875 (71.875)   Acc@5 92.969 (92.969)     
2023-03-18 17:28:35,634 - INFO - Test: [200/782]        Time 0.579 (0.585)      Loss 2.7864 (2.8498)    Acc@1 64.844 (63.775)   Acc@5 84.375 (84.841)                              
2023-03-18 17:30:32,248 - INFO - Test: [400/782]        Time 0.588 (0.584)      Loss 2.6227 (2.8130)    Acc@1 67.188 (64.799)   Acc@5 89.062 (85.478)                              
2023-03-18 17:32:29,843 - INFO - Test: [600/782]        Time 0.576 (0.585)      Loss 2.8480 (2.7780)    Acc@1 62.500 (65.734)   Acc@5 83.594 (86.071)                              
2023-03-18 17:34:13,930 - INFO -  * Acc@1 66.299 Acc@5 86.501                   
2023-03-18 17:34:13,931 - INFO - Max accuracy: 66.2990%                         
2023-03-18 17:34:14,983 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Best.pth saved !!!
2023-03-18 17:34:14,983 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d                             
2023-03-18 17:34:17,423 - INFO - Train: [47/90][0/3907] eta 2:38:38 lr 0.01930201       time 2.4362 (2.4362)    loss 3.2826 (3.2826)    acc@1: 69.8324  acc@5: 79.1830             
2023-03-18 17:35:12,701 - INFO - Train: [47/90][300/3907]       eta 0:11:31 lr 0.01930201       time 0.1803 (0.1917)    loss 2.6169 (3.8400)    acc@1: 72.7649  acc@5: 89.7933     
2023-03-18 17:36:07,772 - INFO - Train: [47/90][600/3907]       eta 0:10:20 lr 0.01930201       time 0.1817 (0.1877)    loss 3.8610 (3.8760)    acc@1: 64.3814  acc@5: 75.6227     
2023-03-18 17:37:03,214 - INFO - Train: [47/90][900/3907]       eta 0:09:21 lr 0.01930201       time 0.1858 (0.1867)    loss 5.8813 (3.8776)    acc@1: 19.3926  acc@5: 37.2228     
2023-03-18 17:37:58,144 - INFO - Train: [47/90][1200/3907]      eta 0:08:22 lr 0.01930201       time 0.1882 (0.1858)    loss 3.6647 (3.8689)    acc@1: 57.2137  acc@5: 80.0532     
2023-03-18 17:38:53,108 - INFO - Train: [47/90][1500/3907]      eta 0:07:25 lr 0.01930201       time 0.1836 (0.1853)    loss 2.6621 (3.8612)    acc@1: 66.8836  acc@5: 88.6584     
2023-03-18 17:39:47,885 - INFO - Train: [47/90][1800/3907]      eta 0:06:29 lr 0.01930201       time 0.1805 (0.1848)    loss 3.7095 (3.8732)    acc@1: 63.5244  acc@5: 78.5282     
2023-03-18 17:40:42,722 - INFO - Train: [47/90][2100/3907]      eta 0:05:33 lr 0.01930201       time 0.1830 (0.1845)    loss 3.4272 (3.8795)    acc@1: 60.6972  acc@5: 82.8338     
2023-03-18 17:41:37,722 - INFO - Train: [47/90][2400/3907]      eta 0:04:37 lr 0.01930201       time 0.1828 (0.1844)    loss 4.0238 (3.8949)    acc@1: 62.0610  acc@5: 75.2395     
2023-03-18 17:42:32,497 - INFO - Train: [47/90][2700/3907]      eta 0:03:42 lr 0.01930201       time 0.1853 (0.1842)    loss 3.5824 (3.8910)    acc@1: 59.6765  acc@5: 77.2049     
2023-03-18 17:43:27,182 - INFO - Train: [47/90][3000/3907]      eta 0:02:46 lr 0.01930201       time 0.1807 (0.1840)    loss 4.4127 (3.8957)    acc@1: 55.7918  acc@5: 67.1115     
2023-03-18 17:44:21,985 - INFO - Train: [47/90][3300/3907]      eta 0:01:51 lr 0.01930201       time 0.1862 (0.1839)    loss 4.0572 (3.8946)    acc@1: 58.2192  acc@5: 72.0836     
2023-03-18 17:45:16,728 - INFO - Train: [47/90][3600/3907]      eta 0:00:56 lr 0.01930201       time 0.1824 (0.1838)    loss 5.7699 (3.8953)    acc@1: 28.5127  acc@5: 42.7551     
2023-03-18 17:46:11,701 - INFO - Train: [47/90][3900/3907]      eta 0:00:01 lr 0.01930201       time 0.1826 (0.1837)    loss 5.2123 (3.9063)    acc@1: 34.3092  acc@5: 51.7798     
2023-03-18 17:46:12,922 - INFO - EPOCH 47 training takes 0:11:57                
2023-03-18 17:46:13,986 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Latest.pth saved !!! 
2023-03-18 17:46:13,987 - INFO - **********Latest test***********               
2023-03-18 17:46:13,987 - INFO - eval epoch 47 
2023-03-18 17:46:14,582 - INFO - Test: [0/782]  Time 0.594 (0.594)      Loss 2.4171 (2.4171)    Acc@1 75.000 (75.000)   Acc@5 92.969 (92.969)     
2023-03-18 17:48:11,123 - INFO - Test: [200/782]        Time 0.575 (0.583)      Loss 2.8819 (2.9151)    Acc@1 65.625 (63.056)   Acc@5 83.594 (84.181)                              
2023-03-18 17:50:07,224 - INFO - Test: [400/782]        Time 0.578 (0.582)      Loss 2.8395 (2.8814)    Acc@1 65.625 (63.922)   Acc@5 86.719 (84.813)                              
2023-03-18 17:52:04,337 - INFO - Test: [600/782]        Time 0.584 (0.583)      Loss 2.8169 (2.8478)    Acc@1 62.500 (64.758)   Acc@5 87.500 (85.314)                              
2023-03-18 17:53:48,294 - INFO -  * Acc@1 65.220 Acc@5 85.733                   
2023-03-18 17:53:48,295 - INFO - Max accuracy: 66.2990%                         
2023-03-18 17:53:48,295 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d                             
2023-03-18 17:53:50,530 - INFO - Train: [48/90][0/3907] eta 2:25:19 lr 0.01860487       time 2.2317 (2.2317)    loss 4.9504 (4.9504)    acc@1: 41.5124  acc@5: 57.9096             
2023-03-18 17:54:45,204 - INFO - Train: [48/90][300/3907]       eta 0:11:21 lr 0.01860487       time 0.1844 (0.1890)    loss 2.4551 (3.6460)    acc@1: 74.3433  acc@5: 88.2826     
2023-03-18 17:55:40,054 - INFO - Train: [48/90][600/3907]       eta 0:10:14 lr 0.01860487       time 0.1804 (0.1859)    loss 5.6277 (3.7465)    acc@1: 27.5363  acc@5: 43.2847     
2023-03-18 17:56:34,926 - INFO - Train: [48/90][900/3907]       eta 0:09:16 lr 0.01860487       time 0.1813 (0.1849)    loss 2.4613 (3.7692)    acc@1: 75.6715  acc@5: 90.4935     
2023-03-18 17:57:29,730 - INFO - Train: [48/90][1200/3907]      eta 0:08:19 lr 0.01860487       time 0.1804 (0.1844)    loss 2.6294 (3.8173)    acc@1: 72.6476  acc@5: 89.0519     
2023-03-18 17:58:24,488 - INFO - Train: [48/90][1500/3907]      eta 0:07:22 lr 0.01860487       time 0.1843 (0.1840)    loss 3.8210 (3.8337)    acc@1: 57.1772  acc@5: 74.0571     
2023-03-18 17:59:19,414 - INFO - Train: [48/90][1800/3907]      eta 0:06:27 lr 0.01860487       time 0.1888 (0.1838)    loss 4.8827 (3.8514)    acc@1: 41.6955  acc@5: 60.4522     
2023-03-18 18:00:14,627 - INFO - Train: [48/90][2100/3907]      eta 0:05:32 lr 0.01860487       time 0.1804 (0.1839)    loss 4.9990 (3.8793)    acc@1: 37.9006  acc@5: 55.0047     
2023-03-18 18:01:09,442 - INFO - Train: [48/90][2400/3907]      eta 0:04:36 lr 0.01860487       time 0.1808 (0.1837)    loss 2.5195 (3.8734)    acc@1: 74.0722  acc@5: 88.8866     
2023-03-18 18:02:04,218 - INFO - Train: [48/90][2700/3907]      eta 0:03:41 lr 0.01860487       time 0.1805 (0.1836)    loss 2.6663 (3.8742)    acc@1: 77.5457  acc@5: 88.2075     
2023-03-18 18:02:59,021 - INFO - Train: [48/90][3000/3907]      eta 0:02:46 lr 0.01860487       time 0.1802 (0.1835)    loss 3.0831 (3.8798)    acc@1: 67.7545  acc@5: 84.7271     
2023-03-18 18:03:53,736 - INFO - Train: [48/90][3300/3907]      eta 0:01:51 lr 0.01860487       time 0.1842 (0.1834)    loss 2.7759 (3.8759)    acc@1: 62.4107  acc@5: 84.2563     
2023-03-18 18:04:48,650 - INFO - Train: [48/90][3600/3907]      eta 0:00:56 lr 0.01860487       time 0.1805 (0.1834)    loss 2.6681 (3.8800)    acc@1: 75.7196  acc@5: 90.3983     
2023-03-18 18:05:43,357 - INFO - Train: [48/90][3900/3907]      eta 0:00:01 lr 0.01860487       time 0.1799 (0.1833)    loss 3.8619 (3.8829)    acc@1: 61.5575  acc@5: 74.5530     
2023-03-18 18:05:44,556 - INFO - EPOCH 48 training takes 0:11:56                
2023-03-18 18:05:45,635 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Latest.pth saved !!! 
2023-03-18 18:05:45,635 - INFO - **********Latest test***********               
2023-03-18 18:05:45,635 - INFO - eval epoch 48 
2023-03-18 18:05:46,232 - INFO - Test: [0/782]  Time 0.596 (0.596)      Loss 2.5073 (2.5073)    Acc@1 67.969 (67.969)   Acc@5 89.844 (89.844)     
2023-03-18 18:07:41,756 - INFO - Test: [200/782]        Time 0.570 (0.578)      Loss 2.9139 (2.9802)    Acc@1 62.500 (61.882)   Acc@5 82.031 (83.174)                              
2023-03-18 18:09:37,416 - INFO - Test: [400/782]        Time 0.591 (0.578)      Loss 2.8825 (2.9422)    Acc@1 61.719 (62.679)   Acc@5 85.156 (83.944)                              
2023-03-18 18:11:34,111 - INFO - Test: [600/782]        Time 0.574 (0.580)      Loss 2.9908 (2.9055)    Acc@1 60.938 (63.549)   Acc@5 80.469 (84.484)                              
2023-03-18 18:13:17,797 - INFO -  * Acc@1 64.159 Acc@5 84.979                   
2023-03-18 18:13:17,797 - INFO - Max accuracy: 66.2990%                         
2023-03-18 18:13:17,797 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d                             
2023-03-18 18:13:19,993 - INFO - Train: [49/90][0/3907] eta 2:22:44 lr 0.01790943       time 2.1920 (2.1920)    loss 4.3199 (4.3199)    acc@1: 52.3008  acc@5: 68.8379             
2023-03-18 18:14:14,443 - INFO - Train: [49/90][300/3907]       eta 0:11:18 lr 0.01790943       time 0.1830 (0.1882)    loss 5.4314 (3.7889)    acc@1: 34.2541  acc@5: 49.5633     
2023-03-18 18:15:09,639 - INFO - Train: [49/90][600/3907]       eta 0:10:15 lr 0.01790943       time 0.1806 (0.1861)    loss 2.4244 (3.7990)    acc@1: 76.5721  acc@5: 92.8147     
2023-03-18 18:16:04,531 - INFO - Train: [49/90][900/3907]       eta 0:09:16 lr 0.01790943       time 0.1800 (0.1850)    loss 3.1923 (3.7799)    acc@1: 67.0380  acc@5: 82.3280     
2023-03-18 18:16:59,220 - INFO - Train: [49/90][1200/3907]      eta 0:08:19 lr 0.01790943       time 0.1869 (0.1844)    loss 5.0098 (3.8002)    acc@1: 37.3086  acc@5: 56.2100     
2023-03-18 18:17:54,103 - INFO - Train: [49/90][1500/3907]      eta 0:07:23 lr 0.01790943       time 0.1806 (0.1841)    loss 2.8665 (3.8096)    acc@1: 71.1445  acc@5: 86.8711     
2023-03-18 18:18:48,823 - INFO - Train: [49/90][1800/3907]      eta 0:06:27 lr 0.01790943       time 0.1804 (0.1838)    loss 5.8224 (3.8161)    acc@1: 17.2800  acc@5: 36.8112     
2023-03-18 18:19:43,633 - INFO - Train: [49/90][2100/3907]      eta 0:05:31 lr 0.01790943       time 0.1803 (0.1836)    loss 2.8126 (3.8228)    acc@1: 70.2678  acc@5: 89.0151     
2023-03-18 18:20:38,345 - INFO - Train: [49/90][2400/3907]      eta 0:04:36 lr 0.01790943       time 0.1861 (0.1835)    loss 2.5324 (3.8183)    acc@1: 71.4705  acc@5: 90.9006     
2023-03-18 18:21:32,932 - INFO - Train: [49/90][2700/3907]      eta 0:03:41 lr 0.01790943       time 0.1815 (0.1833)    loss 4.2036 (3.8232)    acc@1: 53.9530  acc@5: 72.8040     
2023-03-18 18:22:27,944 - INFO - Train: [49/90][3000/3907]      eta 0:02:46 lr 0.01790943       time 0.1805 (0.1833)    loss 3.3189 (3.8263)    acc@1: 69.4576  acc@5: 82.8951     
2023-03-18 18:23:22,840 - INFO - Train: [49/90][3300/3907]      eta 0:01:51 lr 0.01790943       time 0.1808 (0.1833)    loss 5.3307 (3.8412)    acc@1: 34.4069  acc@5: 52.1475     
2023-03-18 18:24:17,576 - INFO - Train: [49/90][3600/3907]      eta 0:00:56 lr 0.01790943       time 0.1807 (0.1832)    loss 5.7284 (3.8524)    acc@1: 22.9685  acc@5: 42.1612     
2023-03-18 18:25:11,173 - INFO - Train: [49/90][3900/3907]      eta 0:00:01 lr 0.01790943       time 0.1757 (0.1829)    loss 2.6306 (3.8511)    acc@1: 69.8925  acc@5: 87.7527     
2023-03-18 18:25:12,369 - INFO - EPOCH 49 training takes 0:11:54                
2023-03-18 18:25:13,440 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Latest.pth saved !!! 
2023-03-18 18:25:13,441 - INFO - **********Latest test***********               
2023-03-18 18:25:13,441 - INFO - eval epoch 49 
2023-03-18 18:25:14,038 - INFO - Test: [0/782]  Time 0.596 (0.596)      Loss 2.5106 (2.5106)    Acc@1 69.531 (69.531)   Acc@5 92.969 (92.969)     
2023-03-18 18:27:09,832 - INFO - Test: [200/782]        Time 0.578 (0.579)      Loss 2.7283 (2.7960)    Acc@1 67.969 (65.345)   Acc@5 84.375 (85.743)                              
2023-03-18 18:29:05,274 - INFO - Test: [400/782]        Time 0.588 (0.578)      Loss 2.7502 (2.7618)    Acc@1 64.844 (66.245)   Acc@5 83.594 (86.364)                              
2023-03-18 18:31:01,959 - INFO - Test: [600/782]        Time 0.560 (0.580)      Loss 2.7538 (2.7280)    Acc@1 64.062 (67.039)   Acc@5 87.500 (86.798)                              
2023-03-18 18:32:45,706 - INFO -  * Acc@1 67.621 Acc@5 87.233                   
2023-03-18 18:32:45,706 - INFO - Max accuracy: 67.6210%                         
2023-03-18 18:32:46,650 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Best.pth saved !!!
2023-03-18 18:32:46,650 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d                             
2023-03-18 18:32:48,925 - INFO - Train: [50/90][0/3907] eta 2:27:51 lr 0.01721654       time 2.2708 (2.2708)    loss 3.7339 (3.7339)    acc@1: 63.6924  acc@5: 80.7645             
2023-03-18 18:33:43,346 - INFO - Train: [50/90][300/3907]       eta 0:11:19 lr 0.01721654       time 0.1865 (0.1883)    loss 5.6266 (3.6810)    acc@1: 25.2672  acc@5: 42.0473     
2023-03-18 18:34:35,478 - INFO - Train: [50/90][600/3907]       eta 0:09:58 lr 0.01721654       time 0.1776 (0.1811)    loss 4.5091 (3.7187)    acc@1: 44.2938  acc@5: 67.5339     
2023-03-18 18:35:27,679 - INFO - Train: [50/90][900/3907]       eta 0:08:57 lr 0.01721654       time 0.1719 (0.1787)    loss 5.2919 (3.7305)    acc@1: 38.5996  acc@5: 51.4866     
2023-03-18 18:36:19,757 - INFO - Train: [50/90][1200/3907]      eta 0:08:00 lr 0.01721654       time 0.1720 (0.1774)    loss 2.5302 (3.7583)    acc@1: 75.2194  acc@5: 89.9508     
2023-03-18 18:37:11,878 - INFO - Train: [50/90][1500/3907]      eta 0:07:05 lr 0.01721654       time 0.1744 (0.1767)    loss 2.9569 (3.7658)    acc@1: 68.4431  acc@5: 87.5777     
2023-03-18 18:38:04,094 - INFO - Train: [50/90][1800/3907]      eta 0:06:11 lr 0.01721654       time 0.1792 (0.1763)    loss 2.9163 (3.7734)    acc@1: 72.1644  acc@5: 84.5563     
2023-03-18 18:38:56,293 - INFO - Train: [50/90][2100/3907]      eta 0:05:17 lr 0.01721654       time 0.1793 (0.1759)    loss 3.6394 (3.7680)    acc@1: 62.5476  acc@5: 76.9597     
2023-03-18 18:39:48,324 - INFO - Train: [50/90][2400/3907]      eta 0:04:24 lr 0.01721654       time 0.1720 (0.1756)    loss 4.6131 (3.7722)    acc@1: 51.6141  acc@5: 63.7586     
2023-03-18 18:40:40,744 - INFO - Train: [50/90][2700/3907]      eta 0:03:31 lr 0.01721654       time 0.1736 (0.1755)    loss 4.2025 (3.7785)    acc@1: 52.3961  acc@5: 70.8694     
2023-03-18 18:41:33,282 - INFO - Train: [50/90][3000/3907]      eta 0:02:39 lr 0.01721654       time 0.1721 (0.1755)    loss 3.4808 (3.7783)    acc@1: 66.8004  acc@5: 80.0042     
2023-03-18 18:42:25,468 - INFO - Train: [50/90][3300/3907]      eta 0:01:46 lr 0.01721654       time 0.1727 (0.1753)    loss 3.4302 (3.7844)    acc@1: 67.0022  acc@5: 81.6406     
2023-03-18 18:43:17,662 - INFO - Train: [50/90][3600/3907]      eta 0:00:53 lr 0.01721654       time 0.1792 (0.1752)    loss 3.2062 (3.7820)    acc@1: 69.9453  acc@5: 82.1931     
2023-03-18 18:44:10,037 - INFO - Train: [50/90][3900/3907]      eta 0:00:01 lr 0.01721654       time 0.1714 (0.1752)    loss 2.3202 (3.7826)    acc@1: 79.1700  acc@5: 94.6935     
2023-03-18 18:44:11,196 - INFO - EPOCH 50 training takes 0:11:24                
2023-03-18 18:44:12,281 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Latest.pth saved !!! 
2023-03-18 18:44:12,282 - INFO - **********Latest test***********               
2023-03-18 18:44:12,282 - INFO - eval epoch 50 
2023-03-18 18:44:12,878 - INFO - Test: [0/782]  Time 0.595 (0.595)      Loss 2.4381 (2.4381)    Acc@1 74.219 (74.219)   Acc@5 95.312 (95.312)      