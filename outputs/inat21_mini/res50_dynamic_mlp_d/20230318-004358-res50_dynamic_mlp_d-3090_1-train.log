2023-03-18 00:44:02,815 - INFO - NVIDIA GeForce RTX 3090
2023-03-18 00:44:02,815 - INFO - --batch_size 128
2023-03-18 00:44:02,815 - INFO - --data inat21_mini
2023-03-18 00:44:02,815 - INFO - --data_dir ./datasets/iNat2021
2023-03-18 00:44:02,816 - INFO - --evaluate False
2023-03-18 00:44:02,816 - INFO - --fold 1
2023-03-18 00:44:02,816 - INFO - --image_only False
2023-03-18 00:44:02,816 - INFO - --metadata geo_temporal
2023-03-18 00:44:02,816 - INFO - --mlp_cin 6
2023-03-18 00:44:02,816 - INFO - --mlp_hidden 64
2023-03-18 00:44:02,816 - INFO - --mlp_num_layers 2
2023-03-18 00:44:02,816 - INFO - --mlp_out_channel 256
2023-03-18 00:44:02,816 - INFO - --mlp_type d
2023-03-18 00:44:02,816 - INFO - --model_file resnet_dynamic_mlp
2023-03-18 00:44:02,816 - INFO - --model_name resnet50
2023-03-18 00:44:02,816 - INFO - --name res50_dynamic_mlp_d
2023-03-18 00:44:02,816 - INFO - --num_classes 10000
2023-03-18 00:44:02,816 - INFO - --num_workers 8
2023-03-18 00:44:02,816 - INFO - --path_log ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-18 00:44:02,816 - INFO - --pretrained True
2023-03-18 00:44:02,816 - INFO - --random_seed 37
2023-03-18 00:44:02,816 - INFO - --resume Latest
2023-03-18 00:44:02,816 - INFO - --save_dir ./outputs
2023-03-18 00:44:02,816 - INFO - --start_lr 0.04
2023-03-18 00:44:02,816 - INFO - --stop_epoch 90
2023-03-18 00:44:02,816 - INFO - --tencrop False
2023-03-18 00:44:02,816 - INFO - --warmup 2
2023-03-18 00:44:02,816 - INFO - Creating model:resnet_dynamic_mlp -> resnet50
2023-03-18 00:44:02,816 - INFO - type: d, cin: 6, d: 256, h: 64, N: 2
2023-03-18 00:44:07,476 - INFO - => no checkpoint found at './outputs/inat21_mini/res50_dynamic_mlp_d/fold1_latest.pth'
2023-03-18 00:44:07,476 - INFO - Start training
2023-03-18 00:44:12,250 - INFO - Train: [1/90][0/3907]	eta 5:10:45 lr 0.00000000	time 4.7722 (4.7722)	loss 9.3808 (9.3808)	acc@1: 0.0000	acc@5: 0.0000	
2023-03-18 00:45:06,019 - INFO - Train: [1/90][300/3907]	eta 0:11:41 lr 0.00153571	time 0.1854 (0.1945)	loss 9.2976 (9.3829)	acc@1: 0.0000	acc@5: 0.0000	
2023-03-18 00:45:59,978 - INFO - Train: [1/90][600/3907]	eta 0:10:19 lr 0.00307141	time 0.1822 (0.1872)	loss 9.2891 (9.3471)	acc@1: 0.0000	acc@5: 0.0000	
2023-03-18 00:46:54,260 - INFO - Train: [1/90][900/3907]	eta 0:09:16 lr 0.00460712	time 0.1797 (0.1851)	loss 8.9838 (9.2866)	acc@1: 0.0000	acc@5: 0.6354	
2023-03-18 00:47:48,567 - INFO - Train: [1/90][1200/3907]	eta 0:08:18 lr 0.00614282	time 0.1799 (0.1841)	loss 8.2938 (9.1401)	acc@1: 0.0000	acc@5: 0.7160	
2023-03-18 00:48:42,686 - INFO - Train: [1/90][1500/3907]	eta 0:07:21 lr 0.00767853	time 0.1799 (0.1833)	loss 7.8030 (8.9609)	acc@1: 0.7409	acc@5: 5.1863	
2023-03-18 00:49:36,791 - INFO - Train: [1/90][1800/3907]	eta 0:06:25 lr 0.00921423	time 0.1883 (0.1828)	loss 7.2123 (8.7764)	acc@1: 3.0078	acc@5: 9.8047	
2023-03-18 00:50:31,123 - INFO - Train: [1/90][2100/3907]	eta 0:05:29 lr 0.01074994	time 0.1819 (0.1826)	loss 8.1834 (8.5951)	acc@1: 0.9531	acc@5: 3.6405	
2023-03-18 00:51:25,472 - INFO - Train: [1/90][2400/3907]	eta 0:04:34 lr 0.01228564	time 0.1800 (0.1824)	loss 7.6277 (8.4327)	acc@1: 1.2664	acc@5: 5.6988	
2023-03-18 00:52:19,838 - INFO - Train: [1/90][2700/3907]	eta 0:03:40 lr 0.01382135	time 0.1796 (0.1823)	loss 6.6640 (8.2898)	acc@1: 5.8529	acc@5: 14.6324	
2023-03-18 00:53:14,557 - INFO - Train: [1/90][3000/3907]	eta 0:02:45 lr 0.01535705	time 0.1797 (0.1823)	loss 6.5949 (8.1529)	acc@1: 6.8636	acc@5: 20.5907	
2023-03-18 00:54:09,199 - INFO - Train: [1/90][3300/3907]	eta 0:01:50 lr 0.01689276	time 0.1797 (0.1823)	loss 5.9781 (8.0319)	acc@1: 6.2481	acc@5: 22.6493	
2023-03-18 00:55:03,751 - INFO - Train: [1/90][3600/3907]	eta 0:00:55 lr 0.01842846	time 0.1793 (0.1822)	loss 7.4711 (7.9228)	acc@1: 7.5908	acc@5: 14.8785	
2023-03-18 00:55:58,582 - INFO - Train: [1/90][3900/3907]	eta 0:00:01 lr 0.01996417	time 0.1855 (0.1823)	loss 7.2930 (7.8205)	acc@1: 9.7691	acc@5: 15.3865	
2023-03-18 00:56:00,426 - INFO - EPOCH 1 training takes 0:11:52
2023-03-18 00:56:01,335 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/fold1_latest.pth saved !!!
2023-03-18 00:56:01,335 - INFO - **********Latest test***********
2023-03-18 00:56:01,335 - INFO - eval epoch 1
2023-03-18 00:56:02,433 - INFO - Test: [0/782]	Time 1.096 (1.096)	Loss 4.8879 (4.8879)	Acc@1 19.531 (19.531)	Acc@5 43.750 (43.750)
2023-03-18 00:58:05,070 - INFO - Test: [200/782]	Time 0.621 (0.616)	Loss 5.3085 (5.4813)	Acc@1 9.375 (13.071)	Acc@5 39.844 (32.533)
2023-03-18 01:00:04,832 - INFO - Test: [400/782]	Time 0.613 (0.607)	Loss 5.4711 (5.4656)	Acc@1 10.938 (13.266)	Acc@5 27.344 (32.955)
2023-03-18 01:02:06,297 - INFO - Test: [600/782]	Time 0.585 (0.607)	Loss 5.5524 (5.4652)	Acc@1 15.625 (13.286)	Acc@5 32.031 (32.901)
2023-03-18 01:03:54,069 - INFO -  * Acc@1 13.697 Acc@5 33.814
2023-03-18 01:03:54,070 - INFO - Max accuracy: 13.6970%
2023-03-18 01:03:54,962 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/fold1_best.pth saved !!!
2023-03-18 01:03:54,962 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-18 01:03:57,936 - INFO - Train: [2/90][0/3907]	eta 3:13:22 lr 0.02000000	time 2.9696 (2.9696)	loss 6.7711 (6.7711)	acc@1: 9.4590	acc@5: 21.5587	
2023-03-18 01:04:52,643 - INFO - Train: [2/90][300/3907]	eta 0:11:31 lr 0.02153571	time 0.1788 (0.1916)	loss 7.9186 (6.3410)	acc@1: 3.4475	acc@5: 9.0899	
2023-03-18 01:05:47,263 - INFO - Train: [2/90][600/3907]	eta 0:10:17 lr 0.02307141	time 0.1833 (0.1868)	loss 7.8213 (6.3303)	acc@1: 3.5587	acc@5: 10.6760	
2023-03-18 01:06:41,845 - INFO - Train: [2/90][900/3907]	eta 0:09:16 lr 0.02460712	time 0.1874 (0.1852)	loss 6.4491 (6.2914)	acc@1: 11.6459	acc@5: 26.9843	
2023-03-18 01:07:36,066 - INFO - Train: [2/90][1200/3907]	eta 0:08:18 lr 0.02614282	time 0.1931 (0.1841)	loss 5.1637 (6.2365)	acc@1: 23.1430	acc@5: 45.5047	
2023-03-18 01:08:30,289 - INFO - Train: [2/90][1500/3907]	eta 0:07:21 lr 0.02767853	time 0.1794 (0.1834)	loss 4.9438 (6.2247)	acc@1: 19.8262	acc@5: 49.5654	
2023-03-18 01:09:24,532 - INFO - Train: [2/90][1800/3907]	eta 0:06:25 lr 0.02921423	time 0.1879 (0.1830)	loss 4.9862 (6.1759)	acc@1: 19.4249	acc@5: 41.9579	
2023-03-18 01:10:18,933 - INFO - Train: [2/90][2100/3907]	eta 0:05:30 lr 0.03074994	time 0.1813 (0.1827)	loss 5.8175 (6.1487)	acc@1: 15.0798	acc@5: 39.1661	
2023-03-18 01:11:13,299 - INFO - Train: [2/90][2400/3907]	eta 0:04:35 lr 0.03228564	time 0.1790 (0.1826)	loss 5.6083 (6.1206)	acc@1: 16.4025	acc@5: 40.5443	
2023-03-18 01:12:07,398 - INFO - Train: [2/90][2700/3907]	eta 0:03:40 lr 0.03382135	time 0.1795 (0.1823)	loss 7.3953 (6.0879)	acc@1: 3.9688	acc@5: 15.1609	
2023-03-18 01:13:01,566 - INFO - Train: [2/90][3000/3907]	eta 0:02:45 lr 0.03535705	time 0.1788 (0.1821)	loss 5.7247 (6.0691)	acc@1: 21.6492	acc@5: 43.2983	
2023-03-18 01:13:55,907 - INFO - Train: [2/90][3300/3907]	eta 0:01:50 lr 0.03689276	time 0.1796 (0.1820)	loss 6.0008 (6.0453)	acc@1: 16.4691	acc@5: 37.5495	
2023-03-18 01:14:50,307 - INFO - Train: [2/90][3600/3907]	eta 0:00:55 lr 0.03842846	time 0.1844 (0.1820)	loss 5.6848 (6.0263)	acc@1: 19.4163	acc@5: 41.6224	
2023-03-18 01:15:44,648 - INFO - Train: [2/90][3900/3907]	eta 0:00:01 lr 0.03996417	time 0.1784 (0.1819)	loss 5.9658 (6.0031)	acc@1: 19.3872	acc@5: 33.4262	
2023-03-18 01:15:45,917 - INFO - EPOCH 2 training takes 0:11:50
2023-03-18 01:15:47,001 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/fold1_latest.pth saved !!!
2023-03-18 01:15:47,001 - INFO - **********Latest test***********
2023-03-18 01:15:47,001 - INFO - eval epoch 2
2023-03-18 01:15:47,620 - INFO - Test: [0/782]	Time 0.616 (0.616)	Loss 3.9347 (3.9347)	Acc@1 37.500 (37.500)	Acc@5 65.625 (65.625)
2023-03-18 01:17:46,709 - INFO - Test: [200/782]	Time 0.590 (0.596)	Loss 4.3613 (4.5074)	Acc@1 30.469 (27.453)	Acc@5 56.250 (54.373)
2023-03-18 01:19:44,622 - INFO - Test: [400/782]	Time 0.608 (0.593)	Loss 4.2292 (4.4704)	Acc@1 32.812 (28.033)	Acc@5 56.250 (55.249)
2023-03-18 01:21:45,010 - INFO - Test: [600/782]	Time 0.599 (0.596)	Loss 4.5700 (4.4479)	Acc@1 25.000 (28.468)	Acc@5 53.906 (55.718)
2023-03-18 01:23:33,336 - INFO -  * Acc@1 28.888 Acc@5 56.443
2023-03-18 01:23:33,336 - INFO - Max accuracy: 28.8880%
2023-03-18 01:23:34,389 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/fold1_best.pth saved !!!
2023-03-18 01:23:34,391 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-18 01:23:37,189 - INFO - Train: [3/90][0/3907]	eta 3:01:35 lr 0.03995128	time 2.7887 (2.7887)	loss 5.0109 (5.0109)	acc@1: 31.6562	acc@5: 53.2400	
2023-03-18 01:24:31,406 - INFO - Train: [3/90][300/3907]	eta 0:11:23 lr 0.03995128	time 0.1782 (0.1894)	loss 5.2937 (5.5229)	acc@1: 24.8821	acc@5: 46.9909	
2023-03-18 01:25:25,547 - INFO - Train: [3/90][600/3907]	eta 0:10:11 lr 0.03995128	time 0.1824 (0.1849)	loss 5.0092 (5.4922)	acc@1: 22.7489	acc@5: 48.4331	
2023-03-18 01:26:19,619 - INFO - Train: [3/90][900/3907]	eta 0:09:11 lr 0.03995128	time 0.1788 (0.1834)	loss 4.8295 (5.5045)	acc@1: 29.3300	acc@5: 50.3874	
2023-03-18 01:27:13,763 - INFO - Train: [3/90][1200/3907]	eta 0:08:14 lr 0.03995128	time 0.1781 (0.1826)	loss 5.4105 (5.5167)	acc@1: 25.7220	acc@5: 48.0595	
2023-03-18 01:28:07,963 - INFO - Train: [3/90][1500/3907]	eta 0:07:18 lr 0.03995128	time 0.1856 (0.1822)	loss 4.3971 (5.5098)	acc@1: 33.3286	acc@5: 58.9015	
2023-03-18 01:29:02,056 - INFO - Train: [3/90][1800/3907]	eta 0:06:23 lr 0.03995128	time 0.1786 (0.1819)	loss 4.4918 (5.4911)	acc@1: 29.4488	acc@5: 52.7042	
2023-03-18 01:29:56,172 - INFO - Train: [3/90][2100/3907]	eta 0:05:28 lr 0.03995128	time 0.1783 (0.1817)	loss 4.8635 (5.4768)	acc@1: 26.4725	acc@5: 50.1488	
2023-03-18 01:30:50,280 - INFO - Train: [3/90][2400/3907]	eta 0:04:33 lr 0.03995128	time 0.1788 (0.1815)	loss 6.3906 (5.4772)	acc@1: 14.9889	acc@5: 33.2057	
2023-03-18 01:31:44,188 - INFO - Train: [3/90][2700/3907]	eta 0:03:38 lr 0.03995128	time 0.1790 (0.1813)	loss 4.5360 (5.4776)	acc@1: 33.7137	acc@5: 56.1895	
2023-03-18 01:32:38,235 - INFO - Train: [3/90][3000/3907]	eta 0:02:44 lr 0.03995128	time 0.1775 (0.1812)	loss 6.2918 (5.4555)	acc@1: 25.8499	acc@5: 40.4178	
2023-03-18 01:33:32,475 - INFO - Train: [3/90][3300/3907]	eta 0:01:49 lr 0.03995128	time 0.1787 (0.1812)	loss 4.8493 (5.4334)	acc@1: 34.3099	acc@5: 56.4684	
2023-03-18 01:34:26,703 - INFO - Train: [3/90][3600/3907]	eta 0:00:55 lr 0.03995128	time 0.1787 (0.1811)	loss 3.9595 (5.4217)	acc@1: 35.7710	acc@5: 69.2056	
2023-03-18 01:35:21,028 - INFO - Train: [3/90][3900/3907]	eta 0:00:01 lr 0.03995128	time 0.1779 (0.1811)	loss 4.6811 (5.4166)	acc@1: 33.3417	acc@5: 54.8286	
2023-03-18 01:35:22,303 - INFO - EPOCH 3 training takes 0:11:47
2023-03-18 01:35:23,407 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/fold1_latest.pth saved !!!
2023-03-18 01:35:23,407 - INFO - **********Latest test***********
2023-03-18 01:35:23,407 - INFO - eval epoch 3
2023-03-18 01:35:24,001 - INFO - Test: [0/782]	Time 0.590 (0.590)	Loss 3.4694 (3.4694)	Acc@1 43.750 (43.750)	Acc@5 75.781 (75.781)
2023-03-18 01:37:24,073 - INFO - Test: [200/782]	Time 0.574 (0.600)	Loss 3.6047 (3.9763)	Acc@1 53.906 (37.792)	Acc@5 71.094 (65.571)
2023-03-18 01:39:23,240 - INFO - Test: [400/782]	Time 0.595 (0.598)	Loss 3.7378 (3.9425)	Acc@1 41.406 (38.686)	Acc@5 68.750 (66.130)
2023-03-18 01:41:24,271 - INFO - Test: [600/782]	Time 0.598 (0.600)	Loss 4.1666 (3.9154)	Acc@1 32.031 (39.290)	Acc@5 61.719 (66.616)
2023-03-18 01:43:11,356 - INFO -  * Acc@1 39.838 Acc@5 67.274
2023-03-18 01:43:11,357 - INFO - Max accuracy: 39.8380%
2023-03-18 01:43:12,430 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/fold1_best.pth saved !!!
2023-03-18 01:43:12,431 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-18 01:43:14,588 - INFO - Train: [4/90][0/3907]	eta 2:19:47 lr 0.03989044	time 2.1468 (2.1468)	loss 3.9585 (3.9585)	acc@1: 40.5906	acc@5: 64.7885	
2023-03-18 01:44:09,101 - INFO - Train: [4/90][300/3907]	eta 0:11:18 lr 0.03989044	time 0.1882 (0.1882)	loss 4.4253 (5.0507)	acc@1: 35.8910	acc@5: 56.8075	
2023-03-18 01:45:04,158 - INFO - Train: [4/90][600/3907]	eta 0:10:14 lr 0.03989044	time 0.1797 (0.1859)	loss 6.9577 (5.1375)	acc@1: 9.6542	acc@5: 19.2228	
2023-03-18 01:45:59,127 - INFO - Train: [4/90][900/3907]	eta 0:09:16 lr 0.03989044	time 0.1797 (0.1850)	loss 7.1025 (5.1219)	acc@1: 8.7715	acc@5: 18.0619	
2023-03-18 01:46:53,515 - INFO - Train: [4/90][1200/3907]	eta 0:08:18 lr 0.03989044	time 0.1798 (0.1841)	loss 4.7123 (5.1132)	acc@1: 40.5501	acc@5: 61.1689	
2023-03-18 01:47:47,953 - INFO - Train: [4/90][1500/3907]	eta 0:07:21 lr 0.03989044	time 0.1796 (0.1835)	loss 6.7521 (5.0904)	acc@1: 12.6080	acc@5: 26.5823	
2023-03-18 01:48:42,266 - INFO - Train: [4/90][1800/3907]	eta 0:06:25 lr 0.03989044	time 0.1800 (0.1831)	loss 3.5806 (5.1094)	acc@1: 47.5660	acc@5: 71.7388	
2023-03-18 01:49:36,375 - INFO - Train: [4/90][2100/3907]	eta 0:05:30 lr 0.03989044	time 0.1794 (0.1827)	loss 5.5463 (5.1020)	acc@1: 29.3339	acc@5: 50.5542	
2023-03-18 01:50:30,705 - INFO - Train: [4/90][2400/3907]	eta 0:04:35 lr 0.03989044	time 0.1805 (0.1825)	loss 5.1693 (5.1049)	acc@1: 29.6315	acc@5: 52.5285	
2023-03-18 01:51:24,816 - INFO - Train: [4/90][2700/3907]	eta 0:03:40 lr 0.03989044	time 0.1796 (0.1823)	loss 4.2043 (5.1075)	acc@1: 32.9811	acc@5: 62.1273	
2023-03-18 01:52:19,192 - INFO - Train: [4/90][3000/3907]	eta 0:02:45 lr 0.03989044	time 0.1802 (0.1822)	loss 3.6985 (5.1094)	acc@1: 44.5233	acc@5: 70.3000	
2023-03-18 01:53:13,678 - INFO - Train: [4/90][3300/3907]	eta 0:01:50 lr 0.03989044	time 0.1807 (0.1821)	loss 6.7310 (5.1073)	acc@1: 11.6487	acc@5: 23.3687	
2023-03-18 01:54:07,982 - INFO - Train: [4/90][3600/3907]	eta 0:00:55 lr 0.03989044	time 0.1803 (0.1820)	loss 4.9437 (5.0979)	acc@1: 34.4392	acc@5: 59.9242	
2023-03-18 01:55:02,267 - INFO - Train: [4/90][3900/3907]	eta 0:00:01 lr 0.03989044	time 0.1787 (0.1820)	loss 6.7625 (5.0936)	acc@1: 15.6980	acc@5: 28.3247	
2023-03-18 01:55:03,453 - INFO - EPOCH 4 training takes 0:11:51
2023-03-18 01:55:04,542 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/fold1_latest.pth saved !!!
2023-03-18 01:55:04,542 - INFO - **********Latest test***********
2023-03-18 01:55:04,543 - INFO - eval epoch 4
2023-03-18 01:55:05,147 - INFO - Test: [0/782]	Time 0.603 (0.603)	Loss 3.3467 (3.3467)	Acc@1 48.438 (48.438)	Acc@5 78.125 (78.125)
2023-03-18 01:57:05,518 - INFO - Test: [200/782]	Time 0.571 (0.602)	Loss 3.5268 (3.8278)	Acc@1 50.000 (41.927)	Acc@5 74.219 (68.474)
2023-03-18 01:59:04,845 - INFO - Test: [400/782]	Time 0.607 (0.599)	Loss 3.6238 (3.7837)	Acc@1 45.312 (42.809)	Acc@5 75.000 (69.457)
2023-03-18 02:01:05,896 - INFO - Test: [600/782]	Time 0.592 (0.601)	Loss 3.9769 (3.7534)	Acc@1 40.625 (43.577)	Acc@5 62.500 (70.162)
2023-03-18 02:02:52,669 - INFO -  * Acc@1 44.034 Acc@5 70.702
2023-03-18 02:02:52,670 - INFO - Max accuracy: 44.0340%
2023-03-18 02:02:53,687 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/fold1_best.pth saved !!!
2023-03-18 02:02:53,687 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-18 02:02:56,472 - INFO - Train: [5/90][0/3907]	eta 3:00:38 lr 0.03980536	time 2.7741 (2.7741)	loss 3.5938 (3.5938)	acc@1: 42.1609	acc@5: 74.1712	
2023-03-18 02:03:50,486 - INFO - Train: [5/90][300/3907]	eta 0:11:20 lr 0.03980536	time 0.1797 (0.1887)	loss 4.6117 (4.8182)	acc@1: 41.4278	acc@5: 61.7906	
2023-03-18 02:04:44,727 - INFO - Train: [5/90][600/3907]	eta 0:10:10 lr 0.03980536	time 0.1801 (0.1847)	loss 5.4300 (4.8778)	acc@1: 32.0583	acc@5: 49.8116	
2023-03-18 02:05:39,007 - INFO - Train: [5/90][900/3907]	eta 0:09:11 lr 0.03980536	time 0.1790 (0.1835)	loss 3.6975 (4.8688)	acc@1: 44.5635	acc@5: 70.6792	
2023-03-18 02:06:33,300 - INFO - Train: [5/90][1200/3907]	eta 0:08:14 lr 0.03980536	time 0.1794 (0.1828)	loss 3.6494 (4.8979)	acc@1: 49.1000	acc@5: 70.9223	
2023-03-18 02:07:27,805 - INFO - Train: [5/90][1500/3907]	eta 0:07:19 lr 0.03980536	time 0.1796 (0.1826)	loss 6.8973 (4.9007)	acc@1: 10.7528	acc@5: 21.3789	
2023-03-18 02:08:22,149 - INFO - Train: [5/90][1800/3907]	eta 0:06:24 lr 0.03980536	time 0.1796 (0.1824)	loss 4.9985 (4.8978)	acc@1: 35.9458	acc@5: 55.2411	
2023-03-18 02:09:16,562 - INFO - Train: [5/90][2100/3907]	eta 0:05:29 lr 0.03980536	time 0.1846 (0.1822)	loss 6.6159 (4.9049)	acc@1: 13.9852	acc@5: 24.8283	
2023-03-18 02:10:11,039 - INFO - Train: [5/90][2400/3907]	eta 0:04:34 lr 0.03980536	time 0.2004 (0.1821)	loss 4.0247 (4.9169)	acc@1: 36.7416	acc@5: 65.0633	
2023-03-18 02:11:05,772 - INFO - Train: [5/90][2700/3907]	eta 0:03:39 lr 0.03980536	time 0.1907 (0.1822)	loss 3.8680 (4.9143)	acc@1: 41.4513	acc@5: 72.1559	
2023-03-18 02:12:00,452 - INFO - Train: [5/90][3000/3907]	eta 0:02:45 lr 0.03980536	time 0.1851 (0.1822)	loss 4.0839 (4.9125)	acc@1: 43.2492	acc@5: 68.1442	
2023-03-18 02:12:54,839 - INFO - Train: [5/90][3300/3907]	eta 0:01:50 lr 0.03980536	time 0.1803 (0.1821)	loss 3.6438 (4.9266)	acc@1: 39.8395	acc@5: 74.2106	
2023-03-18 02:13:49,114 - INFO - Train: [5/90][3600/3907]	eta 0:00:55 lr 0.03980536	time 0.1818 (0.1820)	loss 4.1866 (4.9206)	acc@1: 38.8625	acc@5: 65.8012	
2023-03-18 02:14:43,876 - INFO - Train: [5/90][3900/3907]	eta 0:00:01 lr 0.03980536	time 0.1809 (0.1820)	loss 4.1938 (4.9205)	acc@1: 48.7668	acc@5: 67.9780	
2023-03-18 02:14:45,120 - INFO - EPOCH 5 training takes 0:11:51
2023-03-18 02:14:46,211 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/fold1_latest.pth saved !!!
2023-03-18 02:14:46,211 - INFO - **********Latest test***********
2023-03-18 02:14:46,211 - INFO - eval epoch 5
2023-03-18 02:14:46,876 - INFO - Test: [0/782]	Time 0.664 (0.664)	Loss 3.1495 (3.1495)	Acc@1 55.469 (55.469)	Acc@5 82.031 (82.031)
2023-03-18 02:16:47,033 - INFO - Test: [200/782]	Time 0.604 (0.601)	Loss 3.4418 (3.5746)	Acc@1 46.094 (46.786)	Acc@5 76.562 (72.711)
2023-03-18 02:18:46,857 - INFO - Test: [400/782]	Time 0.595 (0.600)	Loss 3.3179 (3.5390)	Acc@1 55.469 (47.539)	Acc@5 75.000 (73.278)
2023-03-18 02:20:47,265 - INFO - Test: [600/782]	Time 0.591 (0.601)	Loss 3.5841 (3.5066)	Acc@1 46.094 (48.122)	Acc@5 71.094 (73.965)
2023-03-18 02:22:33,914 - INFO -  * Acc@1 48.481 Acc@5 74.540
2023-03-18 02:22:33,914 - INFO - Max accuracy: 48.4810%
2023-03-18 02:22:34,958 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/fold1_best.pth saved !!!
2023-03-18 02:22:34,959 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-18 02:22:37,923 - INFO - Train: [6/90][0/3907]	eta 3:12:26 lr 0.03969616	time 2.9554 (2.9554)	loss 4.1027 (4.1027)	acc@1: 46.0341	acc@5: 66.1740	
2023-03-18 02:23:32,140 - INFO - Train: [6/90][300/3907]	eta 0:11:25 lr 0.03969616	time 0.1779 (0.1899)	loss 3.5309 (4.7499)	acc@1: 47.9963	acc@5: 75.0869	
2023-03-18 02:24:26,258 - INFO - Train: [6/90][600/3907]	eta 0:10:12 lr 0.03969616	time 0.1819 (0.1852)	loss 4.8127 (4.7909)	acc@1: 37.6914	acc@5: 59.5127	
2023-03-18 02:25:20,530 - INFO - Train: [6/90][900/3907]	eta 0:09:12 lr 0.03969616	time 0.1785 (0.1837)	loss 6.7823 (4.8015)	acc@1: 12.5916	acc@5: 22.9312	
2023-03-18 02:26:14,843 - INFO - Train: [6/90][1200/3907]	eta 0:08:15 lr 0.03969616	time 0.1790 (0.1831)	loss 4.5256 (4.7936)	acc@1: 40.6699	acc@5: 66.8641	
2023-03-18 02:27:08,921 - INFO - Train: [6/90][1500/3907]	eta 0:07:19 lr 0.03969616	time 0.1786 (0.1825)	loss 3.6612 (4.7863)	acc@1: 42.7721	acc@5: 72.3237	
2023-03-18 02:28:03,093 - INFO - Train: [6/90][1800/3907]	eta 0:06:23 lr 0.03969616	time 0.1798 (0.1822)	loss 4.5339 (4.7981)	acc@1: 48.0371	acc@5: 65.0869	
2023-03-18 02:28:57,589 - INFO - Train: [6/90][2100/3907]	eta 0:05:29 lr 0.03969616	time 0.1785 (0.1821)	loss 4.4010 (4.8035)	acc@1: 40.7028	acc@5: 62.8394	
2023-03-18 02:29:51,684 - INFO - Train: [6/90][2400/3907]	eta 0:04:34 lr 0.03969616	time 0.1904 (0.1819)	loss 5.0734 (4.8169)	acc@1: 34.9229	acc@5: 57.3263	
2023-03-18 02:30:45,930 - INFO - Train: [6/90][2700/3907]	eta 0:03:39 lr 0.03969616	time 0.1788 (0.1818)	loss 4.5212 (4.8096)	acc@1: 41.3669	acc@5: 63.1822	
2023-03-18 02:31:40,115 - INFO - Train: [6/90][3000/3907]	eta 0:02:44 lr 0.03969616	time 0.1797 (0.1817)	loss 5.2118 (4.8114)	acc@1: 37.9758	acc@5: 54.8747	
2023-03-18 02:32:34,218 - INFO - Train: [6/90][3300/3907]	eta 0:01:50 lr 0.03969616	time 0.1786 (0.1815)	loss 4.9944 (4.8107)	acc@1: 35.1120	acc@5: 58.3403	
2023-03-18 02:33:28,341 - INFO - Train: [6/90][3600/3907]	eta 0:00:55 lr 0.03969616	time 0.1818 (0.1814)	loss 6.5990 (4.8088)	acc@1: 12.4381	acc@5: 23.2098	
2023-03-18 02:34:22,528 - INFO - Train: [6/90][3900/3907]	eta 0:00:01 lr 0.03969616	time 0.1780 (0.1814)	loss 6.1902 (4.8163)	acc@1: 22.8579	acc@5: 32.0546	
2023-03-18 02:34:23,815 - INFO - EPOCH 6 training takes 0:11:48
2023-03-18 02:34:24,787 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/fold1_latest.pth saved !!!
2023-03-18 02:34:24,788 - INFO - **********Latest test***********
2023-03-18 02:34:24,788 - INFO - eval epoch 6
2023-03-18 02:34:25,430 - INFO - Test: [0/782]	Time 0.641 (0.641)	Loss 3.1197 (3.1197)	Acc@1 56.250 (56.250)	Acc@5 83.594 (83.594)
2023-03-18 02:36:23,667 - INFO - Test: [200/782]	Time 0.602 (0.591)	Loss 3.3382 (3.5470)	Acc@1 50.781 (47.921)	Acc@5 76.562 (73.449)
2023-03-18 02:38:23,110 - INFO - Test: [400/782]	Time 0.598 (0.594)	Loss 3.2779 (3.5084)	Acc@1 57.812 (48.545)	Acc@5 78.125 (74.380)
2023-03-18 02:40:23,218 - INFO - Test: [600/782]	Time 0.582 (0.596)	Loss 3.5508 (3.4748)	Acc@1 48.438 (49.262)	Acc@5 74.219 (75.009)
2023-03-18 02:42:09,184 - INFO -  * Acc@1 49.818 Acc@5 75.580
2023-03-18 02:42:09,184 - INFO - Max accuracy: 49.8180%
2023-03-18 02:42:10,248 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/fold1_best.pth saved !!!
2023-03-18 02:42:10,248 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-18 02:42:12,926 - INFO - Train: [7/90][0/3907]	eta 2:54:07 lr 0.03956295	time 2.6740 (2.6740)	loss 5.8070 (5.8070)	acc@1: 29.8028	acc@5: 45.7904	
2023-03-18 02:43:06,899 - INFO - Train: [7/90][300/3907]	eta 0:11:18 lr 0.03956295	time 0.1788 (0.1882)	loss 3.3083 (4.4915)	acc@1: 61.9527	acc@5: 78.2153	
2023-03-18 02:44:00,993 - INFO - Train: [7/90][600/3907]	eta 0:10:09 lr 0.03956295	time 0.1790 (0.1843)	loss 6.3591 (4.5942)	acc@1: 17.8753	acc@5: 33.7938	
2023-03-18 02:44:55,094 - INFO - Train: [7/90][900/3907]	eta 0:09:10 lr 0.03956295	time 0.1786 (0.1829)	loss 3.3982 (4.6167)	acc@1: 46.8075	acc@5: 77.2340	
2023-03-18 02:45:49,188 - INFO - Train: [7/90][1200/3907]	eta 0:08:13 lr 0.03956295	time 0.1796 (0.1823)	loss 3.4662 (4.6605)	acc@1: 50.7752	acc@5: 74.2099	
2023-03-18 02:46:43,408 - INFO - Train: [7/90][1500/3907]	eta 0:07:18 lr 0.03956295	time 0.1793 (0.1820)	loss 4.2613 (4.6848)	acc@1: 46.7335	acc@5: 66.2284	
2023-03-18 02:47:37,707 - INFO - Train: [7/90][1800/3907]	eta 0:06:23 lr 0.03956295	time 0.1793 (0.1818)	loss 5.8023 (4.7061)	acc@1: 29.9110	acc@5: 42.6869	
2023-03-18 02:48:31,974 - INFO - Train: [7/90][2100/3907]	eta 0:05:28 lr 0.03956295	time 0.1790 (0.1817)	loss 5.7544 (4.7319)	acc@1: 29.9129	acc@5: 44.3257	
2023-03-18 02:49:26,183 - INFO - Train: [7/90][2400/3907]	eta 0:04:33 lr 0.03956295	time 0.1813 (0.1816)	loss 3.8293 (4.7274)	acc@1: 38.9884	acc@5: 69.3970	
2023-03-18 02:50:20,410 - INFO - Train: [7/90][2700/3907]	eta 0:03:39 lr 0.03956295	time 0.1785 (0.1815)	loss 3.8317 (4.7278)	acc@1: 48.6428	acc@5: 68.4040	
2023-03-18 02:51:14,746 - INFO - Train: [7/90][3000/3907]	eta 0:02:44 lr 0.03956295	time 0.1787 (0.1814)	loss 3.7415 (4.7313)	acc@1: 51.5179	acc@5: 71.3891	
2023-03-18 02:52:08,892 - INFO - Train: [7/90][3300/3907]	eta 0:01:50 lr 0.03956295	time 0.1783 (0.1813)	loss 3.4035 (4.7258)	acc@1: 52.2691	acc@5: 78.0130	
2023-03-18 02:53:03,258 - INFO - Train: [7/90][3600/3907]	eta 0:00:55 lr 0.03956295	time 0.1788 (0.1813)	loss 3.3839 (4.7293)	acc@1: 52.5341	acc@5: 78.8012	
2023-03-18 02:53:57,466 - INFO - Train: [7/90][3900/3907]	eta 0:00:01 lr 0.03956295	time 0.1785 (0.1813)	loss 4.6887 (4.7291)	acc@1: 41.2329	acc@5: 61.7521	
2023-03-18 02:53:58,760 - INFO - EPOCH 7 training takes 0:11:48
2023-03-18 02:53:59,827 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/fold1_latest.pth saved !!!
2023-03-18 02:53:59,827 - INFO - **********Latest test***********
2023-03-18 02:53:59,827 - INFO - eval epoch 7
2023-03-18 02:54:00,450 - INFO - Test: [0/782]	Time 0.620 (0.620)	Loss 3.0167 (3.0167)	Acc@1 54.688 (54.688)	Acc@5 89.844 (89.844)
2023-03-18 02:55:59,583 - INFO - Test: [200/782]	Time 0.621 (0.596)	Loss 3.0889 (3.4356)	Acc@1 58.594 (50.148)	Acc@5 79.688 (75.556)
2023-03-18 02:57:59,156 - INFO - Test: [400/782]	Time 0.596 (0.597)	Loss 3.1892 (3.4031)	Acc@1 50.781 (50.772)	Acc@5 78.906 (76.103)
2023-03-18 02:59:59,722 - INFO - Test: [600/782]	Time 0.611 (0.599)	Loss 3.3955 (3.3700)	Acc@1 52.344 (51.581)	Acc@5 75.781 (76.785)
2023-03-18 03:01:45,727 - INFO -  * Acc@1 52.058 Acc@5 77.461
2023-03-18 03:01:45,727 - INFO - Max accuracy: 52.0580%
2023-03-18 03:01:46,650 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/fold1_best.pth saved !!!
2023-03-18 03:01:46,650 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-18 03:01:49,170 - INFO - Train: [8/90][0/3907]	eta 2:43:45 lr 0.03940591	time 2.5147 (2.5147)	loss 4.9549 (4.9549)	acc@1: 40.7068	acc@5: 56.1171	
2023-03-18 03:02:43,116 - INFO - Train: [8/90][300/3907]	eta 0:11:16 lr 0.03940591	time 0.1782 (0.1876)	loss 6.0901 (4.6043)	acc@1: 24.5537	acc@5: 39.3571	
2023-03-18 03:03:37,310 - INFO - Train: [8/90][600/3907]	eta 0:10:08 lr 0.03940591	time 0.1794 (0.1841)	loss 3.1122 (4.6086)	acc@1: 60.3295	acc@5: 85.8536	
2023-03-18 03:04:31,510 - INFO - Train: [8/90][900/3907]	eta 0:09:10 lr 0.03940591	time 0.1852 (0.1830)	loss 3.9447 (4.5960)	acc@1: 46.5981	acc@5: 73.5377	
2023-03-18 03:05:25,867 - INFO - Train: [8/90][1200/3907]	eta 0:08:14 lr 0.03940591	time 0.1792 (0.1825)	loss 5.8494 (4.6167)	acc@1: 23.9955	acc@5: 40.4735	
2023-03-18 03:06:20,148 - INFO - Train: [8/90][1500/3907]	eta 0:07:18 lr 0.03940591	time 0.1906 (0.1822)	loss 3.6731 (4.6235)	acc@1: 49.4590	acc@5: 76.4191	
2023-03-18 03:07:14,433 - INFO - Train: [8/90][1800/3907]	eta 0:06:23 lr 0.03940591	time 0.1815 (0.1820)	loss 6.6286 (4.6326)	acc@1: 14.4069	acc@5: 23.5300	
2023-03-18 03:08:08,642 - INFO - Train: [8/90][2100/3907]	eta 0:05:28 lr 0.03940591	time 0.1792 (0.1818)	loss 3.9158 (4.6385)	acc@1: 44.8300	acc@5: 73.2224	
2023-03-18 03:09:03,092 - INFO - Train: [8/90][2400/3907]	eta 0:04:33 lr 0.03940591	time 0.1818 (0.1818)	loss 3.2782 (4.6317)	acc@1: 55.1566	acc@5: 76.9129	
2023-03-18 03:09:57,443 - INFO - Train: [8/90][2700/3907]	eta 0:03:39 lr 0.03940591	time 0.1848 (0.1817)	loss 4.8342 (4.6346)	acc@1: 40.4334	acc@5: 62.5346	
2023-03-18 03:10:51,714 - INFO - Train: [8/90][3000/3907]	eta 0:02:44 lr 0.03940591	time 0.1795 (0.1816)	loss 4.3148 (4.6379)	acc@1: 45.3374	acc@5: 63.0184	
2023-03-18 03:11:45,982 - INFO - Train: [8/90][3300/3907]	eta 0:01:50 lr 0.03940591	time 0.1786 (0.1816)	loss 6.1882 (4.6546)	acc@1: 21.7119	acc@5: 36.6124	
2023-03-18 03:12:40,219 - INFO - Train: [8/90][3600/3907]	eta 0:00:55 lr 0.03940591	time 0.1796 (0.1815)	loss 6.5469 (4.6635)	acc@1: 13.3506	acc@5: 27.9599	
2023-03-18 03:13:34,646 - INFO - Train: [8/90][3900/3907]	eta 0:00:01 lr 0.03940591	time 0.1781 (0.1815)	loss 3.5476 (4.6612)	acc@1: 52.8041	acc@5: 72.9939	
2023-03-18 03:13:35,915 - INFO - EPOCH 8 training takes 0:11:49
2023-03-18 03:13:36,983 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/fold1_latest.pth saved !!!
2023-03-18 03:13:36,984 - INFO - **********Latest test***********
2023-03-18 03:13:36,984 - INFO - eval epoch 8
2023-03-18 03:13:37,574 - INFO - Test: [0/782]	Time 0.589 (0.589)	Loss 2.9324 (2.9324)	Acc@1 52.344 (52.344)	Acc@5 87.500 (87.500)
2023-03-18 03:15:36,426 - INFO - Test: [200/782]	Time 0.581 (0.594)	Loss 3.1976 (3.4273)	Acc@1 53.906 (50.241)	Acc@5 78.125 (75.152)
2023-03-18 03:17:35,110 - INFO - Test: [400/782]	Time 0.603 (0.594)	Loss 3.2474 (3.3916)	Acc@1 50.000 (50.898)	Acc@5 78.906 (75.978)
2023-03-18 03:19:34,272 - INFO - Test: [600/782]	Time 0.613 (0.594)	Loss 3.5252 (3.3619)	Acc@1 53.906 (51.612)	Acc@5 75.781 (76.465)
2023-03-18 03:21:19,322 - INFO -  * Acc@1 52.131 Acc@5 77.063
2023-03-18 03:21:19,322 - INFO - Max accuracy: 52.1310%
2023-03-18 03:21:20,375 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/fold1_best.pth saved !!!
2023-03-18 03:21:20,375 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-18 03:21:23,232 - INFO - Train: [9/90][0/3907]	eta 3:05:16 lr 0.03922523	time 2.8454 (2.8454)	loss 4.6469 (4.6469)	acc@1: 45.5562	acc@5: 63.2850	
2023-03-18 03:22:18,030 - INFO - Train: [9/90][300/3907]	eta 0:11:30 lr 0.03922523	time 0.1803 (0.1915)	loss 6.6196 (4.4535)	acc@1: 11.4116	acc@5: 24.8932	
2023-03-18 03:23:12,719 - INFO - Train: [9/90][600/3907]	eta 0:10:18 lr 0.03922523	time 0.1861 (0.1869)	loss 5.0281 (4.4859)	acc@1: 36.9649	acc@5: 54.5903	
2023-03-18 03:24:08,001 - INFO - Train: [9/90][900/3907]	eta 0:09:19 lr 0.03922523	time 0.1847 (0.1860)	loss 6.0612 (4.4954)	acc@1: 23.8173	acc@5: 35.7259	
2023-03-18 03:25:03,291 - INFO - Train: [9/90][1200/3907]	eta 0:08:22 lr 0.03922523	time 0.1908 (0.1856)	loss 3.4146 (4.5300)	acc@1: 56.6054	acc@5: 75.2194	
2023-03-18 03:25:58,401 - INFO - Train: [9/90][1500/3907]	eta 0:07:25 lr 0.03922523	time 0.1821 (0.1852)	loss 4.0734 (4.5424)	acc@1: 46.4100	acc@5: 66.3258	
2023-03-18 03:26:53,611 - INFO - Train: [9/90][1800/3907]	eta 0:06:29 lr 0.03922523	time 0.1798 (0.1850)	loss 3.9124 (4.5568)	acc@1: 45.9228	acc@5: 72.8933	
2023-03-18 03:27:48,585 - INFO - Train: [9/90][2100/3907]	eta 0:05:33 lr 0.03922523	time 0.1828 (0.1848)	loss 4.4161 (4.5556)	acc@1: 44.6090	acc@5: 68.7242	
2023-03-18 03:28:43,516 - INFO - Train: [9/90][2400/3907]	eta 0:04:38 lr 0.03922523	time 0.1810 (0.1846)	loss 5.3450 (4.5649)	acc@1: 38.2551	acc@5: 53.6098	
2023-03-18 03:29:38,339 - INFO - Train: [9/90][2700/3907]	eta 0:03:42 lr 0.03922523	time 0.1813 (0.1844)	loss 4.7032 (4.5759)	acc@1: 42.0731	acc@5: 64.0094	
2023-03-18 03:30:33,448 - INFO - Train: [9/90][3000/3907]	eta 0:02:47 lr 0.03922523	time 0.1798 (0.1843)	loss 4.0667 (4.5804)	acc@1: 46.6472	acc@5: 75.1397	
2023-03-18 03:31:28,292 - INFO - Train: [9/90][3300/3907]	eta 0:01:51 lr 0.03922523	time 0.1848 (0.1842)	loss 4.2381 (4.5914)	acc@1: 46.2587	acc@5: 68.6489	
2023-03-18 03:32:23,403 - INFO - Train: [9/90][3600/3907]	eta 0:00:56 lr 0.03922523	time 0.1815 (0.1841)	loss 4.1623 (4.5927)	acc@1: 47.6110	acc@5: 69.9453	
2023-03-18 03:33:18,440 - INFO - Train: [9/90][3900/3907]	eta 0:00:01 lr 0.03922523	time 0.1863 (0.1841)	loss 3.5349 (4.5980)	acc@1: 48.9042	acc@5: 71.4133	
2023-03-18 03:33:19,628 - INFO - EPOCH 9 training takes 0:11:59
2023-03-18 03:33:20,730 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/fold1_latest.pth saved !!!
2023-03-18 03:33:20,730 - INFO - **********Latest test***********
2023-03-18 03:33:20,730 - INFO - eval epoch 9
2023-03-18 03:33:21,352 - INFO - Test: [0/782]	Time 0.621 (0.621)	Loss 2.9512 (2.9512)	Acc@1 56.250 (56.250)	Acc@5 85.156 (85.156)
2023-03-18 03:35:20,134 - INFO - Test: [200/782]	Time 0.589 (0.594)	Loss 3.1517 (3.3899)	Acc@1 54.688 (50.529)	Acc@5 75.781 (76.170)
2023-03-18 03:37:19,812 - INFO - Test: [400/782]	Time 0.610 (0.596)	Loss 3.1171 (3.3527)	Acc@1 55.469 (51.471)	Acc@5 79.688 (76.929)
2023-03-18 03:39:20,915 - INFO - Test: [600/782]	Time 0.590 (0.599)	Loss 3.4232 (3.3183)	Acc@1 51.562 (52.348)	Acc@5 74.219 (77.522)
2023-03-18 03:41:07,283 - INFO -  * Acc@1 52.982 Acc@5 78.044
2023-03-18 03:41:07,283 - INFO - Max accuracy: 52.9820%
2023-03-18 03:41:08,311 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/fold1_best.pth saved !!!
2023-03-18 03:41:08,312 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-18 03:41:11,163 - INFO - Train: [10/90][0/3907]	eta 3:05:22 lr 0.03902113	time 2.8468 (2.8468)	loss 5.6120 (5.6120)	acc@1: 32.5847	acc@5: 48.8009	
2023-03-18 03:42:06,239 - INFO - Train: [10/90][300/3907]	eta 0:11:34 lr 0.03902113	time 0.1881 (0.1924)	loss 4.6300 (4.4703)	acc@1: 46.0423	acc@5: 65.2265	
2023-03-18 03:43:01,268 - INFO - Train: [10/90][600/3907]	eta 0:10:21 lr 0.03902113	time 0.1812 (0.1879)	loss 6.5666 (4.4606)	acc@1: 14.6004	acc@5: 27.8065	
2023-03-18 03:43:55,989 - INFO - Train: [10/90][900/3907]	eta 0:09:19 lr 0.03902113	time 0.1832 (0.1861)	loss 5.1639 (4.4784)	acc@1: 33.5957	acc@5: 53.3934	
2023-03-18 03:44:51,292 - INFO - Train: [10/90][1200/3907]	eta 0:08:22 lr 0.03902113	time 0.1820 (0.1857)	loss 6.4525 (4.4904)	acc@1: 15.0287	acc@5: 31.4610	
2023-03-18 03:45:46,187 - INFO - Train: [10/90][1500/3907]	eta 0:07:25 lr 0.03902113	time 0.1809 (0.1851)	loss 6.7460 (4.5076)	acc@1: 12.1884	acc@5: 27.8811	
2023-03-18 03:46:41,114 - INFO - Train: [10/90][1800/3907]	eta 0:06:29 lr 0.03902113	time 0.1861 (0.1848)	loss 6.1143 (4.5147)	acc@1: 25.9376	acc@5: 41.5444	
2023-03-18 03:47:36,121 - INFO - Train: [10/90][2100/3907]	eta 0:05:33 lr 0.03902113	time 0.1812 (0.1846)	loss 3.3303 (4.5162)	acc@1: 53.6069	acc@5: 78.4725	
2023-03-18 03:48:31,119 - INFO - Train: [10/90][2400/3907]	eta 0:04:37 lr 0.03902113	time 0.1852 (0.1844)	loss 3.3564 (4.5219)	acc@1: 51.5619	acc@5: 76.5616	
2023-03-18 03:49:25,942 - INFO - Train: [10/90][2700/3907]	eta 0:03:42 lr 0.03902113	time 0.1866 (0.1842)	loss 5.8233 (4.5333)	acc@1: 29.6550	acc@5: 44.3179	
2023-03-18 03:50:20,918 - INFO - Train: [10/90][3000/3907]	eta 0:02:47 lr 0.03902113	time 0.1808 (0.1841)	loss 6.0764 (4.5465)	acc@1: 27.1762	acc@5: 39.7654	
2023-03-18 03:51:15,849 - INFO - Train: [10/90][3300/3907]	eta 0:01:51 lr 0.03902113	time 0.1835 (0.1840)	loss 5.7559 (4.5507)	acc@1: 29.6446	acc@5: 46.8064	
2023-03-18 03:52:10,824 - INFO - Train: [10/90][3600/3907]	eta 0:00:56 lr 0.03902113	time 0.1890 (0.1840)	loss 4.4104 (4.5625)	acc@1: 46.3733	acc@5: 65.7153	
2023-03-18 03:53:05,423 - INFO - Train: [10/90][3900/3907]	eta 0:00:01 lr 0.03902113	time 0.1793 (0.1838)	loss 5.9016 (4.5672)	acc@1: 27.5879	acc@5: 48.5213	
2023-03-18 03:53:06,726 - INFO - EPOCH 10 training takes 0:11:58
2023-03-18 03:53:07,815 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/fold1_latest.pth saved !!!
2023-03-18 03:53:07,816 - INFO - **********Latest test***********
2023-03-18 03:53:07,816 - INFO - eval epoch 10
2023-03-18 03:53:08,437 - INFO - Test: [0/782]	Time 0.620 (0.620)	Loss 2.9710 (2.9710)	Acc@1 60.156 (60.156)	Acc@5 85.156 (85.156)
2023-03-18 03:55:09,115 - INFO - Test: [200/782]	Time 0.592 (0.603)	Loss 3.3482 (3.4591)	Acc@1 48.438 (49.786)	Acc@5 75.000 (75.358)
2023-03-18 03:57:09,241 - INFO - Test: [400/782]	Time 0.578 (0.602)	Loss 3.2201 (3.4211)	Acc@1 53.906 (50.711)	Acc@5 76.562 (76.015)
2023-03-18 03:59:06,927 - INFO - Test: [600/782]	Time 0.583 (0.598)	Loss 3.5522 (3.3890)	Acc@1 47.656 (51.478)	Acc@5 71.094 (76.568)
2023-03-18 04:00:51,274 - INFO -  * Acc@1 51.981 Acc@5 77.105
2023-03-18 04:00:51,274 - INFO - Max accuracy: 52.9820%
2023-03-18 04:00:51,274 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-18 04:00:54,031 - INFO - Train: [11/90][0/3907]	eta 2:59:16 lr 0.03879385	time 2.7532 (2.7532)	loss 6.4868 (6.4868)	acc@1: 12.0856	acc@5: 28.3288	
2023-03-18 04:01:48,761 - INFO - Train: [11/90][300/3907]	eta 0:11:28 lr 0.03879385	time 0.1840 (0.1910)	loss 3.0753 (4.4402)	acc@1: 60.9296	acc@5: 82.0206	
2023-03-18 04:02:43,648 - INFO - Train: [11/90][600/3907]	eta 0:10:18 lr 0.03879385	time 0.1854 (0.1870)	loss 6.1614 (4.5575)	acc@1: 21.9523	acc@5: 36.3504	
2023-03-18 04:03:38,644 - INFO - Train: [11/90][900/3907]	eta 0:09:18 lr 0.03879385	time 0.1813 (0.1858)	loss 3.4335 (4.5320)	acc@1: 60.0014	acc@5: 81.2895	
2023-03-18 04:04:33,466 - INFO - Train: [11/90][1200/3907]	eta 0:08:20 lr 0.03879385	time 0.1830 (0.1850)	loss 4.5718 (4.5433)	acc@1: 46.1921	acc@5: 70.6956	
2023-03-18 04:05:28,346 - INFO - Train: [11/90][1500/3907]	eta 0:07:24 lr 0.03879385	time 0.1816 (0.1846)	loss 3.8811 (4.5571)	acc@1: 46.9746	acc@5: 69.0194	
2023-03-18 04:06:23,182 - INFO - Train: [11/90][1800/3907]	eta 0:06:28 lr 0.03879385	time 0.1850 (0.1843)	loss 5.0680 (4.5569)	acc@1: 38.2435	acc@5: 57.7558	
2023-03-18 04:07:18,021 - INFO - Train: [11/90][2100/3907]	eta 0:05:32 lr 0.03879385	time 0.1806 (0.1841)	loss 3.2763 (4.5441)	acc@1: 56.6501	acc@5: 78.0852	
2023-03-18 04:08:12,880 - INFO - Train: [11/90][2400/3907]	eta 0:04:37 lr 0.03879385	time 0.1883 (0.1839)	loss 3.4315 (4.5432)	acc@1: 49.2108	acc@5: 76.5500	
2023-03-18 04:09:07,737 - INFO - Train: [11/90][2700/3907]	eta 0:03:41 lr 0.03879385	time 0.1805 (0.1838)	loss 3.1927 (4.5417)	acc@1: 58.5718	acc@5: 76.2943	
2023-03-18 04:10:02,743 - INFO - Train: [11/90][3000/3907]	eta 0:02:46 lr 0.03879385	time 0.1833 (0.1838)	loss 4.3385 (4.5413)	acc@1: 43.9766	acc@5: 70.0878	
2023-03-18 04:10:57,744 - INFO - Train: [11/90][3300/3907]	eta 0:01:51 lr 0.03879385	time 0.1816 (0.1837)	loss 3.5250 (4.5504)	acc@1: 54.4792	acc@5: 75.1913	
2023-03-18 04:11:52,872 - INFO - Train: [11/90][3600/3907]	eta 0:00:56 lr 0.03879385	time 0.1808 (0.1837)	loss 6.0390 (4.5626)	acc@1: 21.4050	acc@5: 41.3844	
2023-03-18 04:12:47,748 - INFO - Train: [11/90][3900/3907]	eta 0:00:01 lr 0.03879385	time 0.1785 (0.1837)	loss 4.9927 (4.5605)	acc@1: 35.6570	acc@5: 53.7746	
2023-03-18 04:12:49,029 - INFO - EPOCH 11 training takes 0:11:57
2023-03-18 04:12:50,110 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/fold1_latest.pth saved !!!
2023-03-18 04:12:50,110 - INFO - **********Latest test***********
2023-03-18 04:12:50,110 - INFO - eval epoch 11
2023-03-18 04:12:50,715 - INFO - Test: [0/782]	Time 0.603 (0.603)	Loss 2.9004 (2.9004)	Acc@1 56.250 (56.250)	Acc@5 88.281 (88.281)
2023-03-18 04:14:47,218 - INFO - Test: [200/782]	Time 0.579 (0.583)	Loss 3.3572 (3.4983)	Acc@1 51.562 (49.732)	Acc@5 73.438 (74.207)
2023-03-18 04:16:44,729 - INFO - Test: [400/782]	Time 0.581 (0.585)	Loss 3.3174 (3.4567)	Acc@1 51.562 (50.546)	Acc@5 77.344 (75.245)
2023-03-18 04:18:43,216 - INFO - Test: [600/782]	Time 0.588 (0.588)	Loss 3.5717 (3.4145)	Acc@1 47.656 (51.405)	Acc@5 77.344 (75.981)
2023-03-18 04:20:28,788 - INFO -  * Acc@1 51.924 Acc@5 76.644
2023-03-18 04:20:28,788 - INFO - Max accuracy: 52.9820%
2023-03-18 04:20:28,788 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-18 04:20:31,511 - INFO - Train: [12/90][0/3907]	eta 2:57:02 lr 0.03854368	time 2.7190 (2.7190)	loss 6.6214 (6.6214)	acc@1: 15.2796	acc@5: 26.2300	
2023-03-18 04:21:26,484 - INFO - Train: [12/90][300/3907]	eta 0:11:31 lr 0.03854368	time 0.1859 (0.1917)	loss 3.4406 (4.3459)	acc@1: 51.6935	acc@5: 74.0640	
2023-03-18 04:22:21,332 - INFO - Train: [12/90][600/3907]	eta 0:10:19 lr 0.03854368	time 0.1806 (0.1872)	loss 3.6042 (4.3501)	acc@1: 49.3588	acc@5: 70.1981	
2023-03-18 04:23:16,251 - INFO - Train: [12/90][900/3907]	eta 0:09:18 lr 0.03854368	time 0.1860 (0.1859)	loss 3.5365 (4.4215)	acc@1: 52.3629	acc@5: 72.3840	
2023-03-18 04:24:11,155 - INFO - Train: [12/90][1200/3907]	eta 0:08:21 lr 0.03854368	time 0.1804 (0.1851)	loss 6.4693 (4.4349)	acc@1: 15.5426	acc@5: 28.0163	
2023-03-18 04:25:06,058 - INFO - Train: [12/90][1500/3907]	eta 0:07:24 lr 0.03854368	time 0.1877 (0.1847)	loss 6.1426 (4.4733)	acc@1: 24.5637	acc@5: 37.4143	
2023-03-18 04:26:00,979 - INFO - Train: [12/90][1800/3907]	eta 0:06:28 lr 0.03854368	time 0.1803 (0.1844)	loss 6.2916 (4.4720)	acc@1: 16.0773	acc@5: 27.5185	
2023-03-18 04:26:55,968 - INFO - Train: [12/90][2100/3907]	eta 0:05:32 lr 0.03854368	time 0.1803 (0.1843)	loss 3.4672 (4.4799)	acc@1: 46.0916	acc@5: 77.3401	
2023-03-18 04:27:50,824 - INFO - Train: [12/90][2400/3907]	eta 0:04:37 lr 0.03854368	time 0.1855 (0.1841)	loss 3.7000 (4.4762)	acc@1: 48.2885	acc@5: 75.7758	
2023-03-18 04:28:45,750 - INFO - Train: [12/90][2700/3907]	eta 0:03:42 lr 0.03854368	time 0.1802 (0.1840)	loss 6.1484 (4.4848)	acc@1: 21.4668	acc@5: 35.0943	
2023-03-18 04:29:40,703 - INFO - Train: [12/90][3000/3907]	eta 0:02:46 lr 0.03854368	time 0.1835 (0.1839)	loss 6.2701 (4.4924)	acc@1: 16.3473	acc@5: 32.1703	
2023-03-18 04:30:35,668 - INFO - Train: [12/90][3300/3907]	eta 0:01:51 lr 0.03854368	time 0.1799 (0.1838)	loss 6.1583 (4.5028)	acc@1: 17.6803	acc@5: 33.0733	
2023-03-18 04:31:30,488 - INFO - Train: [12/90][3600/3907]	eta 0:00:56 lr 0.03854368	time 0.1805 (0.1837)	loss 4.0865 (4.5147)	acc@1: 46.6651	acc@5: 69.9977	
2023-03-18 04:32:25,510 - INFO - Train: [12/90][3900/3907]	eta 0:00:01 lr 0.03854368	time 0.1795 (0.1837)	loss 3.4617 (4.5142)	acc@1: 54.7236	acc@5: 77.0817	
2023-03-18 04:32:26,764 - INFO - EPOCH 12 training takes 0:11:57
2023-03-18 04:32:27,805 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/fold1_latest.pth saved !!!
2023-03-18 04:32:27,805 - INFO - **********Latest test***********
2023-03-18 04:32:27,805 - INFO - eval epoch 12
2023-03-18 04:32:28,426 - INFO - Test: [0/782]	Time 0.620 (0.620)	Loss 2.8674 (2.8674)	Acc@1 62.500 (62.500)	Acc@5 87.500 (87.500)
2023-03-18 04:34:26,646 - INFO - Test: [200/782]	Time 0.585 (0.591)	Loss 3.1357 (3.3966)	Acc@1 56.250 (51.706)	Acc@5 77.344 (76.162)
2023-03-18 04:36:25,024 - INFO - Test: [400/782]	Time 0.584 (0.592)	Loss 3.1097 (3.3535)	Acc@1 59.375 (52.615)	Acc@5 80.469 (77.137)
2023-03-18 04:38:23,637 - INFO - Test: [600/782]	Time 0.586 (0.592)	Loss 3.3414 (3.3168)	Acc@1 47.656 (53.386)	Acc@5 78.906 (77.792)
2023-03-18 04:40:08,607 - INFO -  * Acc@1 53.923 Acc@5 78.431
2023-03-18 04:40:08,608 - INFO - Max accuracy: 53.9230%
2023-03-18 04:40:09,650 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/fold1_best.pth saved !!!
2023-03-18 04:40:09,651 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-18 04:40:12,412 - INFO - Train: [13/90][0/3907]	eta 2:59:27 lr 0.03827091	time 2.7561 (2.7561)	loss 3.1205 (3.1205)	acc@1: 62.2746	acc@5: 77.8460	
2023-03-18 04:41:07,266 - INFO - Train: [13/90][300/3907]	eta 0:11:30 lr 0.03827091	time 0.1799 (0.1914)	loss 5.9093 (4.3301)	acc@1: 24.2109	acc@5: 41.3392	
2023-03-18 04:42:02,236 - INFO - Train: [13/90][600/3907]	eta 0:10:19 lr 0.03827091	time 0.1886 (0.1873)	loss 5.6193 (4.3705)	acc@1: 31.1425	acc@5: 47.1044	
2023-03-18 04:42:57,343 - INFO - Train: [13/90][900/3907]	eta 0:09:19 lr 0.03827091	time 0.1805 (0.1861)	loss 5.9626 (4.4010)	acc@1: 25.5111	acc@5: 40.6104	
2023-03-18 04:43:52,191 - INFO - Train: [13/90][1200/3907]	eta 0:08:21 lr 0.03827091	time 0.1825 (0.1853)	loss 3.0435 (4.3977)	acc@1: 62.4681	acc@5: 83.5508	
2023-03-18 04:44:47,076 - INFO - Train: [13/90][1500/3907]	eta 0:07:24 lr 0.03827091	time 0.1872 (0.1848)	loss 3.6020 (4.4257)	acc@1: 54.8667	acc@5: 75.3315	
2023-03-18 04:45:41,960 - INFO - Train: [13/90][1800/3907]	eta 0:06:28 lr 0.03827091	time 0.1804 (0.1845)	loss 3.8428 (4.4144)	acc@1: 54.4013	acc@5: 74.4439	
2023-03-18 04:46:36,854 - INFO - Train: [13/90][2100/3907]	eta 0:05:33 lr 0.03827091	time 0.1806 (0.1843)	loss 3.2276 (4.4270)	acc@1: 59.3392	acc@5: 75.7355	
2023-03-18 04:47:31,426 - INFO - Train: [13/90][2400/3907]	eta 0:04:37 lr 0.03827091	time 0.1869 (0.1840)	loss 4.2779 (4.4274)	acc@1: 44.1136	acc@5: 68.6211	
2023-03-18 04:48:26,379 - INFO - Train: [13/90][2700/3907]	eta 0:03:41 lr 0.03827091	time 0.1837 (0.1839)	loss 3.6734 (4.4323)	acc@1: 57.9209	acc@5: 74.0232	
2023-03-18 04:49:21,321 - INFO - Train: [13/90][3000/3907]	eta 0:02:46 lr 0.03827091	time 0.1822 (0.1838)	loss 3.5130 (4.4350)	acc@1: 43.5894	acc@5: 73.9491	
2023-03-18 04:50:16,172 - INFO - Train: [13/90][3300/3907]	eta 0:01:51 lr 0.03827091	time 0.1805 (0.1837)	loss 4.5034 (4.4530)	acc@1: 45.2273	acc@5: 66.8285	
2023-03-18 04:51:11,064 - INFO - Train: [13/90][3600/3907]	eta 0:00:56 lr 0.03827091	time 0.1866 (0.1837)	loss 6.5519 (4.4476)	acc@1: 16.1466	acc@5: 30.3962	
2023-03-18 04:52:05,811 - INFO - Train: [13/90][3900/3907]	eta 0:00:01 lr 0.03827091	time 0.1791 (0.1836)	loss 3.2588 (4.4595)	acc@1: 50.5537	acc@5: 80.4263	
2023-03-18 04:52:07,073 - INFO - EPOCH 13 training takes 0:11:57
2023-03-18 04:52:08,158 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/fold1_latest.pth saved !!!
2023-03-18 04:52:08,158 - INFO - **********Latest test***********
2023-03-18 04:52:08,158 - INFO - eval epoch 13
2023-03-18 04:52:08,752 - INFO - Test: [0/782]	Time 0.593 (0.593)	Loss 3.0822 (3.0822)	Acc@1 55.469 (55.469)	Acc@5 84.375 (84.375)
2023-03-18 04:54:06,079 - INFO - Test: [200/782]	Time 0.581 (0.587)	Loss 3.1904 (3.3726)	Acc@1 51.562 (52.406)	Acc@5 80.469 (76.905)
2023-03-18 04:56:03,677 - INFO - Test: [400/782]	Time 0.579 (0.587)	Loss 2.9775 (3.3396)	Acc@1 64.062 (53.304)	Acc@5 83.594 (77.478)
2023-03-18 04:58:02,306 - INFO - Test: [600/782]	Time 0.597 (0.589)	Loss 3.4316 (3.3037)	Acc@1 53.125 (54.171)	Acc@5 72.656 (78.116)
2023-03-18 04:59:47,290 - INFO -  * Acc@1 54.572 Acc@5 78.655
2023-03-18 04:59:47,290 - INFO - Max accuracy: 54.5720%
2023-03-18 04:59:48,295 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/fold1_best.pth saved !!!
2023-03-18 04:59:48,295 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-18 04:59:51,097 - INFO - Train: [14/90][0/3907]	eta 3:02:09 lr 0.03797588	time 2.7974 (2.7974)	loss 2.9688 (2.9688)	acc@1: 63.5971	acc@5: 81.4321	
2023-03-18 05:00:45,788 - INFO - Train: [14/90][300/3907]	eta 0:11:28 lr 0.03797588	time 0.1842 (0.1910)	loss 5.0047 (4.3071)	acc@1: 38.9613	acc@5: 60.5146	
2023-03-18 05:01:40,563 - INFO - Train: [14/90][600/3907]	eta 0:10:17 lr 0.03797588	time 0.1801 (0.1868)	loss 3.3395 (4.3388)	acc@1: 59.0996	acc@5: 78.7995	
2023-03-18 05:02:35,767 - INFO - Train: [14/90][900/3907]	eta 0:09:18 lr 0.03797588	time 0.1804 (0.1859)	loss 6.4509 (4.3666)	acc@1: 12.5000	acc@5: 28.5421	
2023-03-18 05:03:30,758 - INFO - Train: [14/90][1200/3907]	eta 0:08:21 lr 0.03797588	time 0.1870 (0.1852)	loss 3.3091 (4.3777)	acc@1: 53.8888	acc@5: 76.5376	
2023-03-18 05:04:25,753 - INFO - Train: [14/90][1500/3907]	eta 0:07:24 lr 0.03797588	time 0.1804 (0.1848)	loss 3.1350 (4.3660)	acc@1: 59.3580	acc@5: 83.5698	
2023-03-18 05:05:20,754 - INFO - Train: [14/90][1800/3907]	eta 0:06:28 lr 0.03797588	time 0.1862 (0.1846)	loss 4.4006 (4.3973)	acc@1: 47.7680	acc@5: 68.9982	
2023-03-18 05:06:15,685 - INFO - Train: [14/90][2100/3907]	eta 0:05:33 lr 0.03797588	time 0.1820 (0.1844)	loss 4.3918 (4.3950)	acc@1: 44.7868	acc@5: 67.1281	
2023-03-18 05:07:10,534 - INFO - Train: [14/90][2400/3907]	eta 0:04:37 lr 0.03797588	time 0.1870 (0.1842)	loss 3.0321 (4.4161)	acc@1: 62.3305	acc@5: 82.5887	
2023-03-18 05:08:05,492 - INFO - Train: [14/90][2700/3907]	eta 0:03:42 lr 0.03797588	time 0.1812 (0.1841)	loss 5.1680 (4.4378)	acc@1: 36.5569	acc@5: 58.9924	
2023-03-18 05:09:00,430 - INFO - Train: [14/90][3000/3907]	eta 0:02:46 lr 0.03797588	time 0.1877 (0.1840)	loss 3.3239 (4.4440)	acc@1: 53.9477	acc@5: 84.0197	
2023-03-18 05:09:55,200 - INFO - Train: [14/90][3300/3907]	eta 0:01:51 lr 0.03797588	time 0.1814 (0.1838)	loss 3.8108 (4.4403)	acc@1: 54.2365	acc@5: 75.6457	
2023-03-18 05:10:50,233 - INFO - Train: [14/90][3600/3907]	eta 0:00:56 lr 0.03797588	time 0.1880 (0.1838)	loss 6.3725 (4.4505)	acc@1: 17.6547	acc@5: 31.6046	
2023-03-18 05:11:45,159 - INFO - Train: [14/90][3900/3907]	eta 0:00:01 lr 0.03797588	time 0.1873 (0.1838)	loss 4.1445 (4.4654)	acc@1: 49.8621	acc@5: 67.6450	
2023-03-18 05:11:46,416 - INFO - EPOCH 14 training takes 0:11:58
2023-03-18 05:11:47,499 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/fold1_latest.pth saved !!!
2023-03-18 05:11:47,500 - INFO - **********Latest test***********
2023-03-18 05:11:47,500 - INFO - eval epoch 14
2023-03-18 05:11:48,111 - INFO - Test: [0/782]	Time 0.610 (0.610)	Loss 2.9417 (2.9417)	Acc@1 56.250 (56.250)	Acc@5 85.156 (85.156)
2023-03-18 05:13:46,043 - INFO - Test: [200/782]	Time 0.572 (0.590)	Loss 3.1957 (3.3343)	Acc@1 58.594 (52.177)	Acc@5 75.781 (77.103)
2023-03-18 05:15:44,803 - INFO - Test: [400/782]	Time 0.616 (0.592)	Loss 3.1492 (3.2923)	Acc@1 56.250 (53.396)	Acc@5 78.125 (77.969)
2023-03-18 05:17:46,052 - INFO - Test: [600/782]	Time 0.589 (0.597)	Loss 3.3332 (3.2556)	Acc@1 50.000 (54.190)	Acc@5 76.562 (78.677)
2023-03-18 05:19:33,140 - INFO -  * Acc@1 54.887 Acc@5 79.316
2023-03-18 05:19:33,141 - INFO - Max accuracy: 54.8870%
2023-03-18 05:19:34,166 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/fold1_best.pth saved !!!
2023-03-18 05:19:34,167 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-18 05:19:36,920 - INFO - Train: [15/90][0/3907]	eta 2:58:55 lr 0.03765895	time 2.7478 (2.7478)	loss 6.2599 (6.2599)	acc@1: 15.6507	acc@5: 30.8658	
2023-03-18 05:20:31,530 - INFO - Train: [15/90][300/3907]	eta 0:11:27 lr 0.03765895	time 0.1800 (0.1905)	loss 3.1280 (4.4279)	acc@1: 60.6807	acc@5: 78.5728	
2023-03-18 05:21:26,629 - INFO - Train: [15/90][600/3907]	eta 0:10:18 lr 0.03765895	time 0.1857 (0.1871)	loss 3.4147 (4.4022)	acc@1: 55.2907	acc@5: 75.5371	
2023-03-18 05:22:21,570 - INFO - Train: [15/90][900/3907]	eta 0:09:18 lr 0.03765895	time 0.1830 (0.1858)	loss 5.8436 (4.4336)	acc@1: 26.0805	acc@5: 44.2488	
2023-03-18 05:23:16,477 - INFO - Train: [15/90][1200/3907]	eta 0:08:21 lr 0.03765895	time 0.1819 (0.1851)	loss 3.9483 (4.4163)	acc@1: 49.7817	acc@5: 71.5632	
2023-03-18 05:24:11,335 - INFO - Train: [15/90][1500/3907]	eta 0:07:24 lr 0.03765895	time 0.1837 (0.1846)	loss 2.9716 (4.4211)	acc@1: 60.0798	acc@5: 85.0480	
2023-03-18 05:25:06,189 - INFO - Train: [15/90][1800/3907]	eta 0:06:28 lr 0.03765895	time 0.1888 (0.1843)	loss 3.1006 (4.4236)	acc@1: 59.9891	acc@5: 81.8033	
2023-03-18 05:26:01,055 - INFO - Train: [15/90][2100/3907]	eta 0:05:32 lr 0.03765895	time 0.1813 (0.1841)	loss 3.0412 (4.4273)	acc@1: 57.0208	acc@5: 80.4542	
2023-03-18 05:26:55,969 - INFO - Train: [15/90][2400/3907]	eta 0:04:37 lr 0.03765895	time 0.1816 (0.1840)	loss 3.0347 (4.4360)	acc@1: 60.0864	acc@5: 79.5953	
2023-03-18 05:27:50,913 - INFO - Train: [15/90][2700/3907]	eta 0:03:41 lr 0.03765895	time 0.1851 (0.1839)	loss 4.1619 (4.4273)	acc@1: 47.3589	acc@5: 72.0177	
2023-03-18 05:28:46,154 - INFO - Train: [15/90][3000/3907]	eta 0:02:46 lr 0.03765895	time 0.1858 (0.1839)	loss 6.3872 (4.4380)	acc@1: 19.1457	acc@5: 33.4438	
2023-03-18 05:29:41,186 - INFO - Train: [15/90][3300/3907]	eta 0:01:51 lr 0.03765895	time 0.1884 (0.1839)	loss 6.6317 (4.4310)	acc@1: 12.0321	acc@5: 27.0525	
2023-03-18 05:30:36,074 - INFO - Train: [15/90][3600/3907]	eta 0:00:56 lr 0.03765895	time 0.1813 (0.1838)	loss 3.3469 (4.4419)	acc@1: 57.9812	acc@5: 77.0351	
2023-03-18 05:31:30,995 - INFO - Train: [15/90][3900/3907]	eta 0:00:01 lr 0.03765895	time 0.1790 (0.1837)	loss 4.7254 (4.4477)	acc@1: 46.1651	acc@5: 61.8139	
2023-03-18 05:31:32,259 - INFO - EPOCH 15 training takes 0:11:58
2023-03-18 05:31:33,350 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/fold1_latest.pth saved !!!
2023-03-18 05:31:33,350 - INFO - **********Latest test***********
2023-03-18 05:31:33,350 - INFO - eval epoch 15
2023-03-18 05:31:33,937 - INFO - Test: [0/782]	Time 0.585 (0.585)	Loss 2.8833 (2.8833)	Acc@1 62.500 (62.500)	Acc@5 88.281 (88.281)
2023-03-18 05:33:29,816 - INFO - Test: [200/782]	Time 0.572 (0.579)	Loss 3.2798 (3.3068)	Acc@1 50.000 (54.007)	Acc@5 78.125 (78.090)
2023-03-18 05:35:26,762 - INFO - Test: [400/782]	Time 0.589 (0.582)	Loss 3.1298 (3.2725)	Acc@1 59.375 (54.723)	Acc@5 78.906 (78.610)
2023-03-18 05:37:24,305 - INFO - Test: [600/782]	Time 0.572 (0.584)	Loss 3.3925 (3.2381)	Acc@1 50.781 (55.414)	Acc@5 72.656 (79.264)
2023-03-18 05:39:08,887 - INFO -  * Acc@1 55.892 Acc@5 79.757
2023-03-18 05:39:08,888 - INFO - Max accuracy: 55.8920%
2023-03-18 05:39:09,924 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/fold1_best.pth saved !!!
2023-03-18 05:39:09,925 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-18 05:39:12,583 - INFO - Train: [16/90][0/3907]	eta 2:52:51 lr 0.03732051	time 2.6547 (2.6547)	loss 3.9475 (3.9475)	acc@1: 57.7763	acc@5: 72.5528	
2023-03-18 05:40:07,346 - INFO - Train: [16/90][300/3907]	eta 0:11:28 lr 0.03732051	time 0.1796 (0.1907)	loss 3.4613 (4.2862)	acc@1: 56.6738	acc@5: 76.8079	
2023-03-18 05:41:02,572 - INFO - Train: [16/90][600/3907]	eta 0:10:19 lr 0.03732051	time 0.1803 (0.1874)	loss 3.5331 (4.3014)	acc@1: 55.8729	acc@5: 77.4771	
2023-03-18 05:41:57,669 - INFO - Train: [16/90][900/3907]	eta 0:09:19 lr 0.03732051	time 0.1879 (0.1862)	loss 3.5444 (4.3667)	acc@1: 54.6028	acc@5: 76.7213	
2023-03-18 05:42:52,387 - INFO - Train: [16/90][1200/3907]	eta 0:08:21 lr 0.03732051	time 0.1805 (0.1852)	loss 5.5022 (4.3705)	acc@1: 36.5560	acc@5: 51.7995	
2023-03-18 05:43:47,203 - INFO - Train: [16/90][1500/3907]	eta 0:07:24 lr 0.03732051	time 0.1807 (0.1847)	loss 3.5945 (4.3763)	acc@1: 54.0952	acc@5: 77.7903	
2023-03-18 05:44:41,672 - INFO - Train: [16/90][1800/3907]	eta 0:06:28 lr 0.03732051	time 0.1808 (0.1842)	loss 6.4824 (4.3690)	acc@1: 12.2648	acc@5: 23.8175	
2023-03-18 05:45:36,594 - INFO - Train: [16/90][2100/3907]	eta 0:05:32 lr 0.03732051	time 0.1881 (0.1840)	loss 3.5539 (4.3794)	acc@1: 54.3474	acc@5: 75.4824	
2023-03-18 05:46:31,524 - INFO - Train: [16/90][2400/3907]	eta 0:04:37 lr 0.03732051	time 0.1803 (0.1839)	loss 3.4320 (4.3842)	acc@1: 53.8626	acc@5: 75.0952	
2023-03-18 05:47:26,421 - INFO - Train: [16/90][2700/3907]	eta 0:03:41 lr 0.03732051	time 0.1807 (0.1838)	loss 5.7122 (4.3944)	acc@1: 29.9357	acc@5: 44.9849	
2023-03-18 05:48:21,645 - INFO - Train: [16/90][3000/3907]	eta 0:02:46 lr 0.03732051	time 0.1854 (0.1838)	loss 5.8875 (4.3835)	acc@1: 28.8643	acc@5: 44.4439	
2023-03-18 05:49:16,673 - INFO - Train: [16/90][3300/3907]	eta 0:01:51 lr 0.03732051	time 0.1881 (0.1838)	loss 3.4552 (4.3877)	acc@1: 53.9053	acc@5: 74.2175	
2023-03-18 05:50:11,635 - INFO - Train: [16/90][3600/3907]	eta 0:00:56 lr 0.03732051	time 0.1803 (0.1838)	loss 3.9364 (4.3980)	acc@1: 54.2787	acc@5: 73.5619	
2023-03-18 05:51:06,698 - INFO - Train: [16/90][3900/3907]	eta 0:00:01 lr 0.03732051	time 0.1792 (0.1837)	loss 4.8307 (4.4041)	acc@1: 44.7147	acc@5: 62.4781	
2023-03-18 05:51:07,912 - INFO - EPOCH 16 training takes 0:11:57
2023-03-18 05:51:08,977 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/fold1_latest.pth saved !!!
2023-03-18 05:51:08,977 - INFO - **********Latest test***********
2023-03-18 05:51:08,978 - INFO - eval epoch 16
2023-03-18 05:51:09,568 - INFO - Test: [0/782]	Time 0.590 (0.590)	Loss 2.9355 (2.9355)	Acc@1 59.375 (59.375)	Acc@5 88.281 (88.281)
2023-03-18 05:53:05,160 - INFO - Test: [200/782]	Time 0.577 (0.578)	Loss 3.2509 (3.3495)	Acc@1 54.688 (53.211)	Acc@5 76.562 (77.627)
2023-03-18 05:55:03,479 - INFO - Test: [400/782]	Time 0.585 (0.585)	Loss 3.2633 (3.3149)	Acc@1 56.250 (53.887)	Acc@5 75.781 (78.230)
2023-03-18 05:57:01,433 - INFO - Test: [600/782]	Time 0.584 (0.586)	Loss 3.3703 (3.2776)	Acc@1 50.000 (54.738)	Acc@5 77.344 (78.850)
2023-03-18 05:58:46,415 - INFO -  * Acc@1 55.233 Acc@5 79.386
2023-03-18 05:58:46,415 - INFO - Max accuracy: 55.8920%
2023-03-18 05:58:46,415 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-18 05:58:49,125 - INFO - Train: [17/90][0/3907]	eta 2:56:12 lr 0.03696096	time 2.7059 (2.7059)	loss 5.7344 (5.7344)	acc@1: 32.0067	acc@5: 45.3651	
2023-03-18 05:59:43,751 - INFO - Train: [17/90][300/3907]	eta 0:11:27 lr 0.03696096	time 0.1845 (0.1905)	loss 4.2048 (4.2625)	acc@1: 53.2412	acc@5: 69.6231	
2023-03-18 06:00:38,694 - INFO - Train: [17/90][600/3907]	eta 0:10:17 lr 0.03696096	time 0.1807 (0.1868)	loss 4.5366 (4.2876)	acc@1: 46.7994	acc@5: 67.4266	
2023-03-18 06:01:33,514 - INFO - Train: [17/90][900/3907]	eta 0:09:17 lr 0.03696096	time 0.1812 (0.1854)	loss 5.7915 (4.2863)	acc@1: 30.6482	acc@5: 44.0908	
2023-03-18 06:02:28,189 - INFO - Train: [17/90][1200/3907]	eta 0:08:19 lr 0.03696096	time 0.1815 (0.1846)	loss 3.4032 (4.3236)	acc@1: 57.9150	acc@5: 79.4475	
2023-03-18 06:03:22,779 - INFO - Train: [17/90][1500/3907]	eta 0:07:23 lr 0.03696096	time 0.1822 (0.1841)	loss 6.4607 (4.3349)	acc@1: 12.5740	acc@5: 26.2829	
2023-03-18 06:04:17,640 - INFO - Train: [17/90][1800/3907]	eta 0:06:27 lr 0.03696096	time 0.1803 (0.1839)	loss 2.8527 (4.3424)	acc@1: 63.2353	acc@5: 84.3137	
2023-03-18 06:05:12,674 - INFO - Train: [17/90][2100/3907]	eta 0:05:32 lr 0.03696096	time 0.1850 (0.1838)	loss 5.9689 (4.3633)	acc@1: 20.8867	acc@5: 40.3144	
2023-03-18 06:06:07,593 - INFO - Train: [17/90][2400/3907]	eta 0:04:36 lr 0.03696096	time 0.1805 (0.1837)	loss 6.1757 (4.3611)	acc@1: 26.7376	acc@5: 38.3257	
2023-03-18 06:07:02,591 - INFO - Train: [17/90][2700/3907]	eta 0:03:41 lr 0.03696096	time 0.1805 (0.1837)	loss 5.0905 (4.3589)	acc@1: 40.8903	acc@5: 59.1753	
2023-03-18 06:07:57,381 - INFO - Train: [17/90][3000/3907]	eta 0:02:46 lr 0.03696096	time 0.1850 (0.1836)	loss 6.1385 (4.3629)	acc@1: 20.2511	acc@5: 35.2207	
2023-03-18 06:08:52,410 - INFO - Train: [17/90][3300/3907]	eta 0:01:51 lr 0.03696096	time 0.1844 (0.1836)	loss 6.5850 (4.3705)	acc@1: 14.0625	acc@5: 25.7856	
2023-03-18 06:09:47,369 - INFO - Train: [17/90][3600/3907]	eta 0:00:56 lr 0.03696096	time 0.1810 (0.1835)	loss 5.2640 (4.3799)	acc@1: 38.7550	acc@5: 51.6472	
2023-03-18 06:10:42,303 - INFO - Train: [17/90][3900/3907]	eta 0:00:01 lr 0.03696096	time 0.1803 (0.1835)	loss 3.1949 (4.3907)	acc@1: 56.2453	acc@5: 79.6808	
2023-03-18 06:10:43,572 - INFO - EPOCH 17 training takes 0:11:57
2023-03-18 06:10:44,648 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/fold1_latest.pth saved !!!
2023-03-18 06:10:44,648 - INFO - **********Latest test***********
2023-03-18 06:10:44,648 - INFO - eval epoch 17
2023-03-18 06:10:45,239 - INFO - Test: [0/782]	Time 0.589 (0.589)	Loss 2.8801 (2.8801)	Acc@1 57.812 (57.812)	Acc@5 87.500 (87.500)
2023-03-18 06:12:42,527 - INFO - Test: [200/782]	Time 0.590 (0.586)	Loss 3.1457 (3.2725)	Acc@1 53.125 (53.945)	Acc@5 81.250 (77.962)
2023-03-18 06:14:40,226 - INFO - Test: [400/782]	Time 0.621 (0.587)	Loss 3.2346 (3.2346)	Acc@1 56.250 (54.808)	Acc@5 76.562 (78.633)
2023-03-18 06:16:40,383 - INFO - Test: [600/782]	Time 0.595 (0.592)	Loss 3.3231 (3.2017)	Acc@1 52.344 (55.518)	Acc@5 75.781 (79.314)
2023-03-18 06:18:27,213 - INFO -  * Acc@1 56.111 Acc@5 79.868
2023-03-18 06:18:27,214 - INFO - Max accuracy: 56.1110%
2023-03-18 06:18:28,243 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/fold1_best.pth saved !!!
2023-03-18 06:18:28,244 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-18 06:18:30,991 - INFO - Train: [18/90][0/3907]	eta 2:58:19 lr 0.03658075	time 2.7386 (2.7386)	loss 4.9024 (4.9024)	acc@1: 37.1189	acc@5: 60.6276	
2023-03-18 06:19:25,699 - INFO - Train: [18/90][300/3907]	eta 0:11:28 lr 0.03658075	time 0.1802 (0.1908)	loss 3.2332 (4.3410)	acc@1: 58.1785	acc@5: 81.1374	
2023-03-18 06:20:20,640 - INFO - Train: [18/90][600/3907]	eta 0:10:18 lr 0.03658075	time 0.1868 (0.1870)	loss 3.1357 (4.3406)	acc@1: 57.1333	acc@5: 81.8449	
2023-03-18 06:21:15,589 - INFO - Train: [18/90][900/3907]	eta 0:09:18 lr 0.03658075	time 0.1892 (0.1857)	loss 5.3402 (4.3720)	acc@1: 36.2921	acc@5: 54.1407	
2023-03-18 06:22:10,577 - INFO - Train: [18/90][1200/3907]	eta 0:08:21 lr 0.03658075	time 0.1876 (0.1851)	loss 3.3924 (4.3500)	acc@1: 57.5560	acc@5: 74.9594	
2023-03-18 06:23:05,580 - INFO - Train: [18/90][1500/3907]	eta 0:07:24 lr 0.03658075	time 0.1804 (0.1848)	loss 5.5280 (4.3492)	acc@1: 32.4491	acc@5: 47.1111	
2023-03-18 06:24:00,755 - INFO - Train: [18/90][1800/3907]	eta 0:06:28 lr 0.03658075	time 0.1855 (0.1846)	loss 4.8223 (4.3544)	acc@1: 41.8616	acc@5: 61.6031	
2023-03-18 06:24:55,894 - INFO - Train: [18/90][2100/3907]	eta 0:05:33 lr 0.03658075	time 0.1808 (0.1845)	loss 5.1369 (4.3637)	acc@1: 41.4046	acc@5: 58.8363	
2023-03-18 06:25:51,085 - INFO - Train: [18/90][2400/3907]	eta 0:04:37 lr 0.03658075	time 0.1806 (0.1844)	loss 3.5465 (4.3758)	acc@1: 57.9308	acc@5: 76.2480	
2023-03-18 06:26:46,548 - INFO - Train: [18/90][2700/3907]	eta 0:03:42 lr 0.03658075	time 0.1892 (0.1845)	loss 3.5898 (4.3714)	acc@1: 60.8594	acc@5: 76.9908	
2023-03-18 06:27:41,756 - INFO - Train: [18/90][3000/3907]	eta 0:02:47 lr 0.03658075	time 0.1803 (0.1844)	loss 3.3200 (4.3652)	acc@1: 50.7042	acc@5: 79.5666	
2023-03-18 06:28:36,825 - INFO - Train: [18/90][3300/3907]	eta 0:01:51 lr 0.03658075	time 0.1804 (0.1844)	loss 5.8242 (4.3720)	acc@1: 25.8696	acc@5: 42.4521	
2023-03-18 06:29:31,991 - INFO - Train: [18/90][3600/3907]	eta 0:00:56 lr 0.03658075	time 0.1819 (0.1843)	loss 3.5280 (4.3729)	acc@1: 57.7940	acc@5: 76.3177	
2023-03-18 06:30:27,242 - INFO - Train: [18/90][3900/3907]	eta 0:00:01 lr 0.03658075	time 0.1874 (0.1843)	loss 6.3814 (4.3754)	acc@1: 16.5421	acc@5: 30.3091	
2023-03-18 06:30:28,520 - INFO - EPOCH 18 training takes 0:12:00
2023-03-18 06:30:29,611 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/fold1_latest.pth saved !!!
2023-03-18 06:30:29,611 - INFO - **********Latest test***********
2023-03-18 06:30:29,611 - INFO - eval epoch 18
2023-03-18 06:30:30,213 - INFO - Test: [0/782]	Time 0.597 (0.597)	Loss 2.9624 (2.9624)	Acc@1 58.594 (58.594)	Acc@5 87.500 (87.500)
2023-03-18 06:32:26,521 - INFO - Test: [200/782]	Time 0.572 (0.582)	Loss 3.1716 (3.3588)	Acc@1 52.344 (53.144)	Acc@5 79.688 (77.604)
2023-03-18 06:34:23,733 - INFO - Test: [400/782]	Time 0.590 (0.584)	Loss 3.3021 (3.3174)	Acc@1 55.469 (54.140)	Acc@5 76.562 (78.259)
2023-03-18 06:36:21,870 - INFO - Test: [600/782]	Time 0.601 (0.586)	Loss 3.3078 (3.2798)	Acc@1 49.219 (55.123)	Acc@5 82.812 (78.857)
2023-03-18 06:38:06,940 - INFO -  * Acc@1 55.670 Acc@5 79.463
2023-03-18 06:38:06,940 - INFO - Max accuracy: 56.1110%
2023-03-18 06:38:06,940 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-18 06:38:09,689 - INFO - Train: [19/90][0/3907]	eta 2:58:42 lr 0.03618034	time 2.7445 (2.7445)	loss 3.2101 (3.2101)	acc@1: 63.3189	acc@5: 82.1638	
2023-03-18 06:39:04,710 - INFO - Train: [19/90][300/3907]	eta 0:11:32 lr 0.03618034	time 0.1820 (0.1919)	loss 2.8243 (4.2832)	acc@1: 63.8614	acc@5: 84.8889	
2023-03-18 06:39:59,917 - INFO - Train: [19/90][600/3907]	eta 0:10:21 lr 0.03618034	time 0.1850 (0.1880)	loss 5.8296 (4.3105)	acc@1: 25.0867	acc@5: 40.9064	
2023-03-18 06:40:55,155 - INFO - Train: [19/90][900/3907]	eta 0:09:21 lr 0.03618034	time 0.1839 (0.1867)	loss 5.9886 (4.3393)	acc@1: 22.4620	acc@5: 37.8435	
2023-03-18 06:41:50,419 - INFO - Train: [19/90][1200/3907]	eta 0:08:23 lr 0.03618034	time 0.1845 (0.1861)	loss 5.6189 (4.3442)	acc@1: 36.1053	acc@5: 46.0726	
2023-03-18 06:42:45,699 - INFO - Train: [19/90][1500/3907]	eta 0:07:26 lr 0.03618034	time 0.1855 (0.1857)	loss 6.1353 (4.3290)	acc@1: 23.5239	acc@5: 36.1425	
2023-03-18 06:43:40,734 - INFO - Train: [19/90][1800/3907]	eta 0:06:30 lr 0.03618034	time 0.1886 (0.1853)	loss 3.2679 (4.3208)	acc@1: 62.2250	acc@5: 80.9480	
2023-03-18 06:44:35,945 - INFO - Train: [19/90][2100/3907]	eta 0:05:34 lr 0.03618034	time 0.1852 (0.1851)	loss 3.2419 (4.3211)	acc@1: 59.4027	acc@5: 79.9783	
2023-03-18 06:45:31,237 - INFO - Train: [19/90][2400/3907]	eta 0:04:38 lr 0.03618034	time 0.1890 (0.1850)	loss 3.7682 (4.3349)	acc@1: 52.1829	acc@5: 72.4762	
2023-03-18 06:46:26,419 - INFO - Train: [19/90][2700/3907]	eta 0:03:43 lr 0.03618034	time 0.1891 (0.1849)	loss 2.9492 (4.3384)	acc@1: 62.3038	acc@5: 84.1102	
2023-03-18 06:47:21,575 - INFO - Train: [19/90][3000/3907]	eta 0:02:47 lr 0.03618034	time 0.1805 (0.1848)	loss 5.9623 (4.3512)	acc@1: 25.2338	acc@5: 40.1393	
2023-03-18 06:48:16,804 - INFO - Train: [19/90][3300/3907]	eta 0:01:52 lr 0.03618034	time 0.1929 (0.1847)	loss 4.0546 (4.3578)	acc@1: 52.3554	acc@5: 65.4442	
2023-03-18 06:49:11,984 - INFO - Train: [19/90][3600/3907]	eta 0:00:56 lr 0.03618034	time 0.1801 (0.1847)	loss 5.9346 (4.3640)	acc@1: 26.0723	acc@5: 38.5437	
2023-03-18 06:50:07,246 - INFO - Train: [19/90][3900/3907]	eta 0:00:01 lr 0.03618034	time 0.1793 (0.1846)	loss 2.8584 (4.3682)	acc@1: 64.5936	acc@5: 84.0495	
2023-03-18 06:50:08,561 - INFO - EPOCH 19 training takes 0:12:01
2023-03-18 06:50:09,641 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/fold1_latest.pth saved !!!
2023-03-18 06:50:09,641 - INFO - **********Latest test***********
2023-03-18 06:50:09,641 - INFO - eval epoch 19
2023-03-18 06:50:10,305 - INFO - Test: [0/782]	Time 0.663 (0.663)	Loss 2.7503 (2.7503)	Acc@1 63.281 (63.281)	Acc@5 89.844 (89.844)
2023-03-18 06:52:09,557 - INFO - Test: [200/782]	Time 0.575 (0.597)	Loss 3.0770 (3.1975)	Acc@1 60.156 (55.958)	Acc@5 79.688 (79.310)
2023-03-18 06:54:08,074 - INFO - Test: [400/782]	Time 0.585 (0.595)	Loss 3.0647 (3.1680)	Acc@1 64.844 (56.622)	Acc@5 80.469 (80.036)
2023-03-18 06:56:07,557 - INFO - Test: [600/782]	Time 0.581 (0.596)	Loss 3.2156 (3.1317)	Acc@1 54.688 (57.520)	Acc@5 77.344 (80.707)
2023-03-18 06:57:52,978 - INFO -  * Acc@1 58.035 Acc@5 81.230
2023-03-18 06:57:52,978 - INFO - Max accuracy: 58.0350%
2023-03-18 06:57:54,045 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/fold1_best.pth saved !!!
2023-03-18 06:57:54,046 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-18 06:57:56,753 - INFO - Train: [20/90][0/3907]	eta 2:55:12 lr 0.03576022	time 2.6907 (2.6907)	loss 3.1827 (3.1827)	acc@1: 61.3028	acc@5: 82.2354	
2023-03-18 06:58:51,736 - INFO - Train: [20/90][300/3907]	eta 0:11:31 lr 0.03576022	time 0.1802 (0.1916)	loss 4.9564 (4.1748)	acc@1: 41.0228	acc@5: 58.6215	
2023-03-18 06:59:46,866 - INFO - Train: [20/90][600/3907]	eta 0:10:20 lr 0.03576022	time 0.1804 (0.1877)	loss 3.5213 (4.2094)	acc@1: 57.3000	acc@5: 77.1183	
2023-03-18 07:00:42,090 - INFO - Train: [20/90][900/3907]	eta 0:09:20 lr 0.03576022	time 0.1869 (0.1865)	loss 3.3975 (4.2176)	acc@1: 61.1780	acc@5: 79.8299	
2023-03-18 07:01:37,302 - INFO - Train: [20/90][1200/3907]	eta 0:08:23 lr 0.03576022	time 0.1842 (0.1859)	loss 6.0645 (4.2378)	acc@1: 19.0673	acc@5: 34.1491	
2023-03-18 07:02:32,360 - INFO - Train: [20/90][1500/3907]	eta 0:07:26 lr 0.03576022	time 0.1832 (0.1854)	loss 5.9947 (4.2472)	acc@1: 24.5921	acc@5: 38.2665	
2023-03-18 07:03:27,464 - INFO - Train: [20/90][1800/3907]	eta 0:06:30 lr 0.03576022	time 0.1811 (0.1851)	loss 5.9183 (4.2813)	acc@1: 23.9070	acc@5: 40.8137	
2023-03-18 07:04:22,644 - INFO - Train: [20/90][2100/3907]	eta 0:05:34 lr 0.03576022	time 0.1825 (0.1849)	loss 3.6308 (4.3057)	acc@1: 48.1441	acc@5: 73.3056	
2023-03-18 07:05:17,959 - INFO - Train: [20/90][2400/3907]	eta 0:04:38 lr 0.03576022	time 0.1807 (0.1849)	loss 3.0776 (4.3286)	acc@1: 55.4709	acc@5: 80.1198	
2023-03-18 07:06:13,109 - INFO - Train: [20/90][2700/3907]	eta 0:03:43 lr 0.03576022	time 0.1809 (0.1848)	loss 3.1538 (4.3350)	acc@1: 58.3329	acc@5: 79.3302	
2023-03-18 07:07:08,406 - INFO - Train: [20/90][3000/3907]	eta 0:02:47 lr 0.03576022	time 0.1885 (0.1847)	loss 3.1567 (4.3420)	acc@1: 56.9358	acc@5: 78.4791	
2023-03-18 07:08:03,506 - INFO - Train: [20/90][3300/3907]	eta 0:01:52 lr 0.03576022	time 0.1894 (0.1846)	loss 4.1860 (4.3453)	acc@1: 53.9867	acc@5: 66.4243	
2023-03-18 07:08:58,490 - INFO - Train: [20/90][3600/3907]	eta 0:00:56 lr 0.03576022	time 0.1803 (0.1845)	loss 3.3703 (4.3449)	acc@1: 59.7519	acc@5: 77.1407	
2023-03-18 07:09:53,627 - INFO - Train: [20/90][3900/3907]	eta 0:00:01 lr 0.03576022	time 0.1823 (0.1845)	loss 5.5059 (4.3505)	acc@1: 31.6460	acc@5: 48.7875	
2023-03-18 07:09:54,923 - INFO - EPOCH 20 training takes 0:12:00
2023-03-18 07:09:56,013 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/fold1_latest.pth saved !!!
2023-03-18 07:09:56,014 - INFO - **********Latest test***********
2023-03-18 07:09:56,014 - INFO - eval epoch 20
2023-03-18 07:09:56,623 - INFO - Test: [0/782]	Time 0.606 (0.606)	Loss 2.7817 (2.7817)	Acc@1 61.719 (61.719)	Acc@5 88.281 (88.281)
2023-03-18 07:11:56,407 - INFO - Test: [200/782]	Time 0.583 (0.599)	Loss 3.1730 (3.2378)	Acc@1 58.594 (54.928)	Acc@5 79.688 (78.673)
2023-03-18 07:13:55,967 - INFO - Test: [400/782]	Time 0.593 (0.598)	Loss 3.0644 (3.1975)	Acc@1 58.594 (56.174)	Acc@5 82.031 (79.623)
2023-03-18 07:15:56,063 - INFO - Test: [600/782]	Time 0.583 (0.599)	Loss 3.2731 (3.1661)	Acc@1 53.125 (56.797)	Acc@5 78.125 (80.243)
2023-03-18 07:17:42,328 - INFO -  * Acc@1 57.332 Acc@5 80.787
2023-03-18 07:17:42,328 - INFO - Max accuracy: 58.0350%
2023-03-18 07:17:42,328 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-18 07:17:45,096 - INFO - Train: [21/90][0/3907]	eta 2:59:57 lr 0.03532089	time 2.7635 (2.7635)	loss 2.9266 (2.9266)	acc@1: 67.8210	acc@5: 86.5320	
2023-03-18 07:18:40,126 - INFO - Train: [21/90][300/3907]	eta 0:11:32 lr 0.03532089	time 0.1882 (0.1920)	loss 3.1793 (4.2675)	acc@1: 58.5333	acc@5: 83.3282	
2023-03-18 07:19:35,255 - INFO - Train: [21/90][600/3907]	eta 0:10:21 lr 0.03532089	time 0.1807 (0.1879)	loss 6.1111 (4.1792)	acc@1: 18.4821	acc@5: 34.0701	
2023-03-18 07:20:30,580 - INFO - Train: [21/90][900/3907]	eta 0:09:21 lr 0.03532089	time 0.1814 (0.1867)	loss 3.5980 (4.2208)	acc@1: 56.3718	acc@5: 77.6027	
2023-03-18 07:21:25,835 - INFO - Train: [21/90][1200/3907]	eta 0:08:23 lr 0.03532089	time 0.1863 (0.1861)	loss 4.2123 (4.2479)	acc@1: 48.6388	acc@5: 68.4245	
2023-03-18 07:22:20,965 - INFO - Train: [21/90][1500/3907]	eta 0:07:26 lr 0.03532089	time 0.1886 (0.1856)	loss 5.9797 (4.2338)	acc@1: 20.9768	acc@5: 37.6115	
2023-03-18 07:23:16,014 - INFO - Train: [21/90][1800/3907]	eta 0:06:30 lr 0.03532089	time 0.1801 (0.1853)	loss 4.9860 (4.2619)	acc@1: 43.3492	acc@5: 59.3503	
2023-03-18 07:24:10,602 - INFO - Train: [21/90][2100/3907]	eta 0:05:33 lr 0.03532089	time 0.1800 (0.1848)	loss 3.8747 (4.2728)	acc@1: 60.8539	acc@5: 72.8832	
2023-03-18 07:25:05,287 - INFO - Train: [21/90][2400/3907]	eta 0:04:38 lr 0.03532089	time 0.1805 (0.1845)	loss 3.0221 (4.2757)	acc@1: 64.1525	acc@5: 80.9400	
2023-03-18 07:25:59,941 - INFO - Train: [21/90][2700/3907]	eta 0:03:42 lr 0.03532089	time 0.1829 (0.1842)	loss 3.4537 (4.2715)	acc@1: 58.5064	acc@5: 80.4463	
2023-03-18 07:26:54,749 - INFO - Train: [21/90][3000/3907]	eta 0:02:46 lr 0.03532089	time 0.1801 (0.1841)	loss 4.7168 (4.2879)	acc@1: 44.6049	acc@5: 63.2352	
2023-03-18 07:27:49,327 - INFO - Train: [21/90][3300/3907]	eta 0:01:51 lr 0.03532089	time 0.1800 (0.1839)	loss 5.3618 (4.2968)	acc@1: 34.3291	acc@5: 51.4324	
2023-03-18 07:28:44,215 - INFO - Train: [21/90][3600/3907]	eta 0:00:56 lr 0.03532089	time 0.1803 (0.1838)	loss 4.3195 (4.3034)	acc@1: 46.9786	acc@5: 70.5138	
2023-03-18 07:29:38,909 - INFO - Train: [21/90][3900/3907]	eta 0:00:01 lr 0.03532089	time 0.1797 (0.1837)	loss 3.0860 (4.3160)	acc@1: 61.4881	acc@5: 80.9464	
2023-03-18 07:29:40,186 - INFO - EPOCH 21 training takes 0:11:57
2023-03-18 07:29:41,144 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/fold1_latest.pth saved !!!
2023-03-18 07:29:41,144 - INFO - **********Latest test***********
2023-03-18 07:29:41,144 - INFO - eval epoch 21
2023-03-18 07:29:41,762 - INFO - Test: [0/782]	Time 0.617 (0.617)	Loss 2.6849 (2.6849)	Acc@1 66.406 (66.406)	Acc@5 89.844 (89.844)
2023-03-18 07:31:42,138 - INFO - Test: [200/782]	Time 0.591 (0.602)	Loss 2.9774 (3.1605)	Acc@1 60.938 (56.569)	Acc@5 82.812 (80.123)
2023-03-18 07:33:40,493 - INFO - Test: [400/782]	Time 0.595 (0.597)	Loss 2.9777 (3.1311)	Acc@1 58.594 (57.468)	Acc@5 81.250 (80.658)
2023-03-18 07:35:40,414 - INFO - Test: [600/782]	Time 0.598 (0.598)	Loss 3.1342 (3.0988)	Acc@1 55.469 (58.087)	Acc@5 79.688 (81.214)
2023-03-18 07:37:26,639 - INFO -  * Acc@1 58.623 Acc@5 81.737
2023-03-18 07:37:26,639 - INFO - Max accuracy: 58.6230%
2023-03-18 07:37:27,675 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/fold1_best.pth saved !!!
2023-03-18 07:37:27,676 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-18 07:37:30,198 - INFO - Train: [22/90][0/3907]	eta 2:43:53 lr 0.03486290	time 2.5169 (2.5169)	loss 3.4306 (3.4306)	acc@1: 61.6491	acc@5: 80.7010	
2023-03-18 07:38:24,888 - INFO - Train: [22/90][300/3907]	eta 0:11:25 lr 0.03486290	time 0.1814 (0.1901)	loss 2.7337 (4.1086)	acc@1: 71.8684	acc@5: 87.4920	
2023-03-18 07:39:19,770 - INFO - Train: [22/90][600/3907]	eta 0:10:16 lr 0.03486290	time 0.1795 (0.1865)	loss 2.9844 (4.2336)	acc@1: 67.3301	acc@5: 83.5804	
2023-03-18 07:40:14,497 - INFO - Train: [22/90][900/3907]	eta 0:09:16 lr 0.03486290	time 0.1807 (0.1851)	loss 3.9992 (4.2470)	acc@1: 58.1692	acc@5: 70.5647	
2023-03-18 07:41:09,238 - INFO - Train: [22/90][1200/3907]	eta 0:08:19 lr 0.03486290	time 0.1801 (0.1845)	loss 6.2266 (4.2236)	acc@1: 17.1086	acc@5: 32.5981	
2023-03-18 07:42:03,897 - INFO - Train: [22/90][1500/3907]	eta 0:07:22 lr 0.03486290	time 0.1799 (0.1840)	loss 3.3737 (4.2364)	acc@1: 54.5048	acc@5: 78.3820	
2023-03-18 07:42:58,557 - INFO - Train: [22/90][1800/3907]	eta 0:06:27 lr 0.03486290	time 0.1813 (0.1837)	loss 4.3134 (4.2737)	acc@1: 51.0339	acc@5: 68.2661	
2023-03-18 07:43:53,147 - INFO - Train: [22/90][2100/3907]	eta 0:05:31 lr 0.03486290	time 0.1801 (0.1835)	loss 4.4335 (4.2776)	acc@1: 48.6992	acc@5: 65.1094	
2023-03-18 07:44:47,888 - INFO - Train: [22/90][2400/3907]	eta 0:04:36 lr 0.03486290	time 0.1817 (0.1833)	loss 3.8743 (4.2795)	acc@1: 53.6006	acc@5: 76.9234	
2023-03-18 07:45:42,368 - INFO - Train: [22/90][2700/3907]	eta 0:03:41 lr 0.03486290	time 0.1862 (0.1831)	loss 4.0725 (4.2982)	acc@1: 51.9551	acc@5: 70.7164	
2023-03-18 07:46:37,110 - INFO - Train: [22/90][3000/3907]	eta 0:02:46 lr 0.03486290	time 0.1801 (0.1831)	loss 5.4346 (4.3018)	acc@1: 32.8640	acc@5: 51.3255	
2023-03-18 07:47:31,836 - INFO - Train: [22/90][3300/3907]	eta 0:01:51 lr 0.03486290	time 0.1888 (0.1830)	loss 5.9227 (4.2996)	acc@1: 27.4570	acc@5: 41.2690	
2023-03-18 07:48:26,380 - INFO - Train: [22/90][3600/3907]	eta 0:00:56 lr 0.03486290	time 0.1803 (0.1829)	loss 3.9362 (4.3016)	acc@1: 56.4131	acc@5: 70.8629	
2023-03-18 07:49:21,075 - INFO - Train: [22/90][3900/3907]	eta 0:00:01 lr 0.03486290	time 0.1794 (0.1829)	loss 5.1127 (4.3049)	acc@1: 39.4927	acc@5: 56.6786	
2023-03-18 07:49:22,290 - INFO - EPOCH 22 training takes 0:11:54
2023-03-18 07:49:23,627 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/fold1_latest.pth saved !!!
2023-03-18 07:49:23,628 - INFO - **********Latest test***********
2023-03-18 07:49:23,628 - INFO - eval epoch 22
2023-03-18 07:49:24,237 - INFO - Test: [0/782]	Time 0.608 (0.608)	Loss 2.7027 (2.7027)	Acc@1 65.625 (65.625)	Acc@5 89.062 (89.062)
2023-03-18 07:51:22,339 - INFO - Test: [200/782]	Time 0.583 (0.591)	Loss 3.1370 (3.2318)	Acc@1 60.156 (55.523)	Acc@5 77.344 (78.968)
2023-03-18 07:53:20,639 - INFO - Test: [400/782]	Time 0.590 (0.591)	Loss 3.1374 (3.1956)	Acc@1 57.812 (56.178)	Acc@5 78.906 (79.670)
2023-03-18 07:55:19,613 - INFO - Test: [600/782]	Time 0.589 (0.592)	Loss 3.3880 (3.1564)	Acc@1 46.875 (57.046)	Acc@5 74.219 (80.357)
2023-03-18 07:57:04,673 - INFO -  * Acc@1 57.514 Acc@5 80.889
2023-03-18 07:57:04,673 - INFO - Max accuracy: 58.6230%
2023-03-18 07:57:04,673 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-18 07:57:07,398 - INFO - Train: [23/90][0/3907]	eta 2:57:11 lr 0.03438680	time 2.7212 (2.7212)	loss 2.6523 (2.6523)	acc@1: 69.5000	acc@5: 89.0225	
2023-03-18 07:58:01,952 - INFO - Train: [23/90][300/3907]	eta 0:11:26 lr 0.03438680	time 0.1876 (0.1903)	loss 2.7997 (4.0875)	acc@1: 65.4500	acc@5: 88.0499	
2023-03-18 07:58:56,693 - INFO - Train: [23/90][600/3907]	eta 0:10:16 lr 0.03438680	time 0.1854 (0.1864)	loss 4.9776 (4.1494)	acc@1: 42.8856	acc@5: 59.7538	
2023-03-18 07:59:51,278 - INFO - Train: [23/90][900/3907]	eta 0:09:15 lr 0.03438680	time 0.1800 (0.1849)	loss 3.3935 (4.1567)	acc@1: 62.9470	acc@5: 81.2949	
2023-03-18 08:00:45,994 - INFO - Train: [23/90][1200/3907]	eta 0:08:18 lr 0.03438680	time 0.1802 (0.1843)	loss 4.9902 (4.1937)	acc@1: 43.3820	acc@5: 59.7636	
2023-03-18 08:01:40,713 - INFO - Train: [23/90][1500/3907]	eta 0:07:22 lr 0.03438680	time 0.1800 (0.1839)	loss 4.2244 (4.2178)	acc@1: 51.6806	acc@5: 72.1726	
2023-03-18 08:02:35,452 - INFO - Train: [23/90][1800/3907]	eta 0:06:26 lr 0.03438680	time 0.1801 (0.1837)	loss 6.2000 (4.2227)	acc@1: 18.3415	acc@5: 32.3302	
2023-03-18 08:03:30,015 - INFO - Train: [23/90][2100/3907]	eta 0:05:31 lr 0.03438680	time 0.1787 (0.1834)	loss 3.2382 (4.2268)	acc@1: 61.6356	acc@5: 77.6252	
2023-03-18 08:04:24,473 - INFO - Train: [23/90][2400/3907]	eta 0:04:36 lr 0.03438680	time 0.1806 (0.1832)	loss 6.1598 (4.2409)	acc@1: 17.3998	acc@5: 34.2306	
2023-03-18 08:05:19,155 - INFO - Train: [23/90][2700/3907]	eta 0:03:40 lr 0.03438680	time 0.1799 (0.1831)	loss 6.1892 (4.2485)	acc@1: 21.2376	acc@5: 35.4214	
2023-03-18 08:06:13,645 - INFO - Train: [23/90][3000/3907]	eta 0:02:45 lr 0.03438680	time 0.1787 (0.1829)	loss 4.9617 (4.2636)	acc@1: 43.9206	acc@5: 57.7242	
2023-03-18 08:07:08,243 - INFO - Train: [23/90][3300/3907]	eta 0:01:50 lr 0.03438680	time 0.1794 (0.1828)	loss 4.4946 (4.2571)	acc@1: 48.6420	acc@5: 65.3002	
2023-03-18 08:08:02,918 - INFO - Train: [23/90][3600/3907]	eta 0:00:56 lr 0.03438680	time 0.1861 (0.1828)	loss 5.2351 (4.2772)	acc@1: 35.3462	acc@5: 57.3963	
2023-03-18 08:08:57,469 - INFO - Train: [23/90][3900/3907]	eta 0:00:01 lr 0.03438680	time 0.1865 (0.1827)	loss 3.1779 (4.2883)	acc@1: 60.2642	acc@5: 79.5768	
2023-03-18 08:08:58,795 - INFO - EPOCH 23 training takes 0:11:54
2023-03-18 08:08:59,987 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/fold1_latest.pth saved !!!
2023-03-18 08:08:59,987 - INFO - **********Latest test***********
2023-03-18 08:08:59,988 - INFO - eval epoch 23
2023-03-18 08:09:00,604 - INFO - Test: [0/782]	Time 0.614 (0.614)	Loss 2.7520 (2.7520)	Acc@1 59.375 (59.375)	Acc@5 91.406 (91.406)
2023-03-18 08:10:59,790 - INFO - Test: [200/782]	Time 0.606 (0.596)	Loss 3.1561 (3.1389)	Acc@1 60.156 (56.996)	Acc@5 80.469 (80.558)
2023-03-18 08:12:59,801 - INFO - Test: [400/782]	Time 0.602 (0.598)	Loss 3.0054 (3.1040)	Acc@1 63.281 (57.803)	Acc@5 76.562 (81.036)
2023-03-18 08:14:59,776 - INFO - Test: [600/782]	Time 0.582 (0.599)	Loss 3.0617 (3.0640)	Acc@1 59.375 (58.726)	Acc@5 82.031 (81.701)
2023-03-18 08:16:45,229 - INFO -  * Acc@1 59.236 Acc@5 82.262
2023-03-18 08:16:45,230 - INFO - Max accuracy: 59.2360%
2023-03-18 08:16:46,289 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/fold1_best.pth saved !!!
2023-03-18 08:16:46,290 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-18 08:16:48,595 - INFO - Train: [24/90][0/3907]	eta 2:29:29 lr 0.03389317	time 2.2958 (2.2958)	loss 3.1029 (3.1029)	acc@1: 70.5735	acc@5: 83.1955	
2023-03-18 08:17:42,991 - INFO - Train: [24/90][300/3907]	eta 0:11:19 lr 0.03389317	time 0.1864 (0.1883)	loss 3.9539 (4.2666)	acc@1: 57.9759	acc@5: 74.5141	
2023-03-18 08:18:37,686 - INFO - Train: [24/90][600/3907]	eta 0:10:12 lr 0.03389317	time 0.1807 (0.1853)	loss 5.7938 (4.2254)	acc@1: 24.0185	acc@5: 41.7512	
2023-03-18 08:19:32,281 - INFO - Train: [24/90][900/3907]	eta 0:09:13 lr 0.03389317	time 0.1880 (0.1842)	loss 3.1629 (4.1865)	acc@1: 58.9343	acc@5: 81.9116	
2023-03-18 08:20:26,740 - INFO - Train: [24/90][1200/3907]	eta 0:08:16 lr 0.03389317	time 0.1926 (0.1835)	loss 5.0100 (4.2356)	acc@1: 39.9456	acc@5: 59.3942	
2023-03-18 08:21:21,266 - INFO - Train: [24/90][1500/3907]	eta 0:07:20 lr 0.03389317	time 0.1913 (0.1832)	loss 3.3852 (4.2399)	acc@1: 53.4417	acc@5: 77.0841	
2023-03-18 08:22:15,761 - INFO - Train: [24/90][1800/3907]	eta 0:06:25 lr 0.03389317	time 0.1811 (0.1829)	loss 4.4406 (4.2464)	acc@1: 48.0920	acc@5: 69.3626	
2023-03-18 08:23:10,512 - INFO - Train: [24/90][2100/3907]	eta 0:05:30 lr 0.03389317	time 0.1861 (0.1829)	loss 6.1446 (4.2552)	acc@1: 21.8461	acc@5: 38.0413	
2023-03-18 08:24:05,077 - INFO - Train: [24/90][2400/3907]	eta 0:04:35 lr 0.03389317	time 0.1804 (0.1827)	loss 3.0870 (4.2537)	acc@1: 59.3051	acc@5: 77.2527	
2023-03-18 08:24:59,592 - INFO - Train: [24/90][2700/3907]	eta 0:03:40 lr 0.03389317	time 0.1861 (0.1826)	loss 3.2360 (4.2743)	acc@1: 57.0312	acc@5: 75.7812	
2023-03-18 08:25:54,089 - INFO - Train: [24/90][3000/3907]	eta 0:02:45 lr 0.03389317	time 0.1803 (0.1825)	loss 3.5963 (4.2662)	acc@1: 54.0638	acc@5: 74.5009	
2023-03-18 08:26:48,780 - INFO - Train: [24/90][3300/3907]	eta 0:01:50 lr 0.03389317	time 0.1916 (0.1825)	loss 3.6162 (4.2571)	acc@1: 52.0924	acc@5: 72.2593	
2023-03-18 08:27:43,254 - INFO - Train: [24/90][3600/3907]	eta 0:00:56 lr 0.03389317	time 0.1789 (0.1824)	loss 5.6727 (4.2577)	acc@1: 31.0080	acc@5: 48.5780	
2023-03-18 08:28:37,818 - INFO - Train: [24/90][3900/3907]	eta 0:00:01 lr 0.03389317	time 0.1784 (0.1824)	loss 3.5062 (4.2611)	acc@1: 58.4056	acc@5: 77.1578	
2023-03-18 08:28:39,089 - INFO - EPOCH 24 training takes 0:11:52
2023-03-18 08:28:40,190 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/fold1_latest.pth saved !!!
2023-03-18 08:28:40,191 - INFO - **********Latest test***********
2023-03-18 08:28:40,191 - INFO - eval epoch 24
2023-03-18 08:28:40,802 - INFO - Test: [0/782]	Time 0.608 (0.608)	Loss 2.7247 (2.7247)	Acc@1 63.281 (63.281)	Acc@5 87.500 (87.500)
2023-03-18 08:30:37,716 - INFO - Test: [200/782]	Time 0.580 (0.585)	Loss 3.0202 (3.1940)	Acc@1 60.938 (55.811)	Acc@5 80.469 (79.478)
2023-03-18 08:32:35,099 - INFO - Test: [400/782]	Time 0.590 (0.586)	Loss 2.9432 (3.1549)	Acc@1 63.281 (56.780)	Acc@5 82.812 (80.128)
2023-03-18 08:34:33,421 - INFO - Test: [600/782]	Time 0.582 (0.588)	Loss 3.2346 (3.1216)	Acc@1 59.375 (57.525)	Acc@5 79.688 (80.783)
2023-03-18 08:36:18,257 - INFO -  * Acc@1 58.122 Acc@5 81.398
2023-03-18 08:36:18,258 - INFO - Max accuracy: 59.2360%
2023-03-18 08:36:18,258 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-18 08:36:20,590 - INFO - Train: [25/90][0/3907]	eta 2:31:36 lr 0.03338261	time 2.3283 (2.3283)	loss 6.3036 (6.3036)	acc@1: 18.2318	acc@5: 32.5574	
2023-03-18 08:37:14,871 - INFO - Train: [25/90][300/3907]	eta 0:11:18 lr 0.03338261	time 0.1963 (0.1881)	loss 2.9544 (4.2361)	acc@1: 67.6740	acc@5: 82.2854	
2023-03-18 08:38:09,517 - INFO - Train: [25/90][600/3907]	eta 0:10:12 lr 0.03338261	time 0.1797 (0.1851)	loss 3.9427 (4.2053)	acc@1: 56.3693	acc@5: 74.4664	
2023-03-18 08:39:03,557 - INFO - Train: [25/90][900/3907]	eta 0:09:11 lr 0.03338261	time 0.1835 (0.1835)	loss 4.5854 (4.2329)	acc@1: 50.4895	acc@5: 69.0236	
2023-03-18 08:39:57,584 - INFO - Train: [25/90][1200/3907]	eta 0:08:14 lr 0.03338261	time 0.1798 (0.1826)	loss 6.2373 (4.2511)	acc@1: 17.7790	acc@5: 30.8340	
2023-03-18 08:40:51,791 - INFO - Train: [25/90][1500/3907]	eta 0:07:18 lr 0.03338261	time 0.1782 (0.1822)	loss 3.9042 (4.2512)	acc@1: 52.5350	acc@5: 70.0467	
2023-03-18 08:41:45,865 - INFO - Train: [25/90][1800/3907]	eta 0:06:23 lr 0.03338261	time 0.1789 (0.1819)	loss 2.8468 (4.2578)	acc@1: 65.6238	acc@5: 84.3735	
2023-03-18 08:42:39,846 - INFO - Train: [25/90][2100/3907]	eta 0:05:28 lr 0.03338261	time 0.1788 (0.1816)	loss 3.0118 (4.2578)	acc@1: 64.3669	acc@5: 83.5099	
2023-03-18 08:43:33,811 - INFO - Train: [25/90][2400/3907]	eta 0:04:33 lr 0.03338261	time 0.1786 (0.1814)	loss 2.9925 (4.2567)	acc@1: 65.0579	acc@5: 82.8695	
2023-03-18 08:44:27,858 - INFO - Train: [25/90][2700/3907]	eta 0:03:38 lr 0.03338261	time 0.1780 (0.1813)	loss 2.7752 (4.2570)	acc@1: 66.3415	acc@5: 86.6339	
2023-03-18 08:45:21,957 - INFO - Train: [25/90][3000/3907]	eta 0:02:44 lr 0.03338261	time 0.1788 (0.1812)	loss 2.8071 (4.2564)	acc@1: 65.9720	acc@5: 84.5994	
2023-03-18 08:46:16,001 - INFO - Train: [25/90][3300/3907]	eta 0:01:49 lr 0.03338261	time 0.1790 (0.1811)	loss 4.8588 (4.2524)	acc@1: 41.2368	acc@5: 63.5881	
2023-03-18 08:47:10,255 - INFO - Train: [25/90][3600/3907]	eta 0:00:55 lr 0.03338261	time 0.1785 (0.1811)	loss 5.9189 (4.2635)	acc@1: 24.6258	acc@5: 43.8273	
2023-03-18 08:48:04,586 - INFO - Train: [25/90][3900/3907]	eta 0:00:01 lr 0.03338261	time 0.1791 (0.1811)	loss 4.2848 (4.2708)	acc@1: 50.9159	acc@5: 66.9590	
2023-03-18 08:48:05,903 - INFO - EPOCH 25 training takes 0:11:47
2023-03-18 08:48:06,858 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/fold1_latest.pth saved !!!
2023-03-18 08:48:06,858 - INFO - **********Latest test***********
2023-03-18 08:48:06,858 - INFO - eval epoch 25
2023-03-18 08:48:07,488 - INFO - Test: [0/782]	Time 0.628 (0.628)	Loss 2.7936 (2.7936)	Acc@1 58.594 (58.594)	Acc@5 87.500 (87.500)
2023-03-18 08:50:06,854 - INFO - Test: [200/782]	Time 0.606 (0.597)	Loss 3.0965 (3.2222)	Acc@1 63.281 (56.141)	Acc@5 82.031 (79.590)
2023-03-18 08:52:06,131 - INFO - Test: [400/782]	Time 0.591 (0.597)	Loss 2.9873 (3.1838)	Acc@1 59.375 (56.969)	Acc@5 85.156 (80.399)
2023-03-18 08:54:05,460 - INFO - Test: [600/782]	Time 0.584 (0.597)	Loss 3.1886 (3.1469)	Acc@1 58.594 (57.709)	Acc@5 78.906 (80.980)
2023-03-18 08:55:51,467 - INFO -  * Acc@1 58.165 Acc@5 81.446
2023-03-18 08:55:51,468 - INFO - Max accuracy: 59.2360%
2023-03-18 08:55:51,468 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-18 08:55:54,331 - INFO - Train: [26/90][0/3907]	eta 3:06:11 lr 0.03285575	time 2.8592 (2.8592)	loss 4.0458 (4.0458)	acc@1: 54.4641	acc@5: 72.4808	
2023-03-18 08:56:48,556 - INFO - Train: [26/90][300/3907]	eta 0:11:24 lr 0.03285575	time 0.1785 (0.1896)	loss 2.7497 (4.0932)	acc@1: 68.2879	acc@5: 85.3651	
2023-03-18 08:57:42,841 - INFO - Train: [26/90][600/3907]	eta 0:10:12 lr 0.03285575	time 0.1787 (0.1853)	loss 2.8925 (4.1440)	acc@1: 67.6755	acc@5: 85.5648	
2023-03-18 08:58:37,071 - INFO - Train: [26/90][900/3907]	eta 0:09:12 lr 0.03285575	time 0.1822 (0.1838)	loss 3.4357 (4.1870)	acc@1: 62.2973	acc@5: 78.2906	
2023-03-18 08:59:31,314 - INFO - Train: [26/90][1200/3907]	eta 0:08:15 lr 0.03285575	time 0.1786 (0.1830)	loss 4.0294 (4.1920)	acc@1: 54.1438	acc@5: 70.7762	
2023-03-18 09:00:25,512 - INFO - Train: [26/90][1500/3907]	eta 0:07:19 lr 0.03285575	time 0.1862 (0.1826)	loss 4.9221 (4.1729)	acc@1: 39.9573	acc@5: 60.7172	
2023-03-18 09:01:19,779 - INFO - Train: [26/90][1800/3907]	eta 0:06:24 lr 0.03285575	time 0.1803 (0.1823)	loss 3.7951 (4.1637)	acc@1: 55.3631	acc@5: 72.1823	
2023-03-18 09:02:14,011 - INFO - Train: [26/90][2100/3907]	eta 0:05:29 lr 0.03285575	time 0.1822 (0.1821)	loss 3.6058 (4.1709)	acc@1: 61.8618	acc@5: 74.9620	
2023-03-18 09:03:08,163 - INFO - Train: [26/90][2400/3907]	eta 0:04:34 lr 0.03285575	time 0.1863 (0.1819)	loss 5.9852 (4.1755)	acc@1: 22.9762	acc@5: 40.3466	
2023-03-18 09:04:02,388 - INFO - Train: [26/90][2700/3907]	eta 0:03:39 lr 0.03285575	time 0.1809 (0.1817)	loss 2.5843 (4.1851)	acc@1: 69.4559	acc@5: 85.8442	
2023-03-18 09:04:56,675 - INFO - Train: [26/90][3000/3907]	eta 0:02:44 lr 0.03285575	time 0.1786 (0.1817)	loss 3.4223 (4.1847)	acc@1: 62.5579	acc@5: 79.2739	
2023-03-18 09:05:51,168 - INFO - Train: [26/90][3300/3907]	eta 0:01:50 lr 0.03285575	time 0.1786 (0.1817)	loss 6.3075 (4.2039)	acc@1: 17.0909	acc@5: 33.6932	
2023-03-18 09:06:45,509 - INFO - Train: [26/90][3600/3907]	eta 0:00:55 lr 0.03285575	time 0.1783 (0.1816)	loss 6.1109 (4.2058)	acc@1: 18.3265	acc@5: 34.8117	
2023-03-18 09:07:39,591 - INFO - Train: [26/90][3900/3907]	eta 0:00:01 lr 0.03285575	time 0.1784 (0.1815)	loss 4.0274 (4.2081)	acc@1: 54.6639	acc@5: 74.4436	
2023-03-18 09:07:40,879 - INFO - EPOCH 26 training takes 0:11:49
2023-03-18 09:07:41,951 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/fold1_latest.pth saved !!!
2023-03-18 09:07:41,952 - INFO - **********Latest test***********
2023-03-18 09:07:41,952 - INFO - eval epoch 26
2023-03-18 09:07:42,541 - INFO - Test: [0/782]	Time 0.588 (0.588)	Loss 2.6708 (2.6708)	Acc@1 67.188 (67.188)	Acc@5 85.938 (85.938)
2023-03-18 09:09:38,883 - INFO - Test: [200/782]	Time 0.599 (0.582)	Loss 3.0071 (3.1209)	Acc@1 63.281 (57.276)	Acc@5 78.125 (80.407)
2023-03-18 09:11:36,656 - INFO - Test: [400/782]	Time 0.607 (0.585)	Loss 2.9117 (3.0819)	Acc@1 64.062 (58.173)	Acc@5 82.031 (81.071)
2023-03-18 09:13:35,923 - INFO - Test: [600/782]	Time 0.578 (0.589)	Loss 3.2480 (3.0438)	Acc@1 53.906 (59.006)	Acc@5 76.562 (81.713)
2023-03-18 09:15:22,056 - INFO -  * Acc@1 59.571 Acc@5 82.275
2023-03-18 09:15:22,057 - INFO - Max accuracy: 59.5710%
2023-03-18 09:15:23,114 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/fold1_best.pth saved !!!
2023-03-18 09:15:23,114 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-18 09:15:26,020 - INFO - Train: [27/90][0/3907]	eta 3:08:54 lr 0.03231323	time 2.9011 (2.9011)	loss 3.0320 (3.0320)	acc@1: 62.7041	acc@5: 82.0573	
2023-03-18 09:16:20,138 - INFO - Train: [27/90][300/3907]	eta 0:11:23 lr 0.03231323	time 0.1860 (0.1894)	loss 5.1124 (4.2128)	acc@1: 39.9266	acc@5: 57.3936	
2023-03-18 09:17:14,377 - INFO - Train: [27/90][600/3907]	eta 0:10:12 lr 0.03231323	time 0.1787 (0.1851)	loss 4.6759 (4.2250)	acc@1: 40.3421	acc@5: 63.1017	
2023-03-18 09:18:08,583 - INFO - Train: [27/90][900/3907]	eta 0:09:12 lr 0.03231323	time 0.1783 (0.1836)	loss 2.7547 (4.2330)	acc@1: 65.5044	acc@5: 86.5608	
2023-03-18 09:19:02,654 - INFO - Train: [27/90][1200/3907]	eta 0:08:14 lr 0.03231323	time 0.1792 (0.1828)	loss 3.0194 (4.2125)	acc@1: 70.2483	acc@5: 78.8341	
2023-03-18 09:19:56,959 - INFO - Train: [27/90][1500/3907]	eta 0:07:19 lr 0.03231323	time 0.1786 (0.1824)	loss 3.1369 (4.1997)	acc@1: 63.5560	acc@5: 80.9514	
2023-03-18 09:20:51,196 - INFO - Train: [27/90][1800/3907]	eta 0:06:23 lr 0.03231323	time 0.1790 (0.1822)	loss 2.9261 (4.2059)	acc@1: 59.2421	acc@5: 84.9648	
2023-03-18 09:21:45,404 - INFO - Train: [27/90][2100/3907]	eta 0:05:28 lr 0.03231323	time 0.1789 (0.1819)	loss 5.2409 (4.1885)	acc@1: 38.5230	acc@5: 52.6661	
2023-03-18 09:22:39,609 - INFO - Train: [27/90][2400/3907]	eta 0:04:33 lr 0.03231323	time 0.1794 (0.1818)	loss 5.7928 (4.2028)	acc@1: 27.1912	acc@5: 44.8428	
2023-03-18 09:23:33,820 - INFO - Train: [27/90][2700/3907]	eta 0:03:39 lr 0.03231323	time 0.1792 (0.1817)	loss 6.0635 (4.2134)	acc@1: 20.8205	acc@5: 34.1970	
2023-03-18 09:24:27,959 - INFO - Train: [27/90][3000/3907]	eta 0:02:44 lr 0.03231323	time 0.1787 (0.1815)	loss 5.1765 (4.2210)	acc@1: 39.2069	acc@5: 54.7011	
2023-03-18 09:25:22,111 - INFO - Train: [27/90][3300/3907]	eta 0:01:50 lr 0.03231323	time 0.1805 (0.1815)	loss 6.3797 (4.2300)	acc@1: 17.2567	acc@5: 32.1091	
2023-03-18 09:26:16,325 - INFO - Train: [27/90][3600/3907]	eta 0:00:55 lr 0.03231323	time 0.1853 (0.1814)	loss 2.8636 (4.2375)	acc@1: 64.5640	acc@5: 85.5668	
2023-03-18 09:27:10,545 - INFO - Train: [27/90][3900/3907]	eta 0:00:01 lr 0.03231323	time 0.1784 (0.1813)	loss 2.9878 (4.2476)	acc@1: 57.4957	acc@5: 79.2491	
2023-03-18 09:27:11,824 - INFO - EPOCH 27 training takes 0:11:48
2023-03-18 09:27:12,909 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/fold1_latest.pth saved !!!
2023-03-18 09:27:12,909 - INFO - **********Latest test***********
2023-03-18 09:27:12,909 - INFO - eval epoch 27
2023-03-18 09:27:13,518 - INFO - Test: [0/782]	Time 0.608 (0.608)	Loss 2.8209 (2.8209)	Acc@1 61.719 (61.719)	Acc@5 82.812 (82.812)
2023-03-18 09:29:12,056 - INFO - Test: [200/782]	Time 0.596 (0.593)	Loss 3.0767 (3.1106)	Acc@1 57.031 (57.630)	Acc@5 79.688 (81.025)
2023-03-18 09:31:11,189 - INFO - Test: [400/782]	Time 0.602 (0.594)	Loss 2.7843 (3.0695)	Acc@1 64.062 (58.767)	Acc@5 83.594 (81.601)
2023-03-18 09:33:10,951 - INFO - Test: [600/782]	Time 0.579 (0.596)	Loss 3.1635 (3.0343)	Acc@1 51.562 (59.578)	Acc@5 81.250 (82.226)
2023-03-18 09:34:56,026 - INFO -  * Acc@1 60.054 Acc@5 82.697
2023-03-18 09:34:56,026 - INFO - Max accuracy: 60.0540%
2023-03-18 09:34:57,064 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/fold1_best.pth saved !!!
2023-03-18 09:34:57,064 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-18 09:34:59,934 - INFO - Train: [28/90][0/3907]	eta 3:06:14 lr 0.03175571	time 2.8602 (2.8602)	loss 4.7520 (4.7520)	acc@1: 43.3433	acc@5: 60.4057	
2023-03-18 09:35:54,224 - INFO - Train: [28/90][300/3907]	eta 0:11:24 lr 0.03175571	time 0.1787 (0.1899)	loss 6.0161 (4.0774)	acc@1: 18.9382	acc@5: 34.5632	
2023-03-18 09:36:48,456 - INFO - Train: [28/90][600/3907]	eta 0:10:12 lr 0.03175571	time 0.1788 (0.1853)	loss 5.4473 (4.1021)	acc@1: 32.7549	acc@5: 51.6433	
2023-03-18 09:37:42,731 - INFO - Train: [28/90][900/3907]	eta 0:09:12 lr 0.03175571	time 0.1820 (0.1839)	loss 5.0415 (4.1131)	acc@1: 39.7230	acc@5: 57.7789	
2023-03-18 09:38:36,879 - INFO - Train: [28/90][1200/3907]	eta 0:08:15 lr 0.03175571	time 0.1796 (0.1830)	loss 2.9448 (4.1200)	acc@1: 63.0360	acc@5: 81.7106	
2023-03-18 09:39:30,924 - INFO - Train: [28/90][1500/3907]	eta 0:07:19 lr 0.03175571	time 0.1844 (0.1824)	loss 4.0600 (4.1549)	acc@1: 50.6054	acc@5: 71.4902	
2023-03-18 09:40:24,990 - INFO - Train: [28/90][1800/3907]	eta 0:06:23 lr 0.03175571	time 0.1793 (0.1821)	loss 3.0544 (4.1796)	acc@1: 60.1387	acc@5: 78.8832	
2023-03-18 09:41:19,096 - INFO - Train: [28/90][2100/3907]	eta 0:05:28 lr 0.03175571	time 0.1789 (0.1818)	loss 3.1849 (4.1680)	acc@1: 62.1032	acc@5: 81.0848	
2023-03-18 09:42:13,262 - INFO - Train: [28/90][2400/3907]	eta 0:04:33 lr 0.03175571	time 0.1775 (0.1817)	loss 2.9324 (4.1772)	acc@1: 71.9591	acc@5: 87.8688	
2023-03-18 09:43:06,588 - INFO - Train: [28/90][2700/3907]	eta 0:03:38 lr 0.03175571	time 0.1699 (0.1812)	loss 3.2053 (4.1838)	acc@1: 60.8187	acc@5: 81.3660	
2023-03-18 09:43:58,449 - INFO - Train: [28/90][3000/3907]	eta 0:02:43 lr 0.03175571	time 0.1707 (0.1804)	loss 4.3691 (4.1911)	acc@1: 53.5212	acc@5: 71.8824	
2023-03-18 09:44:50,071 - INFO - Train: [28/90][3300/3907]	eta 0:01:49 lr 0.03175571	time 0.1698 (0.1796)	loss 3.2340 (4.1797)	acc@1: 62.3075	acc@5: 81.2971	
2023-03-18 09:45:41,741 - INFO - Train: [28/90][3600/3907]	eta 0:00:54 lr 0.03175571	time 0.1769 (0.1790)	loss 4.6496 (4.1812)	acc@1: 46.3877	acc@5: 64.4274	
2023-03-18 09:46:33,536 - INFO - Train: [28/90][3900/3907]	eta 0:00:01 lr 0.03175571	time 0.1692 (0.1785)	loss 6.1317 (4.1959)	acc@1: 19.8915	acc@5: 34.6538	
2023-03-18 09:46:34,788 - INFO - EPOCH 28 training takes 0:11:37
2023-03-18 09:46:35,864 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/fold1_latest.pth saved !!!
2023-03-18 09:46:35,864 - INFO - **********Latest test***********
2023-03-18 09:46:35,865 - INFO - eval epoch 28
2023-03-18 09:46:36,466 - INFO - Test: [0/782]	Time 0.598 (0.598)	Loss 2.7449 (2.7449)	Acc@1 65.625 (65.625)	Acc@5 86.719 (86.719)
2023-03-18 09:48:33,240 - INFO - Test: [200/782]	Time 0.589 (0.584)	Loss 2.8801 (3.0129)	Acc@1 62.500 (59.787)	Acc@5 83.594 (82.210)
2023-03-18 09:50:32,311 - INFO - Test: [400/782]	Time 0.599 (0.590)	Loss 2.6988 (2.9814)	Acc@1 65.625 (60.509)	Acc@5 88.281 (82.764)
2023-03-18 09:52:31,627 - INFO - Test: [600/782]	Time 0.593 (0.592)	Loss 3.0134 (2.9499)	Acc@1 60.938 (61.299)	Acc@5 82.812 (83.338)
2023-03-18 09:54:18,370 - INFO -  * Acc@1 61.803 Acc@5 83.789
2023-03-18 09:54:18,370 - INFO - Max accuracy: 61.8030%
2023-03-18 09:54:19,440 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/fold1_best.pth saved !!!
2023-03-18 09:54:19,441 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-18 09:54:21,740 - INFO - Train: [29/90][0/3907]	eta 2:29:17 lr 0.03118386	time 2.2927 (2.2927)	loss 3.2813 (3.2813)	acc@1: 66.7059	acc@5: 78.6980	
2023-03-18 09:55:16,141 - INFO - Train: [29/90][300/3907]	eta 0:11:19 lr 0.03118386	time 0.1899 (0.1883)	loss 3.3258 (3.9740)	acc@1: 62.8714	acc@5: 82.5941	
2023-03-18 09:56:10,485 - INFO - Train: [29/90][600/3907]	eta 0:10:10 lr 0.03118386	time 0.1824 (0.1847)	loss 6.0259 (3.9906)	acc@1: 21.1274	acc@5: 37.3217	
2023-03-18 09:57:04,874 - INFO - Train: [29/90][900/3907]	eta 0:09:12 lr 0.03118386	time 0.1798 (0.1836)	loss 3.6617 (4.0122)	acc@1: 58.7781	acc@5: 76.6982	
2023-03-18 09:57:59,400 - INFO - Train: [29/90][1200/3907]	eta 0:08:15 lr 0.03118386	time 0.1789 (0.1831)	loss 6.0123 (4.0308)	acc@1: 24.1288	acc@5: 38.0151	
2023-03-18 09:58:53,955 - INFO - Train: [29/90][1500/3907]	eta 0:07:20 lr 0.03118386	time 0.1796 (0.1829)	loss 4.7005 (4.0587)	acc@1: 48.2266	acc@5: 63.3450	
2023-03-18 09:59:48,097 - INFO - Train: [29/90][1800/3907]	eta 0:06:24 lr 0.03118386	time 0.1868 (0.1825)	loss 4.3962 (4.0914)	acc@1: 49.1060	acc@5: 67.0231	
2023-03-18 10:00:42,442 - INFO - Train: [29/90][2100/3907]	eta 0:05:29 lr 0.03118386	time 0.1827 (0.1823)	loss 5.0082 (4.1119)	acc@1: 39.4078	acc@5: 58.5422	
2023-03-18 10:01:36,797 - INFO - Train: [29/90][2400/3907]	eta 0:04:34 lr 0.03118386	time 0.1791 (0.1821)	loss 2.9716 (4.1364)	acc@1: 68.8992	acc@5: 85.1546	
2023-03-18 10:02:31,020 - INFO - Train: [29/90][2700/3907]	eta 0:03:39 lr 0.03118386	time 0.1791 (0.1820)	loss 5.9412 (4.1501)	acc@1: 25.2784	acc@5: 44.5302	
2023-03-18 10:03:25,241 - INFO - Train: [29/90][3000/3907]	eta 0:02:44 lr 0.03118386	time 0.1796 (0.1819)	loss 4.7763 (4.1635)	acc@1: 46.1933	acc@5: 62.1834	
2023-03-18 10:04:19,468 - INFO - Train: [29/90][3300/3907]	eta 0:01:50 lr 0.03118386	time 0.1815 (0.1818)	loss 2.7766 (4.1728)	acc@1: 67.1252	acc@5: 85.0771	
2023-03-18 10:05:13,791 - INFO - Train: [29/90][3600/3907]	eta 0:00:55 lr 0.03118386	time 0.1790 (0.1817)	loss 3.2287 (4.1804)	acc@1: 62.3948	acc@5: 77.6080	
2023-03-18 10:06:08,176 - INFO - Train: [29/90][3900/3907]	eta 0:00:01 lr 0.03118386	time 0.1780 (0.1817)	loss 3.3291 (4.1827)	acc@1: 57.2414	acc@5: 78.6047	
2023-03-18 10:06:09,419 - INFO - EPOCH 29 training takes 0:11:49
2023-03-18 10:06:10,484 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/fold1_latest.pth saved !!!
2023-03-18 10:06:10,485 - INFO - **********Latest test***********
2023-03-18 10:06:10,485 - INFO - eval epoch 29
2023-03-18 10:06:11,083 - INFO - Test: [0/782]	Time 0.597 (0.597)	Loss 2.7126 (2.7126)	Acc@1 66.406 (66.406)	Acc@5 89.062 (89.062)
2023-03-18 10:08:10,328 - INFO - Test: [200/782]	Time 0.586 (0.596)	Loss 3.0089 (3.0818)	Acc@1 60.156 (58.423)	Acc@5 81.250 (81.452)
2023-03-18 10:10:08,958 - INFO - Test: [400/782]	Time 0.601 (0.595)	Loss 2.8396 (3.0412)	Acc@1 63.281 (59.338)	Acc@5 85.156 (82.123)
2023-03-18 10:12:08,739 - INFO - Test: [600/782]	Time 0.583 (0.596)	Loss 3.0618 (3.0028)	Acc@1 60.156 (60.243)	Acc@5 82.031 (82.729)
2023-03-18 10:13:55,260 - INFO -  * Acc@1 60.657 Acc@5 83.206
2023-03-18 10:13:55,260 - INFO - Max accuracy: 61.8030%
2023-03-18 10:13:55,261 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-18 10:13:58,108 - INFO - Train: [30/90][0/3907]	eta 3:05:10 lr 0.03059839	time 2.8438 (2.8438)	loss 2.7709 (2.7709)	acc@1: 67.8176	acc@5: 87.0839	
2023-03-18 10:14:52,287 - INFO - Train: [30/90][300/3907]	eta 0:11:23 lr 0.03059839	time 0.1862 (0.1894)	loss 3.4142 (4.1636)	acc@1: 63.4441	acc@5: 80.9459	
2023-03-18 10:15:46,454 - INFO - Train: [30/90][600/3907]	eta 0:10:11 lr 0.03059839	time 0.1844 (0.1850)	loss 4.8019 (4.1057)	acc@1: 43.7270	acc@5: 64.0508	
2023-03-18 10:16:40,668 - INFO - Train: [30/90][900/3907]	eta 0:09:12 lr 0.03059839	time 0.1789 (0.1836)	loss 4.1728 (4.1221)	acc@1: 53.4348	acc@5: 70.5472	
2023-03-18 10:17:34,823 - INFO - Train: [30/90][1200/3907]	eta 0:08:14 lr 0.03059839	time 0.1827 (0.1828)	loss 5.7513 (4.1174)	acc@1: 27.1484	acc@5: 41.9868	
2023-03-18 10:18:29,056 - INFO - Train: [30/90][1500/3907]	eta 0:07:19 lr 0.03059839	time 0.1848 (0.1824)	loss 2.7965 (4.1278)	acc@1: 66.8851	acc@5: 85.5498	
2023-03-18 10:19:23,304 - INFO - Train: [30/90][1800/3907]	eta 0:06:23 lr 0.03059839	time 0.1795 (0.1821)	loss 2.9917 (4.1405)	acc@1: 61.4607	acc@5: 86.0450	
2023-03-18 10:20:17,559 - INFO - Train: [30/90][2100/3907]	eta 0:05:28 lr 0.03059839	time 0.1793 (0.1820)	loss 5.9896 (4.1515)	acc@1: 21.3711	acc@5: 37.6401	
2023-03-18 10:21:11,719 - INFO - Train: [30/90][2400/3907]	eta 0:04:33 lr 0.03059839	time 0.1793 (0.1818)	loss 5.5064 (4.1642)	acc@1: 36.3660	acc@5: 46.6975	
2023-03-18 10:22:05,821 - INFO - Train: [30/90][2700/3907]	eta 0:03:39 lr 0.03059839	time 0.1790 (0.1816)	loss 2.5889 (4.1611)	acc@1: 67.7741	acc@5: 92.7025	
2023-03-18 10:22:59,932 - INFO - Train: [30/90][3000/3907]	eta 0:02:44 lr 0.03059839	time 0.1787 (0.1815)	loss 4.7679 (4.1677)	acc@1: 49.3235	acc@5: 64.7206	
2023-03-18 10:23:53,975 - INFO - Train: [30/90][3300/3907]	eta 0:01:50 lr 0.03059839	time 0.1785 (0.1814)	loss 5.9384 (4.1682)	acc@1: 26.8593	acc@5: 39.5283	
2023-03-18 10:24:48,035 - INFO - Train: [30/90][3600/3907]	eta 0:00:55 lr 0.03059839	time 0.1792 (0.1813)	loss 5.5806 (4.1737)	acc@1: 33.4950	acc@5: 45.4021	
2023-03-18 10:25:42,166 - INFO - Train: [30/90][3900/3907]	eta 0:00:01 lr 0.03059839	time 0.1780 (0.1812)	loss 3.0851 (4.1761)	acc@1: 65.1949	acc@5: 84.9282	
2023-03-18 10:25:43,397 - INFO - EPOCH 30 training takes 0:11:48
2023-03-18 10:25:44,496 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/fold1_latest.pth saved !!!
2023-03-18 10:25:44,496 - INFO - **********Latest test***********
2023-03-18 10:25:44,496 - INFO - eval epoch 30
2023-03-18 10:25:45,117 - INFO - Test: [0/782]	Time 0.620 (0.620)	Loss 2.5806 (2.5806)	Acc@1 67.188 (67.188)	Acc@5 92.188 (92.188)
2023-03-18 10:27:43,197 - INFO - Test: [200/782]	Time 0.584 (0.591)	Loss 3.0692 (3.1620)	Acc@1 64.062 (57.676)	Acc@5 82.812 (80.648)
2023-03-18 10:29:41,498 - INFO - Test: [400/782]	Time 0.586 (0.591)	Loss 3.0315 (3.1238)	Acc@1 62.500 (58.485)	Acc@5 83.594 (81.332)
2023-03-18 10:31:40,157 - INFO - Test: [600/782]	Time 0.585 (0.592)	Loss 3.1675 (3.0895)	Acc@1 58.594 (59.298)	Acc@5 82.812 (82.018)
2023-03-18 10:33:25,515 - INFO -  * Acc@1 59.836 Acc@5 82.515
2023-03-18 10:33:25,515 - INFO - Max accuracy: 61.8030%
2023-03-18 10:33:25,515 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-18 10:33:28,440 - INFO - Train: [31/90][0/3907]	eta 3:10:11 lr 0.03000000	time 2.9209 (2.9209)	loss 4.2954 (4.2954)	acc@1: 50.3988	acc@5: 69.7480	
2023-03-18 10:34:22,549 - INFO - Train: [31/90][300/3907]	eta 0:11:23 lr 0.03000000	time 0.1783 (0.1895)	loss 4.6343 (4.0406)	acc@1: 43.4675	acc@5: 64.4920	
2023-03-18 10:35:16,369 - INFO - Train: [31/90][600/3907]	eta 0:10:09 lr 0.03000000	time 0.1796 (0.1844)	loss 3.2123 (4.0787)	acc@1: 60.2726	acc@5: 83.6282	
2023-03-18 10:36:10,419 - INFO - Train: [31/90][900/3907]	eta 0:09:10 lr 0.03000000	time 0.1788 (0.1830)	loss 4.1131 (4.1092)	acc@1: 54.3244	acc@5: 71.7619	
2023-03-18 10:37:04,474 - INFO - Train: [31/90][1200/3907]	eta 0:08:13 lr 0.03000000	time 0.1824 (0.1823)	loss 3.4382 (4.1331)	acc@1: 61.5102	acc@5: 79.0704	
2023-03-18 10:37:58,598 - INFO - Train: [31/90][1500/3907]	eta 0:07:17 lr 0.03000000	time 0.1885 (0.1819)	loss 5.5851 (4.1466)	acc@1: 32.7710	acc@5: 47.0347	
2023-03-18 10:38:52,716 - INFO - Train: [31/90][1800/3907]	eta 0:06:22 lr 0.03000000	time 0.1783 (0.1817)	loss 2.5864 (4.1633)	acc@1: 71.0593	acc@5: 89.8003	
2023-03-18 10:39:46,733 - INFO - Train: [31/90][2100/3907]	eta 0:05:27 lr 0.03000000	time 0.1813 (0.1814)	loss 2.9254 (4.1615)	acc@1: 65.6055	acc@5: 83.3645	
2023-03-18 10:40:40,773 - INFO - Train: [31/90][2400/3907]	eta 0:04:33 lr 0.03000000	time 0.1789 (0.1813)	loss 5.0546 (4.1609)	acc@1: 40.3619	acc@5: 54.5443	
2023-03-18 10:41:34,921 - INFO - Train: [31/90][2700/3907]	eta 0:03:38 lr 0.03000000	time 0.1864 (0.1812)	loss 3.1076 (4.1627)	acc@1: 60.6815	acc@5: 82.1975	
2023-03-18 10:42:29,301 - INFO - Train: [31/90][3000/3907]	eta 0:02:44 lr 0.03000000	time 0.1789 (0.1812)	loss 4.2348 (4.1539)	acc@1: 49.4028	acc@5: 70.0986	
2023-03-18 10:43:23,463 - INFO - Train: [31/90][3300/3907]	eta 0:01:49 lr 0.03000000	time 0.1796 (0.1811)	loss 2.9004 (4.1574)	acc@1: 61.7433	acc@5: 84.1252	
2023-03-18 10:44:17,596 - INFO - Train: [31/90][3600/3907]	eta 0:00:55 lr 0.03000000	time 0.1868 (0.1811)	loss 3.7094 (4.1651)	acc@1: 62.3829	acc@5: 75.8520	
2023-03-18 10:45:11,678 - INFO - Train: [31/90][3900/3907]	eta 0:00:01 lr 0.03000000	time 0.1787 (0.1810)	loss 6.1506 (4.1672)	acc@1: 20.1129	acc@5: 34.4026	
2023-03-18 10:45:12,953 - INFO - EPOCH 31 training takes 0:11:47
2023-03-18 10:45:14,028 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/fold1_latest.pth saved !!!
2023-03-18 10:45:14,028 - INFO - **********Latest test***********
2023-03-18 10:45:14,028 - INFO - eval epoch 31
2023-03-18 10:45:14,640 - INFO - Test: [0/782]	Time 0.610 (0.610)	Loss 2.6425 (2.6425)	Acc@1 66.406 (66.406)	Acc@5 89.062 (89.062)
2023-03-18 10:47:13,559 - INFO - Test: [200/782]	Time 0.592 (0.595)	Loss 2.8729 (3.0768)	Acc@1 66.406 (58.741)	Acc@5 82.031 (81.367)
2023-03-18 10:49:11,634 - INFO - Test: [400/782]	Time 0.583 (0.593)	Loss 2.8767 (3.0430)	Acc@1 61.719 (59.550)	Acc@5 82.812 (82.059)
2023-03-18 10:51:08,175 - INFO - Test: [600/782]	Time 0.567 (0.589)	Loss 3.1292 (3.0063)	Acc@1 57.031 (60.505)	Acc@5 78.906 (82.636)
2023-03-18 10:52:52,851 - INFO -  * Acc@1 61.003 Acc@5 83.103
2023-03-18 10:52:52,852 - INFO - Max accuracy: 61.8030%
2023-03-18 10:52:52,852 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-18 10:52:55,050 - INFO - Train: [32/90][0/3907]	eta 2:22:55 lr 0.02938943	time 2.1950 (2.1950)	loss 3.4538 (3.4538)	acc@1: 60.6804	acc@5: 81.6090	
2023-03-18 10:53:49,173 - INFO - Train: [32/90][300/3907]	eta 0:11:14 lr 0.02938943	time 0.1789 (0.1871)	loss 3.2251 (4.0906)	acc@1: 61.2575	acc@5: 74.8953	
2023-03-18 10:54:43,629 - INFO - Train: [32/90][600/3907]	eta 0:10:09 lr 0.02938943	time 0.1797 (0.1843)	loss 3.7299 (4.1364)	acc@1: 57.3868	acc@5: 77.4968	
2023-03-18 10:55:37,811 - INFO - Train: [32/90][900/3907]	eta 0:09:10 lr 0.02938943	time 0.1803 (0.1831)	loss 6.1679 (4.1330)	acc@1: 17.2523	acc@5: 33.7883	
2023-03-18 10:56:32,163 - INFO - Train: [32/90][1200/3907]	eta 0:08:14 lr 0.02938943	time 0.1794 (0.1826)	loss 4.7142 (4.1196)	acc@1: 48.7169	acc@5: 67.1580	
2023-03-18 10:57:26,703 - INFO - Train: [32/90][1500/3907]	eta 0:07:19 lr 0.02938943	time 0.1797 (0.1824)	loss 5.2932 (4.1381)	acc@1: 38.4866	acc@5: 54.2390	
2023-03-18 10:58:21,062 - INFO - Train: [32/90][1800/3907]	eta 0:06:23 lr 0.02938943	time 0.1795 (0.1822)	loss 6.0741 (4.1420)	acc@1: 23.1209	acc@5: 37.4367	
2023-03-18 10:59:15,187 - INFO - Train: [32/90][2100/3907]	eta 0:05:28 lr 0.02938943	time 0.1793 (0.1820)	loss 4.0545 (4.1547)	acc@1: 52.2283	acc@5: 72.9858	
2023-03-18 11:00:09,274 - INFO - Train: [32/90][2400/3907]	eta 0:04:33 lr 0.02938943	time 0.1796 (0.1818)	loss 3.1576 (4.1611)	acc@1: 68.0855	acc@5: 86.0243	
2023-03-18 11:01:03,569 - INFO - Train: [32/90][2700/3907]	eta 0:03:39 lr 0.02938943	time 0.1842 (0.1817)	loss 6.2974 (4.1695)	acc@1: 20.2649	acc@5: 34.5560	
2023-03-18 11:01:58,616 - INFO - Train: [32/90][3000/3907]	eta 0:02:44 lr 0.02938943	time 0.1815 (0.1819)	loss 4.1691 (4.1623)	acc@1: 55.3632	acc@5: 70.2167	
2023-03-18 11:02:53,037 - INFO - Train: [32/90][3300/3907]	eta 0:01:50 lr 0.02938943	time 0.1795 (0.1818)	loss 5.8606 (4.1703)	acc@1: 27.2441	acc@5: 38.0779	
2023-03-18 11:03:47,102 - INFO - Train: [32/90][3600/3907]	eta 0:00:55 lr 0.02938943	time 0.1857 (0.1817)	loss 5.8121 (4.1763)	acc@1: 28.9802	acc@5: 40.2731	
2023-03-18 11:04:41,226 - INFO - Train: [32/90][3900/3907]	eta 0:00:01 lr 0.02938943	time 0.1783 (0.1816)	loss 2.6376 (4.1787)	acc@1: 72.8185	acc@5: 89.6817	
2023-03-18 11:04:42,451 - INFO - EPOCH 32 training takes 0:11:49
2023-03-18 11:04:43,515 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/fold1_latest.pth saved !!!
2023-03-18 11:04:43,518 - INFO - **********Latest test***********
2023-03-18 11:04:43,518 - INFO - eval epoch 32
2023-03-18 11:04:44,150 - INFO - Test: [0/782]	Time 0.628 (0.628)	Loss 2.6704 (2.6704)	Acc@1 62.500 (62.500)	Acc@5 91.406 (91.406)
2023-03-18 11:06:42,117 - INFO - Test: [200/782]	Time 0.589 (0.590)	Loss 2.9164 (3.0623)	Acc@1 60.156 (59.398)	Acc@5 83.594 (81.915)
2023-03-18 11:08:40,342 - INFO - Test: [400/782]	Time 0.602 (0.591)	Loss 2.9444 (3.0261)	Acc@1 60.156 (60.184)	Acc@5 82.812 (82.659)
2023-03-18 11:10:40,970 - INFO - Test: [600/782]	Time 0.626 (0.595)	Loss 3.0693 (2.9885)	Acc@1 60.156 (61.087)	Acc@5 82.812 (83.208)
2023-03-18 11:12:27,533 - INFO -  * Acc@1 61.602 Acc@5 83.650
2023-03-18 11:12:27,533 - INFO - Max accuracy: 61.8030%
2023-03-18 11:12:27,533 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-18 11:12:29,677 - INFO - Train: [33/90][0/3907]	eta 2:19:16 lr 0.02876742	time 2.1389 (2.1389)	loss 2.7070 (2.7070)	acc@1: 69.4056	acc@5: 85.7819	
2023-03-18 11:13:23,637 - INFO - Train: [33/90][300/3907]	eta 0:11:12 lr 0.02876742	time 0.1811 (0.1864)	loss 2.8455 (3.9781)	acc@1: 65.3708	acc@5: 84.0512	
2023-03-18 11:14:17,797 - INFO - Train: [33/90][600/3907]	eta 0:10:06 lr 0.02876742	time 0.1796 (0.1835)	loss 4.0065 (4.0096)	acc@1: 56.3174	acc@5: 71.7069	
2023-03-18 11:15:12,057 - INFO - Train: [33/90][900/3907]	eta 0:09:09 lr 0.02876742	time 0.1794 (0.1826)	loss 2.7798 (4.0562)	acc@1: 76.2744	acc@5: 86.9475	
2023-03-18 11:16:06,285 - INFO - Train: [33/90][1200/3907]	eta 0:08:13 lr 0.02876742	time 0.1798 (0.1821)	loss 5.9046 (4.0446)	acc@1: 24.6805	acc@5: 38.6786	
2023-03-18 11:17:00,659 - INFO - Train: [33/90][1500/3907]	eta 0:07:17 lr 0.02876742	time 0.1792 (0.1820)	loss 6.2409 (4.0511)	acc@1: 19.9783	acc@5: 31.2626	
2023-03-18 11:17:54,910 - INFO - Train: [33/90][1800/3907]	eta 0:06:22 lr 0.02876742	time 0.1800 (0.1818)	loss 6.3390 (4.0603)	acc@1: 15.6088	acc@5: 28.4492	
2023-03-18 11:18:49,016 - INFO - Train: [33/90][2100/3907]	eta 0:05:28 lr 0.02876742	time 0.1791 (0.1816)	loss 2.8354 (4.0710)	acc@1: 68.6262	acc@5: 85.0026	
2023-03-18 11:19:43,097 - INFO - Train: [33/90][2400/3907]	eta 0:04:33 lr 0.02876742	time 0.1801 (0.1814)	loss 2.8172 (4.0909)	acc@1: 63.1811	acc@5: 85.8027	
2023-03-18 11:20:37,242 - INFO - Train: [33/90][2700/3907]	eta 0:03:38 lr 0.02876742	time 0.1859 (0.1813)	loss 5.3294 (4.1034)	acc@1: 39.2179	acc@5: 51.5590	
2023-03-18 11:21:31,540 - INFO - Train: [33/90][3000/3907]	eta 0:02:44 lr 0.02876742	time 0.1795 (0.1813)	loss 2.6615 (4.1024)	acc@1: 69.4149	acc@5: 88.1336	
2023-03-18 11:22:25,743 - INFO - Train: [33/90][3300/3907]	eta 0:01:49 lr 0.02876742	time 0.1795 (0.1812)	loss 4.8009 (4.1060)	acc@1: 44.9377	acc@5: 63.7366	
2023-03-18 11:23:19,846 - INFO - Train: [33/90][3600/3907]	eta 0:00:55 lr 0.02876742	time 0.1809 (0.1811)	loss 6.0206 (4.1275)	acc@1: 20.1252	acc@5: 35.8356	
2023-03-18 11:24:14,291 - INFO - Train: [33/90][3900/3907]	eta 0:00:01 lr 0.02876742	time 0.1852 (0.1812)	loss 3.8253 (4.1357)	acc@1: 58.7070	acc@5: 73.8780	
2023-03-18 11:24:15,513 - INFO - EPOCH 33 training takes 0:11:47
2023-03-18 11:24:16,451 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/fold1_latest.pth saved !!!
2023-03-18 11:24:16,451 - INFO - **********Latest test***********
2023-03-18 11:24:16,451 - INFO - eval epoch 33
2023-03-18 11:24:17,034 - INFO - Test: [0/782]	Time 0.581 (0.581)	Loss 2.6867 (2.6867)	Acc@1 62.500 (62.500)	Acc@5 90.625 (90.625)
2023-03-18 11:26:16,299 - INFO - Test: [200/782]	Time 0.607 (0.596)	Loss 3.0343 (3.0094)	Acc@1 57.812 (59.915)	Acc@5 82.031 (82.327)
2023-03-18 11:28:15,430 - INFO - Test: [400/782]	Time 0.597 (0.596)	Loss 2.9594 (2.9716)	Acc@1 61.719 (60.764)	Acc@5 78.125 (83.029)
2023-03-18 11:30:15,115 - INFO - Test: [600/782]	Time 0.591 (0.597)	Loss 2.9838 (2.9366)	Acc@1 63.281 (61.624)	Acc@5 83.594 (83.589)
2023-03-18 11:32:01,851 - INFO -  * Acc@1 62.138 Acc@5 84.087
2023-03-18 11:32:01,851 - INFO - Max accuracy: 62.1380%
2023-03-18 11:32:02,792 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/fold1_best.pth saved !!!
2023-03-18 11:32:02,793 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-18 11:32:05,673 - INFO - Train: [34/90][0/3907]	eta 3:07:12 lr 0.02813473	time 2.8751 (2.8751)	loss 2.7532 (2.7532)	acc@1: 68.6880	acc@5: 84.8952	
2023-03-18 11:32:59,847 - INFO - Train: [34/90][300/3907]	eta 0:11:23 lr 0.02813473	time 0.1859 (0.1895)	loss 5.4866 (4.0762)	acc@1: 36.1554	acc@5: 49.6014	
2023-03-18 11:33:54,194 - INFO - Train: [34/90][600/3907]	eta 0:10:12 lr 0.02813473	time 0.1801 (0.1853)	loss 3.6888 (4.0310)	acc@1: 58.6045	acc@5: 77.6686	
2023-03-18 11:34:48,488 - INFO - Train: [34/90][900/3907]	eta 0:09:12 lr 0.02813473	time 0.1800 (0.1839)	loss 2.7667 (4.0188)	acc@1: 64.7517	acc@5: 85.8166	
2023-03-18 11:35:42,739 - INFO - Train: [34/90][1200/3907]	eta 0:08:15 lr 0.02813473	time 0.1798 (0.1831)	loss 3.2601 (4.0375)	acc@1: 59.5907	acc@5: 78.4671	
2023-03-18 11:36:36,914 - INFO - Train: [34/90][1500/3907]	eta 0:07:19 lr 0.02813473	time 0.1800 (0.1826)	loss 3.0676 (4.0523)	acc@1: 64.7942	acc@5: 85.8900	
2023-03-18 11:37:31,030 - INFO - Train: [34/90][1800/3907]	eta 0:06:23 lr 0.02813473	time 0.1799 (0.1822)	loss 5.9037 (4.0665)	acc@1: 21.2060	acc@5: 37.4070	
2023-03-18 11:38:25,224 - INFO - Train: [34/90][2100/3907]	eta 0:05:28 lr 0.02813473	time 0.1792 (0.1820)	loss 4.0172 (4.0694)	acc@1: 52.0481	acc@5: 72.3499	
2023-03-18 11:39:19,395 - INFO - Train: [34/90][2400/3907]	eta 0:04:34 lr 0.02813473	time 0.1799 (0.1818)	loss 3.0539 (4.0718)	acc@1: 61.8077	acc@5: 81.9011	
2023-03-18 11:40:13,727 - INFO - Train: [34/90][2700/3907]	eta 0:03:39 lr 0.02813473	time 0.1903 (0.1818)	loss 6.0738 (4.0788)	acc@1: 22.2895	acc@5: 35.2596	
2023-03-18 11:41:07,973 - INFO - Train: [34/90][3000/3907]	eta 0:02:44 lr 0.02813473	time 0.1797 (0.1817)	loss 5.3364 (4.0907)	acc@1: 30.7066	acc@5: 52.6150	
2023-03-18 11:42:02,219 - INFO - Train: [34/90][3300/3907]	eta 0:01:50 lr 0.02813473	time 0.1793 (0.1816)	loss 5.4478 (4.1038)	acc@1: 32.1484	acc@5: 50.5814	
2023-03-18 11:42:56,511 - INFO - Train: [34/90][3600/3907]	eta 0:00:55 lr 0.02813473	time 0.1799 (0.1815)	loss 4.7664 (4.1138)	acc@1: 40.3234	acc@5: 63.3471	
2023-03-18 11:43:51,266 - INFO - Train: [34/90][3900/3907]	eta 0:00:01 lr 0.02813473	time 0.1785 (0.1816)	loss 5.3265 (4.1222)	acc@1: 36.6935	acc@5: 53.9070	
2023-03-18 11:43:52,469 - INFO - EPOCH 34 training takes 0:11:49
2023-03-18 11:43:53,549 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/fold1_latest.pth saved !!!
2023-03-18 11:43:53,549 - INFO - **********Latest test***********
2023-03-18 11:43:53,549 - INFO - eval epoch 34
2023-03-18 11:43:54,159 - INFO - Test: [0/782]	Time 0.608 (0.608)	Loss 2.6989 (2.6989)	Acc@1 66.406 (66.406)	Acc@5 85.156 (85.156)
2023-03-18 11:45:51,212 - INFO - Test: [200/782]	Time 0.582 (0.585)	Loss 3.0247 (3.0022)	Acc@1 59.375 (60.479)	Acc@5 78.125 (82.844)
2023-03-18 11:47:48,995 - INFO - Test: [400/782]	Time 0.612 (0.587)	Loss 2.8048 (2.9697)	Acc@1 66.406 (61.460)	Acc@5 84.375 (83.409)
2023-03-18 11:49:48,692 - INFO - Test: [600/782]	Time 0.583 (0.591)	Loss 2.9570 (2.9352)	Acc@1 64.844 (62.292)	Acc@5 85.156 (83.946)
2023-03-18 11:51:35,393 - INFO -  * Acc@1 62.852 Acc@5 84.342
2023-03-18 11:51:35,394 - INFO - Max accuracy: 62.8520%
2023-03-18 11:51:36,435 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/fold1_best.pth saved !!!
2023-03-18 11:51:36,435 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-18 11:51:38,571 - INFO - Train: [35/90][0/3907]	eta 2:18:45 lr 0.02749213	time 2.1310 (2.1310)	loss 2.8679 (2.8679)	acc@1: 64.0542	acc@5: 79.6772	
2023-03-18 11:52:33,438 - INFO - Train: [35/90][300/3907]	eta 0:11:23 lr 0.02749213	time 0.1786 (0.1894)	loss 3.1269 (3.9688)	acc@1: 64.2824	acc@5: 84.9710	
2023-03-18 11:53:28,121 - INFO - Train: [35/90][600/3907]	eta 0:10:14 lr 0.02749213	time 0.1796 (0.1858)	loss 3.0735 (4.0284)	acc@1: 64.8899	acc@5: 80.1450	
2023-03-18 11:54:22,617 - INFO - Train: [35/90][900/3907]	eta 0:09:14 lr 0.02749213	time 0.1794 (0.1844)	loss 6.1045 (3.9979)	acc@1: 22.1732	acc@5: 32.3376	
2023-03-18 11:55:16,910 - INFO - Train: [35/90][1200/3907]	eta 0:08:16 lr 0.02749213	time 0.1797 (0.1836)	loss 4.8225 (4.0250)	acc@1: 45.2324	acc@5: 61.7833	
2023-03-18 11:56:11,156 - INFO - Train: [35/90][1500/3907]	eta 0:07:20 lr 0.02749213	time 0.1800 (0.1830)	loss 2.6441 (4.0500)	acc@1: 76.2222	acc@5: 86.2282	
2023-03-18 11:57:05,562 - INFO - Train: [35/90][1800/3907]	eta 0:06:25 lr 0.02749213	time 0.1825 (0.1827)	loss 3.0934 (4.0501)	acc@1: 65.3160	acc@5: 83.1187	
2023-03-18 11:58:00,106 - INFO - Train: [35/90][2100/3907]	eta 0:05:29 lr 0.02749213	time 0.1855 (0.1826)	loss 2.9782 (4.0537)	acc@1: 66.5396	acc@5: 78.1454	
2023-03-18 11:58:54,324 - INFO - Train: [35/90][2400/3907]	eta 0:04:34 lr 0.02749213	time 0.1799 (0.1824)	loss 5.3283 (4.0656)	acc@1: 34.2108	acc@5: 53.7709	
2023-03-18 11:59:48,678 - INFO - Train: [35/90][2700/3907]	eta 0:03:39 lr 0.02749213	time 0.1795 (0.1822)	loss 2.6733 (4.0676)	acc@1: 69.4076	acc@5: 88.1243	
2023-03-18 12:00:43,203 - INFO - Train: [35/90][3000/3907]	eta 0:02:45 lr 0.02749213	time 0.1800 (0.1822)	loss 4.3839 (4.0830)	acc@1: 51.2104	acc@5: 70.6574	
2023-03-18 12:01:37,709 - INFO - Train: [35/90][3300/3907]	eta 0:01:50 lr 0.02749213	time 0.1794 (0.1821)	loss 2.7683 (4.0888)	acc@1: 69.5112	acc@5: 85.1319	
2023-03-18 12:02:32,135 - INFO - Train: [35/90][3600/3907]	eta 0:00:55 lr 0.02749213	time 0.1874 (0.1821)	loss 3.9048 (4.0853)	acc@1: 54.9055	acc@5: 71.7754	
2023-03-18 12:03:26,470 - INFO - Train: [35/90][3900/3907]	eta 0:00:01 lr 0.02749213	time 0.1787 (0.1820)	loss 5.5505 (4.0898)	acc@1: 33.0423	acc@5: 49.6514	
2023-03-18 12:03:27,709 - INFO - EPOCH 35 training takes 0:11:51
2023-03-18 12:03:28,651 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/fold1_latest.pth saved !!!
2023-03-18 12:03:28,652 - INFO - **********Latest test***********
2023-03-18 12:03:28,652 - INFO - eval epoch 35
2023-03-18 12:03:29,257 - INFO - Test: [0/782]	Time 0.605 (0.605)	Loss 2.6859 (2.6859)	Acc@1 65.625 (65.625)	Acc@5 88.281 (88.281)
2023-03-18 12:05:27,137 - INFO - Test: [200/782]	Time 0.571 (0.589)	Loss 3.0386 (3.0614)	Acc@1 61.719 (59.748)	Acc@5 85.938 (82.023)
2023-03-18 12:07:24,481 - INFO - Test: [400/782]	Time 0.593 (0.588)	Loss 2.9740 (3.0299)	Acc@1 60.938 (60.439)	Acc@5 79.688 (82.612)
2023-03-18 12:09:23,186 - INFO - Test: [600/782]	Time 0.600 (0.590)	Loss 3.0460 (2.9937)	Acc@1 59.375 (61.350)	Acc@5 83.594 (83.187)
2023-03-18 12:11:08,560 - INFO -  * Acc@1 61.752 Acc@5 83.600
2023-03-18 12:11:08,560 - INFO - Max accuracy: 62.8520%
2023-03-18 12:11:08,560 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-18 12:11:10,715 - INFO - Train: [36/90][0/3907]	eta 2:20:01 lr 0.02684040	time 2.1505 (2.1505)	loss 5.9487 (5.9487)	acc@1: 23.1656	acc@5: 35.2663	
2023-03-18 12:12:04,976 - INFO - Train: [36/90][300/3907]	eta 0:11:15 lr 0.02684040	time 0.1773 (0.1874)	loss 2.6968 (4.0155)	acc@1: 71.0937	acc@5: 86.7187	
2023-03-18 12:12:59,029 - INFO - Train: [36/90][600/3907]	eta 0:10:07 lr 0.02684040	time 0.1798 (0.1838)	loss 5.0994 (3.9395)	acc@1: 38.6841	acc@5: 59.7496	
2023-03-18 12:13:53,345 - INFO - Train: [36/90][900/3907]	eta 0:09:09 lr 0.02684040	time 0.1816 (0.1829)	loss 5.9459 (3.9779)	acc@1: 20.0975	acc@5: 37.9521	
2023-03-18 12:14:47,845 - INFO - Train: [36/90][1200/3907]	eta 0:08:14 lr 0.02684040	time 0.1797 (0.1826)	loss 4.6215 (4.0236)	acc@1: 48.9693	acc@5: 65.1424	
2023-03-18 12:15:42,358 - INFO - Train: [36/90][1500/3907]	eta 0:07:19 lr 0.02684040	time 0.1821 (0.1824)	loss 5.9919 (4.0304)	acc@1: 23.7541	acc@5: 37.7753	
2023-03-18 12:16:36,693 - INFO - Train: [36/90][1800/3907]	eta 0:06:23 lr 0.02684040	time 0.1900 (0.1822)	loss 3.0193 (4.0330)	acc@1: 66.6545	acc@5: 81.0459	
2023-03-18 12:17:31,719 - INFO - Train: [36/90][2100/3907]	eta 0:05:29 lr 0.02684040	time 0.1868 (0.1824)	loss 2.6538 (4.0408)	acc@1: 69.3616	acc@5: 88.8447	
2023-03-18 12:18:26,405 - INFO - Train: [36/90][2400/3907]	eta 0:04:34 lr 0.02684040	time 0.1876 (0.1824)	loss 4.7357 (4.0509)	acc@1: 45.7639	acc@5: 64.5709	
2023-03-18 12:19:21,081 - INFO - Train: [36/90][2700/3907]	eta 0:03:40 lr 0.02684040	time 0.1874 (0.1823)	loss 3.3233 (4.0562)	acc@1: 60.8291	acc@5: 81.3821	
2023-03-18 12:20:15,582 - INFO - Train: [36/90][3000/3907]	eta 0:02:45 lr 0.02684040	time 0.1829 (0.1823)	loss 2.9326 (4.0613)	acc@1: 68.6642	acc@5: 86.0455	
2023-03-18 12:21:10,199 - INFO - Train: [36/90][3300/3907]	eta 0:01:50 lr 0.02684040	time 0.1801 (0.1823)	loss 2.9232 (4.0726)	acc@1: 61.4704	acc@5: 85.5905	
2023-03-18 12:22:04,873 - INFO - Train: [36/90][3600/3907]	eta 0:00:55 lr 0.02684040	time 0.1843 (0.1823)	loss 3.8178 (4.0783)	acc@1: 60.8886	acc@5: 76.7209	
2023-03-18 12:22:58,969 - INFO - Train: [36/90][3900/3907]	eta 0:00:01 lr 0.02684040	time 0.1784 (0.1821)	loss 4.4662 (4.0868)	acc@1: 46.4030	acc@5: 64.5675	
2023-03-18 12:23:00,188 - INFO - EPOCH 36 training takes 0:11:51
2023-03-18 12:23:01,258 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/fold1_latest.pth saved !!!
2023-03-18 12:23:01,259 - INFO - **********Latest test***********
2023-03-18 12:23:01,259 - INFO - eval epoch 36
2023-03-18 12:23:01,861 - INFO - Test: [0/782]	Time 0.597 (0.597)	Loss 2.6409 (2.6409)	Acc@1 68.750 (68.750)	Acc@5 88.281 (88.281)
2023-03-18 12:25:00,624 - INFO - Test: [200/782]	Time 0.584 (0.594)	Loss 2.9120 (3.0059)	Acc@1 64.844 (60.343)	Acc@5 82.031 (82.560)
2023-03-18 12:26:58,545 - INFO - Test: [400/782]	Time 0.592 (0.592)	Loss 2.8030 (2.9636)	Acc@1 66.406 (61.407)	Acc@5 82.031 (83.167)
2023-03-18 12:28:58,408 - INFO - Test: [600/782]	Time 0.585 (0.594)	Loss 2.9963 (2.9328)	Acc@1 61.719 (62.166)	Acc@5 82.031 (83.691)
2023-03-18 12:30:45,780 - INFO -  * Acc@1 62.683 Acc@5 84.188
2023-03-18 12:30:45,780 - INFO - Max accuracy: 62.8520%
2023-03-18 12:30:45,780 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-18 12:30:48,573 - INFO - Train: [37/90][0/3907]	eta 3:01:29 lr 0.02618034	time 2.7872 (2.7872)	loss 5.3963 (5.3963)	acc@1: 35.6997	acc@5: 50.0785	
2023-03-18 12:31:42,848 - INFO - Train: [37/90][300/3907]	eta 0:11:23 lr 0.02618034	time 0.1889 (0.1896)	loss 4.8589 (3.9918)	acc@1: 46.6221	acc@5: 60.1625	
2023-03-18 12:32:37,076 - INFO - Train: [37/90][600/3907]	eta 0:10:12 lr 0.02618034	time 0.1814 (0.1852)	loss 5.2208 (4.0492)	acc@1: 39.4223	acc@5: 54.3685	
2023-03-18 12:33:31,424 - INFO - Train: [37/90][900/3907]	eta 0:09:12 lr 0.02618034	time 0.1792 (0.1838)	loss 3.0069 (4.0561)	acc@1: 60.5737	acc@5: 82.3227	
2023-03-18 12:34:25,723 - INFO - Train: [37/90][1200/3907]	eta 0:08:15 lr 0.02618034	time 0.1804 (0.1831)	loss 2.5502 (4.0523)	acc@1: 68.7445	acc@5: 88.2742	
2023-03-18 12:35:19,925 - INFO - Train: [37/90][1500/3907]	eta 0:07:19 lr 0.02618034	time 0.1796 (0.1826)	loss 6.2673 (4.0401)	acc@1: 19.3486	acc@5: 34.0845	
2023-03-18 12:36:14,386 - INFO - Train: [37/90][1800/3907]	eta 0:06:24 lr 0.02618034	time 0.1967 (0.1824)	loss 3.5918 (4.0443)	acc@1: 61.1289	acc@5: 78.3888	
2023-03-18 12:37:08,742 - INFO - Train: [37/90][2100/3907]	eta 0:05:29 lr 0.02618034	time 0.1795 (0.1823)	loss 4.9125 (4.0341)	acc@1: 45.1226	acc@5: 60.8840	
2023-03-18 12:38:03,040 - INFO - Train: [37/90][2400/3907]	eta 0:04:34 lr 0.02618034	time 0.1818 (0.1821)	loss 5.8599 (4.0425)	acc@1: 22.6149	acc@5: 42.6867	
2023-03-18 12:38:57,794 - INFO - Train: [37/90][2700/3907]	eta 0:03:39 lr 0.02618034	time 0.1817 (0.1822)	loss 3.0606 (4.0498)	acc@1: 60.6903	acc@5: 81.6984	
2023-03-18 12:39:52,263 - INFO - Train: [37/90][3000/3907]	eta 0:02:45 lr 0.02618034	time 0.1797 (0.1821)	loss 5.0111 (4.0596)	acc@1: 42.5024	acc@5: 58.9653	
2023-03-18 12:40:46,633 - INFO - Train: [37/90][3300/3907]	eta 0:01:50 lr 0.02618034	time 0.1797 (0.1820)	loss 5.6919 (4.0580)	acc@1: 24.5130	acc@5: 41.5475	
2023-03-18 12:41:41,126 - INFO - Train: [37/90][3600/3907]	eta 0:00:55 lr 0.02618034	time 0.1796 (0.1820)	loss 5.7816 (4.0609)	acc@1: 24.4676	acc@5: 41.6908	
2023-03-18 12:42:35,407 - INFO - Train: [37/90][3900/3907]	eta 0:00:01 lr 0.02618034	time 0.1789 (0.1819)	loss 2.9561 (4.0667)	acc@1: 63.1192	acc@5: 79.4834	
2023-03-18 12:42:36,648 - INFO - EPOCH 37 training takes 0:11:50
2023-03-18 12:42:37,725 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/fold1_latest.pth saved !!!
2023-03-18 12:42:37,726 - INFO - **********Latest test***********
2023-03-18 12:42:37,727 - INFO - eval epoch 37
2023-03-18 12:42:38,328 - INFO - Test: [0/782]	Time 0.598 (0.598)	Loss 2.6401 (2.6401)	Acc@1 66.406 (66.406)	Acc@5 89.844 (89.844)
2023-03-18 12:44:36,960 - INFO - Test: [200/782]	Time 0.598 (0.593)	Loss 2.8791 (2.9750)	Acc@1 60.938 (60.545)	Acc@5 81.250 (82.789)
2023-03-18 12:46:35,913 - INFO - Test: [400/782]	Time 0.596 (0.594)	Loss 2.7318 (2.9417)	Acc@1 67.969 (61.378)	Acc@5 85.938 (83.442)
2023-03-18 12:48:35,965 - INFO - Test: [600/782]	Time 0.581 (0.596)	Loss 2.9225 (2.9091)	Acc@1 56.250 (62.209)	Acc@5 81.250 (83.937)
2023-03-18 12:50:21,519 - INFO -  * Acc@1 62.774 Acc@5 84.476
2023-03-18 12:50:21,519 - INFO - Max accuracy: 62.8520%
2023-03-18 12:50:21,519 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-18 12:50:23,749 - INFO - Train: [38/90][0/3907]	eta 2:24:54 lr 0.02551275	time 2.2253 (2.2253)	loss 5.8484 (5.8484)	acc@1: 21.0938	acc@5: 37.5760	
2023-03-18 12:51:18,587 - INFO - Train: [38/90][300/3907]	eta 0:11:23 lr 0.02551275	time 0.1868 (0.1896)	loss 5.3619 (4.0502)	acc@1: 36.5980	acc@5: 53.0777	
2023-03-18 12:52:13,417 - INFO - Train: [38/90][600/3907]	eta 0:10:15 lr 0.02551275	time 0.1835 (0.1862)	loss 5.0924 (4.0175)	acc@1: 37.9078	acc@5: 55.9661	
2023-03-18 12:53:08,259 - INFO - Train: [38/90][900/3907]	eta 0:09:16 lr 0.02551275	time 0.1885 (0.1851)	loss 6.0188 (3.9937)	acc@1: 15.4648	acc@5: 33.0639	
2023-03-18 12:54:02,871 - INFO - Train: [38/90][1200/3907]	eta 0:08:18 lr 0.02551275	time 0.1797 (0.1843)	loss 2.5576 (3.9998)	acc@1: 72.6310	acc@5: 89.8124	
2023-03-18 12:54:57,534 - INFO - Train: [38/90][1500/3907]	eta 0:07:22 lr 0.02551275	time 0.1792 (0.1839)	loss 6.0791 (4.0130)	acc@1: 21.2398	acc@5: 36.3276	
2023-03-18 12:55:51,954 - INFO - Train: [38/90][1800/3907]	eta 0:06:26 lr 0.02551275	time 0.1797 (0.1835)	loss 2.5079 (4.0332)	acc@1: 71.0906	acc@5: 86.7148	
2023-03-18 12:56:46,540 - INFO - Train: [38/90][2100/3907]	eta 0:05:31 lr 0.02551275	time 0.1793 (0.1832)	loss 5.8976 (4.0459)	acc@1: 22.6448	acc@5: 40.3344	
2023-03-18 12:57:41,474 - INFO - Train: [38/90][2400/3907]	eta 0:04:36 lr 0.02551275	time 0.1834 (0.1832)	loss 4.6152 (4.0431)	acc@1: 49.6646	acc@5: 63.6067	
2023-03-18 12:58:36,322 - INFO - Train: [38/90][2700/3907]	eta 0:03:41 lr 0.02551275	time 0.1856 (0.1832)	loss 2.8569 (4.0445)	acc@1: 66.7635	acc@5: 88.2506	
2023-03-18 12:59:31,740 - INFO - Train: [38/90][3000/3907]	eta 0:02:46 lr 0.02551275	time 0.1844 (0.1833)	loss 2.7917 (4.0522)	acc@1: 66.3398	acc@5: 84.2911	
2023-03-18 13:00:26,964 - INFO - Train: [38/90][3300/3907]	eta 0:01:51 lr 0.02551275	time 0.1825 (0.1834)	loss 2.9510 (4.0644)	acc@1: 63.2009	acc@5: 83.2402	
2023-03-18 13:01:22,212 - INFO - Train: [38/90][3600/3907]	eta 0:00:56 lr 0.02551275	time 0.1798 (0.1835)	loss 2.8201 (4.0652)	acc@1: 70.2625	acc@5: 82.7536	
2023-03-18 13:02:17,336 - INFO - Train: [38/90][3900/3907]	eta 0:00:01 lr 0.02551275	time 0.1802 (0.1835)	loss 3.3265 (4.0762)	acc@1: 59.2055	acc@5: 78.4338	
2023-03-18 13:02:18,566 - INFO - EPOCH 38 training takes 0:11:57
2023-03-18 13:02:19,631 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/fold1_latest.pth saved !!!
2023-03-18 13:02:19,632 - INFO - **********Latest test***********
2023-03-18 13:02:19,632 - INFO - eval epoch 38
2023-03-18 13:02:20,228 - INFO - Test: [0/782]	Time 0.595 (0.595)	Loss 2.6216 (2.6216)	Acc@1 70.312 (70.312)	Acc@5 91.406 (91.406)
2023-03-18 13:04:19,072 - INFO - Test: [200/782]	Time 0.590 (0.594)	Loss 2.9170 (3.0081)	Acc@1 60.156 (60.514)	Acc@5 80.469 (82.572)
2023-03-18 13:06:19,164 - INFO - Test: [400/782]	Time 0.592 (0.597)	Loss 2.9324 (2.9786)	Acc@1 61.719 (61.195)	Acc@5 82.812 (83.247)
2023-03-18 13:08:19,766 - INFO - Test: [600/782]	Time 0.583 (0.599)	Loss 2.9348 (2.9452)	Acc@1 64.062 (61.972)	Acc@5 85.156 (83.743)
2023-03-18 13:10:05,199 - INFO -  * Acc@1 62.509 Acc@5 84.176
2023-03-18 13:10:05,199 - INFO - Max accuracy: 62.8520%
2023-03-18 13:10:05,199 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-18 13:10:07,265 - INFO - Train: [39/90][0/3907]	eta 2:14:18 lr 0.02483844	time 2.0626 (2.0626)	loss 2.4543 (2.4543)	acc@1: 77.7086	acc@5: 88.5866	
2023-03-18 13:11:01,868 - INFO - Train: [39/90][300/3907]	eta 0:11:19 lr 0.02483844	time 0.1786 (0.1883)	loss 3.0008 (3.8904)	acc@1: 71.8720	acc@5: 83.3355	
2023-03-18 13:11:56,715 - INFO - Train: [39/90][600/3907]	eta 0:10:13 lr 0.02483844	time 0.1802 (0.1855)	loss 5.4318 (3.9351)	acc@1: 34.3509	acc@5: 50.3254	
2023-03-18 13:12:51,702 - INFO - Train: [39/90][900/3907]	eta 0:09:15 lr 0.02483844	time 0.1882 (0.1848)	loss 2.5009 (3.9589)	acc@1: 75.4036	acc@5: 90.1726	
2023-03-18 13:13:46,976 - INFO - Train: [39/90][1200/3907]	eta 0:08:19 lr 0.02483844	time 0.1895 (0.1847)	loss 5.9278 (3.9619)	acc@1: 24.4284	acc@5: 38.3727	
2023-03-18 13:14:41,678 - INFO - Train: [39/90][1500/3907]	eta 0:07:23 lr 0.02483844	time 0.1850 (0.1842)	loss 5.8868 (3.9688)	acc@1: 22.5433	acc@5: 34.9311	
2023-03-18 13:15:36,686 - INFO - Train: [39/90][1800/3907]	eta 0:06:27 lr 0.02483844	time 0.1797 (0.1840)	loss 4.4357 (3.9721)	acc@1: 49.1143	acc@5: 66.2852	
2023-03-18 13:16:31,562 - INFO - Train: [39/90][2100/3907]	eta 0:05:32 lr 0.02483844	time 0.1843 (0.1839)	loss 2.9411 (3.9782)	acc@1: 68.1317	acc@5: 88.3369	
2023-03-18 13:17:25,685 - INFO - Train: [39/90][2400/3907]	eta 0:04:36 lr 0.02483844	time 0.1711 (0.1835)	loss 2.6347 (3.9837)	acc@1: 67.1874	acc@5: 85.1561	
2023-03-18 13:18:18,013 - INFO - Train: [39/90][2700/3907]	eta 0:03:40 lr 0.02483844	time 0.1712 (0.1825)	loss 2.6560 (3.9918)	acc@1: 69.4716	acc@5: 88.2055	
2023-03-18 13:19:10,368 - INFO - Train: [39/90][3000/3907]	eta 0:02:44 lr 0.02483844	time 0.1707 (0.1817)	loss 5.5546 (4.0063)	acc@1: 35.0956	acc@5: 47.9026	
2023-03-18 13:20:02,742 - INFO - Train: [39/90][3300/3907]	eta 0:01:49 lr 0.02483844	time 0.1724 (0.1810)	loss 3.0439 (4.0219)	acc@1: 63.8726	acc@5: 81.1392	
2023-03-18 13:20:55,004 - INFO - Train: [39/90][3600/3907]	eta 0:00:55 lr 0.02483844	time 0.1715 (0.1804)	loss 3.7046 (4.0291)	acc@1: 55.9426	acc@5: 77.6204	
2023-03-18 13:21:47,413 - INFO - Train: [39/90][3900/3907]	eta 0:00:01 lr 0.02483844	time 0.1709 (0.1800)	loss 6.0170 (4.0375)	acc@1: 18.7656	acc@5: 34.2879	
2023-03-18 13:21:48,569 - INFO - EPOCH 39 training takes 0:11:43
2023-03-18 13:21:49,664 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/fold1_latest.pth saved !!!
2023-03-18 13:21:49,665 - INFO - **********Latest test***********
2023-03-18 13:21:49,665 - INFO - eval epoch 39
2023-03-18 13:21:50,278 - INFO - Test: [0/782]	Time 0.612 (0.612)	Loss 2.6287 (2.6287)	Acc@1 69.531 (69.531)	Acc@5 90.625 (90.625)
2023-03-18 13:23:49,771 - INFO - Test: [200/782]	Time 0.599 (0.598)	Loss 2.9729 (3.0483)	Acc@1 60.938 (60.308)	Acc@5 82.812 (82.696)
2023-03-18 13:25:49,224 - INFO - Test: [400/782]	Time 0.578 (0.597)	Loss 2.8095 (3.0027)	Acc@1 62.500 (61.393)	Acc@5 86.719 (83.455)
2023-03-18 13:27:47,001 - INFO - Test: [600/782]	Time 0.582 (0.595)	Loss 3.0228 (2.9749)	Acc@1 57.812 (62.236)	Acc@5 82.812 (83.880)
2023-03-18 13:29:33,112 - INFO -  * Acc@1 62.858 Acc@5 84.451
2023-03-18 13:29:33,113 - INFO - Max accuracy: 62.8580%
2023-03-18 13:29:34,169 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/fold1_best.pth saved !!!
2023-03-18 13:29:34,170 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-18 13:29:36,228 - INFO - Train: [40/90][0/3907]	eta 2:13:30 lr 0.02415823	time 2.0502 (2.0502)	loss 2.7685 (2.7685)	acc@1: 71.0810	acc@5: 84.9865	
2023-03-18 13:30:31,485 - INFO - Train: [40/90][300/3907]	eta 0:11:26 lr 0.02415823	time 0.1841 (0.1904)	loss 3.2803 (4.1602)	acc@1: 67.1863	acc@5: 79.6011	
2023-03-18 13:31:27,067 - INFO - Train: [40/90][600/3907]	eta 0:10:21 lr 0.02415823	time 0.1816 (0.1878)	loss 6.1024 (4.0179)	acc@1: 20.3571	acc@5: 34.4643	
2023-03-18 13:32:22,612 - INFO - Train: [40/90][900/3907]	eta 0:09:22 lr 0.02415823	time 0.1828 (0.1869)	loss 2.9498 (4.0302)	acc@1: 64.4130	acc@5: 84.8970	
2023-03-18 13:33:17,336 - INFO - Train: [40/90][1200/3907]	eta 0:08:22 lr 0.02415823	time 0.1861 (0.1858)	loss 3.9756 (4.0121)	acc@1: 54.5329	acc@5: 73.5841	
2023-03-18 13:34:12,503 - INFO - Train: [40/90][1500/3907]	eta 0:07:26 lr 0.02415823	time 0.1809 (0.1854)	loss 3.8551 (3.9891)	acc@1: 60.3199	acc@5: 73.6464	
2023-03-18 13:35:07,747 - INFO - Train: [40/90][1800/3907]	eta 0:06:30 lr 0.02415823	time 0.1798 (0.1852)	loss 2.7027 (4.0140)	acc@1: 69.8826	acc@5: 88.3060	
2023-03-18 13:36:02,940 - INFO - Train: [40/90][2100/3907]	eta 0:05:34 lr 0.02415823	time 0.1799 (0.1850)	loss 5.1009 (4.0264)	acc@1: 38.4749	acc@5: 58.2781	
2023-03-18 13:36:58,514 - INFO - Train: [40/90][2400/3907]	eta 0:04:38 lr 0.02415823	time 0.1848 (0.1851)	loss 5.3836 (4.0342)	acc@1: 34.8578	acc@5: 51.8961	
2023-03-18 13:37:53,721 - INFO - Train: [40/90][2700/3907]	eta 0:03:43 lr 0.02415823	time 0.1797 (0.1849)	loss 4.1769 (4.0397)	acc@1: 58.4794	acc@5: 71.5926	
2023-03-18 13:38:48,874 - INFO - Train: [40/90][3000/3907]	eta 0:02:47 lr 0.02415823	time 0.1879 (0.1848)	loss 5.8066 (4.0294)	acc@1: 23.9296	acc@5: 40.7154	
2023-03-18 13:39:44,129 - INFO - Train: [40/90][3300/3907]	eta 0:01:52 lr 0.02415823	time 0.1854 (0.1848)	loss 5.0532 (4.0464)	acc@1: 45.4280	acc@5: 54.2897	
2023-03-18 13:40:39,145 - INFO - Train: [40/90][3600/3907]	eta 0:00:56 lr 0.02415823	time 0.1885 (0.1847)	loss 2.5580 (4.0464)	acc@1: 70.3036	acc@5: 89.0512	
2023-03-18 13:41:34,406 - INFO - Train: [40/90][3900/3907]	eta 0:00:01 lr 0.02415823	time 0.1800 (0.1846)	loss 4.1830 (4.0484)	acc@1: 50.3100	acc@5: 69.0506	
2023-03-18 13:41:35,609 - INFO - EPOCH 40 training takes 0:12:01
2023-03-18 13:41:36,692 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/fold1_latest.pth saved !!!
2023-03-18 13:41:36,692 - INFO - **********Latest test***********
2023-03-18 13:41:36,692 - INFO - eval epoch 40
2023-03-18 13:41:37,287 - INFO - Test: [0/782]	Time 0.594 (0.594)	Loss 2.6742 (2.6742)	Acc@1 66.406 (66.406)	Acc@5 87.500 (87.500)
2023-03-18 13:43:34,331 - INFO - Test: [200/782]	Time 0.578 (0.585)	Loss 3.0792 (3.0465)	Acc@1 60.156 (60.669)	Acc@5 80.469 (82.424)
2023-03-18 13:45:32,334 - INFO - Test: [400/782]	Time 0.601 (0.588)	Loss 2.8559 (3.0098)	Acc@1 65.625 (61.810)	Acc@5 83.594 (83.132)
2023-03-18 13:47:32,668 - INFO - Test: [600/782]	Time 0.571 (0.592)	Loss 3.0615 (2.9744)	Acc@1 57.031 (62.548)	Acc@5 82.031 (83.680)
2023-03-18 13:49:17,759 - INFO -  * Acc@1 63.041 Acc@5 84.139
2023-03-18 13:49:17,760 - INFO - Max accuracy: 63.0410%
2023-03-18 13:49:18,817 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/fold1_best.pth saved !!!
2023-03-18 13:49:18,818 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-18 13:49:21,022 - INFO - Train: [41/90][0/3907]	eta 2:23:16 lr 0.02347296	time 2.2002 (2.2002)	loss 2.5111 (2.5111)	acc@1: 78.5351	acc@5: 91.4972	
2023-03-18 13:50:15,944 - INFO - Train: [41/90][300/3907]	eta 0:11:24 lr 0.02347296	time 0.1861 (0.1898)	loss 3.1445 (3.8772)	acc@1: 68.9712	acc@5: 82.7654	
2023-03-18 13:51:10,795 - INFO - Train: [41/90][600/3907]	eta 0:10:16 lr 0.02347296	time 0.1810 (0.1863)	loss 5.6337 (3.9419)	acc@1: 27.5283	acc@5: 42.5325	
2023-03-18 13:52:06,124 - INFO - Train: [41/90][900/3907]	eta 0:09:18 lr 0.02347296	time 0.1819 (0.1857)	loss 5.9109 (3.9214)	acc@1: 25.0299	acc@5: 39.2015	
2023-03-18 13:53:01,132 - INFO - Train: [41/90][1200/3907]	eta 0:08:21 lr 0.02347296	time 0.1797 (0.1851)	loss 3.1063 (3.9301)	acc@1: 63.7923	acc@5: 84.2915	
2023-03-18 13:53:56,434 - INFO - Train: [41/90][1500/3907]	eta 0:07:25 lr 0.02347296	time 0.1833 (0.1849)	loss 5.6099 (3.9260)	acc@1: 28.8500	acc@5: 46.8511	
2023-03-18 13:54:51,542 - INFO - Train: [41/90][1800/3907]	eta 0:06:29 lr 0.02347296	time 0.1796 (0.1847)	loss 4.2847 (3.9184)	acc@1: 53.0984	acc@5: 73.3264	
2023-03-18 13:55:46,745 - INFO - Train: [41/90][2100/3907]	eta 0:05:33 lr 0.02347296	time 0.1805 (0.1846)	loss 5.7510 (3.9483)	acc@1: 26.0461	acc@5: 43.3876	
2023-03-18 13:56:41,980 - INFO - Train: [41/90][2400/3907]	eta 0:04:38 lr 0.02347296	time 0.1996 (0.1846)	loss 5.2843 (3.9560)	acc@1: 40.9737	acc@5: 50.3394	
2023-03-18 13:57:37,085 - INFO - Train: [41/90][2700/3907]	eta 0:03:42 lr 0.02347296	time 0.1800 (0.1845)	loss 5.6195 (3.9535)	acc@1: 30.2992	acc@5: 44.6552	
2023-03-18 13:58:31,801 - INFO - Train: [41/90][3000/3907]	eta 0:02:47 lr 0.02347296	time 0.1824 (0.1843)	loss 5.4177 (3.9592)	acc@1: 33.5461	acc@5: 49.6759	
2023-03-18 13:59:26,992 - INFO - Train: [41/90][3300/3907]	eta 0:01:51 lr 0.02347296	time 0.1835 (0.1842)	loss 2.6655 (3.9721)	acc@1: 69.9609	acc@5: 89.3922	
2023-03-18 14:00:22,174 - INFO - Train: [41/90][3600/3907]	eta 0:00:56 lr 0.02347296	time 0.1857 (0.1842)	loss 4.7953 (3.9770)	acc@1: 44.9087	acc@5: 62.8722	
2023-03-18 14:01:17,197 - INFO - Train: [41/90][3900/3907]	eta 0:00:01 lr 0.02347296	time 0.1858 (0.1841)	loss 2.8478 (3.9868)	acc@1: 65.9851	acc@5: 84.6147	
2023-03-18 14:01:18,404 - INFO - EPOCH 41 training takes 0:11:59
2023-03-18 14:01:19,481 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/fold1_latest.pth saved !!!
2023-03-18 14:01:19,481 - INFO - **********Latest test***********
2023-03-18 14:01:19,481 - INFO - eval epoch 41
2023-03-18 14:01:20,112 - INFO - Test: [0/782]	Time 0.630 (0.630)	Loss 2.5437 (2.5437)	Acc@1 71.875 (71.875)	Acc@5 92.188 (92.188)
2023-03-18 14:03:18,185 - INFO - Test: [200/782]	Time 0.576 (0.591)	Loss 2.8242 (2.9061)	Acc@1 67.188 (62.710)	Acc@5 82.812 (84.080)
2023-03-18 14:05:15,601 - INFO - Test: [400/782]	Time 0.579 (0.589)	Loss 2.7982 (2.8744)	Acc@1 64.844 (63.369)	Acc@5 85.156 (84.696)
2023-03-18 14:07:13,585 - INFO - Test: [600/782]	Time 0.578 (0.589)	Loss 2.9301 (2.8399)	Acc@1 63.281 (64.222)	Acc@5 84.375 (85.217)
