# 2080Ti
2023-03-17 06:57:44,642 - INFO - --batch_size 128
2023-03-17 06:57:44,642 - INFO - --data inat21_mini
2023-03-17 06:57:44,642 - INFO - --data_dir ./datasets/iNat2021
2023-03-17 06:57:44,642 - INFO - --evaluate False
2023-03-17 06:57:44,642 - INFO - --fold 1
2023-03-17 06:57:44,642 - INFO - --image_only False
2023-03-17 06:57:44,642 - INFO - --metadata geo_temporal
2023-03-17 06:57:44,642 - INFO - --mlp_cin 6
2023-03-17 06:57:44,642 - INFO - --mlp_d 256
2023-03-17 06:57:44,642 - INFO - --mlp_h 64
2023-03-17 06:57:44,643 - INFO - --mlp_n 2
2023-03-17 06:57:44,643 - INFO - --mlp_type c
2023-03-17 06:57:44,643 - INFO - --model_file resnet_dynamic_mlp
2023-03-17 06:57:44,643 - INFO - --model_name resnet50
2023-03-17 06:57:44,643 - INFO - --name res50_dynamic_mlp_c
2023-03-17 06:57:44,643 - INFO - --num_classes 10000
2023-03-17 06:57:44,643 - INFO - --num_workers 8
2023-03-17 06:57:44,643 - INFO - --path_log ./outputs/inat21_mini/res50_dynamic_mlp_c
2023-03-17 06:57:44,643 - INFO - --pretrained True
2023-03-17 06:57:44,643 - INFO - --random_seed 37
2023-03-17 06:57:44,643 - INFO - --resume Latest
2023-03-17 06:57:44,643 - INFO - --save_dir ./outputs
2023-03-17 06:57:44,643 - INFO - --start_lr 0.04
2023-03-17 06:57:44,643 - INFO - --stop_epoch 90
2023-03-17 06:57:44,643 - INFO - --tencrop False
2023-03-17 06:57:44,643 - INFO - --warmup 2
2023-03-17 06:57:44,643 - INFO - Creating model:resnet_dynamic_mlp -> resnet50
2023-03-17 06:57:44,643 - INFO - type: c, cin: 6, d: 256, h: 64, N: 2
2023-03-17 06:57:54,112 - INFO - => no checkpoint found at './outputs/inat21_mini/res50_dynamic_mlp_c/fold1_latest.pth'
2023-03-17 06:57:54,113 - INFO - Start training
2023-03-17 06:58:00,657 - INFO - Train: [1/90][0/3907]	eta 7:06:04 lr 0.00000000	time 6.5432 (6.5432)	loss 9.4072 (9.4072)	acc@1: 0.0000	acc@5: 0.0000	
2023-03-17 06:59:44,322 - INFO - Train: [1/90][300/3907]	eta 0:22:00 lr 0.00153571	time 2.2464 (0.3661)	loss 9.3158 (9.3867)	acc@1: 0.0000	acc@5: 0.0000	
2023-03-17 07:01:43,050 - INFO - Train: [1/90][600/3907]	eta 0:20:59 lr 0.00307141	time 0.2729 (0.3809)	loss 9.2807 (9.3459)	acc@1: 0.0000	acc@5: 0.0000	
2023-03-17 07:03:57,298 - INFO - Train: [1/90][900/3907]	eta 0:20:12 lr 0.00460712	time 0.2726 (0.4031)	loss 8.9369 (9.2719)	acc@1: 0.6354	acc@5: 0.6354	
2023-03-17 07:06:27,750 - INFO - Train: [1/90][1200/3907]	eta 0:19:17 lr 0.00614282	time 0.2723 (0.4277)	loss 8.2797 (9.1204)	acc@1: 0.0000	acc@5: 1.4320	
2023-03-17 07:09:10,343 - INFO - Train: [1/90][1500/3907]	eta 0:18:04 lr 0.00767853	time 0.2722 (0.4505)	loss 7.7575 (8.9410)	acc@1: 2.2227	acc@5: 5.9272	
2023-03-17 07:12:12,697 - INFO - Train: [1/90][1800/3907]	eta 0:16:44 lr 0.00921423	time 0.2769 (0.4767)	loss 7.1107 (8.7584)	acc@1: 3.7598	acc@5: 12.0313	
2023-03-17 07:15:47,192 - INFO - Train: [1/90][2100/3907]	eta 0:15:22 lr 0.01074994	time 0.2713 (0.5107)	loss 8.0960 (8.5790)	acc@1: 2.0390	acc@5: 3.9452	
2023-03-17 07:19:43,090 - INFO - Train: [1/90][2400/3907]	eta 0:13:41 lr 0.01228564	time 0.2790 (0.5452)	loss 7.4690 (8.4184)	acc@1: 5.0656	acc@5: 11.3975	
2023-03-17 07:24:05,373 - INFO - Train: [1/90][2700/3907]	eta 0:11:42 lr 0.01382135	time 0.2770 (0.5817)	loss 6.5538 (8.2756)	acc@1: 5.1213	acc@5: 18.2905	
2023-03-17 07:28:42,248 - INFO - Train: [1/90][3000/3907]	eta 0:09:18 lr 0.01535705	time 0.2913 (0.6158)	loss 6.8320 (8.1411)	acc@1: 7.5499	acc@5: 13.8220	
2023-03-17 07:33:34,658 - INFO - Train: [1/90][3300/3907]	eta 0:06:33 lr 0.01689276	time 0.2714 (0.6484)	loss 5.8098 (8.0211)	acc@1: 7.0291	acc@5: 24.2113	
2023-03-17 07:39:22,048 - INFO - Train: [1/90][3600/3907]	eta 0:03:32 lr 0.01842846	time 3.1151 (0.6909)	loss 7.3618 (7.9126)	acc@1: 5.4220	acc@5: 13.5551	
2023-03-17 07:45:21,913 - INFO - Train: [1/90][3900/3907]	eta 0:00:05 lr 0.01996417	time 1.6896 (0.7300)	loss 7.3308 (7.8118)	acc@1: 6.1792	acc@5: 14.6053	
2023-03-17 07:45:24,294 - INFO - EPOCH 1 training takes 0:47:30
2023-03-17 07:45:25,290 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_c/fold1_latest.pth saved !!!
2023-03-17 07:45:25,290 - INFO - **********Latest test***********
2023-03-17 07:45:25,290 - INFO - eval epoch 1
2023-03-17 07:45:28,225 - INFO - Test: [0/782]	Time 2.934 (2.934)	Loss 4.9227 (4.9227)	Acc@1 21.094 (21.094)	Acc@5 39.844 (39.844)
2023-03-17 07:52:58,519 - INFO - Test: [200/782]	Time 2.315 (2.255)	Loss 5.3140 (5.4843)	Acc@1 15.625 (13.176)	Acc@5 39.062 (32.645)
2023-03-17 08:00:35,671 - INFO - Test: [400/782]	Time 2.240 (2.270)	Loss 5.4508 (5.4558)	Acc@1 15.625 (13.457)	Acc@5 39.844 (33.259)
2023-03-17 08:07:28,680 - INFO - Test: [600/782]	Time 1.909 (2.202)	Loss 5.6576 (5.4539)	Acc@1 14.062 (13.543)	Acc@5 28.125 (33.248)
2023-03-17 08:13:53,287 - INFO -  * Acc@1 13.905 Acc@5 34.105
2023-03-17 08:13:53,287 - INFO - Max accuracy: 13.9050%
2023-03-17 08:13:54,163 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_c/fold1_best.pth saved !!!
2023-03-17 08:13:54,163 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_c
2023-03-17 08:13:57,349 - INFO - Train: [2/90][0/3907]	eta 3:27:08 lr 0.02000000	time 3.1811 (3.1811)	loss 6.8553 (6.8553)	acc@1: 8.0579	acc@5: 26.6529	
2023-03-17 08:15:41,157 - INFO - Train: [2/90][300/3907]	eta 0:21:22 lr 0.02153571	time 0.2811 (0.3554)	loss 7.8062 (6.3386)	acc@1: 5.1836	acc@5: 9.8960	
2023-03-17 08:17:30,084 - INFO - Train: [2/90][600/3907]	eta 0:19:48 lr 0.02307141	time 1.7998 (0.3593)	loss 7.8242 (6.3252)	acc@1: 3.5013	acc@5: 10.9662	
2023-03-17 08:19:32,931 - INFO - Train: [2/90][900/3907]	eta 0:18:50 lr 0.02460712	time 1.3866 (0.3760)	loss 6.4037 (6.2806)	acc@1: 13.4211	acc@5: 31.3158	
2023-03-17 08:21:55,099 - INFO - Train: [2/90][1200/3907]	eta 0:18:03 lr 0.02614282	time 0.2729 (0.4004)	loss 4.9775 (6.2212)	acc@1: 20.0485	acc@5: 47.0469	
2023-03-17 08:24:29,630 - INFO - Train: [2/90][1500/3907]	eta 0:16:59 lr 0.02767853	time 1.3974 (0.4234)	loss 5.1804 (6.2113)	acc@1: 19.0636	acc@5: 44.9902	
2023-03-17 08:27:24,317 - INFO - Train: [2/90][1800/3907]	eta 0:15:47 lr 0.02921423	time 0.2816 (0.4498)	loss 5.1908 (6.1629)	acc@1: 20.9789	acc@5: 42.7349	
2023-03-17 08:30:41,038 - INFO - Train: [2/90][2100/3907]	eta 0:14:25 lr 0.03074994	time 0.2738 (0.4792)	loss 5.7247 (6.1347)	acc@1: 19.1924	acc@5: 40.4412	
2023-03-17 08:34:32,621 - INFO - Train: [2/90][2400/3907]	eta 0:12:57 lr 0.03228564	time 4.8035 (0.5158)	loss 5.6218 (6.1037)	acc@1: 17.0413	acc@5: 38.3430	
2023-03-17 08:39:02,845 - INFO - Train: [2/90][2700/3907]	eta 0:11:14 lr 0.03382135	time 0.2700 (0.5586)	loss 7.3119 (6.0733)	acc@1: 6.8305	acc@5: 13.5315	
2023-03-17 08:43:55,032 - INFO - Train: [2/90][3000/3907]	eta 0:09:04 lr 0.03535705	time 0.2715 (0.6001)	loss 5.8686 (6.0539)	acc@1: 19.6810	acc@5: 39.3621	
2023-03-17 08:48:50,748 - INFO - Train: [2/90][3300/3907]	eta 0:06:25 lr 0.03689276	time 0.2833 (0.6351)	loss 5.5015 (6.0315)	acc@1: 29.1081	acc@5: 48.8709	
2023-03-17 08:54:19,557 - INFO - Train: [2/90][3600/3907]	eta 0:03:26 lr 0.03842846	time 0.2711 (0.6735)	loss 5.5655 (6.0134)	acc@1: 21.7600	acc@5: 43.4084	
2023-03-17 09:00:05,096 - INFO - Train: [2/90][3900/3907]	eta 0:00:04 lr 0.03996417	time 0.2821 (0.7103)	loss 5.6200 (5.9925)	acc@1: 20.7243	acc@5: 42.8983	
2023-03-17 09:00:06,723 - INFO - EPOCH 2 training takes 0:46:12
2023-03-17 09:00:10,458 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_c/fold1_latest.pth saved !!!
2023-03-17 09:00:10,459 - INFO - **********Latest test***********
2023-03-17 09:00:10,459 - INFO - eval epoch 2
2023-03-17 09:00:12,787 - INFO - Test: [0/782]	Time 2.327 (2.327)	Loss 3.9763 (3.9763)	Acc@1 40.625 (40.625)	Acc@5 64.844 (64.844)
2023-03-17 09:07:30,510 - INFO - Test: [200/782]	Time 2.310 (2.189)	Loss 4.2866 (4.5285)	Acc@1 30.469 (28.187)	Acc@5 58.594 (54.466)
2023-03-17 09:12:34,123 - INFO - Test: [400/782]	Time 0.776 (1.855)	Loss 4.3998 (4.5006)	Acc@1 27.344 (28.517)	Acc@5 56.250 (55.073)
2023-03-17 09:15:11,295 - INFO - Test: [600/782]	Time 0.786 (1.499)	Loss 4.6766 (4.4833)	Acc@1 26.562 (28.934)	Acc@5 53.906 (55.523)
2023-03-17 09:18:35,343 - INFO -  * Acc@1 29.383 Acc@5 56.212
2023-03-17 09:18:35,343 - INFO - Max accuracy: 29.3830%
2023-03-17 09:18:39,029 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_c/fold1_best.pth saved !!!
2023-03-17 09:18:39,030 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_c
2023-03-17 09:18:41,455 - INFO - Train: [3/90][0/3907]	eta 2:37:27 lr 0.03995128	time 2.4180 (2.4180)	loss 4.8776 (4.8776)	acc@1: 25.9623	acc@5: 51.1434	
2023-03-17 09:20:18,802 - INFO - Train: [3/90][300/3907]	eta 0:19:55 lr 0.03995128	time 0.2851 (0.3314)	loss 4.9719 (5.5006)	acc@1: 32.7022	acc@5: 54.8110	
2023-03-17 09:22:10,927 - INFO - Train: [3/90][600/3907]	eta 0:19:25 lr 0.03995128	time 0.2846 (0.3526)	loss 5.1088 (5.4837)	acc@1: 22.0150	acc@5: 48.4331	
2023-03-17 09:24:14,405 - INFO - Train: [3/90][900/3907]	eta 0:18:39 lr 0.03995128	time 0.2824 (0.3722)	loss 4.7734 (5.4991)	acc@1: 27.8259	acc@5: 48.9125	
2023-03-17 09:26:29,208 - INFO - Train: [3/90][1200/3907]	eta 0:17:39 lr 0.03995128	time 0.2730 (0.3915)	loss 5.3439 (5.5098)	acc@1: 25.0451	acc@5: 47.4870	
2023-03-17 09:28:59,762 - INFO - Train: [3/90][1500/3907]	eta 0:16:35 lr 0.03995128	time 0.2796 (0.4135)	loss 4.3842 (5.5036)	acc@1: 28.6726	acc@5: 58.8952	
2023-03-17 09:31:47,852 - INFO - Train: [3/90][1800/3907]	eta 0:15:22 lr 0.03995128	time 0.2910 (0.4380)	loss 4.5001 (5.4832)	acc@1: 30.9987	acc@5: 53.4728	
2023-03-17 09:34:57,158 - INFO - Train: [3/90][2100/3907]	eta 0:14:01 lr 0.03995128	time 0.2773 (0.4655)	loss 4.8242 (5.4706)	acc@1: 32.9117	acc@5: 54.3759	
2023-03-17 09:38:35,243 - INFO - Train: [3/90][2400/3907]	eta 0:12:30 lr 0.03995128	time 4.2529 (0.4982)	loss 6.5732 (5.4731)	acc@1: 16.6543	acc@5: 30.9851	
2023-03-17 09:42:40,137 - INFO - Train: [3/90][2700/3907]	eta 0:10:43 lr 0.03995128	time 0.2717 (0.5335)	loss 4.2986 (5.4741)	acc@1: 37.5238	acc@5: 65.2759	
2023-03-17 09:46:55,896 - INFO - Train: [3/90][3000/3907]	eta 0:08:32 lr 0.03995128	time 0.2743 (0.5654)	loss 6.2167 (5.4541)	acc@1: 20.3123	acc@5: 36.6035	
2023-03-17 09:51:12,584 - INFO - Train: [3/90][3300/3907]	eta 0:05:59 lr 0.03995128	time 0.2769 (0.5918)	loss 5.1075 (5.4327)	acc@1: 31.5837	acc@5: 48.0238	
2023-03-17 09:56:00,304 - INFO - Train: [3/90][3600/3907]	eta 0:03:11 lr 0.03995128	time 0.2721 (0.6224)	loss 3.8598 (5.4206)	acc@1: 46.6567	acc@5: 68.4280	
2023-03-17 10:01:00,497 - INFO - Train: [3/90][3900/3907]	eta 0:00:04 lr 0.03995128	time 0.2710 (0.6515)	loss 4.3062 (5.4173)	acc@1: 39.2692	acc@5: 60.7561	
2023-03-17 10:01:04,021 - INFO - EPOCH 3 training takes 0:42:24
2023-03-17 10:01:07,827 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_c/fold1_latest.pth saved !!!
2023-03-17 10:01:07,828 - INFO - **********Latest test***********
2023-03-17 10:01:07,828 - INFO - eval epoch 3
2023-03-17 10:01:10,113 - INFO - Test: [0/782]	Time 2.284 (2.284)	Loss 3.5622 (3.5622)	Acc@1 46.875 (46.875)	Acc@5 75.000 (75.000)
2023-03-17 10:08:26,310 - INFO - Test: [200/782]	Time 2.290 (2.181)	Loss 3.6970 (4.0570)	Acc@1 42.188 (36.692)	Acc@5 73.438 (63.689)
2023-03-17 10:13:31,259 - INFO - Test: [400/782]	Time 0.762 (1.854)	Loss 3.7050 (4.0165)	Acc@1 42.969 (37.519)	Acc@5 70.312 (64.639)
2023-03-17 10:16:07,956 - INFO - Test: [600/782]	Time 0.794 (1.498)	Loss 4.1030 (3.9834)	Acc@1 38.281 (38.363)	Acc@5 61.719 (65.286)
2023-03-17 10:19:31,551 - INFO -  * Acc@1 38.863 Acc@5 65.879
2023-03-17 10:19:31,551 - INFO - Max accuracy: 38.8630%
2023-03-17 10:19:35,340 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_c/fold1_best.pth saved !!!
2023-03-17 10:19:35,341 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_c
2023-03-17 10:19:38,036 - INFO - Train: [4/90][0/3907]	eta 2:55:01 lr 0.03989044	time 2.6878 (2.6878)	loss 4.2017 (4.2017)	acc@1: 36.6878	acc@5: 60.8856	
2023-03-17 10:21:03,477 - INFO - Train: [4/90][300/3907]	eta 0:17:36 lr 0.03989044	time 0.2733 (0.2928)	loss 4.3885 (5.0554)	acc@1: 33.6158	acc@5: 62.7836	
2023-03-17 10:22:48,158 - INFO - Train: [4/90][600/3907]	eta 0:17:40 lr 0.03989044	time 0.9730 (0.3208)	loss 6.9601 (5.1455)	acc@1: 10.5502	acc@5: 18.4415	
2023-03-17 10:24:50,780 - INFO - Train: [4/90][900/3907]	eta 0:17:32 lr 0.03989044	time 0.2725 (0.3501)	loss 6.9962 (5.1251)	acc@1: 8.8590	acc@5: 17.2836	
2023-03-17 10:27:03,120 - INFO - Train: [4/90][1200/3907]	eta 0:16:49 lr 0.03989044	time 0.2750 (0.3728)	loss 4.6382 (5.1166)	acc@1: 43.3933	acc@5: 66.0739	
2023-03-17 10:29:23,158 - INFO - Train: [4/90][1500/3907]	eta 0:15:42 lr 0.03989044	time 0.2732 (0.3916)	loss 6.7190 (5.0925)	acc@1: 12.6080	acc@5: 28.1487	
2023-03-17 10:32:04,390 - INFO - Train: [4/90][1800/3907]	eta 0:14:36 lr 0.03989044	time 0.2719 (0.4159)	loss 3.4900 (5.1107)	acc@1: 49.9053	acc@5: 74.8579	
2023-03-17 10:34:57,282 - INFO - Train: [4/90][2100/3907]	eta 0:13:12 lr 0.03989044	time 0.2724 (0.4388)	loss 5.3379 (5.1037)	acc@1: 31.8304	acc@5: 56.1713	
2023-03-17 10:38:15,582 - INFO - Train: [4/90][2400/3907]	eta 0:11:43 lr 0.03989044	time 0.2724 (0.4666)	loss 5.1637 (5.1048)	acc@1: 35.9081	acc@5: 56.7848	
2023-03-17 10:42:02,207 - INFO - Train: [4/90][2700/3907]	eta 0:10:01 lr 0.03989044	time 1.1331 (0.4986)	loss 4.0918 (5.1056)	acc@1: 39.8984	acc@5: 65.2095	
2023-03-17 10:46:14,927 - INFO - Train: [4/90][3000/3907]	eta 0:08:03 lr 0.03989044	time 0.2759 (0.5330)	loss 3.8100 (5.1078)	acc@1: 43.7422	acc@5: 67.1760	
2023-03-17 10:50:36,259 - INFO - Train: [4/90][3300/3907]	eta 0:05:42 lr 0.03989044	time 5.1144 (0.5637)	loss 6.9776 (5.1063)	acc@1: 10.5825	acc@5: 22.4450	
2023-03-17 10:56:12,002 - INFO - Train: [4/90][3600/3907]	eta 0:03:07 lr 0.03989044	time 0.2705 (0.6100)	loss 4.6903 (5.0970)	acc@1: 35.1280	acc@5: 64.1494	
2023-03-17 11:00:59,522 - INFO - Train: [4/90][3900/3907]	eta 0:00:04 lr 0.03989044	time 0.2730 (0.6368)	loss 6.5985 (5.0935)	acc@1: 14.0817	acc@5: 28.7201	
2023-03-17 11:01:01,133 - INFO - EPOCH 4 training takes 0:41:25
2023-03-17 11:01:04,949 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_c/fold1_latest.pth saved !!!
2023-03-17 11:01:04,950 - INFO - **********Latest test***********
2023-03-17 11:01:04,950 - INFO - eval epoch 4
2023-03-17 11:01:07,308 - INFO - Test: [0/782]	Time 2.357 (2.357)	Loss 3.4257 (3.4257)	Acc@1 47.656 (47.656)	Acc@5 77.344 (77.344)
2023-03-17 11:08:22,882 - INFO - Test: [200/782]	Time 2.275 (2.179)	Loss 3.6362 (3.8255)	Acc@1 45.312 (41.993)	Acc@5 71.094 (68.287)
2023-03-17 11:13:25,681 - INFO - Test: [400/782]	Time 0.823 (1.847)	Loss 3.6747 (3.7980)	Acc@1 46.094 (42.489)	Acc@5 70.312 (68.919)
2023-03-17 11:16:03,432 - INFO - Test: [600/782]	Time 0.782 (1.495)	Loss 3.8847 (3.7756)	Acc@1 38.281 (42.830)	Acc@5 70.312 (69.471)
2023-03-17 11:19:27,017 - INFO -  * Acc@1 43.526 Acc@5 70.181
2023-03-17 11:19:27,018 - INFO - Max accuracy: 43.5260%
2023-03-17 11:19:30,728 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_c/fold1_best.pth saved !!!
2023-03-17 11:19:30,728 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_c
2023-03-17 11:19:33,334 - INFO - Train: [5/90][0/3907]	eta 2:49:03 lr 0.03980536	time 2.5962 (2.5962)	loss 3.6669 (3.6669)	acc@1: 45.2829	acc@5: 67.9243	
2023-03-17 11:20:57,914 - INFO - Train: [5/90][300/3907]	eta 0:17:24 lr 0.03980536	time 0.2736 (0.2896)	loss 4.5756 (4.8206)	acc@1: 39.3213	acc@5: 63.1950	
2023-03-17 11:22:32,753 - INFO - Train: [5/90][600/3907]	eta 0:16:41 lr 0.03980536	time 0.2747 (0.3028)	loss 5.2178 (4.8881)	acc@1: 30.9538	acc@5: 55.6216	
2023-03-17 11:24:24,786 - INFO - Train: [5/90][900/3907]	eta 0:16:21 lr 0.03980536	time 0.3011 (0.3264)	loss 3.6393 (4.8762)	acc@1: 49.9271	acc@5: 72.2022	
2023-03-17 11:26:34,449 - INFO - Train: [5/90][1200/3907]	eta 0:15:55 lr 0.03980536	time 0.2908 (0.3528)	loss 3.4820 (4.9063)	acc@1: 49.8813	acc@5: 75.6004	
2023-03-17 11:29:02,380 - INFO - Train: [5/90][1500/3907]	eta 0:15:16 lr 0.03980536	time 0.2750 (0.3808)	loss 7.0767 (4.9091)	acc@1: 10.5627	acc@5: 21.2205	
2023-03-17 11:31:48,798 - INFO - Train: [5/90][1800/3907]	eta 0:14:23 lr 0.03980536	time 0.2832 (0.4098)	loss 5.1875 (4.9060)	acc@1: 29.0935	acc@5: 52.8973	
2023-03-17 11:34:49,704 - INFO - Train: [5/90][2100/3907]	eta 0:13:10 lr 0.03980536	time 0.2725 (0.4374)	loss 6.5608 (4.9119)	acc@1: 17.4364	acc@5: 29.6960	
2023-03-17 11:38:15,207 - INFO - Train: [5/90][2400/3907]	eta 0:11:45 lr 0.03980536	time 0.2714 (0.4683)	loss 3.9370 (4.9260)	acc@1: 48.2234	acc@5: 67.3597	
2023-03-17 11:41:58,897 - INFO - Train: [5/90][2700/3907]	eta 0:10:02 lr 0.03980536	time 0.2781 (0.4991)	loss 3.5535 (4.9231)	acc@1: 48.3735	acc@5: 74.4861	
2023-03-17 11:45:57,632 - INFO - Train: [5/90][3000/3907]	eta 0:07:59 lr 0.03980536	time 1.7467 (0.5288)	loss 4.1365 (4.9216)	acc@1: 43.2002	acc@5: 67.3630	
2023-03-17 11:49:59,595 - INFO - Train: [5/90][3300/3907]	eta 0:05:36 lr 0.03980536	time 3.4860 (0.5540)	loss 3.5848 (4.9355)	acc@1: 49.9944	acc@5: 72.6481	
2023-03-17 11:54:19,145 - INFO - Train: [5/90][3600/3907]	eta 0:02:58 lr 0.03980536	time 0.2777 (0.5799)	loss 4.0049 (4.9294)	acc@1: 46.3361	acc@5: 68.7567	
2023-03-17 11:58:58,518 - INFO - Train: [5/90][3900/3907]	eta 0:00:04 lr 0.03980536	time 0.2810 (0.6070)	loss 4.2437 (4.9293)	acc@1: 40.6390	acc@5: 64.2836	
2023-03-17 11:59:00,172 - INFO - EPOCH 5 training takes 0:39:29
2023-03-17 11:59:04,423 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_c/fold1_latest.pth saved !!!
2023-03-17 11:59:04,423 - INFO - **********Latest test***********
2023-03-17 11:59:04,423 - INFO - eval epoch 5
2023-03-17 11:59:06,718 - INFO - Test: [0/782]	Time 2.294 (2.294)	Loss 3.2793 (3.2793)	Acc@1 45.312 (45.312)	Acc@5 81.250 (81.250)
2023-03-17 12:06:21,782 - INFO - Test: [200/782]	Time 2.288 (2.176)	Loss 3.3590 (3.6267)	Acc@1 48.438 (45.176)	Acc@5 79.688 2023-03-17 12:11:28,268 - INFO - Test: [400/782]	Time 0.790 (1.855)	Loss 3.5219 (3.5890)	Acc@1 48.438 (46.037)	Acc@5 71.875 (72.526)
2023-03-17 12:14:06,355 - INFO - Test: [600/782]	Time 0.785 (1.501)	Loss 3.7212 (3.5593)	Acc@1 45.312 (46.771)	Acc@5 67.969 (73.062)
2023-03-17 12:17:31,960 - INFO -  * Acc@1 47.317 Acc@5 73.639
2023-03-17 12:17:31,961 - INFO - Max accuracy: 47.3170%
2023-03-17 12:17:35,781 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_c/fold1_best.pth saved !!!
2023-03-17 12:17:35,781 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_c
2023-03-17 12:17:38,222 - INFO - Train: [6/90][0/3907]	eta 2:38:24 lr 0.03969616	time 2.4328 (2.4328)	loss 4.1498 (4.1498)	acc@1: 46.0341	acc@5: 68.3938	
2023-03-17 12:19:10,096 - INFO - Train: [6/90][300/3907]	eta 0:18:50 lr 0.03969616	time 0.2731 (0.3133)	loss 3.6676 (4.7658)	acc@1: 47.9963	acc@5: 71.9981	
2023-03-17 12:21:01,408 - INFO - Train: [6/90][600/3907]	eta 0:18:51 lr 0.03969616	time 0.5309 (0.3421)	loss 4.8198 (4.8073)	acc@1: 34.5051	acc@5: 67.0265	
2023-03-17 12:23:10,988 - INFO - Train: [6/90][900/3907]	eta 0:18:38 lr 0.03969616	time 0.2731 (0.3720)	loss 6.8542 (4.8186)	acc@1: 9.1906	acc@5: 20.7707	
2023-03-17 12:25:35,324 - INFO - Train: [6/90][1200/3907]	eta 0:18:00 lr 0.03969616	time 0.2723 (0.3993)	loss 4.7943 (4.8056)	acc@1: 39.9806	acc@5: 58.5923	
2023-03-17 12:28:11,385 - INFO - Train: [6/90][1500/3907]	eta 0:16:59 lr 0.03969616	time 0.2738 (0.4234)	loss 3.5588 (4.8003)	acc@1: 53.6667	acc@5: 76.2192	
2023-03-17 12:31:02,421 - INFO - Train: [6/90][1800/3907]	eta 0:15:43 lr 0.03969616	time 0.2721 (0.4479)	loss 4.4622 (4.8122)	acc@1: 47.1566	acc@5: 62.8424	
2023-03-17 12:34:09,863 - INFO - Train: [6/90][2100/3907]	eta 0:14:14 lr 0.03969616	time 0.2798 (0.4731)	loss 4.3894 (4.8145)	acc@1: 41.4841	acc@5: 68.6864	
2023-03-17 12:37:41,579 - INFO - Train: [6/90][2400/3907]	eta 0:12:36 lr 0.03969616	time 1.2103 (0.5022)	loss 5.0190 (4.8298)	acc@1: 37.6809	acc@5: 58.7664	
2023-03-17 12:41:41,913 - INFO - Train: [6/90][2700/3907]	eta 0:10:46 lr 0.03969616	time 3.7728 (0.5354)	loss 4.5161 (4.8222)	acc@1: 42.7692	acc@5: 63.1021	
2023-03-17 12:45:42,543 - INFO - Train: [6/90][3000/3907]	eta 0:08:29 lr 0.03969616	time 0.2829 (0.5621)	loss 5.1453 (4.8243)	acc@1: 42.9351	acc@5: 60.2925	
2023-03-17 12:49:58,657 - INFO - Train: [6/90][3300/3907]	eta 0:05:57 lr 0.03969616	time 0.2719 (0.5886)	loss 4.8640 (4.8223)	acc@1: 40.2726	acc@5: 64.1611	
2023-03-17 12:54:36,239 - INFO - Train: [6/90][3600/3907]	eta 0:03:09 lr 0.03969616	time 0.2847 (0.6166)	loss 6.7024 (4.8202)	acc@1: 11.6428	acc@5: 25.2978	
2023-03-17 12:59:26,569 - INFO - Train: [6/90][3900/3907]	eta 0:00:04 lr 0.03969616	time 0.2825 (0.6436)	loss 6.2348 (4.8272)	acc@1: 19.8667	acc@5: 32.5606	
2023-03-17 12:59:29,031 - INFO - EPOCH 6 training takes 0:41:53
2023-03-17 12:59:32,804 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_c/fold1_latest.pth saved !!!
2023-03-17 12:59:32,804 - INFO - **********Latest test***********
2023-03-17 12:59:32,805 - INFO - eval epoch 6
2023-03-17 12:59:35,152 - INFO - Test: [0/782]	Time 2.347 (2.347)	Loss 2.8909 (2.8909)	Acc@1 61.719 (61.719)	Acc@5 86.719 (86.719)
2023-03-17 13:06:48,330 - INFO - Test: [200/782]	Time 2.306 (2.167)	Loss 3.3343 (3.5190)	Acc@1 52.344 (48.134)	Acc@5 74.219 (73.958)
2023-03-17 13:11:49,733 - INFO - Test: [400/782]	Time 0.761 (1.838)	Loss 3.3198 (3.4892)	Acc@1 52.344 (48.706)	Acc@5 75.000 (74.501)
2023-03-17 13:14:26,374 - INFO - Test: [600/782]	Time 0.767 (1.487)	Loss 3.5295 (3.4567)	Acc@1 48.438 (49.523)	Acc@5 71.094 (75.045)
2023-03-17 13:17:48,404 - INFO -  * Acc@1 50.125 Acc@5 75.631
2023-03-17 13:17:48,404 - INFO - Max accuracy: 50.1250%
2023-03-17 13:17:52,042 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp/fold1_best.pth saved !!!
2023-03-17 13:17:52,042 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp
2023-03-17 13:17:54,153 - INFO - Train: [7/90][0/3907]	eta 2:16:52 lr 0.03956295	time 2.1021 (2.1021)	loss 5.9600 (5.9600)	acc@1: 23.5907	acc@5: 41.2075	
2023-03-17 13:19:23,105 - INFO - Train: [7/90][300/3907]	eta 0:18:11 lr 0.03956295	time 0.3019 (0.3025)	loss 3.4886 (4.4885)	acc@1: 54.2086	acc@5: 77.4409	
2023-03-17 13:21:05,840 - INFO - Train: [7/90][600/3907]	eta 0:17:46 lr 0.03956295	time 0.4835 (0.3224)	loss 6.2101 (4.5803)	acc@1: 18.6024	acc@5: 34.5751	
2023-03-17 13:23:06,489 - INFO - Train: [7/90][900/3907]	eta 0:17:29 lr 0.03956295	time 0.2809 (0.3490)	loss 3.7332 (4.6094)	acc@1: 46.0286	acc@5: 67.0926	
2023-03-17 13:25:23,823 - INFO - Train: [7/90][1200/3907]	eta 0:16:58 lr 0.03956295	time 0.2839 (0.3762)	loss 3.3210 (4.6631)	acc@1: 51.5565	acc@5: 82.0216	
2023-03-17 13:27:57,058 - INFO - Train: [7/90][1500/3907]	eta 0:16:10 lr 0.03956295	time 0.9926 (0.4031)	loss 4.2874 (4.6876)	acc@1: 45.2560	acc@5: 68.2321	
2023-03-17 13:30:47,916 - INFO - Train: [7/90][1800/3907]	eta 0:15:07 lr 0.03956295	time 0.2724 (0.4308)	loss 6.0084 (4.7092)	acc@1: 24.5604	acc@5: 40.4022	
2023-03-17 13:33:59,344 - INFO - Train: [7/90][2100/3907]	eta 0:13:51 lr 0.03956295	time 0.2798 (0.4604)	loss 5.8496 (4.7383)	acc@1: 27.3078	acc@5: 44.4564	
2023-03-17 13:37:35,833 - INFO - Train: [7/90][2400/3907]	eta 0:12:22 lr 0.03956295	time 0.2800 (0.4930)	loss 3.3833 (4.7340)	acc@1: 53.8013	acc@5: 75.6331	
2023-03-17 13:41:29,052 - INFO - Train: [7/90][2700/3907]	eta 0:10:33 lr 0.03956295	time 0.2712 (0.5246)	loss 3.9164 (4.7358)	acc@1: 44.0826	acc@5: 65.3638	
2023-03-17 13:45:32,640 - INFO - Train: [7/90][3000/3907]	eta 0:08:21 lr 0.03956295	time 0.2724 (0.5533)	loss 4.1347 (4.7392)	acc@1: 44.1582	acc@5: 64.0294	
2023-03-17 13:49:32,259 - INFO - Train: [7/90][3300/3907]	eta 0:05:49 lr 0.03956295	time 0.2803 (0.5756)	loss 3.8866 (4.7341)	acc@1: 42.9066	acc@5: 70.2107	
2023-03-17 13:53:37,685 - INFO - Train: [7/90][3600/3907]	eta 0:03:02 lr 0.03956295	time 1.1627 (0.5958)	loss 3.3804 (4.7375)	acc@1: 52.5341	acc@5: 80.3463	
2023-03-17 13:58:11,555 - INFO - Train: [7/90][3900/3907]	eta 0:00:04 lr 0.03956295	time 0.2724 (0.6202)	loss 4.5970 (4.7392)	acc@1: 41.0383	acc@5: 62.2415	
2023-03-17 13:58:13,157 - INFO - EPOCH 7 training takes 0:40:21
2023-03-17 13:58:16,886 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp/fold1_latest.pth saved !!!
2023-03-17 13:58:16,886 - INFO - **********latest test***********
2023-03-17 13:58:16,886 - INFO - eval epoch 7
2023-03-17 13:58:19,242 - INFO - Test: [0/782]	Time 2.354 (2.354)	Loss 2.9653 (2.9653)	Acc@1 63.281 (63.281)	Acc@5 88.281 (88.281)
2023-03-17 14:05:44,382 - INFO - Test: [200/782]	Time 2.263 (2.226)	Loss 3.2525 (3.4597)	Acc@1 57.812 (50.257)	Acc@5 76.562 (75.202)
2023-03-17 14:10:31,256 - INFO - Test: [400/782]	Time 0.802 (1.831)	Loss 3.2401 (3.4235)	Acc@1 59.375 (50.844)	Acc@5 79.688 (76.048)
2023-03-17 14:13:07,600 - INFO - Test: [600/782]	Time 0.793 (1.482)	Loss 3.5295 (3.3928)	Acc@1 46.094 (51.542)	Acc@5 73.438 (76.592)
2023-03-17 14:16:28,589 - INFO -  * Acc@1 52.159 Acc@5 77.142
2023-03-17 14:16:28,589 - INFO - Max accuracy: 52.1590%
2023-03-17 14:16:32,103 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp/fold1_best.pth saved !!!
2023-03-17 14:16:32,103 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp
2023-03-17 14:16:34,125 - INFO - Train: [8/90][0/3907]	eta 2:11:10 lr 0.03940591	time 2.0145 (2.0145)	loss 4.7350 (4.7350)	acc@1: 44.5231	acc@5: 65.1669	
2023-03-17 14:17:58,047 - INFO - Train: [8/90][300/3907]	eta 0:17:09 lr 0.03940591	time 0.2889 (0.2855)	loss 6.2473 (4.6227)	acc@1: 18.7596	acc@5: 38.1603	
2023-03-17 14:19:22,329 - INFO - Train: [8/90][600/3907]	eta 0:15:36 lr 0.03940591	time 0.2778 (0.2832)	loss 3.2415 (4.6187)	acc@1: 58.0170	acc@5: 76.5877	
2023-03-17 14:20:48,819 - INFO - Train: [8/90][900/3907]	eta 0:14:16 lr 0.03940591	time 0.2746 (0.2849)	loss 4.1897 (4.6069)	acc@1: 41.5546	acc@5: 67.0380	
2023-03-17 14:22:27,436 - INFO - Train: [8/90][1200/3907]	eta 0:13:20 lr 0.03940591	time 0.3693 (0.2959)	loss 5.8941 (4.6306)	acc@1: 29.5838	acc@5: 43.9652	
2023-03-17 14:24:19,455 - INFO - Train: [8/90][1500/3907]	eta 0:12:29 lr 0.03940591	time 0.2913 (0.3114)	loss 3.7768 (4.6346)	acc@1: 50.2079	acc@5: 71.1768	
2023-03-17 14:26:26,558 - INFO - Train: [8/90][1800/3907]	eta 0:11:35 lr 0.03940591	time 0.2731 (0.3301)	loss 6.4418 (4.6419)	acc@1: 17.3108	acc@5: 28.7468	
2023-03-17 14:29:00,131 - INFO - Train: [8/90][2100/3907]	eta 0:10:43 lr 0.03940591	time 3.8214 (0.3560)	loss 3.6924 (4.6485)	acc@1: 52.3017	acc@5: 74.0036	
2023-03-17 14:31:50,216 - INFO - Train: [8/90][2400/3907]	eta 0:09:36 lr 0.03940591	time 2.2010 (0.3824)	loss 3.4667 (4.6437)	acc@1: 51.2811	acc@5: 76.9173	
2023-03-17 14:35:08,837 - INFO - Train: [8/90][2700/3907]	eta 0:08:19 lr 0.03940591	time 0.2722 (0.4134)	loss 5.0674 (4.6478)	acc@1: 37.1832	acc@5: 56.0343	
2023-03-17 14:38:49,194 - INFO - Train: [8/90][3000/3907]	eta 0:06:44 lr 0.03940591	time 0.2722 (0.4455)	loss 3.9891 (4.6493)	acc@1: 53.8243	acc@5: 73.6270	
2023-03-17 14:42:41,472 - INFO - Train: [8/90][3300/3907]	eta 0:04:48 lr 0.03940591	time 0.2720 (0.4754)	loss 6.2564 (4.6646)	acc@1: 22.2733	acc@5: 35.3997	
2023-03-17 14:46:43,768 - INFO - Train: [8/90][3600/3907]	eta 0:02:34 lr 0.03940591	time 0.2830 (0.5031)	loss 6.8071 (4.6746)	acc@1: 11.8228	acc@5: 21.6058	
2023-03-17 14:51:09,159 - INFO - Train: [8/90][3900/3907]	eta 0:00:03 lr 0.03940591	time 0.4096 (0.5324)	loss 3.4873 (4.6726)	acc@1: 51.2511	acc@5: 72.9939	
2023-03-17 14:51:10,793 - INFO - EPOCH 8 training takes 0:34:38
2023-03-17 14:51:14,529 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp/fold1_latest.pth saved !!!
2023-03-17 14:51:14,529 - INFO - **********latest test***********
2023-03-17 14:51:14,529 - INFO - eval epoch 8
2023-03-17 14:51:16,808 - INFO - Test: [0/782]	Time 2.277 (2.277)	Loss 2.9909 (2.9909)	Acc@1 57.812 (57.812)	Acc@5 84.375 (84.375)
2023-03-17 14:58:07,000 - INFO - Test: [200/782]	Time 2.278 (2.052)	Loss 3.3307 (3.4704)	Acc@1 52.344 (49.712)	Acc@5 78.125 (75.004)
2023-03-17 15:02:51,703 - INFO - Test: [400/782]	Time 0.765 (1.739)	Loss 3.2943 (3.4301)	Acc@1 52.344 (50.567)	Acc@5 76.562 (75.657)
2023-03-17 15:05:28,641 - INFO - Test: [600/782]	Time 0.756 (1.421)	Loss 3.5033 (3.3906)	Acc@1 46.094 (51.353)	Acc@5 73.438 (76.343)
2023-03-17 15:08:51,954 - INFO -  * Acc@1 51.879 Acc@5 76.904
2023-03-17 15:08:51,954 - INFO - Max accuracy: 52.1590%
2023-03-17 15:08:51,955 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp
2023-03-17 15:08:53,761 - INFO - Train: [9/90][0/3907]	eta 1:57:20 lr 0.03922523	time 1.8020 (1.8020)	loss 4.8142 (4.8142)	acc@1: 41.6165	acc@5: 60.6585	
2023-03-17 15:10:17,510 - INFO - Train: [9/90][300/3907]	eta 0:17:05 lr 0.03922523	time 0.2980 (0.2842)	loss 6.4396 (4.4498)	acc@1: 16.0323	acc@5: 29.9946	
2023-03-17 15:11:41,791 - INFO - Train: [9/90][600/3907]	eta 0:15:34 lr 0.03922523	time 0.2748 (0.2826)	loss 5.1960 (4.4831)	acc@1: 31.1928	acc@5: 54.2755	
2023-03-17 15:13:06,427 - INFO - Train: [9/90][900/3907]	eta 0:14:09 lr 0.03922523	time 0.2757 (0.2824)	loss 5.9434 (4.4972)	acc@1: 24.6257	acc@5: 43.1713	
2023-03-17 15:14:32,123 - INFO - Train: [9/90][1200/3907]	eta 0:12:46 lr 0.03922523	time 0.2951 (0.2832)	loss 3.6389 (4.5354)	acc@1: 45.7448	acc@5: 70.5556	
2023-03-17 15:16:11,811 - INFO - Train: [9/90][1500/3907]	eta 0:11:45 lr 0.03922523	time 0.3004 (0.2930)	loss 4.0885 (4.5506)	acc@1: 42.7302	acc@5: 69.2243	
2023-03-17 15:18:05,037 - INFO - Train: [9/90][1800/3907]	eta 0:10:47 lr 0.03922523	time 0.2726 (0.3071)	loss 3.8810 (4.5647)	acc@1: 47.4330	acc@5: 70.8112	
2023-03-17 15:20:15,184 - INFO - Train: [9/90][2100/3907]	eta 0:09:47 lr 0.03922523	time 0.2727 (0.3252)	loss 4.3884 (4.5650)	acc@1: 44.7040	acc@5: 68.0379	
2023-03-17 15:23:00,442 - INFO - Train: [9/90][2400/3907]	eta 0:08:52 lr 0.03922523	time 0.2721 (0.3534)	loss 5.3692 (4.5743)	acc@1: 32.0977	acc@5: 49.7073	
2023-03-17 15:26:01,760 - INFO - Train: [9/90][2700/3907]	eta 0:07:40 lr 0.03922523	time 0.2847 (0.3813)	loss 4.6744 (4.5815)	acc@1: 43.3635	acc@5: 65.4358	
2023-03-17 15:29:28,493 - INFO - Train: [9/90][3000/3907]	eta 0:06:13 lr 0.03922523	time 0.2720 (0.4120)	loss 4.2777 (4.5874)	acc@1: 47.9508	acc@5: 66.8004	
2023-03-17 15:32:59,817 - INFO - Train: [9/90][3300/3907]	eta 0:04:26 lr 0.03922523	time 0.2716 (0.4386)	loss 4.5211 (4.5987)	acc@1: 40.4297	acc@5: 58.6375	
2023-03-17 15:36:43,070 - INFO - Train: [9/90][3600/3907]	eta 0:02:22 lr 0.03922523	time 0.4330 (0.4641)	loss 4.0418 (4.6011)	acc@1: 49.7724	acc@5: 70.0061	
2023-03-17 15:40:48,263 - INFO - Train: [9/90][3900/3907]	eta 0:00:03 lr 0.03922523	time 0.2716 (0.4912)	loss 3.4962 (4.6057)	acc@1: 48.1229	acc@5: 76.0653	
2023-03-17 15:40:49,883 - INFO - EPOCH 9 training takes 0:31:57
2023-03-17 15:40:53,574 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp/fold1_latest.pth saved !!!
2023-03-17 15:40:53,574 - INFO - **********latest test***********
2023-03-17 15:40:53,574 - INFO - eval epoch 9
2023-03-17 15:40:55,940 - INFO - Test: [0/782]	Time 2.365 (2.365)	Loss 2.9003 (2.9003)	Acc@1 64.844 (64.844)	Acc@5 85.938 (85.938)
2023-03-17 15:47:38,193 - INFO - Test: [200/782]	Time 2.260 (2.013)	Loss 3.2832 (3.3818)	Acc@1 50.000 (50.999)	Acc@5 76.562 (76.306)
2023-03-17 15:52:19,157 - INFO - Test: [400/782]	Time 0.772 (1.710)	Loss 3.1928 (3.3391)	Acc@1 57.812 (52.050)	Acc@5 78.125 (77.014)
2023-03-17 15:54:55,498 - INFO - Test: [600/782]	Time 0.767 (1.401)	Loss 3.4184 (3.3061)	Acc@1 51.562 (52.626)	Acc@5 77.344 (77.634)
2023-03-17 15:58:16,920 - INFO -  * Acc@1 53.267 Acc@5 78.292
2023-03-17 15:58:16,920 - INFO - Max accuracy: 53.2670%
2023-03-17 15:58:20,549 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp/fold1_best.pth saved !!!
2023-03-17 15:58:20,549 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp
2023-03-17 15:58:22,629 - INFO - Train: [10/90][0/3907]	eta 2:14:56 lr 0.03902113	time 2.0723 (2.0723)	loss 5.4405 (5.4405)	acc@1: 33.7852	acc@5: 54.7842	
2023-03-17 15:59:46,384 - INFO - Train: [10/90][300/3907]	eta 0:17:08 lr 0.03902113	time 0.2840 (0.2851)	loss 4.8330 (4.4888)	acc@1: 44.9051	acc@5: 60.8920	
2023-03-17 16:01:10,671 - INFO - Train: [10/90][600/3907]	eta 0:15:36 lr 0.03902113	time 0.2747 (0.2830)	loss 6.5831 (4.4748)	acc@1: 13.8612	acc@5: 26.5295	
2023-03-17 16:02:35,249 - INFO - Train: [10/90][900/3907]	eta 0:14:09 lr 0.03902113	time 0.2756 (0.2827)	loss 4.9009 (4.4890)	acc@1: 39.9346	acc@5: 59.7323	
2023-03-17 16:04:03,602 - INFO - Train: [10/90][1200/3907]	eta 0:12:53 lr 0.03902113	time 0.2885 (0.2856)	loss 6.2814 (4.4973)	acc@1: 18.9480	acc@5: 30.8451	
2023-03-17 16:05:44,102 - INFO - Train: [10/90][1500/3907]	eta 0:11:51 lr 0.03902113	time 0.2739 (0.2955)	loss 6.5101 (4.5118)	acc@1: 13.3038	acc@5: 24.6658	
2023-03-17 16:07:41,351 - INFO - Train: [10/90][1800/3907]	eta 0:10:56 lr 0.03902113	time 0.2823 (0.3114)	loss 6.1496 (4.5213)	acc@1: 22.7835	acc@5: 37.8308	
2023-03-17 16:10:00,046 - INFO - Train: [10/90][2100/3907]	eta 0:10:01 lr 0.03902113	time 0.3331 (0.3329)	loss 3.4247 (4.5245)	acc@1: 54.3838	acc@5: 73.0297	
2023-03-17 16:12:49,764 - INFO - Train: [10/90][2400/3907]	eta 0:09:05 lr 0.03902113	time 0.2708 (0.3620)	loss 3.3707 (4.5284)	acc@1: 43.7495	acc@5: 78.9053	
2023-03-17 16:16:13,644 - INFO - Train: [10/90][2700/3907]	eta 0:07:59 lr 0.03902113	time 0.2710 (0.3973)	loss 5.7554 (4.5390)	acc@1: 28.7705	acc@5: 47.0942	
2023-03-17 16:19:51,315 - INFO - Train: [10/90][3000/3907]	eta 0:06:30 lr 0.03902113	time 0.2921 (0.4301)	loss 6.4168 (4.5536)	acc@1: 21.2722	acc@5: 35.1036	
2023-03-17 16:23:36,265 - INFO - Train: [10/90][3300/3907]	eta 0:04:38 lr 0.03902113	time 0.2828 (0.4592)	loss 5.9416 (4.5597)	acc@1: 24.2600	acc@5: 41.4218	
2023-03-17 16:27:18,654 - INFO - Train: [10/90][3600/3907]	eta 0:02:28 lr 0.03902113	time 0.2801 (0.4827)	loss 4.1458 (4.5715)	acc@1: 48.3552	acc@5: 70.5508	
2023-03-17 16:31:20,819 - INFO - Train: [10/90][3900/3907]	eta 0:00:03 lr 0.03902113	time 0.2799 (0.5076)	loss 5.6808 (4.5770)	acc@1: 27.5879	acc@5: 43.9952	
2023-03-17 16:31:22,427 - INFO - EPOCH 10 training takes 0:33:01
2023-03-17 16:31:26,126 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp/fold1_latest.pth saved !!!
2023-03-17 16:31:26,126 - INFO - **********latest test***********
2023-03-17 16:31:26,126 - INFO - eval epoch 10
2023-03-17 16:31:28,644 - INFO - Test: [0/782]	Time 2.516 (2.516)	Loss 2.9373 (2.9373)	Acc@1 63.281 (63.281)	Acc@5 84.375 (84.375)
2023-03-17 16:38:09,081 - INFO - Test: [200/782]	Time 2.277 (2.005)	Loss 3.1962 (3.3808)	Acc@1 55.469 (52.068)	Acc@5 79.688 (76.683)
2023-03-17 16:42:49,648 - INFO - Test: [400/782]	Time 0.780 (1.705)	Loss 3.1441 (3.3479)	Acc@1 56.250 (52.731)	Acc@5 81.250 (77.465)
2023-03-17 16:45:27,141 - INFO - Test: [600/782]	Time 0.776 (1.399)	Loss 3.3550 (3.3144)	Acc@1 53.125 (53.398)	Acc@5 80.469 (78.047)
2023-03-17 16:49:57,666 - INFO -  * Acc@1 54.010 Acc@5 78.614
2023-03-17 16:49:57,666 - INFO - Max accuracy: 54.0100%
2023-03-17 16:50:01,315 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp/fold1_best.pth saved !!!
2023-03-17 16:50:01,316 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp
2023-03-17 16:50:03,156 - INFO - Train: [11/90][0/3907]	eta 1:59:10 lr 0.03879385	time 1.8301 (1.8301)	loss 6.4699 (6.4699)	acc@1: 16.9803	acc@5: 28.8213	
2023-03-17 16:51:27,259 - INFO - Train: [11/90][300/3907]	eta 0:17:09 lr 0.03879385	time 0.2832 (0.2855)	loss 2.8886 (4.4584)	acc@1: 63.2728	acc@5: 82.8014	
2023-03-17 16:52:51,310 - INFO - Train: [11/90][600/3907]	eta 0:15:35 lr 0.03879385	time 0.2744 (0.2828)	loss 6.2490 (4.5748)	acc@1: 23.6890	acc@5: 36.3762	
2023-03-17 16:54:15,392 - INFO - Train: [11/90][900/3907]	eta 0:14:07 lr 0.03879385	time 0.2825 (0.2820)	loss 3.3535 (4.5413)	acc@1: 60.0232	acc@5: 79.0110	
2023-03-17 16:55:41,801 - INFO - Train: [11/90][1200/3907]	eta 0:12:47 lr 0.03879385	time 0.2747 (0.2835)	loss 5.0395 (4.5479)	acc@1: 34.8207	acc@5: 61.3951	
2023-03-17 16:57:19,160 - INFO - Train: [11/90][1500/3907]	eta 0:11:42 lr 0.03879385	time 0.2735 (0.2917)	loss 3.7063 (4.5569)	acc@1: 52.7923	acc@5: 75.5224	
2023-03-17 16:59:07,645 - INFO - Train: [11/90][1800/3907]	eta 0:10:39 lr 0.03879385	time 1.4048 (0.3033)	loss 5.2513 (4.5589)	acc@1: 36.8378	acc@5: 54.3202	
2023-03-17 17:01:16,464 - INFO - Train: [11/90][2100/3907]	eta 0:09:40 lr 0.03879385	time 0.2845 (0.3213)	loss 3.3975 (4.5488)	acc@1: 52.8381	acc@5: 77.3354	
2023-03-17 17:03:51,410 - INFO - Train: [11/90][2400/3907]	eta 0:08:40 lr 0.03879385	time 0.7708 (0.3457)	loss 3.2775 (4.5479)	acc@1: 48.4294	acc@5: 76.5496	
2023-03-17 17:07:01,237 - INFO - Train: [11/90][2700/3907]	eta 0:07:35 lr 0.03879385	time 0.2720 (0.3776)	loss 3.3079 (4.5464)	acc@1: 51.6477	acc@5: 77.0755	
2023-03-17 17:10:46,554 - INFO - Train: [11/90][3000/3907]	eta 0:06:16 lr 0.03879385	time 0.2710 (0.4149)	loss 4.3662 (4.5484)	acc@1: 43.2895	acc@5: 68.7135	
2023-03-17 17:14:32,853 - INFO - Train: [11/90][3300/3907]	eta 0:04:30 lr 0.03879385	time 0.2710 (0.4458)	loss 3.4685 (4.5590)	acc@1: 55.9993	acc@5: 74.4100	
2023-03-17 17:18:23,529 - INFO - Train: [11/90][3600/3907]	eta 0:02:25 lr 0.03879385	time 0.2719 (0.4727)	loss 6.2435 (4.5712)	acc@1: 21.5513	acc@5: 35.6324	
2023-03-17 17:22:25,768 - INFO - Train: [11/90][3900/3907]	eta 0:00:03 lr 0.03879385	time 0.2809 (0.4984)	loss 4.9087 (4.5715)	acc@1: 37.5672	acc@5: 59.2161	
2023-03-17 17:22:27,754 - INFO - EPOCH 11 training takes 0:32:26
2023-03-17 17:22:31,532 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp/fold1_latest.pth saved !!!
2023-03-17 17:22:31,533 - INFO - **********latest test***********
2023-03-17 17:22:31,533 - INFO - eval epoch 11
2023-03-17 17:22:33,838 - INFO - Test: [0/782]	Time 2.304 (2.304)	Loss 2.9713 (2.9713)	Acc@1 57.812 (57.812)	Acc@5 85.938 (85.938)
2023-03-17 17:29:59,599 - INFO - Test: [200/782]	Time 2.338 (2.229)	Loss 3.2264 (3.3819)	Acc@1 57.812 (52.418)	Acc@5 76.562 (76.765)
2023-03-17 17:37:07,251 - INFO - Test: [400/782]	Time 2.051 (2.184)	Loss 3.2181 (3.3435)	Acc@1 56.250 (53.070)	Acc@5 79.688 (77.578)
2023-03-17 17:43:55,307 - INFO - Test: [600/782]	Time 0.765 (2.136)	Loss 3.3914 (3.3062)	Acc@1 54.688 (53.936)	Acc@5 75.781 (78.258)
2023-03-17 17:47:15,804 - INFO -  * Acc@1 54.463 Acc@5 78.762
2023-03-17 17:47:15,804 - INFO - Max accuracy: 54.4630%
2023-03-17 17:47:19,486 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp/fold1_best.pth saved !!!
2023-03-17 17:47:19,487 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp
2023-03-17 17:47:21,478 - INFO - Train: [12/90][0/3907]	eta 2:09:00 lr 0.03854368	time 1.9811 (1.9811)	loss 6.5844 (6.5844)	acc@1: 16.4192	acc@5: 29.3550	
2023-03-17 17:48:45,092 - INFO - Train: [12/90][300/3907]	eta 0:17:05 lr 0.03854368	time 0.2736 (0.2844)	loss 3.1567 (4.3486)	acc@1: 62.4832	acc@5: 80.2253	
2023-03-17 17:50:09,326 - INFO - Train: [12/90][600/3907]	eta 0:15:34 lr 0.03854368	time 0.2837 (0.2826)	loss 3.3477 (4.3555)	acc@1: 53.9750	acc@5: 75.5651	
2023-03-17 17:51:33,909 - INFO - Train: [12/90][900/3907]	eta 0:14:09 lr 0.03854368	time 0.2746 (0.2824)	loss 3.0811 (4.4265)	acc@1: 62.3734	acc@5: 83.1758	
2023-03-17 17:53:05,889 - INFO - Train: [12/90][1200/3907]	eta 0:13:00 lr 0.03854368	time 0.2742 (0.2884)	loss 6.6585 (4.4405)	acc@1: 11.9990	acc@5: 25.9791	
2023-03-17 17:54:49,270 - INFO - Train: [12/90][1500/3907]	eta 0:12:01 lr 0.03854368	time 0.2754 (0.2996)	loss 6.1874 (4.4795)	acc@1: 24.0668	acc@5: 39.1175	
2023-03-17 17:56:46,530 - INFO - Train: [12/90][1800/3907]	eta 0:11:03 lr 0.03854368	time 0.2732 (0.3148)	loss 6.3433 (4.4789)	acc@1: 16.1013	acc@5: 30.4653	
2023-03-17 17:59:03,798 - INFO - Train: [12/90][2100/3907]	eta 0:10:05 lr 0.03854368	time 1.3240 (0.3352)	loss 3.0802 (4.4853)	acc@1: 53.1225	acc@5: 81.2462	
2023-03-17 18:01:46,063 - INFO - Train: [12/90][2400/3907]	eta 0:09:03 lr 0.03854368	time 0.2778 (0.3609)	loss 3.9869 (4.4825)	acc@1: 51.2601	acc@5: 69.0897	
2023-03-17 18:04:47,851 - INFO - Train: [12/90][2700/3907]	eta 0:07:48 lr 0.03854368	time 0.2830 (0.3881)	loss 6.2864 (4.4894)	acc@1: 19.2650	acc@5: 31.3301	
2023-03-17 18:08:01,610 - INFO - Train: [12/90][3000/3907]	eta 0:06:15 lr 0.03854368	time 0.2719 (0.4139)	loss 5.9728 (4.4987)	acc@1: 21.0348	acc@5: 38.3092	
2023-03-17 18:11:19,576 - INFO - Train: [12/90][3300/3907]	eta 0:04:24 lr 0.03854368	time 0.2856 (0.4363)	loss 6.2678 (4.5087)	acc@1: 18.6427	acc@5: 33.3734	
2023-03-17 18:15:30,005 - INFO - Train: [12/90][3600/3907]	eta 0:02:24 lr 0.03854368	time 0.2755 (0.4694)	loss 4.1863 (4.5206)	acc@1: 45.9581	acc@5: 68.6578	
2023-03-17 18:20:00,254 - INFO - Train: [12/90][3900/3907]	eta 0:00:03 lr 0.03854368	time 0.2714 (0.5026)	loss 3.3753 (4.5205)	acc@1: 57.8060	acc@5: 77.8417	
2023-03-17 18:20:02,363 - INFO - EPOCH 12 training takes 0:32:42
2023-03-17 18:20:06,119 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp/fold1_latest.pth saved !!!
2023-03-17 18:20:06,119 - INFO - **********latest test***********
2023-03-17 18:20:06,120 - INFO - eval epoch 12
2023-03-17 18:20:09,142 - INFO - Test: [0/782]	Time 3.021 (3.021)	Loss 3.0364 (3.0364)	Acc@1 60.156 (60.156)	Acc@5 85.156 (85.156)
2023-03-17 18:27:08,952 - INFO - Test: [200/782]	Time 2.255 (2.104)	Loss 3.3313 (3.4174)	Acc@1 50.000 (51.314)	Acc@5 76.562 (76.077)
2023-03-17 18:34:21,185 - INFO - Test: [400/782]	Time 2.259 (2.132)	Loss 3.2514 (3.3807)	Acc@1 55.469 (52.112)	Acc@5 76.562 (76.787)
2023-03-17 18:41:05,553 - INFO - Test: [600/782]	Time 1.862 (2.096)	Loss 3.4244 (3.3447)	Acc@1 50.781 (52.920)	Acc@5 76.562 (77.407)
2023-03-17 18:45:54,632 - INFO -  * Acc@1 53.390 Acc@5 78.071
2023-03-17 18:45:54,632 - INFO - Max accuracy: 54.4630%
2023-03-17 18:45:54,632 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp
2023-03-17 18:45:56,418 - INFO - Train: [13/90][0/3907]	eta 1:55:55 lr 0.03827091	time 1.7803 (1.7803)	loss 3.3125 (3.3125)	acc@1: 56.0471	acc@5: 75.5079	
2023-03-17 18:47:20,167 - INFO - Train: [13/90][300/3907]	eta 0:17:04 lr 0.03827091	time 0.2736 (0.2841)	loss 5.9391 (4.3304)	acc@1: 24.2478	acc@5: 44.1915	
2023-03-17 18:48:44,267 - INFO - Train: [13/90][600/3907]	eta 0:15:33 lr 0.03827091	time 0.2822 (0.2822)	loss 5.6852 (4.3768)	acc@1: 29.9064	acc@5: 48.9638	
2023-03-17 18:50:09,341 - INFO - Train: [13/90][900/3907]	eta 0:14:10 lr 0.03827091	time 0.2755 (0.2827)	loss 5.9808 (4.4054)	acc@1: 22.4612	acc@5: 37.9211	
2023-03-17 18:51:39,397 - INFO - Train: [13/90][1200/3907]	eta 0:12:57 lr 0.03827091	time 0.2739 (0.2871)	loss 3.2552 (4.4063)	acc@1: 55.4397	acc@5: 77.3032	
2023-03-17 18:53:15,738 - INFO - Train: [13/90][1500/3907]	eta 0:11:47 lr 0.03827091	time 0.8386 (0.2939)	loss 3.8227 (4.4343)	acc@1: 55.5976	acc@5: 70.9462	
2023-03-17 18:55:06,981 - INFO - Train: [13/90][1800/3907]	eta 0:10:46 lr 0.03827091	time 0.2769 (0.3067)	loss 3.9845 (4.4253)	acc@1: 48.6749	acc@5: 71.6461	
2023-03-17 18:57:14,685 - INFO - Train: [13/90][2100/3907]	eta 0:09:44 lr 0.03827091	time 0.2864 (0.3237)	loss 3.3031 (4.4389)	acc@1: 54.6545	acc@5: 76.5163	
2023-03-17 18:59:41,565 - INFO - Train: [13/90][2400/3907]	eta 0:08:39 lr 0.03827091	time 0.2726 (0.3444)	loss 4.0989 (4.4377)	acc@1: 49.9584	acc@5: 70.9648	
2023-03-17 19:02:42,665 - INFO - Train: [13/90][2700/3907]	eta 0:07:30 lr 0.03827091	time 2.7492 (0.3732)	loss 3.7281 (4.4420)	acc@1: 58.5541	acc@5: 76.9016	
2023-03-17 19:06:02,402 - INFO - Train: [13/90][3000/3907]	eta 0:06:05 lr 0.03827091	time 0.2815 (0.4024)	loss 2.8921 (4.4441)	acc@1: 59.9383	acc@5: 82.5113	
2023-03-17 19:09:37,077 - INFO - Train: [13/90][3300/3907]	eta 0:04:21 lr 0.03827091	time 0.2748 (0.4309)	loss 4.4070 (4.4615)	acc@1: 47.9275	acc@5: 68.2848	
2023-03-17 19:13:40,875 - INFO - Train: [13/90][3600/3907]	eta 0:02:22 lr 0.03827091	time 0.2829 (0.4627)	loss 6.4299 (4.4582)	acc@1: 17.3746	acc@5: 27.9402	
2023-03-17 19:18:16,102 - INFO - Train: [13/90][3900/3907]	eta 0:00:03 lr 0.03827091	time 0.2833 (0.4977)	loss 3.6514 (4.4715)	acc@1: 51.3197	acc@5: 72.0007	
2023-03-17 19:18:17,750 - INFO - EPOCH 13 training takes 0:32:23
2023-03-17 19:18:21,548 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp/fold1_latest.pth saved !!!
2023-03-17 19:18:21,548 - INFO - **********latest test***********
2023-03-17 19:18:21,548 - INFO - eval epoch 13
2023-03-17 19:18:23,809 - INFO - Test: [0/782]	Time 2.259 (2.259)	Loss 2.9131 (2.9131)	Acc@1 64.844 (64.844)	Acc@5 88.281 (88.281)
2023-03-17 19:25:00,084 - INFO - Test: [200/782]	Time 2.244 (1.983)	Loss 3.2118 (3.4138)	Acc@1 53.906 (51.244)	Acc@5 76.562 (75.991)
2023-03-17 19:29:36,950 - INFO - Test: [400/782]	Time 0.763 (1.684)	Loss 3.1601 (3.3760)	Acc@1 56.250 (52.089)	Acc@5 78.906 (76.798)
2023-03-17 19:32:13,247 - INFO - Test: [600/782]	Time 0.771 (1.384)	Loss 3.3391 (3.3435)	Acc@1 50.781 (52.799)	Acc@5 78.906 (77.415)
2023-03-17 19:36:36,100 - INFO -  * Acc@1 53.339 Acc@5 78.005
2023-03-17 19:36:36,100 - INFO - Max accuracy: 54.4630%
2023-03-17 19:36:36,100 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp
2023-03-17 19:36:38,078 - INFO - Train: [14/90][0/3907]	eta 2:08:32 lr 0.03797588	time 1.9740 (1.9740)	loss 3.2608 (3.2608)	acc@1: 54.2861	acc@5: 78.3245	
2023-03-17 19:38:01,602 - INFO - Train: [14/90][300/3907]	eta 0:17:04 lr 0.03797588	time 0.2859 (0.2840)	loss 5.0535 (4.3255)	acc@1: 39.2922	acc@5: 59.7793	
2023-03-17 19:39:25,950 - INFO - Train: [14/90][600/3907]	eta 0:15:34 lr 0.03797588	time 0.2875 (0.2826)	loss 3.1119 (4.3588)	acc@1: 62.1303	acc@5: 82.6115	
2023-03-17 19:40:50,100 - INFO - Train: [14/90][900/3907]	eta 0:14:07 lr 0.03797588	time 0.2751 (0.2819)	loss 6.5031 (4.3787)	acc@1: 19.1318	acc@5: 29.3233	
2023-03-17 19:42:17,405 - INFO - Train: [14/90][1200/3907]	eta 0:12:49 lr 0.03797588	time 0.2894 (0.2842)	loss 3.0639 (4.3888)	acc@1: 60.1367	acc@5: 81.2236	
2023-03-17 19:43:55,225 - INFO - Train: [14/90][1500/3907]	eta 0:11:44 lr 0.03797588	time 0.2749 (0.2925)	loss 3.1404 (4.3766)	acc@1: 58.5770	acc@5: 82.0080	
2023-03-17 19:45:48,078 - INFO - Train: [14/90][1800/3907]	eta 0:10:45 lr 0.03797588	time 0.2801 (0.3065)	loss 4.5950 (4.4083)	acc@1: 47.1046	acc@5: 61.7003	
2023-03-17 19:48:04,127 - INFO - Train: [14/90][2100/3907]	eta 0:09:51 lr 0.03797588	time 0.2727 (0.3275)	loss 4.1971 (4.4047)	acc@1: 55.0462	acc@5: 69.9403	
2023-03-17 19:50:48,675 - INFO - Train: [14/90][2400/3907]	eta 0:08:55 lr 0.03797588	time 0.2760 (0.3551)	loss 3.2963 (4.4246)	acc@1: 52.1982	acc@5: 74.7936	
2023-03-17 19:53:52,044 - INFO - Train: [14/90][2700/3907]	eta 0:07:42 lr 0.03797588	time 0.2724 (0.3835)	loss 5.3395 (4.4473)	acc@1: 36.5569	acc@5: 52.0658	
2023-03-17 19:57:13,880 - INFO - Train: [14/90][3000/3907]	eta 0:06:14 lr 0.03797588	time 0.2715 (0.4124)	loss 3.2815 (4.4520)	acc@1: 54.7075	acc@5: 81.6759	
2023-03-17 20:00:37,429 - INFO - Train: [14/90][3300/3907]	eta 0:04:25 lr 0.03797588	time 0.2724 (0.4366)	loss 4.0424 (4.4503)	acc@1: 47.8138	acc@5: 70.7178	
2023-03-17 20:04:20,507 - INFO - Train: [14/90][3600/3907]	eta 0:02:21 lr 0.03797588	time 1.8807 (0.4622)	loss 6.2359 (4.4606)	acc@1: 19.8535	acc@5: 35.5390	
2023-03-17 20:08:24,545 - INFO - Train: [14/90][3900/3907]	eta 0:00:03 lr 0.03797588	time 0.2794 (0.4892)	loss 4.0672 (4.4751)	acc@1: 46.9469	acc@5: 68.9977	
2023-03-17 20:08:26,167 - INFO - EPOCH 14 training takes 0:31:50
2023-03-17 20:08:30,017 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp/fold1_latest.pth saved !!!
2023-03-17 20:08:30,017 - INFO - **********latest test***********
2023-03-17 20:08:30,017 - INFO - eval epoch 14
2023-03-17 20:08:32,969 - INFO - Test: [0/782]	Time 2.951 (2.951)	Loss 2.7297 (2.7297)	Acc@1 63.281 (63.281)	Acc@5 90.625 (90.625)
2023-03-17 20:15:10,661 - INFO - Test: [200/782]	Time 2.153 (1.993)	Loss 3.1259 (3.1920)	Acc@1 57.812 (55.313)	Acc@5 77.344 (79.754)
2023-03-17 20:19:55,350 - INFO - Test: [400/782]	Time 0.762 (1.709)	Loss 3.0015 (3.1587)	Acc@1 62.500 (56.155)	Acc@5 82.031 (80.229)
2023-03-17 20:22:39,471 - INFO - Test: [600/782]	Time 0.766 (1.413)	Loss 3.1139 (3.1192)	Acc@1 57.031 (57.199)	Acc@5 80.469 (80.766)
2023-03-17 20:26:21,498 - INFO -  * Acc@1 57.723 Acc@5 81.247
2023-03-17 20:26:21,498 - INFO - Max accuracy: 57.7230%
2023-03-17 20:26:25,157 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp/fold1_best.pth saved !!!
2023-03-17 20:26:25,158 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp
2023-03-17 20:26:27,413 - INFO - Train: [15/90][0/3907]	eta 2:26:20 lr 0.03765895	time 2.2473 (2.2473)	loss 6.4187 (6.4187)	acc@1: 15.1895	acc@5: 29.2648	
2023-03-17 20:27:51,124 - INFO - Train: [15/90][300/3907]	eta 0:17:10 lr 0.03765895	time 0.2938 (0.2856)	loss 2.8905 (4.4489)	acc@1: 66.9007	acc@5: 86.3486	
2023-03-17 20:29:15,636 - INFO - Train: [15/90][600/3907]	eta 0:15:37 lr 0.03765895	time 0.2739 (0.2836)	loss 2.7918 (4.4176)	acc@1: 66.9688	acc@5: 87.2177	
2023-03-17 20:30:39,994 - INFO - Train: [15/90][900/3907]	eta 0:14:10 lr 0.03765895	time 0.2749 (0.2828)	loss 5.6800 (4.4451)	acc@1: 29.5785	acc@5: 47.0683	
2023-03-17 20:32:07,691 - INFO - Train: [15/90][1200/3907]	eta 0:12:52 lr 0.03765895	time 0.2744 (0.2852)	loss 4.0422 (4.4316)	acc@1: 53.2005	acc@5: 70.0007	
2023-03-17 20:33:47,206 - INFO - Train: [15/90][1500/3907]	eta 0:11:48 lr 0.03765895	time 0.2735 (0.2945)	loss 2.9515 (4.4338)	acc@1: 58.5203	acc@5: 86.6105	
2023-03-17 20:35:38,460 - INFO - Train: [15/90][1800/3907]	eta 0:10:47 lr 0.03765895	time 0.2721 (0.3072)	loss 3.4355 (4.4376)	acc@1: 45.9657	acc@5: 73.2356	
2023-03-17 20:37:52,307 - INFO - Train: [15/90][2100/3907]	eta 0:09:50 lr 0.03765895	time 0.2728 (0.3270)	loss 3.0651 (4.4408)	acc@1: 62.4886	acc@5: 81.2351	
2023-03-17 20:40:31,588 - INFO - Train: [15/90][2400/3907]	eta 0:08:51 lr 0.03765895	time 0.2715 (0.3525)	loss 3.3413 (4.4494)	acc@1: 56.9642	acc@5: 78.8131	
2023-03-17 20:43:43,361 - INFO - Train: [15/90][2700/3907]	eta 0:07:43 lr 0.03765895	time 0.2726 (0.3844)	loss 4.2137 (4.4419)	acc@1: 51.6613	acc@5: 70.8404	
2023-03-17 20:47:08,733 - INFO - Train: [15/90][3000/3907]	eta 0:06:15 lr 0.03765895	time 1.1169 (0.4144)	loss 6.2737 (4.4521)	acc@1: 16.6418	acc@5: 32.3800	
2023-03-17 20:50:36,361 - INFO - Train: [15/90][3300/3907]	eta 0:04:26 lr 0.03765895	time 0.2911 (0.4396)	loss 6.6291 (4.4464)	acc@1: 11.7408	acc@5: 22.7445	
2023-03-17 20:54:15,248 - INFO - Train: [15/90][3600/3907]	eta 0:02:22 lr 0.03765895	time 0.2708 (0.4638)	loss 3.2711 (4.4589)	acc@1: 62.4969	acc@5: 77.7591	
2023-03-17 20:58:24,231 - INFO - Train: [15/90][3900/3907]	eta 0:00:03 lr 0.03765895	time 0.2824 (0.4919)	loss 4.5586 (4.4636)	acc@1: 47.4579	acc@5: 68.4129	
2023-03-17 20:58:25,841 - INFO - EPOCH 15 training takes 0:32:00
2023-03-17 20:58:29,449 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp/fold1_latest.pth saved !!!
2023-03-17 20:58:29,450 - INFO - **********latest test***********
2023-03-17 20:58:29,450 - INFO - eval epoch 15
2023-03-17 20:58:32,940 - INFO - Test: [0/782]	Time 3.489 (3.489)	Loss 2.8760 (2.8760)	Acc@1 60.938 (60.938)	Acc@5 88.281 (88.281)
2023-03-17 21:04:58,497 - INFO - Test: [200/782]	Time 2.261 (1.936)	Loss 3.1566 (3.3550)	Acc@1 57.031 (52.896)	Acc@5 78.906 (77.305)
2023-03-17 21:09:38,482 - INFO - Test: [400/782]	Time 0.777 (1.668)	Loss 3.2674 (3.3204)	Acc@1 53.125 (53.717)	Acc@5 79.688 (77.765)
2023-03-17 21:12:23,092 - INFO - Test: [600/782]	Time 0.762 (1.387)	Loss 3.2363 (3.2847)	Acc@1 56.250 (54.443)	Acc@5 82.031 (78.469)
2023-03-17 21:16:05,434 - INFO -  * Acc@1 54.912 Acc@5 78.987
2023-03-17 21:16:05,434 - INFO - Max accuracy: 57.7230%
2023-03-17 21:16:05,434 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp
2023-03-17 21:16:07,106 - INFO - Train: [16/90][0/3907]	eta 1:48:34 lr 0.03732051	time 1.6675 (1.6675)	loss 3.8400 (3.8400)	acc@1: 54.1805	acc@5: 74.5861	
2023-03-17 21:17:30,834 - INFO - Train: [16/90][300/3907]	eta 0:17:03 lr 0.03732051	time 0.2737 (0.2837)	loss 3.3338 (4.3023)	acc@1: 63.4207	acc@5: 79.8262	
2023-03-17 21:18:54,882 - INFO - Train: [16/90][600/3907]	eta 0:15:32 lr 0.03732051	time 0.2744 (0.2819)	loss 3.3372 (4.3041)	acc@1: 61.1240	acc@5: 81.9832	
2023-03-17 21:20:19,155 - INFO - Train: [16/90][900/3907]	eta 0:14:06 lr 0.03732051	time 0.2747 (0.2816)	loss 3.7827 (4.3655)	acc@1: 49.3979	acc@5: 73.7282	
2023-03-17 21:21:44,139 - INFO - Train: [16/90][1200/3907]	eta 0:12:43 lr 0.03732051	time 0.2748 (0.2820)	loss 5.7107 (4.3750)	acc@1: 31.2879	acc@5: 46.4311	
2023-03-17 21:23:14,975 - INFO - Train: [16/90][1500/3907]	eta 0:11:28 lr 0.03732051	time 0.2812 (0.2862)	loss 3.3788 (4.3816)	acc@1: 59.9782	acc@5: 81.4519	
2023-03-17 21:24:58,220 - INFO - Train: [16/90][1800/3907]	eta 0:10:23 lr 0.03732051	time 0.2735 (0.2958)	loss 6.3934 (4.3755)	acc@1: 15.7977	acc@5: 29.3487	
2023-03-17 21:26:56,606 - INFO - Train: [16/90][2100/3907]	eta 0:09:20 lr 0.03732051	time 0.2729 (0.3099)	loss 3.2953 (4.3871)	acc@1: 55.1550	acc@5: 80.8455	
2023-03-17 21:29:18,815 - INFO - Train: [16/90][2400/3907]	eta 0:08:17 lr 0.03732051	time 0.2730 (0.3304)	loss 3.2083 (4.3901)	acc@1: 59.1478	acc@5: 81.8970	
2023-03-17 21:32:13,732 - INFO - Train: [16/90][2700/3907]	eta 0:07:12 lr 0.03732051	time 0.2712 (0.3585)	loss 5.6200 (4.4023)	acc@1: 32.8395	acc@5: 46.0755	
2023-03-17 21:35:54,721 - INFO - Train: [16/90][3000/3907]	eta 0:05:59 lr 0.03732051	time 2.3275 (0.3963)	loss 5.8651 (4.3917)	acc@1: 25.7619	acc@5: 41.4843	
2023-03-17 21:39:34,080 - INFO - Train: [16/90][3300/3907]	eta 0:04:19 lr 0.03732051	time 0.2805 (0.4267)	loss 3.0261 (4.3969)	acc@1: 57.8115	acc@5: 78.1237	
2023-03-17 21:43:18,412 - INFO - Train: [16/90][3600/3907]	eta 0:02:19 lr 0.03732051	time 0.8197 (0.4535)	loss 3.8686 (4.4070)	acc@1: 54.9929	acc@5: 74.9903	
2023-03-17 21:47:04,117 - INFO - Train: [16/90][3900/3907]	eta 0:00:03 lr 0.03732051	time 0.2717 (0.4765)	loss 5.0313 (4.4130)	acc@1: 38.1456	acc@5: 57.7466	
2023-03-17 21:47:06,814 - INFO - EPOCH 16 training takes 0:31:01
2023-03-17 21:47:10,628 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp/fold1_latest.pth saved !!!
2023-03-17 21:47:10,628 - INFO - **********latest test***********
2023-03-17 21:47:10,628 - INFO - eval epoch 16
2023-03-17 21:47:12,934 - INFO - Test: [0/782]	Time 2.305 (2.305)	Loss 2.8633 (2.8633)	Acc@1 60.938 (60.938)	Acc@5 86.719 (86.719)
2023-03-17 21:54:00,657 - INFO - Test: [200/782]	Time 2.253 (2.040)	Loss 3.1908 (3.2877)	Acc@1 57.031 (53.992)	Acc@5 78.125 (78.265)
2023-03-17 22:01:02,983 - INFO - Test: [400/782]	Time 2.217 (2.076)	Loss 3.1203 (3.2533)	Acc@1 53.906 (54.654)	Acc@5 79.688 (78.754)
2023-03-17 22:06:25,322 - INFO - Test: [600/782]	Time 0.757 (1.921)	Loss 3.3814 (3.2137)	Acc@1 48.438 (55.497)	Acc@5 78.125 (79.378)
2023-03-17 22:10:08,521 - INFO -  * Acc@1 56.010 Acc@5 79.942
2023-03-17 22:10:08,521 - INFO - Max accuracy: 57.7230%
2023-03-17 22:10:08,521 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp
2023-03-17 22:10:10,338 - INFO - Train: [17/90][0/3907]	eta 1:57:58 lr 0.03696096	time 1.8118 (1.8118)	loss 5.6148 (5.6148)	acc@1: 29.6500	acc@5: 43.8155	
2023-03-17 22:11:34,065 - INFO - Train: [17/90][300/3907]	eta 0:17:05 lr 0.03696096	time 0.2826 (0.2842)	loss 4.2778 (4.2590)	acc@1: 53.2412	acc@5: 67.6741	
2023-03-17 22:12:58,310 - INFO - Train: [17/90][600/3907]	eta 0:15:34 lr 0.03696096	time 0.2747 (0.2825)	loss 4.4862 (4.2904)	acc@1: 49.9626	acc@5: 70.3421	
2023-03-17 22:14:22,706 - INFO - Train: [17/90][900/3907]	eta 0:14:08 lr 0.03696096	time 0.2873 (0.2821)	loss 5.5640 (4.2919)	acc@1: 30.0385	acc@5: 47.2825	
2023-03-17 22:15:46,972 - INFO - Train: [17/90][1200/3907]	eta 0:12:42 lr 0.03696096	time 0.2747 (0.2818)	loss 3.4101 (4.3262)	acc@1: 63.8937	acc@5: 75.7738	
2023-03-17 22:17:11,663 - INFO - Train: [17/90][1500/3907]	eta 0:11:18 lr 0.03696096	time 0.2852 (0.2819)	loss 6.4265 (4.3414)	acc@1: 15.7731	acc@5: 27.1135	
2023-03-17 22:18:49,173 - INFO - Train: [17/90][1800/3907]	eta 0:10:09 lr 0.03696096	time 0.4872 (0.2891)	loss 3.0998 (4.3464)	acc@1: 56.2091	acc@5: 83.5330	
2023-03-17 22:20:40,254 - INFO - Train: [17/90][2100/3907]	eta 0:09:03 lr 0.03696096	time 0.2735 (0.3007)	loss 6.0840 (4.3691)	acc@1: 27.3289	acc@5: 37.8721	
2023-03-17 22:22:47,489 - INFO - Train: [17/90][2400/3907]	eta 0:07:56 lr 0.03696096	time 0.2729 (0.3161)	loss 6.0082 (4.3683)	acc@1: 25.6655	acc@5: 40.9529	
2023-03-17 22:25:27,782 - INFO - Train: [17/90][2700/3907]	eta 0:06:50 lr 0.03696096	time 0.4220 (0.3403)	loss 5.3123 (4.3649)	acc@1: 35.7731	acc@5: 51.3004	
2023-03-17 22:28:27,832 - INFO - Train: [17/90][3000/3907]	eta 0:05:32 lr 0.03696096	time 0.2720 (0.3663)	loss 6.0814 (4.3697)	acc@1: 21.3453	acc@5: 37.2525	
2023-03-17 22:31:37,030 - INFO - Train: [17/90][3300/3907]	eta 0:03:56 lr 0.03696096	time 1.9160 (0.3903)	loss 6.3738 (4.3770)	acc@1: 12.1083	acc@5: 26.1708	
2023-03-17 22:35:07,684 - INFO - Train: [17/90][3600/3907]	eta 0:02:07 lr 0.03696096	time 0.2714 (0.4163)	loss 5.0362 (4.3870)	acc@1: 39.3605	acc@5: 58.4839	
2023-03-17 22:39:15,642 - INFO - Train: [17/90][3900/3907]	eta 0:00:03 lr 0.03696096	time 0.2729 (0.4479)	loss 3.0523 (4.3977)	acc@1: 60.1512	acc@5: 78.8996	
2023-03-17 22:39:17,247 - INFO - EPOCH 17 training takes 0:29:08
2023-03-17 22:39:21,026 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp/fold1_latest.pth saved !!!
2023-03-17 22:39:21,026 - INFO - **********latest test***********
2023-03-17 22:39:21,027 - INFO - eval epoch 17
2023-03-17 22:39:23,295 - INFO - Test: [0/782]	Time 2.266 (2.266)	Loss 2.8583 (2.8583)	Acc@1 62.500 (62.500)	Acc@5 85.156 (85.156)
2023-03-17 22:46:46,890 - INFO - Test: [200/782]	Time 2.186 (2.218)	Loss 3.1676 (3.2712)	Acc@1 58.594 (53.825)	Acc@5 78.906 (77.954)
2023-03-17 22:51:25,243 - INFO - Test: [400/782]	Time 0.902 (1.806)	Loss 3.0160 (3.2343)	Acc@1 57.031 (54.773)	Acc@5 82.031 (78.596)
2023-03-17 22:54:08,650 - INFO - Test: [600/782]	Time 0.756 (1.477)	Loss 3.1966 (3.1996)	Acc@1 58.594 (55.600)	Acc@5 78.906 (79.269)
2023-03-17 22:57:42,475 - INFO -  * Acc@1 55.914 Acc@5 79.863
2023-03-17 22:57:42,475 - INFO - Max accuracy: 57.7230%
2023-03-17 22:57:42,475 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp
2023-03-17 22:57:44,063 - INFO - Train: [18/90][0/3907]	eta 1:43:04 lr 0.03658075	time 1.5830 (1.5830)	loss 4.9811 (4.9811)	acc@1: 42.0681	acc@5: 57.8596	
2023-03-17 22:59:07,883 - INFO - Train: [18/90][300/3907]	eta 0:17:03 lr 0.03658075	time 0.2899 (0.2837)	loss 2.9197 (4.3459)	acc@1: 65.0502	acc@5: 84.9480	
2023-03-17 23:00:31,928 - INFO - Train: [18/90][600/3907]	eta 0:15:32 lr 0.03658075	time 0.2830 (0.2819)	loss 2.9303 (4.3429)	acc@1: 66.4060	acc@5: 85.7046	
2023-03-17 23:01:56,268 - INFO - Train: [18/90][900/3907]	eta 0:14:06 lr 0.03658075	time 0.2745 (0.2817)	loss 5.2017 (4.3774)	acc@1: 36.2921	acc@5: 54.3270	
2023-03-17 23:03:20,422 - INFO - Train: [18/90][1200/3907]	eta 0:12:41 lr 0.03658075	time 0.2750 (0.2814)	loss 3.4465 (4.3537)	acc@1: 57.5069	acc@5: 73.4215	
2023-03-17 23:04:46,196 - INFO - Train: [18/90][1500/3907]	eta 0:11:19 lr 0.03658075	time 0.2748 (0.2823)	loss 5.9331 (4.3555)	acc@1: 26.9021	acc@5: 41.8115	
2023-03-17 23:06:17,034 - INFO - Train: [18/90][1800/3907]	eta 0:10:01 lr 0.03658075	time 0.2739 (0.2857)	loss 4.9009 (4.3612)	acc@1: 37.2883	acc@5: 62.5686	
2023-03-17 23:08:04,940 - INFO - Train: [18/90][2100/3907]	eta 0:08:55 lr 0.03658075	time 0.2828 (0.2963)	loss 5.3320 (4.3730)	acc@1: 35.6795	acc@5: 51.9219	
2023-03-17 23:10:15,411 - INFO - Train: [18/90][2400/3907]	eta 0:07:52 lr 0.03658075	time 2.9886 (0.3136)	loss 3.5884 (4.3827)	acc@1: 54.2674	acc@5: 77.7133	
2023-03-17 23:12:49,757 - INFO - Train: [18/90][2700/3907]	eta 0:06:45 lr 0.03658075	time 0.8935 (0.3359)	loss 3.6684 (4.3773)	acc@1: 52.1084	acc@5: 77.0868	
2023-03-17 23:15:49,105 - INFO - Train: [18/90][3000/3907]	eta 0:05:28 lr 0.03658075	time 1.5406 (0.3621)	loss 3.0138 (4.3693)	acc@1: 62.4064	acc@5: 84.2505	
2023-03-17 23:18:56,843 - INFO - Train: [18/90][3300/3907]	eta 0:03:54 lr 0.03658075	time 0.2720 (0.3860)	loss 5.7542 (4.3772)	acc@1: 29.5008	acc@5: 45.5441	
2023-03-17 23:22:30,434 - INFO - Train: [18/90][3600/3907]	eta 0:02:06 lr 0.03658075	time 0.2720 (0.4132)	loss 3.4921 (4.3785)	acc@1: 53.3483	acc@5: 79.3218	
2023-03-17 23:26:34,268 - INFO - Train: [18/90][3900/3907]	eta 0:00:03 lr 0.03658075	time 0.2787 (0.4439)	loss 6.7233 (4.3826)	acc@1: 11.3960	acc@5: 25.5401	
2023-03-17 23:26:37,278 - INFO - EPOCH 18 training takes 0:28:54
2023-03-17 23:26:41,005 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp/fold1_latest.pth saved !!!
2023-03-17 23:26:41,006 - INFO - **********latest test***********
2023-03-17 23:26:41,006 - INFO - eval epoch 18
2023-03-17 23:26:43,309 - INFO - Test: [0/782]	Time 2.301 (2.301)	Loss 2.9081 (2.9081)	Acc@1 59.375 (59.375)	Acc@5 87.500 (87.500)
2023-03-17 23:33:19,074 - INFO - Test: [200/782]	Time 2.281 (1.980)	Loss 3.3071 (3.3441)	Acc@1 57.031 (53.090)	Acc@5 71.875 (77.390)
2023-03-17 23:38:53,133 - INFO - Test: [400/782]	Time 1.644 (1.826)	Loss 3.1366 (3.3002)	Acc@1 58.594 (53.976)	Acc@5 80.469 (78.275)
2023-03-17 23:41:47,426 - INFO - Test: [600/782]	Time 0.755 (1.508)	Loss 3.4364 (3.2585)	Acc@1 50.781 (54.899)	Acc@5 74.219 (78.996)
2023-03-17 23:45:12,790 - INFO -  * Acc@1 55.420 Acc@5 79.488
2023-03-17 23:45:12,790 - INFO - Max accuracy: 57.7230%
2023-03-17 23:45:12,790 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp
2023-03-17 23:45:14,770 - INFO - Train: [19/90][0/3907]	eta 2:08:35 lr 0.03618034	time 1.9749 (1.9749)	loss 3.2374 (3.2374)	acc@1: 63.3189	acc@5: 77.6410	
2023-03-17 23:46:38,647 - INFO - Train: [19/90][300/3907]	eta 0:17:08 lr 0.03618034	time 0.2732 (0.2852)	loss 2.8504 (4.3084)	acc@1: 63.8614	acc@5: 87.2253	
2023-03-17 23:48:02,842 - INFO - Train: [19/90][600/3907]	eta 0:15:35 lr 0.03618034	time 0.2741 (0.2829)	loss 5.9035 (4.3254)	acc@1: 21.2101	acc@5: 36.9028	
2023-03-17 23:49:27,006 - INFO - Train: [19/90][900/3907]	eta 0:14:08 lr 0.03618034	time 0.2839 (0.2821)	loss 6.1309 (4.3443)	acc@1: 20.2482	acc@5: 32.9275	
2023-03-17 23:50:51,104 - INFO - Train: [19/90][1200/3907]	eta 0:12:42 lr 0.03618034	time 0.2925 (0.2817)	loss 5.4950 (4.3512)	acc@1: 32.5302	acc@5: 51.2813	
2023-03-17 23:52:18,078 - INFO - Train: [19/90][1500/3907]	eta 0:11:21 lr 0.03618034	time 0.2839 (0.2833)	loss 5.9223 (4.3349)	acc@1: 25.0110	acc@5: 38.7557	
2023-03-17 23:53:55,570 - INFO - Train: [19/90][1800/3907]	eta 0:10:11 lr 0.03618034	time 1.3334 (0.2903)	loss 3.4815 (4.3289)	acc@1: 59.1647	acc@5: 75.6409	
2023-03-17 23:55:52,161 - INFO - Train: [19/90][2100/3907]	eta 0:09:09 lr 0.03618034	time 0.2734 (0.3043)	loss 3.1952 (4.3316)	acc@1: 57.8602	acc@5: 82.2423	
2023-03-17 23:58:07,691 - INFO - Train: [19/90][2400/3907]	eta 0:08:06 lr 0.03618034	time 1.3450 (0.3227)	loss 4.0495 (4.3458)	acc@1: 50.0086	acc@5: 71.0267	
2023-03-18 00:00:57,586 - INFO - Train: [19/90][2700/3907]	eta 0:07:02 lr 0.03618034	time 0.2760 (0.3498)	loss 3.0622 (4.3479)	acc@1: 56.0735	acc@5: 81.7738	
2023-03-18 00:04:21,456 - INFO - Train: [19/90][3000/3907]	eta 0:05:47 lr 0.03618034	time 1.6274 (0.3828)	loss 5.8161 (4.3596)	acc@1: 25.6812	acc@5: 44.2142	
2023-03-18 00:07:59,222 - INFO - Train: [19/90][3300/3907]	eta 0:04:11 lr 0.03618034	time 0.2711 (0.4139)	loss 3.8562 (4.3644)	acc@1: 45.0838	acc@5: 72.0968	
2023-03-18 00:11:34,988 - INFO - Train: [19/90][3600/3907]	eta 0:02:14 lr 0.03618034	time 3.9548 (0.4394)	loss 5.8722 (4.3715)	acc@1: 31.1173	acc@5: 43.6640	
2023-03-18 00:15:07,199 - INFO - Train: [19/90][3900/3907]	eta 0:00:03 lr 0.03618034	time 0.7859 (0.4600)	loss 3.4406 (4.3762)	acc@1: 51.3666	acc@5: 73.1572	
2023-03-18 00:15:08,792 - INFO - EPOCH 19 training takes 0:29:55
2023-03-18 00:15:12,582 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp/fold1_latest.pth saved !!!
2023-03-18 00:15:12,583 - INFO - **********latest test***********
2023-03-18 00:15:12,583 - INFO - eval epoch 19
2023-03-18 00:15:14,891 - INFO - Test: [0/782]	Time 2.307 (2.307)	Loss 2.6686 (2.6686)	Acc@1 63.281 (63.281)	Acc@5 87.500 (87.500)
2023-03-18 00:21:16,272 - INFO - Test: [200/782]	Time 2.039 (1.809)	Loss 3.0064 (3.2054)	Acc@1 58.594 (54.983)	Acc@5 80.469 (79.198)
2023-03-18 00:25:49,073 - INFO - Test: [400/782]	Time 0.835 (1.587)	Loss 2.9514 (3.1704)	Acc@1 58.594 (55.971)	Acc@5 81.250 (79.765)
2023-03-18 00:32:02,302 - INFO - Test: [600/782]	Time 2.214 (1.680)	Loss 3.2560 (3.1359)	Acc@1 53.906 (56.739)	Acc@5 78.906 (80.379)
2023-03-18 00:38:51,500 - INFO -  * Acc@1 57.180 Acc@5 80.913
2023-03-18 00:38:51,500 - INFO - Max accuracy: 57.7230%
2023-03-18 00:38:51,500 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp
2023-03-18 00:38:53,428 - INFO - Train: [20/90][0/3907]	eta 2:04:31 lr 0.03576022	time 1.9124 (1.9124)	loss 3.4148 (3.4148)	acc@1: 54.5744	acc@5: 76.2546	
2023-03-18 00:40:17,517 - INFO - Train: [20/90][300/3907]	eta 0:17:10 lr 0.03576022	time 0.2732 (0.2857)	loss 4.7651 (4.1824)	acc@1: 43.2447	acc@5: 65.2283	
2023-03-18 00:41:41,536 - INFO - Train: [20/90][600/3907]	eta 0:15:35 lr 0.03576022	time 0.2959 (0.2829)	loss 3.5032 (4.2240)	acc@1: 56.5660	acc@5: 75.6503	
2023-03-18 00:43:05,718 - INFO - Train: [20/90][900/3907]	eta 0:14:08 lr 0.03576022	time 0.2871 (0.2821)	loss 3.3478 (4.2260)	acc@1: 59.0102	acc@5: 76.1699	
2023-03-18 00:44:29,916 - INFO - Train: [20/90][1200/3907]	eta 0:12:42 lr 0.03576022	time 0.2841 (0.2818)	loss 6.1926 (4.2478)	acc@1: 23.2971	acc@5: 35.1745	
2023-03-18 00:45:56,956 - INFO - Train: [20/90][1500/3907]	eta 0:11:22 lr 0.03576022	time 0.2742 (0.2834)	loss 5.9351 (4.2566)	acc@1: 25.2589	acc@5: 38.3809	
2023-03-18 00:47:37,465 - INFO - Train: [20/90][1800/3907]	eta 0:10:15 lr 0.03576022	time 1.4415 (0.2920)	loss 5.6596 (4.2891)	acc@1: 30.9697	acc@5: 44.0636	
2023-03-18 00:49:30,864 - INFO - Train: [20/90][2100/3907]	eta 0:09:09 lr 0.03576022	time 0.3526 (0.3043)	loss 3.5752 (4.3143)	acc@1: 59.9436	acc@5: 76.2246	
2023-03-18 00:51:48,495 - INFO - Train: [20/90][2400/3907]	eta 0:08:07 lr 0.03576022	time 0.2727 (0.3236)	loss 3.2581 (4.3388)	acc@1: 58.5520	acc@5: 76.2794	
2023-03-18 00:54:33,588 - INFO - Train: [20/90][2700/3907]	eta 0:07:00 lr 0.03576022	time 0.2717 (0.3488)	loss 3.1150 (4.3440)	acc@1: 56.7740	acc@5: 80.8820	
2023-03-18 00:57:39,436 - INFO - Train: [20/90][3000/3907]	eta 0:05:40 lr 0.03576022	time 0.2720 (0.3758)	loss 3.2712 (4.3516)	acc@1: 56.9358	acc@5: 79.2485	
2023-03-18 01:00:45,128 - INFO - Train: [20/90][3300/3907]	eta 0:04:01 lr 0.03576022	time 3.2910 (0.3979)	loss 4.0740 (4.3546)	acc@1: 50.4415	acc@5: 72.8237	
2023-03-18 01:04:26,177 - INFO - Train: [20/90][3600/3907]	eta 0:02:10 lr 0.03576022	time 0.2704 (0.4262)	loss 3.4271 (4.3535)	acc@1: 51.4356	acc@5: 77.1407	
2023-03-18 01:08:12,472 - INFO - Train: [20/90][3900/3907]	eta 0:00:03 lr 0.03576022	time 0.8532 (0.4514)	loss 5.7951 (4.3586)	acc@1: 23.8811	acc@5: 44.1967	
2023-03-18 01:08:14,149 - INFO - EPOCH 20 training takes 0:29:22
2023-03-18 01:08:18,141 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp/fold1_latest.pth saved !!!
2023-03-18 01:08:18,141 - INFO - **********latest test***********
2023-03-18 01:08:18,157 - INFO - eval epoch 20
2023-03-18 01:08:20,437 - INFO - Test: [0/782]	Time 2.270 (2.270)	Loss 2.9021 (2.9021)	Acc@1 57.812 (57.812)	Acc@5 87.500 (87.500)
2023-03-18 01:14:56,362 - INFO - Test: [200/782]	Time 2.375 (1.981)	Loss 3.1500 (3.2660)	Acc@1 59.375 (54.275)	Acc@5 78.125 (78.665)
2023-03-18 01:22:21,054 - INFO - Test: [400/782]	Time 2.233 (2.102)	Loss 3.1425 (3.2238)	Acc@1 57.031 (55.422)	Acc@5 80.469 (79.387)
2023-03-18 01:29:13,757 - INFO - Test: [600/782]	Time 1.856 (2.089)	Loss 3.2209 (3.1853)	Acc@1 57.031 (56.451)	Acc@5 76.562 (80.037)
2023-03-18 01:34:12,522 - INFO -  * Acc@1 57.024 Acc@5 80.631
2023-03-18 01:34:12,522 - INFO - Max accuracy: 57.7230%
2023-03-18 01:34:12,523 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp
2023-03-18 01:34:18,748 - INFO - Train: [21/90][0/3907]	eta 6:42:55 lr 0.03532089	time 6.1876 (6.1876)	loss 2.8994 (2.8994)	acc@1: 68.6006	acc@5: 86.5303	
2023-03-18 01:35:41,145 - INFO - Train: [21/90][300/3907]	eta 0:17:41 lr 0.03532089	time 0.2738 (0.2943)	loss 3.4396 (4.2668)	acc@1: 51.8102	acc@5: 77.3247	
2023-03-18 01:37:04,504 - INFO - Train: [21/90][600/3907]	eta 0:15:46 lr 0.03532089	time 0.2740 (0.2861)	loss 6.0389 (4.1826)	acc@1: 16.0966	acc@5: 33.8343	
2023-03-18 01:38:30,523 - INFO - Train: [21/90][900/3907]	eta 0:14:20 lr 0.03532089	time 0.2868 (0.2863)	loss 3.3819 (4.2178)	acc@1: 62.9607	acc@5: 80.5311	
2023-03-18 01:40:09,097 - INFO - Train: [21/90][1200/3907]	eta 0:13:23 lr 0.03532089	time 0.2825 (0.2969)	loss 4.1158 (4.2444)	acc@1: 52.5344	acc@5: 70.9556	
2023-03-18 01:41:59,756 - INFO - Train: [21/90][1500/3907]	eta 0:12:29 lr 0.03532089	time 0.2735 (0.3113)	loss 6.2679 (4.2306)	acc@1: 22.2558	acc@5: 33.9126	
2023-03-18 01:44:05,881 - INFO - Train: [21/90][1800/3907]	eta 0:11:34 lr 0.03532089	time 0.2730 (0.3294)	loss 5.3219 (4.2591)	acc@1: 36.0449	acc@5: 52.6235	
2023-03-18 01:46:34,074 - INFO - Train: [21/90][2100/3907]	eta 0:10:37 lr 0.03532089	time 0.2726 (0.3529)	loss 3.8062 (4.2734)	acc@1: 60.9275	acc@5: 72.9568	
2023-03-18 01:49:32,001 - INFO - Train: [21/90][2400/3907]	eta 0:09:37 lr 0.03532089	time 0.2742 (0.3829)	loss 3.1662 (4.2769)	acc@1: 60.2826	acc@5: 81.6485	
2023-03-18 01:52:47,420 - INFO - Train: [21/90][2700/3907]	eta 0:08:18 lr 0.03532089	time 0.2769 (0.4128)	loss 3.4136 (4.2747)	acc@1: 62.1631	acc@5: 79.7150	
2023-03-18 01:56:40,198 - INFO - Train: [21/90][3000/3907]	eta 0:06:47 lr 0.03532089	time 2.7785 (0.4491)	loss 4.7436 (4.2927)	acc@1: 49.4666	acc@5: 62.3151	
2023-03-18 02:00:43,431 - INFO - Train: [21/90][3300/3907]	eta 0:04:52 lr 0.03532089	time 0.2813 (0.4819)	loss 5.4806 (4.3032)	acc@1: 31.7556	acc@5: 50.6435	
2023-03-18 02:04:59,448 - INFO - Train: [21/90][3600/3907]	eta 0:02:37 lr 0.03532089	time 1.7783 (0.5129)	loss 4.1517 (4.3123)	acc@1: 54.5632	acc@5: 73.8696	
2023-03-18 02:09:35,657 - INFO - Train: [21/90][3900/3907]	eta 0:00:03 lr 0.03532089	time 0.2928 (0.5442)	loss 3.0752 (4.3258)	acc@1: 62.2665	acc@5: 80.1681	
2023-03-18 02:09:39,603 - INFO - EPOCH 21 training takes 0:35:27
2023-03-18 02:09:43,862 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp/fold1_latest.pth saved !!!
2023-03-18 02:09:43,862 - INFO - **********latest test***********
2023-03-18 02:09:43,862 - INFO - eval epoch 21
2023-03-18 02:09:50,352 - INFO - Test: [0/782]	Time 6.489 (6.489)	Loss 2.7872 (2.7872)	Acc@1 60.938 (60.938)	Acc@5 85.938 (85.938)
2023-03-18 02:29:48,819 - INFO - Test: [200/782]	Time 4.570 (5.995)	Loss 3.0659 (3.2024)	Acc@1 60.156 (56.409)	Acc@5 79.688 (79.944)
2023-03-18 02:40:34,155 - INFO - Test: [400/782]	Time 1.923 (4.614)	Loss 2.9060 (3.1669)	Acc@1 61.719 (57.060)	Acc@5 85.156 (80.533)
2023-03-18 02:45:43,217 - INFO - Test: [600/782]	Time 0.862 (3.593)	Loss 3.1095 (3.1319)	Acc@1 59.375 (57.853)	Acc@5 83.594 (81.080)
2023-03-18 02:50:24,623 - INFO -  * Acc@1 58.327 Acc@5 81.602
2023-03-18 02:50:24,623 - INFO - Max accuracy: 58.3270%
2023-03-18 02:50:28,930 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp/fold1_best.pth saved !!!
2023-03-18 02:50:28,930 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp
2023-03-18 02:50:35,657 - INFO - Train: [22/90][0/3907]	eta 7:17:13 lr 0.03486290	time 6.7145 (6.7145)	loss 3.2776 (3.2776)	acc@1: 64.4832	acc@5: 82.8023	
2023-03-18 02:53:59,243 - INFO - Train: [22/90][300/3907]	eta 0:42:00 lr 0.03486290	time 2.5817 (0.6987)	loss 2.7333 (4.1181)	acc@1: 67.1812	acc@5: 86.7107	
2023-03-18 02:57:11,652 - INFO - Train: [22/90][600/3907]	eta 0:36:55 lr 0.03486290	time 0.2722 (0.6701)	loss 3.0689 (4.2329)	acc@1: 64.2274	acc@5: 81.2515	
2023-03-18 03:00:34,054 - INFO - Train: [22/90][900/3907]	eta 0:33:39 lr 0.03486290	time 0.2834 (0.6716)	loss 4.0060 (4.2502)	acc@1: 57.3880	acc@5: 71.0518	
2023-03-18 03:04:07,581 - INFO - Train: [22/90][1200/3907]	eta 0:30:45 lr 0.03486290	time 0.2823 (0.6816)	loss 6.2712 (4.2292)	acc@1: 15.3539	acc@5: 31.1489	
2023-03-18 03:07:48,621 - INFO - Train: [22/90][1500/3907]	eta 0:27:47 lr 0.03486290	time 0.2719 (0.6927)	loss 3.6175 (4.2396)	acc@1: 52.2313	acc@5: 75.3973	
2023-03-18 03:11:35,687 - INFO - Train: [22/90][1800/3907]	eta 0:24:41 lr 0.03486290	time 0.2726 (0.7034)	loss 4.4319 (4.2767)	acc@1: 44.4061	acc@5: 70.9172	
2023-03-18 03:15:39,359 - INFO - Train: [22/90][2100/3907]	eta 0:21:39 lr 0.03486290	time 0.2824 (0.7189)	loss 4.5136 (4.2836)	acc@1: 43.9795	acc@5: 64.9846	
2023-03-18 03:19:40,939 - INFO - Train: [22/90][2400/3907]	eta 0:18:19 lr 0.03486290	time 2.9194 (0.7297)	loss 4.1714 (4.2858)	acc@1: 52.1334	acc@5: 72.0264	
2023-03-18 03:24:00,071 - INFO - Train: [22/90][2700/3907]	eta 0:14:58 lr 0.03486290	time 0.2790 (0.7446)	loss 4.1302 (4.3054)	acc@1: 53.3382	acc@5: 70.0248	
2023-03-18 03:28:39,439 - INFO - Train: [22/90][3000/3907]	eta 0:11:32 lr 0.03486290	time 0.2713 (0.7632)	loss 5.4811 (4.3099)	acc@1: 34.6600	acc@5: 51.6397	
2023-03-18 03:33:45,795 - INFO - Train: [22/90][3300/3907]	eta 0:07:57 lr 0.03486290	time 0.2714 (0.7867)	loss 6.1332 (4.3116)	acc@1: 20.5510	acc@5: 38.3348	
2023-03-18 03:39:05,826 - INFO - Train: [22/90][3600/3907]	eta 0:04:08 lr 0.03486290	time 0.2842 (0.8100)	loss 3.5843 (4.3126)	acc@1: 60.7480	acc@5: 77.3653	
2023-03-18 03:44:35,741 - INFO - Train: [22/90][3900/3907]	eta 0:00:05 lr 0.03486290	time 0.2712 (0.8323)	loss 5.2662 (4.3157)	acc@1: 33.5905	acc@5: 54.8558	
2023-03-18 03:44:38,385 - INFO - EPOCH 22 training takes 0:54:09
2023-03-18 03:44:42,343 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp/fold1_latest.pth saved !!!
2023-03-18 03:44:42,343 - INFO - **********latest test***********
2023-03-18 03:44:42,343 - INFO - eval epoch 22
2023-03-18 03:44:46,070 - INFO - Test: [0/782]	Time 3.726 (3.726)	Loss 2.7577 (2.7577)	Acc@1 63.281 (63.281)	Acc@5 87.500 (87.500)
2023-03-18 03:53:24,135 - INFO - Test: [200/782]	Time 2.266 (2.596)	Loss 3.0862 (3.1996)	Acc@1 58.594 (56.328)	Acc@5 79.688 (79.967)
2023-03-18 03:59:29,124 - INFO - Test: [400/782]	Time 1.680 (2.211)	Loss 3.0189 (3.1601)	Acc@1 61.719 (57.277)	Acc@5 78.906 (80.601)
2023-03-18 04:04:05,371 - INFO - Test: [600/782]	Time 1.612 (1.935)	Loss 3.2232 (3.1261)	Acc@1 54.688 (58.200)	Acc@5 78.906 (81.146)
2023-03-18 04:08:24,373 - INFO -  * Acc@1 58.744 Acc@5 81.660
2023-03-18 04:08:24,373 - INFO - Max accuracy: 58.7440%
2023-03-18 04:08:28,032 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp/fold1_best.pth saved !!!
2023-03-18 04:08:28,033 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp
2023-03-18 04:08:36,119 - INFO - Train: [23/90][0/3907]	eta 8:45:54 lr 0.03438680	time 8.0763 (8.0763)	loss 2.6962 (2.6962)	acc@1: 67.9382	acc@5: 85.1180	
2023-03-18 04:10:38,093 - INFO - Train: [23/90][300/3907]	eta 0:25:58 lr 0.03438680	time 0.2727 (0.4321)	loss 2.9423 (4.0926)	acc@1: 65.4520	acc@5: 84.9312	
2023-03-18 04:12:58,652 - INFO - Train: [23/90][600/3907]	eta 0:24:49 lr 0.03438680	time 0.2702 (0.4503)	loss 4.9619 (4.1575)	acc@1: 43.7329	acc@5: 58.5489	
2023-03-18 04:15:29,899 - INFO - Train: [23/90][900/3907]	eta 0:23:27 lr 0.03438680	time 0.9369 (0.4682)	loss 3.5513 (4.1686)	acc@1: 54.2130	acc@5: 74.7567	
2023-03-18 04:18:17,548 - INFO - Train: [23/90][1200/3907]	eta 0:22:08 lr 0.03438680	time 0.2804 (0.4908)	loss 4.9695 (4.2111)	acc@1: 40.5632	acc@5: 58.1448	
2023-03-18 04:21:21,174 - INFO - Train: [23/90][1500/3907]	eta 0:20:39 lr 0.03438680	time 0.2724 (0.5151)	loss 4.2867 (4.2335)	acc@1: 49.0365	acc@5: 72.1726	
2023-03-18 04:24:42,921 - INFO - Train: [23/90][1800/3907]	eta 0:19:00 lr 0.03438680	time 0.2719 (0.5413)	loss 6.0081 (4.2385)	acc@1: 22.5455	acc@5: 38.4129	
2023-03-18 04:28:31,606 - INFO - Train: [23/90][2100/3907]	eta 0:17:15 lr 0.03438680	time 0.3678 (0.5728)	loss 3.1429 (4.2433)	acc@1: 63.1148	acc@5: 82.8857	
2023-03-18 04:32:49,183 - INFO - Train: [23/90][2400/3907]	eta 0:15:17 lr 0.03438680	time 0.2714 (0.6085)	loss 6.3960 (4.2567)	acc@1: 16.4756	acc@5: 28.0514	
2023-03-18 04:37:39,122 - INFO - Train: [23/90][2700/3907]	eta 0:13:02 lr 0.03438680	time 0.4730 (0.6483)	loss 6.0905 (4.2646)	acc@1: 18.6588	acc@5: 34.5264	
2023-03-18 04:42:34,916 - INFO - Train: [23/90][3000/3907]	eta 0:10:18 lr 0.03438680	time 0.2756 (0.6821)	loss 4.8003 (4.2788)	acc@1: 47.6852	acc@5: 61.4888	
2023-03-18 04:47:34,828 - INFO - Train: [23/90][3300/3907]	eta 0:07:11 lr 0.03438680	time 0.2744 (0.7109)	loss 4.5488 (4.2724)	acc@1: 40.6460	acc@5: 65.4151	
2023-03-18 04:52:57,345 - INFO - Train: [23/90][3600/3907]	eta 0:03:47 lr 0.03438680	time 1.8190 (0.7413)	loss 5.0745 (4.2927)	acc@1: 42.9083	acc@5: 58.4029	
2023-03-18 04:58:27,581 - INFO - Train: [23/90][3900/3907]	eta 0:00:05 lr 0.03438680	time 2.0253 (0.7689)	loss 3.3063 (4.3021)	acc@1: 62.5729	acc@5: 79.5681	
2023-03-18 04:58:29,169 - INFO - EPOCH 23 training takes 0:50:01
2023-03-18 04:58:32,925 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp/fold1_latest.pth saved !!!
2023-03-18 04:58:32,925 - INFO - **********latest test***********
2023-03-18 04:58:32,925 - INFO - eval epoch 23
2023-03-18 04:58:35,166 - INFO - Test: [0/782]	Time 2.239 (2.239)	Loss 2.7860 (2.7860)	Acc@1 63.281 (63.281)	Acc@5 89.844 (89.844)
2023-03-18 05:05:51,146 - INFO - Test: [200/782]	Time 2.009 (2.180)	Loss 3.1312 (3.1944)	Acc@1 52.344 (55.651)	Acc@5 80.469 (79.656)
2023-03-18 05:11:19,540 - INFO - Test: [400/782]	Time 1.077 (1.912)	Loss 2.9993 (3.1608)	Acc@1 57.812 (56.468)	Acc@5 80.469 (80.328)
2023-03-18 05:15:05,391 - INFO - Test: [600/782]	Time 0.754 (1.651)	Loss 3.2538 (3.1257)	Acc@1 51.562 (57.346)	Acc@5 77.344 (80.857)
2023-03-18 05:18:17,042 - INFO -  * Acc@1 57.992 Acc@5 81.409
2023-03-18 05:18:17,042 - INFO - Max accuracy: 58.7440%
2023-03-18 05:18:17,042 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp
2023-03-18 05:18:22,211 - INFO - Train: [24/90][0/3907]	eta 5:36:18 lr 0.03389317	time 5.1648 (5.1648)	loss 3.3937 (3.3937)	acc@1: 56.4278	acc@5: 78.7019	
2023-03-18 05:19:51,825 - INFO - Train: [24/90][300/3907]	eta 0:18:55 lr 0.03389317	time 0.2755 (0.3149)	loss 3.9145 (4.2804)	acc@1: 56.5055	acc@5: 71.6656	
2023-03-18 05:21:34,648 - INFO - Train: [24/90][600/3907]	eta 0:18:07 lr 0.03389317	time 0.2755 (0.3288)	loss 5.7764 (4.2420)	acc@1: 29.5903	acc@5: 42.7367	
2023-03-18 05:23:33,159 - INFO - Train: [24/90][900/3907]	eta 0:17:34 lr 0.03389317	time 0.2731 (0.3508)	loss 2.9792 (4.1991)	acc@1: 71.2121	acc@5: 81.9433	
2023-03-18 05:25:50,214 - INFO - Train: [24/90][1200/3907]	eta 0:17:01 lr 0.03389317	time 0.2840 (0.3773)	loss 5.0494 (4.2491)	acc@1: 41.1380	acc@5: 59.9904	
2023-03-18 05:28:25,528 - INFO - Train: [24/90][1500/3907]	eta 0:16:15 lr 0.03389317	time 0.2818 (0.4054)	loss 3.2151 (4.2573)	acc@1: 57.9805	acc@5: 80.8602	
2023-03-18 05:31:14,146 - INFO - Train: [24/90][1800/3907]	eta 0:15:09 lr 0.03389317	time 0.2821 (0.4315)	loss 4.2472 (4.2615)	acc@1: 54.5060	acc@5: 72.4531	
2023-03-18 05:34:23,967 - INFO - Train: [24/90][2100/3907]	eta 0:13:51 lr 0.03389317	time 0.2838 (0.4602)	loss 6.2827 (4.2664)	acc@1: 22.1655	acc@5: 32.6808	
2023-03-18 05:38:23,058 - INFO - Train: [24/90][2400/3907]	eta 0:12:36 lr 0.03389317	time 0.2711 (0.5023)	loss 3.1287 (4.2646)	acc@1: 57.7454	acc@5: 76.4733	
2023-03-18 05:42:46,869 - INFO - Train: [24/90][2700/3907]	eta 0:10:56 lr 0.03389317	time 0.2826 (0.5442)	loss 3.0428 (4.2824)	acc@1: 61.7187	acc@5: 78.1250	
2023-03-18 05:47:17,272 - INFO - Train: [24/90][3000/3907]	eta 0:08:45 lr 0.03389317	time 0.2714 (0.5799)	loss 3.4811 (4.2757)	acc@1: 56.2535	acc@5: 79.6615	
2023-03-18 05:51:50,255 - INFO - Train: [24/90][3300/3907]	eta 0:06:10 lr 0.03389317	time 0.2738 (0.6099)	loss 3.4695 (4.2660)	acc@1: 56.5574	acc@5: 74.4177	
2023-03-18 05:56:43,329 - INFO - Train: [24/90][3600/3907]	eta 0:03:16 lr 0.03389317	time 0.2717 (0.6405)	loss 5.6838 (4.2690)	acc@1: 28.8900	acc@5: 46.2343	
2023-03-18 06:01:45,341 - INFO - Train: [24/90][3900/3907]	eta 0:00:04 lr 0.03389317	time 1.4281 (0.6686)	loss 3.4117 (4.2719)	acc@1: 56.1917	acc@5: 77.9065	
2023-03-18 06:01:47,318 - INFO - EPOCH 24 training takes 0:43:30
2023-03-18 06:01:51,098 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp/fold1_latest.pth saved !!!
2023-03-18 06:01:51,099 - INFO - **********latest test***********
2023-03-18 06:01:51,099 - INFO - eval epoch 24
2023-03-18 06:01:53,358 - INFO - Test: [0/782]	Time 2.258 (2.258)	Loss 2.6209 (2.6209)	Acc@1 64.844 (64.844)	Acc@5 92.969 (92.969)
2023-03-18 06:08:59,640 - INFO - Test: [200/782]	Time 2.068 (2.132)	Loss 3.0573 (3.1222)	Acc@1 59.375 (57.669)	Acc@5 79.688 (80.683)
2023-03-18 06:14:24,265 - INFO - Test: [400/782]	Time 1.070 (1.878)	Loss 2.9497 (3.0865)	Acc@1 60.938 (58.477)	Acc@5 83.594 (81.379)
2023-03-18 06:18:09,116 - INFO - Test: [600/782]	Time 0.767 (1.627)	Loss 3.1355 (3.0531)	Acc@1 53.906 (59.257)	Acc@5 83.594 (81.923)
2023-03-18 06:21:19,597 - INFO -  * Acc@1 59.740 Acc@5 82.414
2023-03-18 06:21:19,597 - INFO - Max accuracy: 59.7400%
2023-03-18 06:21:23,318 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp/fold1_best.pth saved !!!
2023-03-18 06:21:23,319 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp
2023-03-18 06:21:26,544 - INFO - Train: [25/90][0/3907]	eta 3:29:39 lr 0.03338261	time 3.2197 (3.2197)	loss 6.1965 (6.1965)	acc@1: 18.6882	acc@5: 30.3631	
2023-03-18 06:22:53,098 - INFO - Train: [25/90][300/3907]	eta 0:17:55 lr 0.03338261	time 0.2797 (0.2982)	loss 2.8313 (4.2460)	acc@1: 72.2881	acc@5: 88.4498	
2023-03-18 06:24:38,420 - INFO - Train: [25/90][600/3907]	eta 0:17:53 lr 0.03338261	time 0.2728 (0.3246)	loss 3.9890 (4.2183)	acc@1: 50.5624	acc@5: 71.4300	
2023-03-18 06:26:41,380 - INFO - Train: [25/90][900/3907]	eta 0:17:41 lr 0.03338261	time 0.2826 (0.3530)	loss 4.6286 (4.2527)	acc@1: 47.9331	acc@5: 64.1950	
2023-03-18 06:28:55,313 - INFO - Train: [25/90][1200/3907]	eta 0:16:58 lr 0.03338261	time 0.2729 (0.3763)	loss 6.3817 (4.2683)	acc@1: 17.0708	acc@5: 32.8490	
2023-03-18 06:31:20,861 - INFO - Train: [25/90][1500/3907]	eta 0:15:58 lr 0.03338261	time 0.3176 (0.3981)	loss 4.0447 (4.2680)	acc@1: 50.5144	acc@5: 65.9247	
2023-03-18 06:34:01,601 - INFO - Train: [25/90][1800/3907]	eta 0:14:47 lr 0.03338261	time 0.2776 (0.4210)	loss 2.8263 (4.2735)	acc@1: 58.5927	acc@5: 89.0609	
2023-03-18 06:36:56,806 - INFO - Train: [25/90][2100/3907]	eta 0:13:22 lr 0.03338261	time 0.2717 (0.4443)	loss 3.1784 (4.2747)	acc@1: 60.4917	acc@5: 79.6347	
2023-03-18 06:40:17,465 - INFO - Train: [25/90][2400/3907]	eta 0:11:51 lr 0.03338261	time 0.2720 (0.4724)	loss 2.9015 (4.2712)	acc@1: 61.1790	acc@5: 81.3206	
2023-03-18 06:44:06,950 - INFO - Train: [25/90][2700/3907]	eta 0:10:09 lr 0.03338261	time 3.0412 (0.5049)	loss 2.9760 (4.2703)	acc@1: 67.1212	acc@5: 81.1698	
2023-03-18 06:48:23,690 - INFO - Train: [25/90][3000/3907]	eta 0:08:09 lr 0.03338261	time 0.2709 (0.5399)	loss 3.0644 (4.2700)	acc@1: 64.4249	acc@5: 81.5000	
2023-03-18 06:52:59,296 - INFO - Train: [25/90][3300/3907]	eta 0:05:48 lr 0.03338261	time 0.2830 (0.5744)	loss 4.7357 (4.2665)	acc@1: 44.4089	acc@5: 60.2692	
2023-03-18 06:57:40,123 - INFO - Train: [25/90][3600/3907]	eta 0:03:05 lr 0.03338261	time 0.2810 (0.6045)	loss 5.7188 (4.2776)	acc@1: 28.5246	acc@5: 47.2078	
2023-03-18 07:02:41,268 - INFO - Train: [25/90][3900/3907]	eta 0:00:04 lr 0.03338261	time 0.2688 (0.6352)	loss 4.3317 (4.2835)	acc@1: 50.2474	acc@5: 70.4141	
2023-03-18 07:02:42,840 - INFO - EPOCH 25 training takes 0:41:19
2023-03-18 07:02:46,847 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp/fold1_latest.pth saved !!!
2023-03-18 07:02:46,848 - INFO - **********latest test***********
2023-03-18 07:02:46,848 - INFO - eval epoch 25
2023-03-18 07:02:49,112 - INFO - Test: [0/782]	Time 2.264 (2.264)	Loss 2.8633 (2.8633)	Acc@1 61.719 (61.719)	Acc@5 85.156 (85.156)
2023-03-18 07:09:54,889 - INFO - Test: [200/782]	Time 2.023 (2.130)	Loss 3.0909 (3.2267)	Acc@1 57.031 (56.312)	Acc@5 81.250 (79.777)
2023-03-18 07:15:32,886 - INFO - Test: [400/782]	Time 1.053 (1.910)	Loss 3.0259 (3.1895)	Acc@1 60.938 (57.080)	Acc@5 81.250 (80.537)
2023-03-18 07:19:17,177 - INFO - Test: [600/782]	Time 0.760 (1.648)	Loss 3.1327 (3.1588)	Acc@1 58.594 (57.757)	Acc@5 83.594 (81.039)
2023-03-18 07:22:28,423 - INFO -  * Acc@1 58.284 Acc@5 81.567
2023-03-18 07:22:28,423 - INFO - Max accuracy: 59.7400%
2023-03-18 07:22:28,423 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp
2023-03-18 07:22:30,396 - INFO - Train: [26/90][0/3907]	eta 2:08:12 lr 0.03285575	time 1.9689 (1.9689)	loss 3.9420 (3.9420)	acc@1: 54.4641	acc@5: 73.1702	
2023-03-18 07:23:54,888 - INFO - Train: [26/90][300/3907]	eta 0:17:16 lr 0.03285575	time 0.3041 (0.2872)	loss 2.7954 (4.0922)	acc@1: 68.2984	acc@5: 84.5944	
2023-03-18 07:25:30,126 - INFO - Train: [26/90][600/3907]	eta 0:16:39 lr 0.03285575	time 0.2821 (0.3023)	loss 2.8526 (4.1494)	acc@1: 64.5608	acc@5: 86.3392	
2023-03-18 07:27:19,134 - INFO - Train: [26/90][900/3907]	eta 0:16:10 lr 0.03285575	time 1.3955 (0.3226)	loss 3.5244 (4.2000)	acc@1: 60.1241	acc@5: 79.6825	
2023-03-18 07:29:26,257 - INFO - Train: [26/90][1200/3907]	eta 0:15:41 lr 0.03285575	time 0.2840 (0.3479)	loss 3.9570 (4.2062)	acc@1: 56.1346	acc@5: 74.8461	
2023-03-18 07:31:42,545 - INFO - Train: [26/90][1500/3907]	eta 0:14:48 lr 0.03285575	time 0.3642 (0.3692)	loss 4.8568 (4.1881)	acc@1: 43.5898	acc@5: 58.7251	
2023-03-18 07:34:14,735 - INFO - Train: [26/90][1800/3907]	eta 0:13:46 lr 0.03285575	time 0.2815 (0.3922)	loss 3.7907 (4.1804)	acc@1: 54.8232	acc@5: 76.6285	
2023-03-18 07:37:02,830 - INFO - Train: [26/90][2100/3907]	eta 0:12:32 lr 0.03285575	time 1.7440 (0.4162)	loss 3.6716 (4.1895)	acc@1: 53.1819	acc@5: 75.8502	
2023-03-18 07:40:16,219 - INFO - Train: [26/90][2400/3907]	eta 0:11:10 lr 0.03285575	time 0.2708 (0.4447)	loss 6.3420 (4.1937)	acc@1: 20.3291	acc@5: 36.9640	
2023-03-18 07:43:48,503 - INFO - Train: [26/90][2700/3907]	eta 0:09:32 lr 0.03285575	time 3.4630 (0.4739)	loss 2.6233 (4.2041)	acc@1: 64.7727	acc@5: 93.6472	
2023-03-18 07:47:41,951 - INFO - Train: [26/90][3000/3907]	eta 0:07:37 lr 0.03285575	time 3.2157 (0.5043)	loss 3.6572 (4.2029)	acc@1: 61.1043	acc@5: 75.6400	
2023-03-18 07:51:33,137 - INFO - Train: [26/90][3300/3907]	eta 0:05:20 lr 0.03285575	time 0.2718 (0.5285)	loss 6.2550 (4.2219)	acc@1: 21.1570	acc@5: 36.3477	
2023-03-18 07:55:39,765 - INFO - Train: [26/90][3600/3907]	eta 0:02:49 lr 0.03285575	time 0.2863 (0.5530)	loss 6.2850 (4.2256)	acc@1: 12.4868	acc@5: 30.4951	
2023-03-18 08:00:06,635 - INFO - Train: [26/90][3900/3907]	eta 0:00:04 lr 0.03285575	time 0.2709 (0.5789)	loss 4.5968 (4.2273)	acc@1: 46.3800	acc@5: 62.7494	
2023-03-18 08:00:08,206 - INFO - EPOCH 26 training takes 0:37:39
2023-03-18 08:00:11,928 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp/fold1_latest.pth saved !!!
2023-03-18 08:00:11,929 - INFO - **********latest test***********
2023-03-18 08:00:11,929 - INFO - eval epoch 26
2023-03-18 08:00:14,248 - INFO - Test: [0/782]	Time 2.317 (2.317)	Loss 2.7382 (2.7382)	Acc@1 64.062 (64.062)	Acc@5 86.719 (86.719)
2023-03-18 08:07:15,378 - INFO - Test: [200/782]	Time 2.070 (2.107)	Loss 3.0190 (3.0879)	Acc@1 57.031 (58.003)	Acc@5 79.688 (81.052)
2023-03-18 08:12:37,740 - INFO - Test: [400/782]	Time 1.133 (1.860)	Loss 2.9266 (3.0519)	Acc@1 63.281 (58.841)	Acc@5 78.906 (81.653)
2023-03-18 08:16:21,930 - INFO - Test: [600/782]	Time 0.768 (1.614)	Loss 3.0434 (3.0183)	Acc@1 57.812 (59.669)	Acc@5 80.469 (82.256)
2023-03-18 08:19:30,385 - INFO -  * Acc@1 60.323 Acc@5 82.851
2023-03-18 08:19:30,385 - INFO - Max accuracy: 60.3230%
2023-03-18 08:19:34,034 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp/fold1_best.pth saved !!!
2023-03-18 08:19:34,034 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp
2023-03-18 08:19:35,782 - INFO - Train: [27/90][0/3907]	eta 1:53:19 lr 0.03231323	time 1.7404 (1.7404)	loss 2.8705 (2.8705)	acc@1: 61.9300	acc@5: 85.1538	
2023-03-18 08:21:00,438 - INFO - Train: [27/90][300/3907]	eta 0:17:15 lr 0.03231323	time 0.2885 (0.2870)	loss 5.2090 (4.2288)	acc@1: 41.1184	acc@5: 50.6132	
2023-03-18 08:22:24,458 - INFO - Train: [27/90][600/3907]	eta 0:15:37 lr 0.03231323	time 0.2868 (0.2835)	loss 4.7692 (4.2333)	acc@1: 44.7378	acc@5: 62.9484	
2023-03-18 08:23:52,113 - INFO - Train: [27/90][900/3907]	eta 0:14:21 lr 0.03231323	time 0.3051 (0.2864)	loss 2.8665 (4.2386)	acc@1: 67.0640	acc@5: 84.2199	
2023-03-18 08:25:35,505 - INFO - Train: [27/90][1200/3907]	eta 0:13:34 lr 0.03231323	time 1.1893 (0.3010)	loss 2.6088 (4.2110)	acc@1: 70.2490	acc@5: 89.7622	
2023-03-18 08:27:34,646 - INFO - Train: [27/90][1500/3907]	eta 0:12:50 lr 0.03231323	time 0.2847 (0.3202)	loss 3.1499 (4.1988)	acc@1: 61.2621	acc@5: 83.9767	
2023-03-18 08:29:48,921 - INFO - Train: [27/90][1800/3907]	eta 0:11:59 lr 0.03231323	time 0.8000 (0.3414)	loss 3.1708 (4.2116)	acc@1: 56.1224	acc@5: 80.2862	
2023-03-18 08:32:21,998 - INFO - Train: [27/90][2100/3907]	eta 0:11:00 lr 0.03231323	time 0.2723 (0.3655)	loss 5.3070 (4.1965)	acc@1: 36.5980	acc@5: 51.4660	
2023-03-18 08:35:14,417 - INFO - Train: [27/90][2400/3907]	eta 0:09:50 lr 0.03231323	time 0.2716 (0.3917)	loss 5.9297 (4.2117)	acc@1: 25.8578	acc@5: 40.9131	
2023-03-18 08:38:28,399 - INFO - Train: [27/90][2700/3907]	eta 0:08:26 lr 0.03231323	time 0.2837 (0.4200)	loss 6.1938 (4.2219)	acc@1: 18.0131	acc@5: 31.3641	
2023-03-18 08:42:08,415 - INFO - Train: [27/90][3000/3907]	eta 0:06:49 lr 0.03231323	time 0.5781 (0.4513)	loss 4.8329 (4.2292)	acc@1: 44.7848	acc@5: 62.7581	
2023-03-18 08:45:55,039 - INFO - Train: [27/90][3300/3907]	eta 0:04:50 lr 0.03231323	time 0.2720 (0.4789)	loss 6.3203 (4.2381)	acc@1: 15.2387	acc@5: 29.3099	
2023-03-18 08:49:46,054 - INFO - Train: [27/90][3600/3907]	eta 0:02:34 lr 0.03231323	time 0.2712 (0.5032)	loss 2.9383 (4.2446)	acc@1: 63.7895	acc@5: 83.2365	
2023-03-18 08:54:01,857 - INFO - Train: [27/90][3900/3907]	eta 0:00:03 lr 0.03231323	time 0.2714 (0.5301)	loss 3.0449 (4.2560)	acc@1: 62.1571	acc@5: 81.5842	
2023-03-18 08:54:04,988 - INFO - EPOCH 27 training takes 0:34:30
2023-03-18 08:54:08,808 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp/fold1_latest.pth saved !!!
2023-03-18 08:54:08,809 - INFO - **********latest test***********
2023-03-18 08:54:08,809 - INFO - eval epoch 27
2023-03-18 08:54:11,131 - INFO - Test: [0/782]	Time 2.320 (2.320)	Loss 2.7223 (2.7223)	Acc@1 65.625 (65.625)	Acc@5 85.938 (85.938)
2023-03-18 09:01:04,192 - INFO - Test: [200/782]	Time 1.985 (2.067)	Loss 3.1044 (3.0918)	Acc@1 60.156 (58.602)	Acc@5 79.688 (81.398)
2023-03-18 09:06:23,604 - INFO - Test: [400/782]	Time 1.052 (1.832)	Loss 2.8934 (3.0551)	Acc@1 60.938 (59.248)	Acc@5 82.031 (82.173)
2023-03-18 09:10:08,401 - INFO - Test: [600/782]	Time 0.760 (1.597)	Loss 3.0206 (3.0172)	Acc@1 57.031 (60.138)	Acc@5 82.031 (82.753)
2023-03-18 09:12:57,363 - INFO -  * Acc@1 60.633 Acc@5 83.128
2023-03-18 09:12:57,363 - INFO - Max accuracy: 60.6330%
2023-03-18 09:13:00,925 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp/fold1_best.pth saved !!!
2023-03-18 09:13:00,926 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp
2023-03-18 09:13:02,915 - INFO - Train: [28/90][0/3907]	eta 2:08:53 lr 0.03175571	time 1.9793 (1.9793)	loss 4.6172 (4.6172)	acc@1: 49.0933	acc@5: 65.5462	
2023-03-18 09:14:27,061 - INFO - Train: [28/90][300/3907]	eta 0:17:12 lr 0.03175571	time 0.2828 (0.2861)	loss 6.0455 (4.0839)	acc@1: 21.3289	acc@5: 36.6809	
2023-03-18 09:15:51,522 - INFO - Train: [28/90][600/3907]	eta 0:15:38 lr 0.03175571	time 0.2746 (0.2838)	loss 5.4284 (4.1092)	acc@1: 35.2659	acc@5: 53.7545	
2023-03-18 09:17:15,718 - INFO - Train: [28/90][900/3907]	eta 0:14:10 lr 0.03175571	time 0.2835 (0.2828)	loss 4.9729 (4.1226)	acc@1: 41.4649	acc@5: 58.6758	
2023-03-18 09:18:47,194 - INFO - Train: [28/90][1200/3907]	eta 0:13:00 lr 0.03175571	time 0.2744 (0.2883)	loss 2.8613 (4.1293)	acc@1: 67.6952	acc@5: 87.1510	
2023-03-18 09:20:33,131 - INFO - Train: [28/90][1500/3907]	eta 0:12:05 lr 0.03175571	time 0.2794 (0.3013)	loss 3.8388 (4.1631)	acc@1: 62.6544	acc@5: 75.8256	
2023-03-18 09:22:34,732 - INFO - Train: [28/90][1800/3907]	eta 0:11:11 lr 0.03175571	time 0.2733 (0.3186)	loss 2.7907 (4.1893)	acc@1: 71.0732	acc@5: 85.9126	
2023-03-18 09:24:58,700 - INFO - Train: [28/90][2100/3907]	eta 0:10:17 lr 0.03175571	time 0.2730 (0.3416)	loss 3.1024 (4.1786)	acc@1: 62.8605	acc@5: 83.3091	
2023-03-18 09:27:48,107 - INFO - Train: [28/90][2400/3907]	eta 0:09:16 lr 0.03175571	time 0.2746 (0.3695)	loss 3.3226 (4.1910)	acc@1: 58.2443	acc@5: 74.8855	
2023-03-18 09:30:57,664 - INFO - Train: [28/90][2700/3907]	eta 0:08:01 lr 0.03175571	time 0.2720 (0.3986)	loss 3.2751 (4.1986)	acc@1: 63.0994	acc@5: 78.3041	
2023-03-18 09:34:20,079 - INFO - Train: [28/90][3000/3907]	eta 0:06:26 lr 0.03175571	time 0.2884 (0.4262)	loss 4.4220 (4.2039)	acc@1: 48.9634	acc@5: 68.6268	
2023-03-18 09:37:44,787 - INFO - Train: [28/90][3300/3907]	eta 0:04:32 lr 0.03175571	time 0.2717 (0.4495)	loss 3.3076 (4.1938)	acc@1: 51.6517	acc@5: 80.5375	
2023-03-18 09:41:07,314 - INFO - Train: [28/90][3600/3907]	eta 0:02:23 lr 0.03175571	time 0.2841 (0.4683)	loss 4.5755 (4.1958)	acc@1: 46.3877	acc@5: 65.7159	
2023-03-18 09:44:57,837 - INFO - Train: [28/90][3900/3907]	eta 0:00:03 lr 0.03175571	time 0.2699 (0.4914)	loss 6.1262 (4.2115)	acc@1: 17.2013	acc@5: 32.7448	
2023-03-18 09:44:59,450 - INFO - EPOCH 28 training takes 0:31:58
2023-03-18 09:45:03,202 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp/fold1_latest.pth saved !!!
2023-03-18 09:45:03,202 - INFO - **********latest test***********
2023-03-18 09:45:03,203 - INFO - eval epoch 28
2023-03-18 09:45:05,522 - INFO - Test: [0/782]	Time 2.319 (2.319)	Loss 2.6766 (2.6766)	Acc@1 60.938 (60.938)	Acc@5 90.625 (90.625)
2023-03-18 09:51:54,271 - INFO - Test: [200/782]	Time 1.799 (2.045)	Loss 2.9956 (3.0607)	Acc@1 55.469 (58.792)	Acc@5 81.250 (81.635)
2023-03-18 09:57:08,653 - INFO - Test: [400/782]	Time 1.066 (1.809)	Loss 2.9192 (3.0311)	Acc@1 59.375 (59.422)	Acc@5 81.250 (82.168)
2023-03-18 10:00:52,740 - INFO - Test: [600/782]	Time 0.759 (1.580)	Loss 3.1268 (2.9955)	Acc@1 59.375 (60.293)	Acc@5 78.125 (82.746)
2023-03-18 10:04:25,018 - INFO -  * Acc@1 60.837 Acc@5 83.234
2023-03-18 10:04:25,018 - INFO - Max accuracy: 60.8370%
2023-03-18 10:04:28,678 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp/fold1_best.pth saved !!!
2023-03-18 10:04:28,679 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp
2023-03-18 10:04:30,636 - INFO - Train: [29/90][0/3907]	eta 2:07:01 lr 0.03118386	time 1.9506 (1.9506)	loss 3.4215 (3.4215)	acc@1: 56.2764	acc@5: 78.7933	
2023-03-18 10:05:54,426 - INFO - Train: [29/90][300/3907]	eta 0:17:07 lr 0.03118386	time 0.2850 (0.2849)	loss 3.5470 (4.0075)	acc@1: 59.1682	acc@5: 74.5082	
2023-03-18 10:07:21,789 - INFO - Train: [29/90][600/3907]	eta 0:15:52 lr 0.03118386	time 0.2737 (0.2880)	loss 5.9077 (4.0150)	acc@1: 19.4030	acc@5: 40.4522	
2023-03-18 10:09:12,509 - INFO - Train: [29/90][900/3907]	eta 0:15:47 lr 0.03118386	time 0.2849 (0.3150)	loss 3.9262 (4.0367)	acc@1: 51.6745	acc@5: 73.1786	
2023-03-18 10:11:40,555 - INFO - Train: [29/90][1200/3907]	eta 0:16:13 lr 0.03118386	time 0.2721 (0.3596)	loss 5.9506 (4.0470)	acc@1: 23.0617	acc@5: 42.1740	
2023-03-18 10:14:09,752 - INFO - Train: [29/90][1500/3907]	eta 0:15:31 lr 0.03118386	time 0.6684 (0.3871)	loss 4.7980 (4.0763)	acc@1: 46.5432	acc@5: 63.9611	
2023-03-18 10:17:03,419 - INFO - Train: [29/90][1800/3907]	eta 0:14:42 lr 0.03118386	time 0.2722 (0.4191)	loss 4.2980 (4.1073)	acc@1: 47.7788	acc@5: 72.3318	
2023-03-18 10:20:13,367 - INFO - Train: [29/90][2100/3907]	eta 0:13:32 lr 0.03118386	time 0.2713 (0.4496)	loss 4.9472 (4.1264)	acc@1: 41.2551	acc@5: 60.6742	
2023-03-18 10:23:56,624 - INFO - Train: [29/90][2400/3907]	eta 0:12:13 lr 0.03118386	time 0.2719 (0.4864)	loss 3.2162 (4.1526)	acc@1: 60.3773	acc@5: 75.8658	
2023-03-18 10:28:25,533 - INFO - Train: [29/90][2700/3907]	eta 0:10:42 lr 0.03118386	time 0.2716 (0.5320)	loss 5.9440 (4.1664)	acc@1: 25.3343	acc@5: 41.2937	
2023-03-18 10:33:59,210 - INFO - Train: [29/90][3000/3907]	eta 0:08:55 lr 0.03118386	time 2.1101 (0.5900)	loss 4.4632 (4.1778)	acc@1: 48.7517	acc@5: 67.9399	
