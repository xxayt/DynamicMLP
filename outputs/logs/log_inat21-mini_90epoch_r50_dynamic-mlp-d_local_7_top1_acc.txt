2023-03-18 00:44:02,815 - INFO - NVIDIA GeForce RTX 3090
2023-03-18 00:44:02,815 - INFO - --batch_size 128
2023-03-18 00:44:02,815 - INFO - --data inat21_mini
2023-03-18 00:44:02,815 - INFO - --data_dir ./datasets/iNat2021
2023-03-18 00:44:02,816 - INFO - --evaluate False
2023-03-18 00:44:02,816 - INFO - --fold 1
2023-03-18 00:44:02,816 - INFO - --image_only False
2023-03-18 00:44:02,816 - INFO - --metadata geo_temporal
2023-03-18 00:44:02,816 - INFO - --mlp_cin 6
2023-03-18 00:44:02,816 - INFO - --mlp_hidden 64
2023-03-18 00:44:02,816 - INFO - --mlp_num_layers 2
2023-03-18 00:44:02,816 - INFO - --mlp_out_channel 256
2023-03-18 00:44:02,816 - INFO - --mlp_type d
2023-03-18 00:44:02,816 - INFO - --model_file resnet_dynamic_mlp
2023-03-18 00:44:02,816 - INFO - --model_name resnet50
2023-03-18 00:44:02,816 - INFO - --name res50_dynamic_mlp_d
2023-03-18 00:44:02,816 - INFO - --num_classes 10000
2023-03-18 00:44:02,816 - INFO - --num_workers 8
2023-03-18 00:44:02,816 - INFO - --path_log ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-18 00:44:02,816 - INFO - --pretrained True
2023-03-18 00:44:02,816 - INFO - --random_seed 37
2023-03-18 00:44:02,816 - INFO - --resume Latest
2023-03-18 00:44:02,816 - INFO - --save_dir ./outputs
2023-03-18 00:44:02,816 - INFO - --start_lr 0.04
2023-03-18 00:44:02,816 - INFO - --stop_epoch 90
2023-03-18 00:44:02,816 - INFO - --tencrop False
2023-03-18 00:44:02,816 - INFO - --warmup 2
2023-03-18 00:44:02,816 - INFO - Creating model:resnet_dynamic_mlp -> resnet50
2023-03-18 00:44:02,816 - INFO - type: d, cin: 6, d: 256, h: 64, N: 2
2023-03-18 00:44:07,476 - INFO - => no checkpoint found at './outputs/inat21_mini/res50_dynamic_mlp_d/fold1_latest.pth'
2023-03-18 00:44:07,476 - INFO - Start training
2023-03-18 00:44:12,250 - INFO - Train: [1/90][0/3907]	eta 5:10:45 lr 0.00000000	time 4.7722 (4.7722)	loss 9.3808 (9.3808)	acc@1: 0.0000	acc@5: 0.0000	
2023-03-18 00:45:06,019 - INFO - Train: [1/90][300/3907]	eta 0:11:41 lr 0.00153571	time 0.1854 (0.1945)	loss 9.2976 (9.3829)	acc@1: 0.0000	acc@5: 0.0000	
2023-03-18 00:45:59,978 - INFO - Train: [1/90][600/3907]	eta 0:10:19 lr 0.00307141	time 0.1822 (0.1872)	loss 9.2891 (9.3471)	acc@1: 0.0000	acc@5: 0.0000	
2023-03-18 00:46:54,260 - INFO - Train: [1/90][900/3907]	eta 0:09:16 lr 0.00460712	time 0.1797 (0.1851)	loss 8.9838 (9.2866)	acc@1: 0.0000	acc@5: 0.6354	
2023-03-18 00:47:48,567 - INFO - Train: [1/90][1200/3907]	eta 0:08:18 lr 0.00614282	time 0.1799 (0.1841)	loss 8.2938 (9.1401)	acc@1: 0.0000	acc@5: 0.7160	
2023-03-18 00:48:42,686 - INFO - Train: [1/90][1500/3907]	eta 0:07:21 lr 0.00767853	time 0.1799 (0.1833)	loss 7.8030 (8.9609)	acc@1: 0.7409	acc@5: 5.1863	
2023-03-18 00:49:36,791 - INFO - Train: [1/90][1800/3907]	eta 0:06:25 lr 0.00921423	time 0.1883 (0.1828)	loss 7.2123 (8.7764)	acc@1: 3.0078	acc@5: 9.8047	
2023-03-18 00:50:31,123 - INFO - Train: [1/90][2100/3907]	eta 0:05:29 lr 0.01074994	time 0.1819 (0.1826)	loss 8.1834 (8.5951)	acc@1: 0.9531	acc@5: 3.6405	
2023-03-18 00:51:25,472 - INFO - Train: [1/90][2400/3907]	eta 0:04:34 lr 0.01228564	time 0.1800 (0.1824)	loss 7.6277 (8.4327)	acc@1: 1.2664	acc@5: 5.6988	
2023-03-18 00:52:19,838 - INFO - Train: [1/90][2700/3907]	eta 0:03:40 lr 0.01382135	time 0.1796 (0.1823)	loss 6.6640 (8.2898)	acc@1: 5.8529	acc@5: 14.6324	
2023-03-18 00:53:14,557 - INFO - Train: [1/90][3000/3907]	eta 0:02:45 lr 0.01535705	time 0.1797 (0.1823)	loss 6.5949 (8.1529)	acc@1: 6.8636	acc@5: 20.5907	
2023-03-18 00:54:09,199 - INFO - Train: [1/90][3300/3907]	eta 0:01:50 lr 0.01689276	time 0.1797 (0.1823)	loss 5.9781 (8.0319)	acc@1: 6.2481	acc@5: 22.6493	
2023-03-18 00:55:03,751 - INFO - Train: [1/90][3600/3907]	eta 0:00:55 lr 0.01842846	time 0.1793 (0.1822)	loss 7.4711 (7.9228)	acc@1: 7.5908	acc@5: 14.8785	
2023-03-18 00:55:58,582 - INFO - Train: [1/90][3900/3907]	eta 0:00:01 lr 0.01996417	time 0.1855 (0.1823)	loss 7.2930 (7.8205)	acc@1: 9.7691	acc@5: 15.3865	
2023-03-18 00:56:00,426 - INFO - EPOCH 1 training takes 0:11:52
2023-03-18 00:56:01,335 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/fold1_latest.pth saved !!!
2023-03-18 00:56:01,335 - INFO - **********Latest test***********
2023-03-18 00:56:01,335 - INFO - eval epoch 1
2023-03-18 00:56:02,433 - INFO - Test: [0/782]	Time 1.096 (1.096)	Loss 4.8879 (4.8879)	Acc@1 19.531 (19.531)	Acc@5 43.750 (43.750)
2023-03-18 00:58:05,070 - INFO - Test: [200/782]	Time 0.621 (0.616)	Loss 5.3085 (5.4813)	Acc@1 9.375 (13.071)	Acc@5 39.844 (32.533)
2023-03-18 01:00:04,832 - INFO - Test: [400/782]	Time 0.613 (0.607)	Loss 5.4711 (5.4656)	Acc@1 10.938 (13.266)	Acc@5 27.344 (32.955)
2023-03-18 01:02:06,297 - INFO - Test: [600/782]	Time 0.585 (0.607)	Loss 5.5524 (5.4652)	Acc@1 15.625 (13.286)	Acc@5 32.031 (32.901)
2023-03-18 01:03:54,069 - INFO -  * Acc@1 13.697 Acc@5 33.814
2023-03-18 01:03:54,070 - INFO - Max accuracy: 13.6970%
2023-03-18 01:03:54,962 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/fold1_best.pth saved !!!
2023-03-18 01:03:54,962 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-18 01:03:57,936 - INFO - Train: [2/90][0/3907]	eta 3:13:22 lr 0.02000000	time 2.9696 (2.9696)	loss 6.7711 (6.7711)	acc@1: 9.4590	acc@5: 21.5587	
2023-03-18 01:04:52,643 - INFO - Train: [2/90][300/3907]	eta 0:11:31 lr 0.02153571	time 0.1788 (0.1916)	loss 7.9186 (6.3410)	acc@1: 3.4475	acc@5: 9.0899	
2023-03-18 01:05:47,263 - INFO - Train: [2/90][600/3907]	eta 0:10:17 lr 0.02307141	time 0.1833 (0.1868)	loss 7.8213 (6.3303)	acc@1: 3.5587	acc@5: 10.6760	
2023-03-18 01:06:41,845 - INFO - Train: [2/90][900/3907]	eta 0:09:16 lr 0.02460712	time 0.1874 (0.1852)	loss 6.4491 (6.2914)	acc@1: 11.6459	acc@5: 26.9843	
2023-03-18 01:07:36,066 - INFO - Train: [2/90][1200/3907]	eta 0:08:18 lr 0.02614282	time 0.1931 (0.1841)	loss 5.1637 (6.2365)	acc@1: 23.1430	acc@5: 45.5047	
2023-03-18 01:08:30,289 - INFO - Train: [2/90][1500/3907]	eta 0:07:21 lr 0.02767853	time 0.1794 (0.1834)	loss 4.9438 (6.2247)	acc@1: 19.8262	acc@5: 49.5654	
2023-03-18 01:09:24,532 - INFO - Train: [2/90][1800/3907]	eta 0:06:25 lr 0.02921423	time 0.1879 (0.1830)	loss 4.9862 (6.1759)	acc@1: 19.4249	acc@5: 41.9579	
2023-03-18 01:10:18,933 - INFO - Train: [2/90][2100/3907]	eta 0:05:30 lr 0.03074994	time 0.1813 (0.1827)	loss 5.8175 (6.1487)	acc@1: 15.0798	acc@5: 39.1661	
2023-03-18 01:11:13,299 - INFO - Train: [2/90][2400/3907]	eta 0:04:35 lr 0.03228564	time 0.1790 (0.1826)	loss 5.6083 (6.1206)	acc@1: 16.4025	acc@5: 40.5443	
2023-03-18 01:12:07,398 - INFO - Train: [2/90][2700/3907]	eta 0:03:40 lr 0.03382135	time 0.1795 (0.1823)	loss 7.3953 (6.0879)	acc@1: 3.9688	acc@5: 15.1609	
2023-03-18 01:13:01,566 - INFO - Train: [2/90][3000/3907]	eta 0:02:45 lr 0.03535705	time 0.1788 (0.1821)	loss 5.7247 (6.0691)	acc@1: 21.6492	acc@5: 43.2983	
2023-03-18 01:13:55,907 - INFO - Train: [2/90][3300/3907]	eta 0:01:50 lr 0.03689276	time 0.1796 (0.1820)	loss 6.0008 (6.0453)	acc@1: 16.4691	acc@5: 37.5495	
2023-03-18 01:14:50,307 - INFO - Train: [2/90][3600/3907]	eta 0:00:55 lr 0.03842846	time 0.1844 (0.1820)	loss 5.6848 (6.0263)	acc@1: 19.4163	acc@5: 41.6224	
2023-03-18 01:15:44,648 - INFO - Train: [2/90][3900/3907]	eta 0:00:01 lr 0.03996417	time 0.1784 (0.1819)	loss 5.9658 (6.0031)	acc@1: 19.3872	acc@5: 33.4262	
2023-03-18 01:15:45,917 - INFO - EPOCH 2 training takes 0:11:50
2023-03-18 01:15:47,001 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/fold1_latest.pth saved !!!
2023-03-18 01:15:47,001 - INFO - **********Latest test***********
2023-03-18 01:15:47,001 - INFO - eval epoch 2
2023-03-18 01:15:47,620 - INFO - Test: [0/782]	Time 0.616 (0.616)	Loss 3.9347 (3.9347)	Acc@1 37.500 (37.500)	Acc@5 65.625 (65.625)
2023-03-18 01:17:46,709 - INFO - Test: [200/782]	Time 0.590 (0.596)	Loss 4.3613 (4.5074)	Acc@1 30.469 (27.453)	Acc@5 56.250 (54.373)
2023-03-18 01:19:44,622 - INFO - Test: [400/782]	Time 0.608 (0.593)	Loss 4.2292 (4.4704)	Acc@1 32.812 (28.033)	Acc@5 56.250 (55.249)
2023-03-18 01:21:45,010 - INFO - Test: [600/782]	Time 0.599 (0.596)	Loss 4.5700 (4.4479)	Acc@1 25.000 (28.468)	Acc@5 53.906 (55.718)
2023-03-18 01:23:33,336 - INFO -  * Acc@1 28.888 Acc@5 56.443
2023-03-18 01:23:33,336 - INFO - Max accuracy: 28.8880%
2023-03-18 01:23:34,389 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/fold1_best.pth saved !!!
2023-03-18 01:23:34,391 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-18 01:23:37,189 - INFO - Train: [3/90][0/3907]	eta 3:01:35 lr 0.03995128	time 2.7887 (2.7887)	loss 5.0109 (5.0109)	acc@1: 31.6562	acc@5: 53.2400	
2023-03-18 01:24:31,406 - INFO - Train: [3/90][300/3907]	eta 0:11:23 lr 0.03995128	time 0.1782 (0.1894)	loss 5.2937 (5.5229)	acc@1: 24.8821	acc@5: 46.9909	
2023-03-18 01:25:25,547 - INFO - Train: [3/90][600/3907]	eta 0:10:11 lr 0.03995128	time 0.1824 (0.1849)	loss 5.0092 (5.4922)	acc@1: 22.7489	acc@5: 48.4331	
2023-03-18 01:26:19,619 - INFO - Train: [3/90][900/3907]	eta 0:09:11 lr 0.03995128	time 0.1788 (0.1834)	loss 4.8295 (5.5045)	acc@1: 29.3300	acc@5: 50.3874	
2023-03-18 01:27:13,763 - INFO - Train: [3/90][1200/3907]	eta 0:08:14 lr 0.03995128	time 0.1781 (0.1826)	loss 5.4105 (5.5167)	acc@1: 25.7220	acc@5: 48.0595	
2023-03-18 01:28:07,963 - INFO - Train: [3/90][1500/3907]	eta 0:07:18 lr 0.03995128	time 0.1856 (0.1822)	loss 4.3971 (5.5098)	acc@1: 33.3286	acc@5: 58.9015	
2023-03-18 01:29:02,056 - INFO - Train: [3/90][1800/3907]	eta 0:06:23 lr 0.03995128	time 0.1786 (0.1819)	loss 4.4918 (5.4911)	acc@1: 29.4488	acc@5: 52.7042	
2023-03-18 01:29:56,172 - INFO - Train: [3/90][2100/3907]	eta 0:05:28 lr 0.03995128	time 0.1783 (0.1817)	loss 4.8635 (5.4768)	acc@1: 26.4725	acc@5: 50.1488	
2023-03-18 01:30:50,280 - INFO - Train: [3/90][2400/3907]	eta 0:04:33 lr 0.03995128	time 0.1788 (0.1815)	loss 6.3906 (5.4772)	acc@1: 14.9889	acc@5: 33.2057	
2023-03-18 01:31:44,188 - INFO - Train: [3/90][2700/3907]	eta 0:03:38 lr 0.03995128	time 0.1790 (0.1813)	loss 4.5360 (5.4776)	acc@1: 33.7137	acc@5: 56.1895	
2023-03-18 01:32:38,235 - INFO - Train: [3/90][3000/3907]	eta 0:02:44 lr 0.03995128	time 0.1775 (0.1812)	loss 6.2918 (5.4555)	acc@1: 25.8499	acc@5: 40.4178	
2023-03-18 01:33:32,475 - INFO - Train: [3/90][3300/3907]	eta 0:01:49 lr 0.03995128	time 0.1787 (0.1812)	loss 4.8493 (5.4334)	acc@1: 34.3099	acc@5: 56.4684	
2023-03-18 01:34:26,703 - INFO - Train: [3/90][3600/3907]	eta 0:00:55 lr 0.03995128	time 0.1787 (0.1811)	loss 3.9595 (5.4217)	acc@1: 35.7710	acc@5: 69.2056	
2023-03-18 01:35:21,028 - INFO - Train: [3/90][3900/3907]	eta 0:00:01 lr 0.03995128	time 0.1779 (0.1811)	loss 4.6811 (5.4166)	acc@1: 33.3417	acc@5: 54.8286	
2023-03-18 01:35:22,303 - INFO - EPOCH 3 training takes 0:11:47
2023-03-18 01:35:23,407 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/fold1_latest.pth saved !!!
2023-03-18 01:35:23,407 - INFO - **********Latest test***********
2023-03-18 01:35:23,407 - INFO - eval epoch 3
2023-03-18 01:35:24,001 - INFO - Test: [0/782]	Time 0.590 (0.590)	Loss 3.4694 (3.4694)	Acc@1 43.750 (43.750)	Acc@5 75.781 (75.781)
2023-03-18 01:37:24,073 - INFO - Test: [200/782]	Time 0.574 (0.600)	Loss 3.6047 (3.9763)	Acc@1 53.906 (37.792)	Acc@5 71.094 (65.571)
2023-03-18 01:39:23,240 - INFO - Test: [400/782]	Time 0.595 (0.598)	Loss 3.7378 (3.9425)	Acc@1 41.406 (38.686)	Acc@5 68.750 (66.130)
2023-03-18 01:41:24,271 - INFO - Test: [600/782]	Time 0.598 (0.600)	Loss 4.1666 (3.9154)	Acc@1 32.031 (39.290)	Acc@5 61.719 (66.616)
2023-03-18 01:43:11,356 - INFO -  * Acc@1 39.838 Acc@5 67.274
2023-03-18 01:43:11,357 - INFO - Max accuracy: 39.8380%
2023-03-18 01:43:12,430 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/fold1_best.pth saved !!!
2023-03-18 01:43:12,431 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-18 01:43:14,588 - INFO - Train: [4/90][0/3907]	eta 2:19:47 lr 0.03989044	time 2.1468 (2.1468)	loss 3.9585 (3.9585)	acc@1: 40.5906	acc@5: 64.7885	
2023-03-18 01:44:09,101 - INFO - Train: [4/90][300/3907]	eta 0:11:18 lr 0.03989044	time 0.1882 (0.1882)	loss 4.4253 (5.0507)	acc@1: 35.8910	acc@5: 56.8075	
2023-03-18 01:45:04,158 - INFO - Train: [4/90][600/3907]	eta 0:10:14 lr 0.03989044	time 0.1797 (0.1859)	loss 6.9577 (5.1375)	acc@1: 9.6542	acc@5: 19.2228	
2023-03-18 01:45:59,127 - INFO - Train: [4/90][900/3907]	eta 0:09:16 lr 0.03989044	time 0.1797 (0.1850)	loss 7.1025 (5.1219)	acc@1: 8.7715	acc@5: 18.0619	
2023-03-18 01:46:53,515 - INFO - Train: [4/90][1200/3907]	eta 0:08:18 lr 0.03989044	time 0.1798 (0.1841)	loss 4.7123 (5.1132)	acc@1: 40.5501	acc@5: 61.1689	
2023-03-18 01:47:47,953 - INFO - Train: [4/90][1500/3907]	eta 0:07:21 lr 0.03989044	time 0.1796 (0.1835)	loss 6.7521 (5.0904)	acc@1: 12.6080	acc@5: 26.5823	
2023-03-18 01:48:42,266 - INFO - Train: [4/90][1800/3907]	eta 0:06:25 lr 0.03989044	time 0.1800 (0.1831)	loss 3.5806 (5.1094)	acc@1: 47.5660	acc@5: 71.7388	
2023-03-18 01:49:36,375 - INFO - Train: [4/90][2100/3907]	eta 0:05:30 lr 0.03989044	time 0.1794 (0.1827)	loss 5.5463 (5.1020)	acc@1: 29.3339	acc@5: 50.5542	
2023-03-18 01:50:30,705 - INFO - Train: [4/90][2400/3907]	eta 0:04:35 lr 0.03989044	time 0.1805 (0.1825)	loss 5.1693 (5.1049)	acc@1: 29.6315	acc@5: 52.5285	
2023-03-18 01:51:24,816 - INFO - Train: [4/90][2700/3907]	eta 0:03:40 lr 0.03989044	time 0.1796 (0.1823)	loss 4.2043 (5.1075)	acc@1: 32.9811	acc@5: 62.1273	
2023-03-18 01:52:19,192 - INFO - Train: [4/90][3000/3907]	eta 0:02:45 lr 0.03989044	time 0.1802 (0.1822)	loss 3.6985 (5.1094)	acc@1: 44.5233	acc@5: 70.3000	
2023-03-18 01:53:13,678 - INFO - Train: [4/90][3300/3907]	eta 0:01:50 lr 0.03989044	time 0.1807 (0.1821)	loss 6.7310 (5.1073)	acc@1: 11.6487	acc@5: 23.3687	
2023-03-18 01:54:07,982 - INFO - Train: [4/90][3600/3907]	eta 0:00:55 lr 0.03989044	time 0.1803 (0.1820)	loss 4.9437 (5.0979)	acc@1: 34.4392	acc@5: 59.9242	
2023-03-18 01:55:02,267 - INFO - Train: [4/90][3900/3907]	eta 0:00:01 lr 0.03989044	time 0.1787 (0.1820)	loss 6.7625 (5.0936)	acc@1: 15.6980	acc@5: 28.3247	
2023-03-18 01:55:03,453 - INFO - EPOCH 4 training takes 0:11:51
2023-03-18 01:55:04,542 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/fold1_latest.pth saved !!!
2023-03-18 01:55:04,542 - INFO - **********Latest test***********
2023-03-18 01:55:04,543 - INFO - eval epoch 4
2023-03-18 01:55:05,147 - INFO - Test: [0/782]	Time 0.603 (0.603)	Loss 3.3467 (3.3467)	Acc@1 48.438 (48.438)	Acc@5 78.125 (78.125)
2023-03-18 01:57:05,518 - INFO - Test: [200/782]	Time 0.571 (0.602)	Loss 3.5268 (3.8278)	Acc@1 50.000 (41.927)	Acc@5 74.219 (68.474)
2023-03-18 01:59:04,845 - INFO - Test: [400/782]	Time 0.607 (0.599)	Loss 3.6238 (3.7837)	Acc@1 45.312 (42.809)	Acc@5 75.000 (69.457)
2023-03-18 02:01:05,896 - INFO - Test: [600/782]	Time 0.592 (0.601)	Loss 3.9769 (3.7534)	Acc@1 40.625 (43.577)	Acc@5 62.500 (70.162)
2023-03-18 02:02:52,669 - INFO -  * Acc@1 44.034 Acc@5 70.702
2023-03-18 02:02:52,670 - INFO - Max accuracy: 44.0340%
2023-03-18 02:02:53,687 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/fold1_best.pth saved !!!
2023-03-18 02:02:53,687 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-18 02:02:56,472 - INFO - Train: [5/90][0/3907]	eta 3:00:38 lr 0.03980536	time 2.7741 (2.7741)	loss 3.5938 (3.5938)	acc@1: 42.1609	acc@5: 74.1712	
2023-03-18 02:03:50,486 - INFO - Train: [5/90][300/3907]	eta 0:11:20 lr 0.03980536	time 0.1797 (0.1887)	loss 4.6117 (4.8182)	acc@1: 41.4278	acc@5: 61.7906	
2023-03-18 02:04:44,727 - INFO - Train: [5/90][600/3907]	eta 0:10:10 lr 0.03980536	time 0.1801 (0.1847)	loss 5.4300 (4.8778)	acc@1: 32.0583	acc@5: 49.8116	
2023-03-18 02:05:39,007 - INFO - Train: [5/90][900/3907]	eta 0:09:11 lr 0.03980536	time 0.1790 (0.1835)	loss 3.6975 (4.8688)	acc@1: 44.5635	acc@5: 70.6792	
2023-03-18 02:06:33,300 - INFO - Train: [5/90][1200/3907]	eta 0:08:14 lr 0.03980536	time 0.1794 (0.1828)	loss 3.6494 (4.8979)	acc@1: 49.1000	acc@5: 70.9223	
2023-03-18 02:07:27,805 - INFO - Train: [5/90][1500/3907]	eta 0:07:19 lr 0.03980536	time 0.1796 (0.1826)	loss 6.8973 (4.9007)	acc@1: 10.7528	acc@5: 21.3789	
2023-03-18 02:08:22,149 - INFO - Train: [5/90][1800/3907]	eta 0:06:24 lr 0.03980536	time 0.1796 (0.1824)	loss 4.9985 (4.8978)	acc@1: 35.9458	acc@5: 55.2411	
2023-03-18 02:09:16,562 - INFO - Train: [5/90][2100/3907]	eta 0:05:29 lr 0.03980536	time 0.1846 (0.1822)	loss 6.6159 (4.9049)	acc@1: 13.9852	acc@5: 24.8283	
2023-03-18 02:10:11,039 - INFO - Train: [5/90][2400/3907]	eta 0:04:34 lr 0.03980536	time 0.2004 (0.1821)	loss 4.0247 (4.9169)	acc@1: 36.7416	acc@5: 65.0633	
2023-03-18 02:11:05,772 - INFO - Train: [5/90][2700/3907]	eta 0:03:39 lr 0.03980536	time 0.1907 (0.1822)	loss 3.8680 (4.9143)	acc@1: 41.4513	acc@5: 72.1559	
2023-03-18 02:12:00,452 - INFO - Train: [5/90][3000/3907]	eta 0:02:45 lr 0.03980536	time 0.1851 (0.1822)	loss 4.0839 (4.9125)	acc@1: 43.2492	acc@5: 68.1442	
2023-03-18 02:12:54,839 - INFO - Train: [5/90][3300/3907]	eta 0:01:50 lr 0.03980536	time 0.1803 (0.1821)	loss 3.6438 (4.9266)	acc@1: 39.8395	acc@5: 74.2106	
2023-03-18 02:13:49,114 - INFO - Train: [5/90][3600/3907]	eta 0:00:55 lr 0.03980536	time 0.1818 (0.1820)	loss 4.1866 (4.9206)	acc@1: 38.8625	acc@5: 65.8012	
2023-03-18 02:14:43,876 - INFO - Train: [5/90][3900/3907]	eta 0:00:01 lr 0.03980536	time 0.1809 (0.1820)	loss 4.1938 (4.9205)	acc@1: 48.7668	acc@5: 67.9780	
2023-03-18 02:14:45,120 - INFO - EPOCH 5 training takes 0:11:51
2023-03-18 02:14:46,211 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/fold1_latest.pth saved !!!
2023-03-18 02:14:46,211 - INFO - **********Latest test***********
2023-03-18 02:14:46,211 - INFO - eval epoch 5
2023-03-18 02:14:46,876 - INFO - Test: [0/782]	Time 0.664 (0.664)	Loss 3.1495 (3.1495)	Acc@1 55.469 (55.469)	Acc@5 82.031 (82.031)
2023-03-18 02:16:47,033 - INFO - Test: [200/782]	Time 0.604 (0.601)	Loss 3.4418 (3.5746)	Acc@1 46.094 (46.786)	Acc@5 76.562 (72.711)
2023-03-18 02:18:46,857 - INFO - Test: [400/782]	Time 0.595 (0.600)	Loss 3.3179 (3.5390)	Acc@1 55.469 (47.539)	Acc@5 75.000 (73.278)
2023-03-18 02:20:47,265 - INFO - Test: [600/782]	Time 0.591 (0.601)	Loss 3.5841 (3.5066)	Acc@1 46.094 (48.122)	Acc@5 71.094 (73.965)
2023-03-18 02:22:33,914 - INFO -  * Acc@1 48.481 Acc@5 74.540
2023-03-18 02:22:33,914 - INFO - Max accuracy: 48.4810%
2023-03-18 02:22:34,958 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/fold1_best.pth saved !!!
2023-03-18 02:22:34,959 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-18 02:22:37,923 - INFO - Train: [6/90][0/3907]	eta 3:12:26 lr 0.03969616	time 2.9554 (2.9554)	loss 4.1027 (4.1027)	acc@1: 46.0341	acc@5: 66.1740	
2023-03-18 02:23:32,140 - INFO - Train: [6/90][300/3907]	eta 0:11:25 lr 0.03969616	time 0.1779 (0.1899)	loss 3.5309 (4.7499)	acc@1: 47.9963	acc@5: 75.0869	
2023-03-18 02:24:26,258 - INFO - Train: [6/90][600/3907]	eta 0:10:12 lr 0.03969616	time 0.1819 (0.1852)	loss 4.8127 (4.7909)	acc@1: 37.6914	acc@5: 59.5127	
2023-03-18 02:25:20,530 - INFO - Train: [6/90][900/3907]	eta 0:09:12 lr 0.03969616	time 0.1785 (0.1837)	loss 6.7823 (4.8015)	acc@1: 12.5916	acc@5: 22.9312	
2023-03-18 02:26:14,843 - INFO - Train: [6/90][1200/3907]	eta 0:08:15 lr 0.03969616	time 0.1790 (0.1831)	loss 4.5256 (4.7936)	acc@1: 40.6699	acc@5: 66.8641	
2023-03-18 02:27:08,921 - INFO - Train: [6/90][1500/3907]	eta 0:07:19 lr 0.03969616	time 0.1786 (0.1825)	loss 3.6612 (4.7863)	acc@1: 42.7721	acc@5: 72.3237	
2023-03-18 02:28:03,093 - INFO - Train: [6/90][1800/3907]	eta 0:06:23 lr 0.03969616	time 0.1798 (0.1822)	loss 4.5339 (4.7981)	acc@1: 48.0371	acc@5: 65.0869	
2023-03-18 02:28:57,589 - INFO - Train: [6/90][2100/3907]	eta 0:05:29 lr 0.03969616	time 0.1785 (0.1821)	loss 4.4010 (4.8035)	acc@1: 40.7028	acc@5: 62.8394	
2023-03-18 02:29:51,684 - INFO - Train: [6/90][2400/3907]	eta 0:04:34 lr 0.03969616	time 0.1904 (0.1819)	loss 5.0734 (4.8169)	acc@1: 34.9229	acc@5: 57.3263	
2023-03-18 02:30:45,930 - INFO - Train: [6/90][2700/3907]	eta 0:03:39 lr 0.03969616	time 0.1788 (0.1818)	loss 4.5212 (4.8096)	acc@1: 41.3669	acc@5: 63.1822	
2023-03-18 02:31:40,115 - INFO - Train: [6/90][3000/3907]	eta 0:02:44 lr 0.03969616	time 0.1797 (0.1817)	loss 5.2118 (4.8114)	acc@1: 37.9758	acc@5: 54.8747	
2023-03-18 02:32:34,218 - INFO - Train: [6/90][3300/3907]	eta 0:01:50 lr 0.03969616	time 0.1786 (0.1815)	loss 4.9944 (4.8107)	acc@1: 35.1120	acc@5: 58.3403	
2023-03-18 02:33:28,341 - INFO - Train: [6/90][3600/3907]	eta 0:00:55 lr 0.03969616	time 0.1818 (0.1814)	loss 6.5990 (4.8088)	acc@1: 12.4381	acc@5: 23.2098	
2023-03-18 02:34:22,528 - INFO - Train: [6/90][3900/3907]	eta 0:00:01 lr 0.03969616	time 0.1780 (0.1814)	loss 6.1902 (4.8163)	acc@1: 22.8579	acc@5: 32.0546	
2023-03-18 02:34:23,815 - INFO - EPOCH 6 training takes 0:11:48
2023-03-18 02:34:24,787 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/fold1_latest.pth saved !!!
2023-03-18 02:34:24,788 - INFO - **********Latest test***********
2023-03-18 02:34:24,788 - INFO - eval epoch 6
2023-03-18 02:34:25,430 - INFO - Test: [0/782]	Time 0.641 (0.641)	Loss 3.1197 (3.1197)	Acc@1 56.250 (56.250)	Acc@5 83.594 (83.594)
2023-03-18 02:36:23,667 - INFO - Test: [200/782]	Time 0.602 (0.591)	Loss 3.3382 (3.5470)	Acc@1 50.781 (47.921)	Acc@5 76.562 (73.449)
2023-03-18 02:38:23,110 - INFO - Test: [400/782]	Time 0.598 (0.594)	Loss 3.2779 (3.5084)	Acc@1 57.812 (48.545)	Acc@5 78.125 (74.380)
2023-03-18 02:40:23,218 - INFO - Test: [600/782]	Time 0.582 (0.596)	Loss 3.5508 (3.4748)	Acc@1 48.438 (49.262)	Acc@5 74.219 (75.009)
2023-03-18 02:42:09,184 - INFO -  * Acc@1 49.818 Acc@5 75.580
2023-03-18 02:42:09,184 - INFO - Max accuracy: 49.8180%
2023-03-18 02:42:10,248 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/fold1_best.pth saved !!!
2023-03-18 02:42:10,248 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-18 02:42:12,926 - INFO - Train: [7/90][0/3907]	eta 2:54:07 lr 0.03956295	time 2.6740 (2.6740)	loss 5.8070 (5.8070)	acc@1: 29.8028	acc@5: 45.7904	
2023-03-18 02:43:06,899 - INFO - Train: [7/90][300/3907]	eta 0:11:18 lr 0.03956295	time 0.1788 (0.1882)	loss 3.3083 (4.4915)	acc@1: 61.9527	acc@5: 78.2153	
2023-03-18 02:44:00,993 - INFO - Train: [7/90][600/3907]	eta 0:10:09 lr 0.03956295	time 0.1790 (0.1843)	loss 6.3591 (4.5942)	acc@1: 17.8753	acc@5: 33.7938	
2023-03-18 02:44:55,094 - INFO - Train: [7/90][900/3907]	eta 0:09:10 lr 0.03956295	time 0.1786 (0.1829)	loss 3.3982 (4.6167)	acc@1: 46.8075	acc@5: 77.2340	
2023-03-18 02:45:49,188 - INFO - Train: [7/90][1200/3907]	eta 0:08:13 lr 0.03956295	time 0.1796 (0.1823)	loss 3.4662 (4.6605)	acc@1: 50.7752	acc@5: 74.2099	
2023-03-18 02:46:43,408 - INFO - Train: [7/90][1500/3907]	eta 0:07:18 lr 0.03956295	time 0.1793 (0.1820)	loss 4.2613 (4.6848)	acc@1: 46.7335	acc@5: 66.2284	
2023-03-18 02:47:37,707 - INFO - Train: [7/90][1800/3907]	eta 0:06:23 lr 0.03956295	time 0.1793 (0.1818)	loss 5.8023 (4.7061)	acc@1: 29.9110	acc@5: 42.6869	
2023-03-18 02:48:31,974 - INFO - Train: [7/90][2100/3907]	eta 0:05:28 lr 0.03956295	time 0.1790 (0.1817)	loss 5.7544 (4.7319)	acc@1: 29.9129	acc@5: 44.3257	
2023-03-18 02:49:26,183 - INFO - Train: [7/90][2400/3907]	eta 0:04:33 lr 0.03956295	time 0.1813 (0.1816)	loss 3.8293 (4.7274)	acc@1: 38.9884	acc@5: 69.3970	
2023-03-18 02:50:20,410 - INFO - Train: [7/90][2700/3907]	eta 0:03:39 lr 0.03956295	time 0.1785 (0.1815)	loss 3.8317 (4.7278)	acc@1: 48.6428	acc@5: 68.4040	
2023-03-18 02:51:14,746 - INFO - Train: [7/90][3000/3907]	eta 0:02:44 lr 0.03956295	time 0.1787 (0.1814)	loss 3.7415 (4.7313)	acc@1: 51.5179	acc@5: 71.3891	
2023-03-18 02:52:08,892 - INFO - Train: [7/90][3300/3907]	eta 0:01:50 lr 0.03956295	time 0.1783 (0.1813)	loss 3.4035 (4.7258)	acc@1: 52.2691	acc@5: 78.0130	
2023-03-18 02:53:03,258 - INFO - Train: [7/90][3600/3907]	eta 0:00:55 lr 0.03956295	time 0.1788 (0.1813)	loss 3.3839 (4.7293)	acc@1: 52.5341	acc@5: 78.8012	
2023-03-18 02:53:57,466 - INFO - Train: [7/90][3900/3907]	eta 0:00:01 lr 0.03956295	time 0.1785 (0.1813)	loss 4.6887 (4.7291)	acc@1: 41.2329	acc@5: 61.7521	
2023-03-18 02:53:58,760 - INFO - EPOCH 7 training takes 0:11:48
2023-03-18 02:53:59,827 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/fold1_latest.pth saved !!!
2023-03-18 02:53:59,827 - INFO - **********Latest test***********
2023-03-18 02:53:59,827 - INFO - eval epoch 7
2023-03-18 02:54:00,450 - INFO - Test: [0/782]	Time 0.620 (0.620)	Loss 3.0167 (3.0167)	Acc@1 54.688 (54.688)	Acc@5 89.844 (89.844)
2023-03-18 02:55:59,583 - INFO - Test: [200/782]	Time 0.621 (0.596)	Loss 3.0889 (3.4356)	Acc@1 58.594 (50.148)	Acc@5 79.688 (75.556)
2023-03-18 02:57:59,156 - INFO - Test: [400/782]	Time 0.596 (0.597)	Loss 3.1892 (3.4031)	Acc@1 50.781 (50.772)	Acc@5 78.906 (76.103)
2023-03-18 02:59:59,722 - INFO - Test: [600/782]	Time 0.611 (0.599)	Loss 3.3955 (3.3700)	Acc@1 52.344 (51.581)	Acc@5 75.781 (76.785)
2023-03-18 03:01:45,727 - INFO -  * Acc@1 52.058 Acc@5 77.461
2023-03-18 03:01:45,727 - INFO - Max accuracy: 52.0580%
2023-03-18 03:01:46,650 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/fold1_best.pth saved !!!
2023-03-18 03:01:46,650 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-18 03:01:49,170 - INFO - Train: [8/90][0/3907]	eta 2:43:45 lr 0.03940591	time 2.5147 (2.5147)	loss 4.9549 (4.9549)	acc@1: 40.7068	acc@5: 56.1171	
2023-03-18 03:02:43,116 - INFO - Train: [8/90][300/3907]	eta 0:11:16 lr 0.03940591	time 0.1782 (0.1876)	loss 6.0901 (4.6043)	acc@1: 24.5537	acc@5: 39.3571	
2023-03-18 03:03:37,310 - INFO - Train: [8/90][600/3907]	eta 0:10:08 lr 0.03940591	time 0.1794 (0.1841)	loss 3.1122 (4.6086)	acc@1: 60.3295	acc@5: 85.8536	
2023-03-18 03:04:31,510 - INFO - Train: [8/90][900/3907]	eta 0:09:10 lr 0.03940591	time 0.1852 (0.1830)	loss 3.9447 (4.5960)	acc@1: 46.5981	acc@5: 73.5377	
2023-03-18 03:05:25,867 - INFO - Train: [8/90][1200/3907]	eta 0:08:14 lr 0.03940591	time 0.1792 (0.1825)	loss 5.8494 (4.6167)	acc@1: 23.9955	acc@5: 40.4735	
2023-03-18 03:06:20,148 - INFO - Train: [8/90][1500/3907]	eta 0:07:18 lr 0.03940591	time 0.1906 (0.1822)	loss 3.6731 (4.6235)	acc@1: 49.4590	acc@5: 76.4191	
2023-03-18 03:07:14,433 - INFO - Train: [8/90][1800/3907]	eta 0:06:23 lr 0.03940591	time 0.1815 (0.1820)	loss 6.6286 (4.6326)	acc@1: 14.4069	acc@5: 23.5300	
2023-03-18 03:08:08,642 - INFO - Train: [8/90][2100/3907]	eta 0:05:28 lr 0.03940591	time 0.1792 (0.1818)	loss 3.9158 (4.6385)	acc@1: 44.8300	acc@5: 73.2224	
2023-03-18 03:09:03,092 - INFO - Train: [8/90][2400/3907]	eta 0:04:33 lr 0.03940591	time 0.1818 (0.1818)	loss 3.2782 (4.6317)	acc@1: 55.1566	acc@5: 76.9129	
2023-03-18 03:09:57,443 - INFO - Train: [8/90][2700/3907]	eta 0:03:39 lr 0.03940591	time 0.1848 (0.1817)	loss 4.8342 (4.6346)	acc@1: 40.4334	acc@5: 62.5346	
2023-03-18 03:10:51,714 - INFO - Train: [8/90][3000/3907]	eta 0:02:44 lr 0.03940591	time 0.1795 (0.1816)	loss 4.3148 (4.6379)	acc@1: 45.3374	acc@5: 63.0184	
2023-03-18 03:11:45,982 - INFO - Train: [8/90][3300/3907]	eta 0:01:50 lr 0.03940591	time 0.1786 (0.1816)	loss 6.1882 (4.6546)	acc@1: 21.7119	acc@5: 36.6124	
2023-03-18 03:12:40,219 - INFO - Train: [8/90][3600/3907]	eta 0:00:55 lr 0.03940591	time 0.1796 (0.1815)	loss 6.5469 (4.6635)	acc@1: 13.3506	acc@5: 27.9599	
2023-03-18 03:13:34,646 - INFO - Train: [8/90][3900/3907]	eta 0:00:01 lr 0.03940591	time 0.1781 (0.1815)	loss 3.5476 (4.6612)	acc@1: 52.8041	acc@5: 72.9939	
2023-03-18 03:13:35,915 - INFO - EPOCH 8 training takes 0:11:49
2023-03-18 03:13:36,983 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/fold1_latest.pth saved !!!
2023-03-18 03:13:36,984 - INFO - **********Latest test***********
2023-03-18 03:13:36,984 - INFO - eval epoch 8
2023-03-18 03:13:37,574 - INFO - Test: [0/782]	Time 0.589 (0.589)	Loss 2.9324 (2.9324)	Acc@1 52.344 (52.344)	Acc@5 87.500 (87.500)
2023-03-18 03:15:36,426 - INFO - Test: [200/782]	Time 0.581 (0.594)	Loss 3.1976 (3.4273)	Acc@1 53.906 (50.241)	Acc@5 78.125 (75.152)
2023-03-18 03:17:35,110 - INFO - Test: [400/782]	Time 0.603 (0.594)	Loss 3.2474 (3.3916)	Acc@1 50.000 (50.898)	Acc@5 78.906 (75.978)
2023-03-18 03:19:34,272 - INFO - Test: [600/782]	Time 0.613 (0.594)	Loss 3.5252 (3.3619)	Acc@1 53.906 (51.612)	Acc@5 75.781 (76.465)
2023-03-18 03:21:19,322 - INFO -  * Acc@1 52.131 Acc@5 77.063
2023-03-18 03:21:19,322 - INFO - Max accuracy: 52.1310%
2023-03-18 03:21:20,375 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/fold1_best.pth saved !!!
2023-03-18 03:21:20,375 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-18 03:21:23,232 - INFO - Train: [9/90][0/3907]	eta 3:05:16 lr 0.03922523	time 2.8454 (2.8454)	loss 4.6469 (4.6469)	acc@1: 45.5562	acc@5: 63.2850	
2023-03-18 03:22:18,030 - INFO - Train: [9/90][300/3907]	eta 0:11:30 lr 0.03922523	time 0.1803 (0.1915)	loss 6.6196 (4.4535)	acc@1: 11.4116	acc@5: 24.8932	
2023-03-18 03:23:12,719 - INFO - Train: [9/90][600/3907]	eta 0:10:18 lr 0.03922523	time 0.1861 (0.1869)	loss 5.0281 (4.4859)	acc@1: 36.9649	acc@5: 54.5903	
2023-03-18 03:24:08,001 - INFO - Train: [9/90][900/3907]	eta 0:09:19 lr 0.03922523	time 0.1847 (0.1860)	loss 6.0612 (4.4954)	acc@1: 23.8173	acc@5: 35.7259	
2023-03-18 03:25:03,291 - INFO - Train: [9/90][1200/3907]	eta 0:08:22 lr 0.03922523	time 0.1908 (0.1856)	loss 3.4146 (4.5300)	acc@1: 56.6054	acc@5: 75.2194	
2023-03-18 03:25:58,401 - INFO - Train: [9/90][1500/3907]	eta 0:07:25 lr 0.03922523	time 0.1821 (0.1852)	loss 4.0734 (4.5424)	acc@1: 46.4100	acc@5: 66.3258	
2023-03-18 03:26:53,611 - INFO - Train: [9/90][1800/3907]	eta 0:06:29 lr 0.03922523	time 0.1798 (0.1850)	loss 3.9124 (4.5568)	acc@1: 45.9228	acc@5: 72.8933	
2023-03-18 03:27:48,585 - INFO - Train: [9/90][2100/3907]	eta 0:05:33 lr 0.03922523	time 0.1828 (0.1848)	loss 4.4161 (4.5556)	acc@1: 44.6090	acc@5: 68.7242	
2023-03-18 03:28:43,516 - INFO - Train: [9/90][2400/3907]	eta 0:04:38 lr 0.03922523	time 0.1810 (0.1846)	loss 5.3450 (4.5649)	acc@1: 38.2551	acc@5: 53.6098	
2023-03-18 03:29:38,339 - INFO - Train: [9/90][2700/3907]	eta 0:03:42 lr 0.03922523	time 0.1813 (0.1844)	loss 4.7032 (4.5759)	acc@1: 42.0731	acc@5: 64.0094	
2023-03-18 03:30:33,448 - INFO - Train: [9/90][3000/3907]	eta 0:02:47 lr 0.03922523	time 0.1798 (0.1843)	loss 4.0667 (4.5804)	acc@1: 46.6472	acc@5: 75.1397	
2023-03-18 03:31:28,292 - INFO - Train: [9/90][3300/3907]	eta 0:01:51 lr 0.03922523	time 0.1848 (0.1842)	loss 4.2381 (4.5914)	acc@1: 46.2587	acc@5: 68.6489	
2023-03-18 03:32:23,403 - INFO - Train: [9/90][3600/3907]	eta 0:00:56 lr 0.03922523	time 0.1815 (0.1841)	loss 4.1623 (4.5927)	acc@1: 47.6110	acc@5: 69.9453	
2023-03-18 03:33:18,440 - INFO - Train: [9/90][3900/3907]	eta 0:00:01 lr 0.03922523	time 0.1863 (0.1841)	loss 3.5349 (4.5980)	acc@1: 48.9042	acc@5: 71.4133	
2023-03-18 03:33:19,628 - INFO - EPOCH 9 training takes 0:11:59
2023-03-18 03:33:20,730 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/fold1_latest.pth saved !!!
2023-03-18 03:33:20,730 - INFO - **********Latest test***********
2023-03-18 03:33:20,730 - INFO - eval epoch 9
2023-03-18 03:33:21,352 - INFO - Test: [0/782]	Time 0.621 (0.621)	Loss 2.9512 (2.9512)	Acc@1 56.250 (56.250)	Acc@5 85.156 (85.156)
2023-03-18 03:35:20,134 - INFO - Test: [200/782]	Time 0.589 (0.594)	Loss 3.1517 (3.3899)	Acc@1 54.688 (50.529)	Acc@5 75.781 (76.170)
2023-03-18 03:37:19,812 - INFO - Test: [400/782]	Time 0.610 (0.596)	Loss 3.1171 (3.3527)	Acc@1 55.469 (51.471)	Acc@5 79.688 (76.929)
2023-03-18 03:39:20,915 - INFO - Test: [600/782]	Time 0.590 (0.599)	Loss 3.4232 (3.3183)	Acc@1 51.562 (52.348)	Acc@5 74.219 (77.522)
2023-03-18 03:41:07,283 - INFO -  * Acc@1 52.982 Acc@5 78.044
2023-03-18 03:41:07,283 - INFO - Max accuracy: 52.9820%
2023-03-18 03:41:08,311 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/fold1_best.pth saved !!!
2023-03-18 03:41:08,312 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-18 03:41:11,163 - INFO - Train: [10/90][0/3907]	eta 3:05:22 lr 0.03902113	time 2.8468 (2.8468)	loss 5.6120 (5.6120)	acc@1: 32.5847	acc@5: 48.8009	
2023-03-18 03:42:06,239 - INFO - Train: [10/90][300/3907]	eta 0:11:34 lr 0.03902113	time 0.1881 (0.1924)	loss 4.6300 (4.4703)	acc@1: 46.0423	acc@5: 65.2265	
2023-03-18 03:43:01,268 - INFO - Train: [10/90][600/3907]	eta 0:10:21 lr 0.03902113	time 0.1812 (0.1879)	loss 6.5666 (4.4606)	acc@1: 14.6004	acc@5: 27.8065	
2023-03-18 03:43:55,989 - INFO - Train: [10/90][900/3907]	eta 0:09:19 lr 0.03902113	time 0.1832 (0.1861)	loss 5.1639 (4.4784)	acc@1: 33.5957	acc@5: 53.3934	
2023-03-18 03:44:51,292 - INFO - Train: [10/90][1200/3907]	eta 0:08:22 lr 0.03902113	time 0.1820 (0.1857)	loss 6.4525 (4.4904)	acc@1: 15.0287	acc@5: 31.4610	
2023-03-18 03:45:46,187 - INFO - Train: [10/90][1500/3907]	eta 0:07:25 lr 0.03902113	time 0.1809 (0.1851)	loss 6.7460 (4.5076)	acc@1: 12.1884	acc@5: 27.8811	
2023-03-18 03:46:41,114 - INFO - Train: [10/90][1800/3907]	eta 0:06:29 lr 0.03902113	time 0.1861 (0.1848)	loss 6.1143 (4.5147)	acc@1: 25.9376	acc@5: 41.5444	
2023-03-18 03:47:36,121 - INFO - Train: [10/90][2100/3907]	eta 0:05:33 lr 0.03902113	time 0.1812 (0.1846)	loss 3.3303 (4.5162)	acc@1: 53.6069	acc@5: 78.4725	
2023-03-18 03:48:31,119 - INFO - Train: [10/90][2400/3907]	eta 0:04:37 lr 0.03902113	time 0.1852 (0.1844)	loss 3.3564 (4.5219)	acc@1: 51.5619	acc@5: 76.5616	
2023-03-18 03:49:25,942 - INFO - Train: [10/90][2700/3907]	eta 0:03:42 lr 0.03902113	time 0.1866 (0.1842)	loss 5.8233 (4.5333)	acc@1: 29.6550	acc@5: 44.3179	
2023-03-18 03:50:20,918 - INFO - Train: [10/90][3000/3907]	eta 0:02:47 lr 0.03902113	time 0.1808 (0.1841)	loss 6.0764 (4.5465)	acc@1: 27.1762	acc@5: 39.7654	
2023-03-18 03:51:15,849 - INFO - Train: [10/90][3300/3907]	eta 0:01:51 lr 0.03902113	time 0.1835 (0.1840)	loss 5.7559 (4.5507)	acc@1: 29.6446	acc@5: 46.8064	
2023-03-18 03:52:10,824 - INFO - Train: [10/90][3600/3907]	eta 0:00:56 lr 0.03902113	time 0.1890 (0.1840)	loss 4.4104 (4.5625)	acc@1: 46.3733	acc@5: 65.7153	
2023-03-18 03:53:05,423 - INFO - Train: [10/90][3900/3907]	eta 0:00:01 lr 0.03902113	time 0.1793 (0.1838)	loss 5.9016 (4.5672)	acc@1: 27.5879	acc@5: 48.5213	
2023-03-18 03:53:06,726 - INFO - EPOCH 10 training takes 0:11:58
2023-03-18 03:53:07,815 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/fold1_latest.pth saved !!!
2023-03-18 03:53:07,816 - INFO - **********Latest test***********
2023-03-18 03:53:07,816 - INFO - eval epoch 10
2023-03-18 03:53:08,437 - INFO - Test: [0/782]	Time 0.620 (0.620)	Loss 2.9710 (2.9710)	Acc@1 60.156 (60.156)	Acc@5 85.156 (85.156)
2023-03-18 03:55:09,115 - INFO - Test: [200/782]	Time 0.592 (0.603)	Loss 3.3482 (3.4591)	Acc@1 48.438 (49.786)	Acc@5 75.000 (75.358)
2023-03-18 03:57:09,241 - INFO - Test: [400/782]	Time 0.578 (0.602)	Loss 3.2201 (3.4211)	Acc@1 53.906 (50.711)	Acc@5 76.562 (76.015)
2023-03-18 03:59:06,927 - INFO - Test: [600/782]	Time 0.583 (0.598)	Loss 3.5522 (3.3890)	Acc@1 47.656 (51.478)	Acc@5 71.094 (76.568)
2023-03-18 04:00:51,274 - INFO -  * Acc@1 51.981 Acc@5 77.105
2023-03-18 04:00:51,274 - INFO - Max accuracy: 52.9820%
2023-03-18 04:00:51,274 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-18 04:00:54,031 - INFO - Train: [11/90][0/3907]	eta 2:59:16 lr 0.03879385	time 2.7532 (2.7532)	loss 6.4868 (6.4868)	acc@1: 12.0856	acc@5: 28.3288	
2023-03-18 04:01:48,761 - INFO - Train: [11/90][300/3907]	eta 0:11:28 lr 0.03879385	time 0.1840 (0.1910)	loss 3.0753 (4.4402)	acc@1: 60.9296	acc@5: 82.0206	
2023-03-18 04:02:43,648 - INFO - Train: [11/90][600/3907]	eta 0:10:18 lr 0.03879385	time 0.1854 (0.1870)	loss 6.1614 (4.5575)	acc@1: 21.9523	acc@5: 36.3504	
2023-03-18 04:03:38,644 - INFO - Train: [11/90][900/3907]	eta 0:09:18 lr 0.03879385	time 0.1813 (0.1858)	loss 3.4335 (4.5320)	acc@1: 60.0014	acc@5: 81.2895	
2023-03-18 04:04:33,466 - INFO - Train: [11/90][1200/3907]	eta 0:08:20 lr 0.03879385	time 0.1830 (0.1850)	loss 4.5718 (4.5433)	acc@1: 46.1921	acc@5: 70.6956	
2023-03-18 04:05:28,346 - INFO - Train: [11/90][1500/3907]	eta 0:07:24 lr 0.03879385	time 0.1816 (0.1846)	loss 3.8811 (4.5571)	acc@1: 46.9746	acc@5: 69.0194	
2023-03-18 04:06:23,182 - INFO - Train: [11/90][1800/3907]	eta 0:06:28 lr 0.03879385	time 0.1850 (0.1843)	loss 5.0680 (4.5569)	acc@1: 38.2435	acc@5: 57.7558	
2023-03-18 04:07:18,021 - INFO - Train: [11/90][2100/3907]	eta 0:05:32 lr 0.03879385	time 0.1806 (0.1841)	loss 3.2763 (4.5441)	acc@1: 56.6501	acc@5: 78.0852	
2023-03-18 04:08:12,880 - INFO - Train: [11/90][2400/3907]	eta 0:04:37 lr 0.03879385	time 0.1883 (0.1839)	loss 3.4315 (4.5432)	acc@1: 49.2108	acc@5: 76.5500	
2023-03-18 04:09:07,737 - INFO - Train: [11/90][2700/3907]	eta 0:03:41 lr 0.03879385	time 0.1805 (0.1838)	loss 3.1927 (4.5417)	acc@1: 58.5718	acc@5: 76.2943	
2023-03-18 04:10:02,743 - INFO - Train: [11/90][3000/3907]	eta 0:02:46 lr 0.03879385	time 0.1833 (0.1838)	loss 4.3385 (4.5413)	acc@1: 43.9766	acc@5: 70.0878	
2023-03-18 04:10:57,744 - INFO - Train: [11/90][3300/3907]	eta 0:01:51 lr 0.03879385	time 0.1816 (0.1837)	loss 3.5250 (4.5504)	acc@1: 54.4792	acc@5: 75.1913	
2023-03-18 04:11:52,872 - INFO - Train: [11/90][3600/3907]	eta 0:00:56 lr 0.03879385	time 0.1808 (0.1837)	loss 6.0390 (4.5626)	acc@1: 21.4050	acc@5: 41.3844	
2023-03-18 04:12:47,748 - INFO - Train: [11/90][3900/3907]	eta 0:00:01 lr 0.03879385	time 0.1785 (0.1837)	loss 4.9927 (4.5605)	acc@1: 35.6570	acc@5: 53.7746	
2023-03-18 04:12:49,029 - INFO - EPOCH 11 training takes 0:11:57
2023-03-18 04:12:50,110 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/fold1_latest.pth saved !!!
2023-03-18 04:12:50,110 - INFO - **********Latest test***********
2023-03-18 04:12:50,110 - INFO - eval epoch 11
2023-03-18 04:12:50,715 - INFO - Test: [0/782]	Time 0.603 (0.603)	Loss 2.9004 (2.9004)	Acc@1 56.250 (56.250)	Acc@5 88.281 (88.281)
2023-03-18 04:14:47,218 - INFO - Test: [200/782]	Time 0.579 (0.583)	Loss 3.3572 (3.4983)	Acc@1 51.562 (49.732)	Acc@5 73.438 (74.207)
2023-03-18 04:16:44,729 - INFO - Test: [400/782]	Time 0.581 (0.585)	Loss 3.3174 (3.4567)	Acc@1 51.562 (50.546)	Acc@5 77.344 (75.245)
2023-03-18 04:18:43,216 - INFO - Test: [600/782]	Time 0.588 (0.588)	Loss 3.5717 (3.4145)	Acc@1 47.656 (51.405)	Acc@5 77.344 (75.981)
2023-03-18 04:20:28,788 - INFO -  * Acc@1 51.924 Acc@5 76.644
2023-03-18 04:20:28,788 - INFO - Max accuracy: 52.9820%
2023-03-18 04:20:28,788 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-18 04:20:31,511 - INFO - Train: [12/90][0/3907]	eta 2:57:02 lr 0.03854368	time 2.7190 (2.7190)	loss 6.6214 (6.6214)	acc@1: 15.2796	acc@5: 26.2300	
2023-03-18 04:21:26,484 - INFO - Train: [12/90][300/3907]	eta 0:11:31 lr 0.03854368	time 0.1859 (0.1917)	loss 3.4406 (4.3459)	acc@1: 51.6935	acc@5: 74.0640	
2023-03-18 04:22:21,332 - INFO - Train: [12/90][600/3907]	eta 0:10:19 lr 0.03854368	time 0.1806 (0.1872)	loss 3.6042 (4.3501)	acc@1: 49.3588	acc@5: 70.1981	
2023-03-18 04:23:16,251 - INFO - Train: [12/90][900/3907]	eta 0:09:18 lr 0.03854368	time 0.1860 (0.1859)	loss 3.5365 (4.4215)	acc@1: 52.3629	acc@5: 72.3840	
2023-03-18 04:24:11,155 - INFO - Train: [12/90][1200/3907]	eta 0:08:21 lr 0.03854368	time 0.1804 (0.1851)	loss 6.4693 (4.4349)	acc@1: 15.5426	acc@5: 28.0163	
2023-03-18 04:25:06,058 - INFO - Train: [12/90][1500/3907]	eta 0:07:24 lr 0.03854368	time 0.1877 (0.1847)	loss 6.1426 (4.4733)	acc@1: 24.5637	acc@5: 37.4143	
2023-03-18 04:26:00,979 - INFO - Train: [12/90][1800/3907]	eta 0:06:28 lr 0.03854368	time 0.1803 (0.1844)	loss 6.2916 (4.4720)	acc@1: 16.0773	acc@5: 27.5185	
2023-03-18 04:26:55,968 - INFO - Train: [12/90][2100/3907]	eta 0:05:32 lr 0.03854368	time 0.1803 (0.1843)	loss 3.4672 (4.4799)	acc@1: 46.0916	acc@5: 77.3401	
2023-03-18 04:27:50,824 - INFO - Train: [12/90][2400/3907]	eta 0:04:37 lr 0.03854368	time 0.1855 (0.1841)	loss 3.7000 (4.4762)	acc@1: 48.2885	acc@5: 75.7758	
2023-03-18 04:28:45,750 - INFO - Train: [12/90][2700/3907]	eta 0:03:42 lr 0.03854368	time 0.1802 (0.1840)	loss 6.1484 (4.4848)	acc@1: 21.4668	acc@5: 35.0943	
2023-03-18 04:29:40,703 - INFO - Train: [12/90][3000/3907]	eta 0:02:46 lr 0.03854368	time 0.1835 (0.1839)	loss 6.2701 (4.4924)	acc@1: 16.3473	acc@5: 32.1703	
2023-03-18 04:30:35,668 - INFO - Train: [12/90][3300/3907]	eta 0:01:51 lr 0.03854368	time 0.1799 (0.1838)	loss 6.1583 (4.5028)	acc@1: 17.6803	acc@5: 33.0733	
2023-03-18 04:31:30,488 - INFO - Train: [12/90][3600/3907]	eta 0:00:56 lr 0.03854368	time 0.1805 (0.1837)	loss 4.0865 (4.5147)	acc@1: 46.6651	acc@5: 69.9977	
2023-03-18 04:32:25,510 - INFO - Train: [12/90][3900/3907]	eta 0:00:01 lr 0.03854368	time 0.1795 (0.1837)	loss 3.4617 (4.5142)	acc@1: 54.7236	acc@5: 77.0817	
2023-03-18 04:32:26,764 - INFO - EPOCH 12 training takes 0:11:57
2023-03-18 04:32:27,805 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/fold1_latest.pth saved !!!
2023-03-18 04:32:27,805 - INFO - **********Latest test***********
2023-03-18 04:32:27,805 - INFO - eval epoch 12
2023-03-18 04:32:28,426 - INFO - Test: [0/782]	Time 0.620 (0.620)	Loss 2.8674 (2.8674)	Acc@1 62.500 (62.500)	Acc@5 87.500 (87.500)
2023-03-18 04:34:26,646 - INFO - Test: [200/782]	Time 0.585 (0.591)	Loss 3.1357 (3.3966)	Acc@1 56.250 (51.706)	Acc@5 77.344 (76.162)
2023-03-18 04:36:25,024 - INFO - Test: [400/782]	Time 0.584 (0.592)	Loss 3.1097 (3.3535)	Acc@1 59.375 (52.615)	Acc@5 80.469 (77.137)
2023-03-18 04:38:23,637 - INFO - Test: [600/782]	Time 0.586 (0.592)	Loss 3.3414 (3.3168)	Acc@1 47.656 (53.386)	Acc@5 78.906 (77.792)
2023-03-18 04:40:08,607 - INFO -  * Acc@1 53.923 Acc@5 78.431
2023-03-18 04:40:08,608 - INFO - Max accuracy: 53.9230%
2023-03-18 04:40:09,650 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/fold1_best.pth saved !!!
2023-03-18 04:40:09,651 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-18 04:40:12,412 - INFO - Train: [13/90][0/3907]	eta 2:59:27 lr 0.03827091	time 2.7561 (2.7561)	loss 3.1205 (3.1205)	acc@1: 62.2746	acc@5: 77.8460	
2023-03-18 04:41:07,266 - INFO - Train: [13/90][300/3907]	eta 0:11:30 lr 0.03827091	time 0.1799 (0.1914)	loss 5.9093 (4.3301)	acc@1: 24.2109	acc@5: 41.3392	
2023-03-18 04:42:02,236 - INFO - Train: [13/90][600/3907]	eta 0:10:19 lr 0.03827091	time 0.1886 (0.1873)	loss 5.6193 (4.3705)	acc@1: 31.1425	acc@5: 47.1044	
2023-03-18 04:42:57,343 - INFO - Train: [13/90][900/3907]	eta 0:09:19 lr 0.03827091	time 0.1805 (0.1861)	loss 5.9626 (4.4010)	acc@1: 25.5111	acc@5: 40.6104	
2023-03-18 04:43:52,191 - INFO - Train: [13/90][1200/3907]	eta 0:08:21 lr 0.03827091	time 0.1825 (0.1853)	loss 3.0435 (4.3977)	acc@1: 62.4681	acc@5: 83.5508	
2023-03-18 04:44:47,076 - INFO - Train: [13/90][1500/3907]	eta 0:07:24 lr 0.03827091	time 0.1872 (0.1848)	loss 3.6020 (4.4257)	acc@1: 54.8667	acc@5: 75.3315	
2023-03-18 04:45:41,960 - INFO - Train: [13/90][1800/3907]	eta 0:06:28 lr 0.03827091	time 0.1804 (0.1845)	loss 3.8428 (4.4144)	acc@1: 54.4013	acc@5: 74.4439	
2023-03-18 04:46:36,854 - INFO - Train: [13/90][2100/3907]	eta 0:05:33 lr 0.03827091	time 0.1806 (0.1843)	loss 3.2276 (4.4270)	acc@1: 59.3392	acc@5: 75.7355	
2023-03-18 04:47:31,426 - INFO - Train: [13/90][2400/3907]	eta 0:04:37 lr 0.03827091	time 0.1869 (0.1840)	loss 4.2779 (4.4274)	acc@1: 44.1136	acc@5: 68.6211	
2023-03-18 04:48:26,379 - INFO - Train: [13/90][2700/3907]	eta 0:03:41 lr 0.03827091	time 0.1837 (0.1839)	loss 3.6734 (4.4323)	acc@1: 57.9209	acc@5: 74.0232	
2023-03-18 04:49:21,321 - INFO - Train: [13/90][3000/3907]	eta 0:02:46 lr 0.03827091	time 0.1822 (0.1838)	loss 3.5130 (4.4350)	acc@1: 43.5894	acc@5: 73.9491	
2023-03-18 04:50:16,172 - INFO - Train: [13/90][3300/3907]	eta 0:01:51 lr 0.03827091	time 0.1805 (0.1837)	loss 4.5034 (4.4530)	acc@1: 45.2273	acc@5: 66.8285	
2023-03-18 04:51:11,064 - INFO - Train: [13/90][3600/3907]	eta 0:00:56 lr 0.03827091	time 0.1866 (0.1837)	loss 6.5519 (4.4476)	acc@1: 16.1466	acc@5: 30.3962	
2023-03-18 04:52:05,811 - INFO - Train: [13/90][3900/3907]	eta 0:00:01 lr 0.03827091	time 0.1791 (0.1836)	loss 3.2588 (4.4595)	acc@1: 50.5537	acc@5: 80.4263	
2023-03-18 04:52:07,073 - INFO - EPOCH 13 training takes 0:11:57
2023-03-18 04:52:08,158 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/fold1_latest.pth saved !!!
2023-03-18 04:52:08,158 - INFO - **********Latest test***********
2023-03-18 04:52:08,158 - INFO - eval epoch 13
2023-03-18 04:52:08,752 - INFO - Test: [0/782]	Time 0.593 (0.593)	Loss 3.0822 (3.0822)	Acc@1 55.469 (55.469)	Acc@5 84.375 (84.375)
2023-03-18 04:54:06,079 - INFO - Test: [200/782]	Time 0.581 (0.587)	Loss 3.1904 (3.3726)	Acc@1 51.562 (52.406)	Acc@5 80.469 (76.905)
2023-03-18 04:56:03,677 - INFO - Test: [400/782]	Time 0.579 (0.587)	Loss 2.9775 (3.3396)	Acc@1 64.062 (53.304)	Acc@5 83.594 (77.478)
2023-03-18 04:58:02,306 - INFO - Test: [600/782]	Time 0.597 (0.589)	Loss 3.4316 (3.3037)	Acc@1 53.125 (54.171)	Acc@5 72.656 (78.116)
2023-03-18 04:59:47,290 - INFO -  * Acc@1 54.572 Acc@5 78.655
2023-03-18 04:59:47,290 - INFO - Max accuracy: 54.5720%
2023-03-18 04:59:48,295 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/fold1_best.pth saved !!!
2023-03-18 04:59:48,295 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-18 04:59:51,097 - INFO - Train: [14/90][0/3907]	eta 3:02:09 lr 0.03797588	time 2.7974 (2.7974)	loss 2.9688 (2.9688)	acc@1: 63.5971	acc@5: 81.4321	
2023-03-18 05:00:45,788 - INFO - Train: [14/90][300/3907]	eta 0:11:28 lr 0.03797588	time 0.1842 (0.1910)	loss 5.0047 (4.3071)	acc@1: 38.9613	acc@5: 60.5146	
2023-03-18 05:01:40,563 - INFO - Train: [14/90][600/3907]	eta 0:10:17 lr 0.03797588	time 0.1801 (0.1868)	loss 3.3395 (4.3388)	acc@1: 59.0996	acc@5: 78.7995	
2023-03-18 05:02:35,767 - INFO - Train: [14/90][900/3907]	eta 0:09:18 lr 0.03797588	time 0.1804 (0.1859)	loss 6.4509 (4.3666)	acc@1: 12.5000	acc@5: 28.5421	
2023-03-18 05:03:30,758 - INFO - Train: [14/90][1200/3907]	eta 0:08:21 lr 0.03797588	time 0.1870 (0.1852)	loss 3.3091 (4.3777)	acc@1: 53.8888	acc@5: 76.5376	
2023-03-18 05:04:25,753 - INFO - Train: [14/90][1500/3907]	eta 0:07:24 lr 0.03797588	time 0.1804 (0.1848)	loss 3.1350 (4.3660)	acc@1: 59.3580	acc@5: 83.5698	
2023-03-18 05:05:20,754 - INFO - Train: [14/90][1800/3907]	eta 0:06:28 lr 0.03797588	time 0.1862 (0.1846)	loss 4.4006 (4.3973)	acc@1: 47.7680	acc@5: 68.9982	
2023-03-18 05:06:15,685 - INFO - Train: [14/90][2100/3907]	eta 0:05:33 lr 0.03797588	time 0.1820 (0.1844)	loss 4.3918 (4.3950)	acc@1: 44.7868	acc@5: 67.1281	
2023-03-18 05:07:10,534 - INFO - Train: [14/90][2400/3907]	eta 0:04:37 lr 0.03797588	time 0.1870 (0.1842)	loss 3.0321 (4.4161)	acc@1: 62.3305	acc@5: 82.5887	
2023-03-18 05:08:05,492 - INFO - Train: [14/90][2700/3907]	eta 0:03:42 lr 0.03797588	time 0.1812 (0.1841)	loss 5.1680 (4.4378)	acc@1: 36.5569	acc@5: 58.9924	
2023-03-18 05:09:00,430 - INFO - Train: [14/90][3000/3907]	eta 0:02:46 lr 0.03797588	time 0.1877 (0.1840)	loss 3.3239 (4.4440)	acc@1: 53.9477	acc@5: 84.0197	
2023-03-18 05:09:55,200 - INFO - Train: [14/90][3300/3907]	eta 0:01:51 lr 0.03797588	time 0.1814 (0.1838)	loss 3.8108 (4.4403)	acc@1: 54.2365	acc@5: 75.6457	
2023-03-18 05:10:50,233 - INFO - Train: [14/90][3600/3907]	eta 0:00:56 lr 0.03797588	time 0.1880 (0.1838)	loss 6.3725 (4.4505)	acc@1: 17.6547	acc@5: 31.6046	
2023-03-18 05:11:45,159 - INFO - Train: [14/90][3900/3907]	eta 0:00:01 lr 0.03797588	time 0.1873 (0.1838)	loss 4.1445 (4.4654)	acc@1: 49.8621	acc@5: 67.6450	
2023-03-18 05:11:46,416 - INFO - EPOCH 14 training takes 0:11:58
2023-03-18 05:11:47,499 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/fold1_latest.pth saved !!!
2023-03-18 05:11:47,500 - INFO - **********Latest test***********
2023-03-18 05:11:47,500 - INFO - eval epoch 14
2023-03-18 05:11:48,111 - INFO - Test: [0/782]	Time 0.610 (0.610)	Loss 2.9417 (2.9417)	Acc@1 56.250 (56.250)	Acc@5 85.156 (85.156)
2023-03-18 05:13:46,043 - INFO - Test: [200/782]	Time 0.572 (0.590)	Loss 3.1957 (3.3343)	Acc@1 58.594 (52.177)	Acc@5 75.781 (77.103)
2023-03-18 05:15:44,803 - INFO - Test: [400/782]	Time 0.616 (0.592)	Loss 3.1492 (3.2923)	Acc@1 56.250 (53.396)	Acc@5 78.125 (77.969)
2023-03-18 05:17:46,052 - INFO - Test: [600/782]	Time 0.589 (0.597)	Loss 3.3332 (3.2556)	Acc@1 50.000 (54.190)	Acc@5 76.562 (78.677)
2023-03-18 05:19:33,140 - INFO -  * Acc@1 54.887 Acc@5 79.316
2023-03-18 05:19:33,141 - INFO - Max accuracy: 54.8870%
2023-03-18 05:19:34,166 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/fold1_best.pth saved !!!
2023-03-18 05:19:34,167 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-18 05:19:36,920 - INFO - Train: [15/90][0/3907]	eta 2:58:55 lr 0.03765895	time 2.7478 (2.7478)	loss 6.2599 (6.2599)	acc@1: 15.6507	acc@5: 30.8658	
2023-03-18 05:20:31,530 - INFO - Train: [15/90][300/3907]	eta 0:11:27 lr 0.03765895	time 0.1800 (0.1905)	loss 3.1280 (4.4279)	acc@1: 60.6807	acc@5: 78.5728	
2023-03-18 05:21:26,629 - INFO - Train: [15/90][600/3907]	eta 0:10:18 lr 0.03765895	time 0.1857 (0.1871)	loss 3.4147 (4.4022)	acc@1: 55.2907	acc@5: 75.5371	
2023-03-18 05:22:21,570 - INFO - Train: [15/90][900/3907]	eta 0:09:18 lr 0.03765895	time 0.1830 (0.1858)	loss 5.8436 (4.4336)	acc@1: 26.0805	acc@5: 44.2488	
2023-03-18 05:23:16,477 - INFO - Train: [15/90][1200/3907]	eta 0:08:21 lr 0.03765895	time 0.1819 (0.1851)	loss 3.9483 (4.4163)	acc@1: 49.7817	acc@5: 71.5632	
2023-03-18 05:24:11,335 - INFO - Train: [15/90][1500/3907]	eta 0:07:24 lr 0.03765895	time 0.1837 (0.1846)	loss 2.9716 (4.4211)	acc@1: 60.0798	acc@5: 85.0480	
2023-03-18 05:25:06,189 - INFO - Train: [15/90][1800/3907]	eta 0:06:28 lr 0.03765895	time 0.1888 (0.1843)	loss 3.1006 (4.4236)	acc@1: 59.9891	acc@5: 81.8033	
2023-03-18 05:26:01,055 - INFO - Train: [15/90][2100/3907]	eta 0:05:32 lr 0.03765895	time 0.1813 (0.1841)	loss 3.0412 (4.4273)	acc@1: 57.0208	acc@5: 80.4542	
2023-03-18 05:26:55,969 - INFO - Train: [15/90][2400/3907]	eta 0:04:37 lr 0.03765895	time 0.1816 (0.1840)	loss 3.0347 (4.4360)	acc@1: 60.0864	acc@5: 79.5953	
2023-03-18 05:27:50,913 - INFO - Train: [15/90][2700/3907]	eta 0:03:41 lr 0.03765895	time 0.1851 (0.1839)	loss 4.1619 (4.4273)	acc@1: 47.3589	acc@5: 72.0177	
2023-03-18 05:28:46,154 - INFO - Train: [15/90][3000/3907]	eta 0:02:46 lr 0.03765895	time 0.1858 (0.1839)	loss 6.3872 (4.4380)	acc@1: 19.1457	acc@5: 33.4438	
2023-03-18 05:29:41,186 - INFO - Train: [15/90][3300/3907]	eta 0:01:51 lr 0.03765895	time 0.1884 (0.1839)	loss 6.6317 (4.4310)	acc@1: 12.0321	acc@5: 27.0525	
2023-03-18 05:30:36,074 - INFO - Train: [15/90][3600/3907]	eta 0:00:56 lr 0.03765895	time 0.1813 (0.1838)	loss 3.3469 (4.4419)	acc@1: 57.9812	acc@5: 77.0351	
2023-03-18 05:31:30,995 - INFO - Train: [15/90][3900/3907]	eta 0:00:01 lr 0.03765895	time 0.1790 (0.1837)	loss 4.7254 (4.4477)	acc@1: 46.1651	acc@5: 61.8139	
2023-03-18 05:31:32,259 - INFO - EPOCH 15 training takes 0:11:58
2023-03-18 05:31:33,350 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/fold1_latest.pth saved !!!
2023-03-18 05:31:33,350 - INFO - **********Latest test***********
2023-03-18 05:31:33,350 - INFO - eval epoch 15
2023-03-18 05:31:33,937 - INFO - Test: [0/782]	Time 0.585 (0.585)	Loss 2.8833 (2.8833)	Acc@1 62.500 (62.500)	Acc@5 88.281 (88.281)
2023-03-18 05:33:29,816 - INFO - Test: [200/782]	Time 0.572 (0.579)	Loss 3.2798 (3.3068)	Acc@1 50.000 (54.007)	Acc@5 78.125 (78.090)
2023-03-18 05:35:26,762 - INFO - Test: [400/782]	Time 0.589 (0.582)	Loss 3.1298 (3.2725)	Acc@1 59.375 (54.723)	Acc@5 78.906 (78.610)
2023-03-18 05:37:24,305 - INFO - Test: [600/782]	Time 0.572 (0.584)	Loss 3.3925 (3.2381)	Acc@1 50.781 (55.414)	Acc@5 72.656 (79.264)
2023-03-18 05:39:08,887 - INFO -  * Acc@1 55.892 Acc@5 79.757
2023-03-18 05:39:08,888 - INFO - Max accuracy: 55.8920%
2023-03-18 05:39:09,924 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/fold1_best.pth saved !!!
2023-03-18 05:39:09,925 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-18 05:39:12,583 - INFO - Train: [16/90][0/3907]	eta 2:52:51 lr 0.03732051	time 2.6547 (2.6547)	loss 3.9475 (3.9475)	acc@1: 57.7763	acc@5: 72.5528	
2023-03-18 05:40:07,346 - INFO - Train: [16/90][300/3907]	eta 0:11:28 lr 0.03732051	time 0.1796 (0.1907)	loss 3.4613 (4.2862)	acc@1: 56.6738	acc@5: 76.8079	
2023-03-18 05:41:02,572 - INFO - Train: [16/90][600/3907]	eta 0:10:19 lr 0.03732051	time 0.1803 (0.1874)	loss 3.5331 (4.3014)	acc@1: 55.8729	acc@5: 77.4771	
2023-03-18 05:41:57,669 - INFO - Train: [16/90][900/3907]	eta 0:09:19 lr 0.03732051	time 0.1879 (0.1862)	loss 3.5444 (4.3667)	acc@1: 54.6028	acc@5: 76.7213	
2023-03-18 05:42:52,387 - INFO - Train: [16/90][1200/3907]	eta 0:08:21 lr 0.03732051	time 0.1805 (0.1852)	loss 5.5022 (4.3705)	acc@1: 36.5560	acc@5: 51.7995	
2023-03-18 05:43:47,203 - INFO - Train: [16/90][1500/3907]	eta 0:07:24 lr 0.03732051	time 0.1807 (0.1847)	loss 3.5945 (4.3763)	acc@1: 54.0952	acc@5: 77.7903	
2023-03-18 05:44:41,672 - INFO - Train: [16/90][1800/3907]	eta 0:06:28 lr 0.03732051	time 0.1808 (0.1842)	loss 6.4824 (4.3690)	acc@1: 12.2648	acc@5: 23.8175	
2023-03-18 05:45:36,594 - INFO - Train: [16/90][2100/3907]	eta 0:05:32 lr 0.03732051	time 0.1881 (0.1840)	loss 3.5539 (4.3794)	acc@1: 54.3474	acc@5: 75.4824	
2023-03-18 05:46:31,524 - INFO - Train: [16/90][2400/3907]	eta 0:04:37 lr 0.03732051	time 0.1803 (0.1839)	loss 3.4320 (4.3842)	acc@1: 53.8626	acc@5: 75.0952	
2023-03-18 05:47:26,421 - INFO - Train: [16/90][2700/3907]	eta 0:03:41 lr 0.03732051	time 0.1807 (0.1838)	loss 5.7122 (4.3944)	acc@1: 29.9357	acc@5: 44.9849	
2023-03-18 05:48:21,645 - INFO - Train: [16/90][3000/3907]	eta 0:02:46 lr 0.03732051	time 0.1854 (0.1838)	loss 5.8875 (4.3835)	acc@1: 28.8643	acc@5: 44.4439	
2023-03-18 05:49:16,673 - INFO - Train: [16/90][3300/3907]	eta 0:01:51 lr 0.03732051	time 0.1881 (0.1838)	loss 3.4552 (4.3877)	acc@1: 53.9053	acc@5: 74.2175	
2023-03-18 05:50:11,635 - INFO - Train: [16/90][3600/3907]	eta 0:00:56 lr 0.03732051	time 0.1803 (0.1838)	loss 3.9364 (4.3980)	acc@1: 54.2787	acc@5: 73.5619	
2023-03-18 05:51:06,698 - INFO - Train: [16/90][3900/3907]	eta 0:00:01 lr 0.03732051	time 0.1792 (0.1837)	loss 4.8307 (4.4041)	acc@1: 44.7147	acc@5: 62.4781	
2023-03-18 05:51:07,912 - INFO - EPOCH 16 training takes 0:11:57
2023-03-18 05:51:08,977 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/fold1_latest.pth saved !!!
2023-03-18 05:51:08,977 - INFO - **********Latest test***********
2023-03-18 05:51:08,978 - INFO - eval epoch 16
2023-03-18 05:51:09,568 - INFO - Test: [0/782]	Time 0.590 (0.590)	Loss 2.9355 (2.9355)	Acc@1 59.375 (59.375)	Acc@5 88.281 (88.281)
2023-03-18 05:53:05,160 - INFO - Test: [200/782]	Time 0.577 (0.578)	Loss 3.2509 (3.3495)	Acc@1 54.688 (53.211)	Acc@5 76.562 (77.627)
2023-03-18 05:55:03,479 - INFO - Test: [400/782]	Time 0.585 (0.585)	Loss 3.2633 (3.3149)	Acc@1 56.250 (53.887)	Acc@5 75.781 (78.230)
2023-03-18 05:57:01,433 - INFO - Test: [600/782]	Time 0.584 (0.586)	Loss 3.3703 (3.2776)	Acc@1 50.000 (54.738)	Acc@5 77.344 (78.850)
2023-03-18 05:58:46,415 - INFO -  * Acc@1 55.233 Acc@5 79.386
2023-03-18 05:58:46,415 - INFO - Max accuracy: 55.8920%
2023-03-18 05:58:46,415 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-18 05:58:49,125 - INFO - Train: [17/90][0/3907]	eta 2:56:12 lr 0.03696096	time 2.7059 (2.7059)	loss 5.7344 (5.7344)	acc@1: 32.0067	acc@5: 45.3651	
2023-03-18 05:59:43,751 - INFO - Train: [17/90][300/3907]	eta 0:11:27 lr 0.03696096	time 0.1845 (0.1905)	loss 4.2048 (4.2625)	acc@1: 53.2412	acc@5: 69.6231	
2023-03-18 06:00:38,694 - INFO - Train: [17/90][600/3907]	eta 0:10:17 lr 0.03696096	time 0.1807 (0.1868)	loss 4.5366 (4.2876)	acc@1: 46.7994	acc@5: 67.4266	
2023-03-18 06:01:33,514 - INFO - Train: [17/90][900/3907]	eta 0:09:17 lr 0.03696096	time 0.1812 (0.1854)	loss 5.7915 (4.2863)	acc@1: 30.6482	acc@5: 44.0908	
2023-03-18 06:02:28,189 - INFO - Train: [17/90][1200/3907]	eta 0:08:19 lr 0.03696096	time 0.1815 (0.1846)	loss 3.4032 (4.3236)	acc@1: 57.9150	acc@5: 79.4475	
2023-03-18 06:03:22,779 - INFO - Train: [17/90][1500/3907]	eta 0:07:23 lr 0.03696096	time 0.1822 (0.1841)	loss 6.4607 (4.3349)	acc@1: 12.5740	acc@5: 26.2829	
2023-03-18 06:04:17,640 - INFO - Train: [17/90][1800/3907]	eta 0:06:27 lr 0.03696096	time 0.1803 (0.1839)	loss 2.8527 (4.3424)	acc@1: 63.2353	acc@5: 84.3137	
2023-03-18 06:05:12,674 - INFO - Train: [17/90][2100/3907]	eta 0:05:32 lr 0.03696096	time 0.1850 (0.1838)	loss 5.9689 (4.3633)	acc@1: 20.8867	acc@5: 40.3144	
2023-03-18 06:06:07,593 - INFO - Train: [17/90][2400/3907]	eta 0:04:36 lr 0.03696096	time 0.1805 (0.1837)	loss 6.1757 (4.3611)	acc@1: 26.7376	acc@5: 38.3257	
2023-03-18 06:07:02,591 - INFO - Train: [17/90][2700/3907]	eta 0:03:41 lr 0.03696096	time 0.1805 (0.1837)	loss 5.0905 (4.3589)	acc@1: 40.8903	acc@5: 59.1753	
2023-03-18 06:07:57,381 - INFO - Train: [17/90][3000/3907]	eta 0:02:46 lr 0.03696096	time 0.1850 (0.1836)	loss 6.1385 (4.3629)	acc@1: 20.2511	acc@5: 35.2207	
2023-03-18 06:08:52,410 - INFO - Train: [17/90][3300/3907]	eta 0:01:51 lr 0.03696096	time 0.1844 (0.1836)	loss 6.5850 (4.3705)	acc@1: 14.0625	acc@5: 25.7856	
2023-03-18 06:09:47,369 - INFO - Train: [17/90][3600/3907]	eta 0:00:56 lr 0.03696096	time 0.1810 (0.1835)	loss 5.2640 (4.3799)	acc@1: 38.7550	acc@5: 51.6472	
2023-03-18 06:10:42,303 - INFO - Train: [17/90][3900/3907]	eta 0:00:01 lr 0.03696096	time 0.1803 (0.1835)	loss 3.1949 (4.3907)	acc@1: 56.2453	acc@5: 79.6808	
2023-03-18 06:10:43,572 - INFO - EPOCH 17 training takes 0:11:57
2023-03-18 06:10:44,648 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/fold1_latest.pth saved !!!
2023-03-18 06:10:44,648 - INFO - **********Latest test***********
2023-03-18 06:10:44,648 - INFO - eval epoch 17
2023-03-18 06:10:45,239 - INFO - Test: [0/782]	Time 0.589 (0.589)	Loss 2.8801 (2.8801)	Acc@1 57.812 (57.812)	Acc@5 87.500 (87.500)
2023-03-18 06:12:42,527 - INFO - Test: [200/782]	Time 0.590 (0.586)	Loss 3.1457 (3.2725)	Acc@1 53.125 (53.945)	Acc@5 81.250 (77.962)
2023-03-18 06:14:40,226 - INFO - Test: [400/782]	Time 0.621 (0.587)	Loss 3.2346 (3.2346)	Acc@1 56.250 (54.808)	Acc@5 76.562 (78.633)
2023-03-18 06:16:40,383 - INFO - Test: [600/782]	Time 0.595 (0.592)	Loss 3.3231 (3.2017)	Acc@1 52.344 (55.518)	Acc@5 75.781 (79.314)
2023-03-18 06:18:27,213 - INFO -  * Acc@1 56.111 Acc@5 79.868
2023-03-18 06:18:27,214 - INFO - Max accuracy: 56.1110%
2023-03-18 06:18:28,243 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/fold1_best.pth saved !!!
2023-03-18 06:18:28,244 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-18 06:18:30,991 - INFO - Train: [18/90][0/3907]	eta 2:58:19 lr 0.03658075	time 2.7386 (2.7386)	loss 4.9024 (4.9024)	acc@1: 37.1189	acc@5: 60.6276	
2023-03-18 06:19:25,699 - INFO - Train: [18/90][300/3907]	eta 0:11:28 lr 0.03658075	time 0.1802 (0.1908)	loss 3.2332 (4.3410)	acc@1: 58.1785	acc@5: 81.1374	
2023-03-18 06:20:20,640 - INFO - Train: [18/90][600/3907]	eta 0:10:18 lr 0.03658075	time 0.1868 (0.1870)	loss 3.1357 (4.3406)	acc@1: 57.1333	acc@5: 81.8449	
2023-03-18 06:21:15,589 - INFO - Train: [18/90][900/3907]	eta 0:09:18 lr 0.03658075	time 0.1892 (0.1857)	loss 5.3402 (4.3720)	acc@1: 36.2921	acc@5: 54.1407	
2023-03-18 06:22:10,577 - INFO - Train: [18/90][1200/3907]	eta 0:08:21 lr 0.03658075	time 0.1876 (0.1851)	loss 3.3924 (4.3500)	acc@1: 57.5560	acc@5: 74.9594	
2023-03-18 06:23:05,580 - INFO - Train: [18/90][1500/3907]	eta 0:07:24 lr 0.03658075	time 0.1804 (0.1848)	loss 5.5280 (4.3492)	acc@1: 32.4491	acc@5: 47.1111	
2023-03-18 06:24:00,755 - INFO - Train: [18/90][1800/3907]	eta 0:06:28 lr 0.03658075	time 0.1855 (0.1846)	loss 4.8223 (4.3544)	acc@1: 41.8616	acc@5: 61.6031	
2023-03-18 06:24:55,894 - INFO - Train: [18/90][2100/3907]	eta 0:05:33 lr 0.03658075	time 0.1808 (0.1845)	loss 5.1369 (4.3637)	acc@1: 41.4046	acc@5: 58.8363	
2023-03-18 06:25:51,085 - INFO - Train: [18/90][2400/3907]	eta 0:04:37 lr 0.03658075	time 0.1806 (0.1844)	loss 3.5465 (4.3758)	acc@1: 57.9308	acc@5: 76.2480	
2023-03-18 06:26:46,548 - INFO - Train: [18/90][2700/3907]	eta 0:03:42 lr 0.03658075	time 0.1892 (0.1845)	loss 3.5898 (4.3714)	acc@1: 60.8594	acc@5: 76.9908	
2023-03-18 06:27:41,756 - INFO - Train: [18/90][3000/3907]	eta 0:02:47 lr 0.03658075	time 0.1803 (0.1844)	loss 3.3200 (4.3652)	acc@1: 50.7042	acc@5: 79.5666	
2023-03-18 06:28:36,825 - INFO - Train: [18/90][3300/3907]	eta 0:01:51 lr 0.03658075	time 0.1804 (0.1844)	loss 5.8242 (4.3720)	acc@1: 25.8696	acc@5: 42.4521	
2023-03-18 06:29:31,991 - INFO - Train: [18/90][3600/3907]	eta 0:00:56 lr 0.03658075	time 0.1819 (0.1843)	loss 3.5280 (4.3729)	acc@1: 57.7940	acc@5: 76.3177	
2023-03-18 06:30:27,242 - INFO - Train: [18/90][3900/3907]	eta 0:00:01 lr 0.03658075	time 0.1874 (0.1843)	loss 6.3814 (4.3754)	acc@1: 16.5421	acc@5: 30.3091	
2023-03-18 06:30:28,520 - INFO - EPOCH 18 training takes 0:12:00
2023-03-18 06:30:29,611 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/fold1_latest.pth saved !!!
2023-03-18 06:30:29,611 - INFO - **********Latest test***********
2023-03-18 06:30:29,611 - INFO - eval epoch 18
2023-03-18 06:30:30,213 - INFO - Test: [0/782]	Time 0.597 (0.597)	Loss 2.9624 (2.9624)	Acc@1 58.594 (58.594)	Acc@5 87.500 (87.500)
2023-03-18 06:32:26,521 - INFO - Test: [200/782]	Time 0.572 (0.582)	Loss 3.1716 (3.3588)	Acc@1 52.344 (53.144)	Acc@5 79.688 (77.604)
2023-03-18 06:34:23,733 - INFO - Test: [400/782]	Time 0.590 (0.584)	Loss 3.3021 (3.3174)	Acc@1 55.469 (54.140)	Acc@5 76.562 (78.259)
2023-03-18 06:36:21,870 - INFO - Test: [600/782]	Time 0.601 (0.586)	Loss 3.3078 (3.2798)	Acc@1 49.219 (55.123)	Acc@5 82.812 (78.857)
2023-03-18 06:38:06,940 - INFO -  * Acc@1 55.670 Acc@5 79.463
2023-03-18 06:38:06,940 - INFO - Max accuracy: 56.1110%
2023-03-18 06:38:06,940 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-18 06:38:09,689 - INFO - Train: [19/90][0/3907]	eta 2:58:42 lr 0.03618034	time 2.7445 (2.7445)	loss 3.2101 (3.2101)	acc@1: 63.3189	acc@5: 82.1638	
2023-03-18 06:39:04,710 - INFO - Train: [19/90][300/3907]	eta 0:11:32 lr 0.03618034	time 0.1820 (0.1919)	loss 2.8243 (4.2832)	acc@1: 63.8614	acc@5: 84.8889	
2023-03-18 06:39:59,917 - INFO - Train: [19/90][600/3907]	eta 0:10:21 lr 0.03618034	time 0.1850 (0.1880)	loss 5.8296 (4.3105)	acc@1: 25.0867	acc@5: 40.9064	
2023-03-18 06:40:55,155 - INFO - Train: [19/90][900/3907]	eta 0:09:21 lr 0.03618034	time 0.1839 (0.1867)	loss 5.9886 (4.3393)	acc@1: 22.4620	acc@5: 37.8435	
2023-03-18 06:41:50,419 - INFO - Train: [19/90][1200/3907]	eta 0:08:23 lr 0.03618034	time 0.1845 (0.1861)	loss 5.6189 (4.3442)	acc@1: 36.1053	acc@5: 46.0726	
2023-03-18 06:42:45,699 - INFO - Train: [19/90][1500/3907]	eta 0:07:26 lr 0.03618034	time 0.1855 (0.1857)	loss 6.1353 (4.3290)	acc@1: 23.5239	acc@5: 36.1425	
2023-03-18 06:43:40,734 - INFO - Train: [19/90][1800/3907]	eta 0:06:30 lr 0.03618034	time 0.1886 (0.1853)	loss 3.2679 (4.3208)	acc@1: 62.2250	acc@5: 80.9480	
2023-03-18 06:44:35,945 - INFO - Train: [19/90][2100/3907]	eta 0:05:34 lr 0.03618034	time 0.1852 (0.1851)	loss 3.2419 (4.3211)	acc@1: 59.4027	acc@5: 79.9783	
2023-03-18 06:45:31,237 - INFO - Train: [19/90][2400/3907]	eta 0:04:38 lr 0.03618034	time 0.1890 (0.1850)	loss 3.7682 (4.3349)	acc@1: 52.1829	acc@5: 72.4762	
2023-03-18 06:46:26,419 - INFO - Train: [19/90][2700/3907]	eta 0:03:43 lr 0.03618034	time 0.1891 (0.1849)	loss 2.9492 (4.3384)	acc@1: 62.3038	acc@5: 84.1102	
2023-03-18 06:47:21,575 - INFO - Train: [19/90][3000/3907]	eta 0:02:47 lr 0.03618034	time 0.1805 (0.1848)	loss 5.9623 (4.3512)	acc@1: 25.2338	acc@5: 40.1393	
2023-03-18 06:48:16,804 - INFO - Train: [19/90][3300/3907]	eta 0:01:52 lr 0.03618034	time 0.1929 (0.1847)	loss 4.0546 (4.3578)	acc@1: 52.3554	acc@5: 65.4442	
2023-03-18 06:49:11,984 - INFO - Train: [19/90][3600/3907]	eta 0:00:56 lr 0.03618034	time 0.1801 (0.1847)	loss 5.9346 (4.3640)	acc@1: 26.0723	acc@5: 38.5437	
2023-03-18 06:50:07,246 - INFO - Train: [19/90][3900/3907]	eta 0:00:01 lr 0.03618034	time 0.1793 (0.1846)	loss 2.8584 (4.3682)	acc@1: 64.5936	acc@5: 84.0495	
2023-03-18 06:50:08,561 - INFO - EPOCH 19 training takes 0:12:01
2023-03-18 06:50:09,641 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/fold1_latest.pth saved !!!
2023-03-18 06:50:09,641 - INFO - **********Latest test***********
2023-03-18 06:50:09,641 - INFO - eval epoch 19
2023-03-18 06:50:10,305 - INFO - Test: [0/782]	Time 0.663 (0.663)	Loss 2.7503 (2.7503)	Acc@1 63.281 (63.281)	Acc@5 89.844 (89.844)
2023-03-18 06:52:09,557 - INFO - Test: [200/782]	Time 0.575 (0.597)	Loss 3.0770 (3.1975)	Acc@1 60.156 (55.958)	Acc@5 79.688 (79.310)
2023-03-18 06:54:08,074 - INFO - Test: [400/782]	Time 0.585 (0.595)	Loss 3.0647 (3.1680)	Acc@1 64.844 (56.622)	Acc@5 80.469 (80.036)
2023-03-18 06:56:07,557 - INFO - Test: [600/782]	Time 0.581 (0.596)	Loss 3.2156 (3.1317)	Acc@1 54.688 (57.520)	Acc@5 77.344 (80.707)
2023-03-18 06:57:52,978 - INFO -  * Acc@1 58.035 Acc@5 81.230
2023-03-18 06:57:52,978 - INFO - Max accuracy: 58.0350%
2023-03-18 06:57:54,045 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/fold1_best.pth saved !!!
2023-03-18 06:57:54,046 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-18 06:57:56,753 - INFO - Train: [20/90][0/3907]	eta 2:55:12 lr 0.03576022	time 2.6907 (2.6907)	loss 3.1827 (3.1827)	acc@1: 61.3028	acc@5: 82.2354	
2023-03-18 06:58:51,736 - INFO - Train: [20/90][300/3907]	eta 0:11:31 lr 0.03576022	time 0.1802 (0.1916)	loss 4.9564 (4.1748)	acc@1: 41.0228	acc@5: 58.6215	
2023-03-18 06:59:46,866 - INFO - Train: [20/90][600/3907]	eta 0:10:20 lr 0.03576022	time 0.1804 (0.1877)	loss 3.5213 (4.2094)	acc@1: 57.3000	acc@5: 77.1183	
2023-03-18 07:00:42,090 - INFO - Train: [20/90][900/3907]	eta 0:09:20 lr 0.03576022	time 0.1869 (0.1865)	loss 3.3975 (4.2176)	acc@1: 61.1780	acc@5: 79.8299	
2023-03-18 07:01:37,302 - INFO - Train: [20/90][1200/3907]	eta 0:08:23 lr 0.03576022	time 0.1842 (0.1859)	loss 6.0645 (4.2378)	acc@1: 19.0673	acc@5: 34.1491	
2023-03-18 07:02:32,360 - INFO - Train: [20/90][1500/3907]	eta 0:07:26 lr 0.03576022	time 0.1832 (0.1854)	loss 5.9947 (4.2472)	acc@1: 24.5921	acc@5: 38.2665	
2023-03-18 07:03:27,464 - INFO - Train: [20/90][1800/3907]	eta 0:06:30 lr 0.03576022	time 0.1811 (0.1851)	loss 5.9183 (4.2813)	acc@1: 23.9070	acc@5: 40.8137	
2023-03-18 07:04:22,644 - INFO - Train: [20/90][2100/3907]	eta 0:05:34 lr 0.03576022	time 0.1825 (0.1849)	loss 3.6308 (4.3057)	acc@1: 48.1441	acc@5: 73.3056	
2023-03-18 07:05:17,959 - INFO - Train: [20/90][2400/3907]	eta 0:04:38 lr 0.03576022	time 0.1807 (0.1849)	loss 3.0776 (4.3286)	acc@1: 55.4709	acc@5: 80.1198	
2023-03-18 07:06:13,109 - INFO - Train: [20/90][2700/3907]	eta 0:03:43 lr 0.03576022	time 0.1809 (0.1848)	loss 3.1538 (4.3350)	acc@1: 58.3329	acc@5: 79.3302	
2023-03-18 07:07:08,406 - INFO - Train: [20/90][3000/3907]	eta 0:02:47 lr 0.03576022	time 0.1885 (0.1847)	loss 3.1567 (4.3420)	acc@1: 56.9358	acc@5: 78.4791	
2023-03-18 07:08:03,506 - INFO - Train: [20/90][3300/3907]	eta 0:01:52 lr 0.03576022	time 0.1894 (0.1846)	loss 4.1860 (4.3453)	acc@1: 53.9867	acc@5: 66.4243	
2023-03-18 07:08:58,490 - INFO - Train: [20/90][3600/3907]	eta 0:00:56 lr 0.03576022	time 0.1803 (0.1845)	loss 3.3703 (4.3449)	acc@1: 59.7519	acc@5: 77.1407	
2023-03-18 07:09:53,627 - INFO - Train: [20/90][3900/3907]	eta 0:00:01 lr 0.03576022	time 0.1823 (0.1845)	loss 5.5059 (4.3505)	acc@1: 31.6460	acc@5: 48.7875	
2023-03-18 07:09:54,923 - INFO - EPOCH 20 training takes 0:12:00
2023-03-18 07:09:56,013 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/fold1_latest.pth saved !!!
2023-03-18 07:09:56,014 - INFO - **********Latest test***********
2023-03-18 07:09:56,014 - INFO - eval epoch 20
2023-03-18 07:09:56,623 - INFO - Test: [0/782]	Time 0.606 (0.606)	Loss 2.7817 (2.7817)	Acc@1 61.719 (61.719)	Acc@5 88.281 (88.281)
2023-03-18 07:11:56,407 - INFO - Test: [200/782]	Time 0.583 (0.599)	Loss 3.1730 (3.2378)	Acc@1 58.594 (54.928)	Acc@5 79.688 (78.673)
2023-03-18 07:13:55,967 - INFO - Test: [400/782]	Time 0.593 (0.598)	Loss 3.0644 (3.1975)	Acc@1 58.594 (56.174)	Acc@5 82.031 (79.623)
2023-03-18 07:15:56,063 - INFO - Test: [600/782]	Time 0.583 (0.599)	Loss 3.2731 (3.1661)	Acc@1 53.125 (56.797)	Acc@5 78.125 (80.243)
2023-03-18 07:17:42,328 - INFO -  * Acc@1 57.332 Acc@5 80.787
2023-03-18 07:17:42,328 - INFO - Max accuracy: 58.0350%
2023-03-18 07:17:42,328 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-18 07:17:45,096 - INFO - Train: [21/90][0/3907]	eta 2:59:57 lr 0.03532089	time 2.7635 (2.7635)	loss 2.9266 (2.9266)	acc@1: 67.8210	acc@5: 86.5320	
2023-03-18 07:18:40,126 - INFO - Train: [21/90][300/3907]	eta 0:11:32 lr 0.03532089	time 0.1882 (0.1920)	loss 3.1793 (4.2675)	acc@1: 58.5333	acc@5: 83.3282	
2023-03-18 07:19:35,255 - INFO - Train: [21/90][600/3907]	eta 0:10:21 lr 0.03532089	time 0.1807 (0.1879)	loss 6.1111 (4.1792)	acc@1: 18.4821	acc@5: 34.0701	
2023-03-18 07:20:30,580 - INFO - Train: [21/90][900/3907]	eta 0:09:21 lr 0.03532089	time 0.1814 (0.1867)	loss 3.5980 (4.2208)	acc@1: 56.3718	acc@5: 77.6027	
2023-03-18 07:21:25,835 - INFO - Train: [21/90][1200/3907]	eta 0:08:23 lr 0.03532089	time 0.1863 (0.1861)	loss 4.2123 (4.2479)	acc@1: 48.6388	acc@5: 68.4245	
2023-03-18 07:22:20,965 - INFO - Train: [21/90][1500/3907]	eta 0:07:26 lr 0.03532089	time 0.1886 (0.1856)	loss 5.9797 (4.2338)	acc@1: 20.9768	acc@5: 37.6115	
2023-03-18 07:23:16,014 - INFO - Train: [21/90][1800/3907]	eta 0:06:30 lr 0.03532089	time 0.1801 (0.1853)	loss 4.9860 (4.2619)	acc@1: 43.3492	acc@5: 59.3503	
2023-03-18 07:24:10,602 - INFO - Train: [21/90][2100/3907]	eta 0:05:33 lr 0.03532089	time 0.1800 (0.1848)	loss 3.8747 (4.2728)	acc@1: 60.8539	acc@5: 72.8832	
2023-03-18 07:25:05,287 - INFO - Train: [21/90][2400/3907]	eta 0:04:38 lr 0.03532089	time 0.1805 (0.1845)	loss 3.0221 (4.2757)	acc@1: 64.1525	acc@5: 80.9400	
2023-03-18 07:25:59,941 - INFO - Train: [21/90][2700/3907]	eta 0:03:42 lr 0.03532089	time 0.1829 (0.1842)	loss 3.4537 (4.2715)	acc@1: 58.5064	acc@5: 80.4463	
2023-03-18 07:26:54,749 - INFO - Train: [21/90][3000/3907]	eta 0:02:46 lr 0.03532089	time 0.1801 (0.1841)	loss 4.7168 (4.2879)	acc@1: 44.6049	acc@5: 63.2352	
2023-03-18 07:27:49,327 - INFO - Train: [21/90][3300/3907]	eta 0:01:51 lr 0.03532089	time 0.1800 (0.1839)	loss 5.3618 (4.2968)	acc@1: 34.3291	acc@5: 51.4324	
2023-03-18 07:28:44,215 - INFO - Train: [21/90][3600/3907]	eta 0:00:56 lr 0.03532089	time 0.1803 (0.1838)	loss 4.3195 (4.3034)	acc@1: 46.9786	acc@5: 70.5138	
2023-03-18 07:29:38,909 - INFO - Train: [21/90][3900/3907]	eta 0:00:01 lr 0.03532089	time 0.1797 (0.1837)	loss 3.0860 (4.3160)	acc@1: 61.4881	acc@5: 80.9464	
2023-03-18 07:29:40,186 - INFO - EPOCH 21 training takes 0:11:57
2023-03-18 07:29:41,144 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/fold1_latest.pth saved !!!
2023-03-18 07:29:41,144 - INFO - **********Latest test***********
2023-03-18 07:29:41,144 - INFO - eval epoch 21
2023-03-18 07:29:41,762 - INFO - Test: [0/782]	Time 0.617 (0.617)	Loss 2.6849 (2.6849)	Acc@1 66.406 (66.406)	Acc@5 89.844 (89.844)
2023-03-18 07:31:42,138 - INFO - Test: [200/782]	Time 0.591 (0.602)	Loss 2.9774 (3.1605)	Acc@1 60.938 (56.569)	Acc@5 82.812 (80.123)
2023-03-18 07:33:40,493 - INFO - Test: [400/782]	Time 0.595 (0.597)	Loss 2.9777 (3.1311)	Acc@1 58.594 (57.468)	Acc@5 81.250 (80.658)
2023-03-18 07:35:40,414 - INFO - Test: [600/782]	Time 0.598 (0.598)	Loss 3.1342 (3.0988)	Acc@1 55.469 (58.087)	Acc@5 79.688 (81.214)
2023-03-18 07:37:26,639 - INFO -  * Acc@1 58.623 Acc@5 81.737
2023-03-18 07:37:26,639 - INFO - Max accuracy: 58.6230%
2023-03-18 07:37:27,675 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/fold1_best.pth saved !!!
2023-03-18 07:37:27,676 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-18 07:37:30,198 - INFO - Train: [22/90][0/3907]	eta 2:43:53 lr 0.03486290	time 2.5169 (2.5169)	loss 3.4306 (3.4306)	acc@1: 61.6491	acc@5: 80.7010	
2023-03-18 07:38:24,888 - INFO - Train: [22/90][300/3907]	eta 0:11:25 lr 0.03486290	time 0.1814 (0.1901)	loss 2.7337 (4.1086)	acc@1: 71.8684	acc@5: 87.4920	
2023-03-18 07:39:19,770 - INFO - Train: [22/90][600/3907]	eta 0:10:16 lr 0.03486290	time 0.1795 (0.1865)	loss 2.9844 (4.2336)	acc@1: 67.3301	acc@5: 83.5804	
2023-03-18 07:40:14,497 - INFO - Train: [22/90][900/3907]	eta 0:09:16 lr 0.03486290	time 0.1807 (0.1851)	loss 3.9992 (4.2470)	acc@1: 58.1692	acc@5: 70.5647	
2023-03-18 07:41:09,238 - INFO - Train: [22/90][1200/3907]	eta 0:08:19 lr 0.03486290	time 0.1801 (0.1845)	loss 6.2266 (4.2236)	acc@1: 17.1086	acc@5: 32.5981	
2023-03-18 07:42:03,897 - INFO - Train: [22/90][1500/3907]	eta 0:07:22 lr 0.03486290	time 0.1799 (0.1840)	loss 3.3737 (4.2364)	acc@1: 54.5048	acc@5: 78.3820	
2023-03-18 07:42:58,557 - INFO - Train: [22/90][1800/3907]	eta 0:06:27 lr 0.03486290	time 0.1813 (0.1837)	loss 4.3134 (4.2737)	acc@1: 51.0339	acc@5: 68.2661	
2023-03-18 07:43:53,147 - INFO - Train: [22/90][2100/3907]	eta 0:05:31 lr 0.03486290	time 0.1801 (0.1835)	loss 4.4335 (4.2776)	acc@1: 48.6992	acc@5: 65.1094	
2023-03-18 07:44:47,888 - INFO - Train: [22/90][2400/3907]	eta 0:04:36 lr 0.03486290	time 0.1817 (0.1833)	loss 3.8743 (4.2795)	acc@1: 53.6006	acc@5: 76.9234	
2023-03-18 07:45:42,368 - INFO - Train: [22/90][2700/3907]	eta 0:03:41 lr 0.03486290	time 0.1862 (0.1831)	loss 4.0725 (4.2982)	acc@1: 51.9551	acc@5: 70.7164	
2023-03-18 07:46:37,110 - INFO - Train: [22/90][3000/3907]	eta 0:02:46 lr 0.03486290	time 0.1801 (0.1831)	loss 5.4346 (4.3018)	acc@1: 32.8640	acc@5: 51.3255	
2023-03-18 07:47:31,836 - INFO - Train: [22/90][3300/3907]	eta 0:01:51 lr 0.03486290	time 0.1888 (0.1830)	loss 5.9227 (4.2996)	acc@1: 27.4570	acc@5: 41.2690	
2023-03-18 07:48:26,380 - INFO - Train: [22/90][3600/3907]	eta 0:00:56 lr 0.03486290	time 0.1803 (0.1829)	loss 3.9362 (4.3016)	acc@1: 56.4131	acc@5: 70.8629	
2023-03-18 07:49:21,075 - INFO - Train: [22/90][3900/3907]	eta 0:00:01 lr 0.03486290	time 0.1794 (0.1829)	loss 5.1127 (4.3049)	acc@1: 39.4927	acc@5: 56.6786	
2023-03-18 07:49:22,290 - INFO - EPOCH 22 training takes 0:11:54
2023-03-18 07:49:23,627 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/fold1_latest.pth saved !!!
2023-03-18 07:49:23,628 - INFO - **********Latest test***********
2023-03-18 07:49:23,628 - INFO - eval epoch 22
2023-03-18 07:49:24,237 - INFO - Test: [0/782]	Time 0.608 (0.608)	Loss 2.7027 (2.7027)	Acc@1 65.625 (65.625)	Acc@5 89.062 (89.062)
2023-03-18 07:51:22,339 - INFO - Test: [200/782]	Time 0.583 (0.591)	Loss 3.1370 (3.2318)	Acc@1 60.156 (55.523)	Acc@5 77.344 (78.968)
2023-03-18 07:53:20,639 - INFO - Test: [400/782]	Time 0.590 (0.591)	Loss 3.1374 (3.1956)	Acc@1 57.812 (56.178)	Acc@5 78.906 (79.670)
2023-03-18 07:55:19,613 - INFO - Test: [600/782]	Time 0.589 (0.592)	Loss 3.3880 (3.1564)	Acc@1 46.875 (57.046)	Acc@5 74.219 (80.357)
2023-03-18 07:57:04,673 - INFO -  * Acc@1 57.514 Acc@5 80.889
2023-03-18 07:57:04,673 - INFO - Max accuracy: 58.6230%
2023-03-18 07:57:04,673 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-18 07:57:07,398 - INFO - Train: [23/90][0/3907]	eta 2:57:11 lr 0.03438680	time 2.7212 (2.7212)	loss 2.6523 (2.6523)	acc@1: 69.5000	acc@5: 89.0225	
2023-03-18 07:58:01,952 - INFO - Train: [23/90][300/3907]	eta 0:11:26 lr 0.03438680	time 0.1876 (0.1903)	loss 2.7997 (4.0875)	acc@1: 65.4500	acc@5: 88.0499	
2023-03-18 07:58:56,693 - INFO - Train: [23/90][600/3907]	eta 0:10:16 lr 0.03438680	time 0.1854 (0.1864)	loss 4.9776 (4.1494)	acc@1: 42.8856	acc@5: 59.7538	
2023-03-18 07:59:51,278 - INFO - Train: [23/90][900/3907]	eta 0:09:15 lr 0.03438680	time 0.1800 (0.1849)	loss 3.3935 (4.1567)	acc@1: 62.9470	acc@5: 81.2949	
2023-03-18 08:00:45,994 - INFO - Train: [23/90][1200/3907]	eta 0:08:18 lr 0.03438680	time 0.1802 (0.1843)	loss 4.9902 (4.1937)	acc@1: 43.3820	acc@5: 59.7636	
2023-03-18 08:01:40,713 - INFO - Train: [23/90][1500/3907]	eta 0:07:22 lr 0.03438680	time 0.1800 (0.1839)	loss 4.2244 (4.2178)	acc@1: 51.6806	acc@5: 72.1726	
2023-03-18 08:02:35,452 - INFO - Train: [23/90][1800/3907]	eta 0:06:26 lr 0.03438680	time 0.1801 (0.1837)	loss 6.2000 (4.2227)	acc@1: 18.3415	acc@5: 32.3302	
2023-03-18 08:03:30,015 - INFO - Train: [23/90][2100/3907]	eta 0:05:31 lr 0.03438680	time 0.1787 (0.1834)	loss 3.2382 (4.2268)	acc@1: 61.6356	acc@5: 77.6252	
2023-03-18 08:04:24,473 - INFO - Train: [23/90][2400/3907]	eta 0:04:36 lr 0.03438680	time 0.1806 (0.1832)	loss 6.1598 (4.2409)	acc@1: 17.3998	acc@5: 34.2306	
2023-03-18 08:05:19,155 - INFO - Train: [23/90][2700/3907]	eta 0:03:40 lr 0.03438680	time 0.1799 (0.1831)	loss 6.1892 (4.2485)	acc@1: 21.2376	acc@5: 35.4214	
2023-03-18 08:06:13,645 - INFO - Train: [23/90][3000/3907]	eta 0:02:45 lr 0.03438680	time 0.1787 (0.1829)	loss 4.9617 (4.2636)	acc@1: 43.9206	acc@5: 57.7242	
2023-03-18 08:07:08,243 - INFO - Train: [23/90][3300/3907]	eta 0:01:50 lr 0.03438680	time 0.1794 (0.1828)	loss 4.4946 (4.2571)	acc@1: 48.6420	acc@5: 65.3002	
2023-03-18 08:08:02,918 - INFO - Train: [23/90][3600/3907]	eta 0:00:56 lr 0.03438680	time 0.1861 (0.1828)	loss 5.2351 (4.2772)	acc@1: 35.3462	acc@5: 57.3963	
2023-03-18 08:08:57,469 - INFO - Train: [23/90][3900/3907]	eta 0:00:01 lr 0.03438680	time 0.1865 (0.1827)	loss 3.1779 (4.2883)	acc@1: 60.2642	acc@5: 79.5768	
2023-03-18 08:08:58,795 - INFO - EPOCH 23 training takes 0:11:54
2023-03-18 08:08:59,987 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/fold1_latest.pth saved !!!
2023-03-18 08:08:59,987 - INFO - **********Latest test***********
2023-03-18 08:08:59,988 - INFO - eval epoch 23
2023-03-18 08:09:00,604 - INFO - Test: [0/782]	Time 0.614 (0.614)	Loss 2.7520 (2.7520)	Acc@1 59.375 (59.375)	Acc@5 91.406 (91.406)
2023-03-18 08:10:59,790 - INFO - Test: [200/782]	Time 0.606 (0.596)	Loss 3.1561 (3.1389)	Acc@1 60.156 (56.996)	Acc@5 80.469 (80.558)
2023-03-18 08:12:59,801 - INFO - Test: [400/782]	Time 0.602 (0.598)	Loss 3.0054 (3.1040)	Acc@1 63.281 (57.803)	Acc@5 76.562 (81.036)
2023-03-18 08:14:59,776 - INFO - Test: [600/782]	Time 0.582 (0.599)	Loss 3.0617 (3.0640)	Acc@1 59.375 (58.726)	Acc@5 82.031 (81.701)
2023-03-18 08:16:45,229 - INFO -  * Acc@1 59.236 Acc@5 82.262
2023-03-18 08:16:45,230 - INFO - Max accuracy: 59.2360%
2023-03-18 08:16:46,289 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/fold1_best.pth saved !!!
2023-03-18 08:16:46,290 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-18 08:16:48,595 - INFO - Train: [24/90][0/3907]	eta 2:29:29 lr 0.03389317	time 2.2958 (2.2958)	loss 3.1029 (3.1029)	acc@1: 70.5735	acc@5: 83.1955	
2023-03-18 08:17:42,991 - INFO - Train: [24/90][300/3907]	eta 0:11:19 lr 0.03389317	time 0.1864 (0.1883)	loss 3.9539 (4.2666)	acc@1: 57.9759	acc@5: 74.5141	
2023-03-18 08:18:37,686 - INFO - Train: [24/90][600/3907]	eta 0:10:12 lr 0.03389317	time 0.1807 (0.1853)	loss 5.7938 (4.2254)	acc@1: 24.0185	acc@5: 41.7512	
2023-03-18 08:19:32,281 - INFO - Train: [24/90][900/3907]	eta 0:09:13 lr 0.03389317	time 0.1880 (0.1842)	loss 3.1629 (4.1865)	acc@1: 58.9343	acc@5: 81.9116	
2023-03-18 08:20:26,740 - INFO - Train: [24/90][1200/3907]	eta 0:08:16 lr 0.03389317	time 0.1926 (0.1835)	loss 5.0100 (4.2356)	acc@1: 39.9456	acc@5: 59.3942	
2023-03-18 08:21:21,266 - INFO - Train: [24/90][1500/3907]	eta 0:07:20 lr 0.03389317	time 0.1913 (0.1832)	loss 3.3852 (4.2399)	acc@1: 53.4417	acc@5: 77.0841	
2023-03-18 08:22:15,761 - INFO - Train: [24/90][1800/3907]	eta 0:06:25 lr 0.03389317	time 0.1811 (0.1829)	loss 4.4406 (4.2464)	acc@1: 48.0920	acc@5: 69.3626	
2023-03-18 08:23:10,512 - INFO - Train: [24/90][2100/3907]	eta 0:05:30 lr 0.03389317	time 0.1861 (0.1829)	loss 6.1446 (4.2552)	acc@1: 21.8461	acc@5: 38.0413	
2023-03-18 08:24:05,077 - INFO - Train: [24/90][2400/3907]	eta 0:04:35 lr 0.03389317	time 0.1804 (0.1827)	loss 3.0870 (4.2537)	acc@1: 59.3051	acc@5: 77.2527	
2023-03-18 08:24:59,592 - INFO - Train: [24/90][2700/3907]	eta 0:03:40 lr 0.03389317	time 0.1861 (0.1826)	loss 3.2360 (4.2743)	acc@1: 57.0312	acc@5: 75.7812	
2023-03-18 08:25:54,089 - INFO - Train: [24/90][3000/3907]	eta 0:02:45 lr 0.03389317	time 0.1803 (0.1825)	loss 3.5963 (4.2662)	acc@1: 54.0638	acc@5: 74.5009	
2023-03-18 08:26:48,780 - INFO - Train: [24/90][3300/3907]	eta 0:01:50 lr 0.03389317	time 0.1916 (0.1825)	loss 3.6162 (4.2571)	acc@1: 52.0924	acc@5: 72.2593	
2023-03-18 08:27:43,254 - INFO - Train: [24/90][3600/3907]	eta 0:00:56 lr 0.03389317	time 0.1789 (0.1824)	loss 5.6727 (4.2577)	acc@1: 31.0080	acc@5: 48.5780	
2023-03-18 08:28:37,818 - INFO - Train: [24/90][3900/3907]	eta 0:00:01 lr 0.03389317	time 0.1784 (0.1824)	loss 3.5062 (4.2611)	acc@1: 58.4056	acc@5: 77.1578	
2023-03-18 08:28:39,089 - INFO - EPOCH 24 training takes 0:11:52
2023-03-18 08:28:40,190 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/fold1_latest.pth saved !!!
2023-03-18 08:28:40,191 - INFO - **********Latest test***********
2023-03-18 08:28:40,191 - INFO - eval epoch 24
2023-03-18 08:28:40,802 - INFO - Test: [0/782]	Time 0.608 (0.608)	Loss 2.7247 (2.7247)	Acc@1 63.281 (63.281)	Acc@5 87.500 (87.500)
2023-03-18 08:30:37,716 - INFO - Test: [200/782]	Time 0.580 (0.585)	Loss 3.0202 (3.1940)	Acc@1 60.938 (55.811)	Acc@5 80.469 (79.478)
2023-03-18 08:32:35,099 - INFO - Test: [400/782]	Time 0.590 (0.586)	Loss 2.9432 (3.1549)	Acc@1 63.281 (56.780)	Acc@5 82.812 (80.128)
2023-03-18 08:34:33,421 - INFO - Test: [600/782]	Time 0.582 (0.588)	Loss 3.2346 (3.1216)	Acc@1 59.375 (57.525)	Acc@5 79.688 (80.783)
2023-03-18 08:36:18,257 - INFO -  * Acc@1 58.122 Acc@5 81.398
2023-03-18 08:36:18,258 - INFO - Max accuracy: 59.2360%
2023-03-18 08:36:18,258 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-18 08:36:20,590 - INFO - Train: [25/90][0/3907]	eta 2:31:36 lr 0.03338261	time 2.3283 (2.3283)	loss 6.3036 (6.3036)	acc@1: 18.2318	acc@5: 32.5574	
2023-03-18 08:37:14,871 - INFO - Train: [25/90][300/3907]	eta 0:11:18 lr 0.03338261	time 0.1963 (0.1881)	loss 2.9544 (4.2361)	acc@1: 67.6740	acc@5: 82.2854	
2023-03-18 08:38:09,517 - INFO - Train: [25/90][600/3907]	eta 0:10:12 lr 0.03338261	time 0.1797 (0.1851)	loss 3.9427 (4.2053)	acc@1: 56.3693	acc@5: 74.4664	
2023-03-18 08:39:03,557 - INFO - Train: [25/90][900/3907]	eta 0:09:11 lr 0.03338261	time 0.1835 (0.1835)	loss 4.5854 (4.2329)	acc@1: 50.4895	acc@5: 69.0236	
2023-03-18 08:39:57,584 - INFO - Train: [25/90][1200/3907]	eta 0:08:14 lr 0.03338261	time 0.1798 (0.1826)	loss 6.2373 (4.2511)	acc@1: 17.7790	acc@5: 30.8340	
2023-03-18 08:40:51,791 - INFO - Train: [25/90][1500/3907]	eta 0:07:18 lr 0.03338261	time 0.1782 (0.1822)	loss 3.9042 (4.2512)	acc@1: 52.5350	acc@5: 70.0467	
2023-03-18 08:41:45,865 - INFO - Train: [25/90][1800/3907]	eta 0:06:23 lr 0.03338261	time 0.1789 (0.1819)	loss 2.8468 (4.2578)	acc@1: 65.6238	acc@5: 84.3735	
2023-03-18 08:42:39,846 - INFO - Train: [25/90][2100/3907]	eta 0:05:28 lr 0.03338261	time 0.1788 (0.1816)	loss 3.0118 (4.2578)	acc@1: 64.3669	acc@5: 83.5099	
2023-03-18 08:43:33,811 - INFO - Train: [25/90][2400/3907]	eta 0:04:33 lr 0.03338261	time 0.1786 (0.1814)	loss 2.9925 (4.2567)	acc@1: 65.0579	acc@5: 82.8695	
2023-03-18 08:44:27,858 - INFO - Train: [25/90][2700/3907]	eta 0:03:38 lr 0.03338261	time 0.1780 (0.1813)	loss 2.7752 (4.2570)	acc@1: 66.3415	acc@5: 86.6339	
2023-03-18 08:45:21,957 - INFO - Train: [25/90][3000/3907]	eta 0:02:44 lr 0.03338261	time 0.1788 (0.1812)	loss 2.8071 (4.2564)	acc@1: 65.9720	acc@5: 84.5994	
2023-03-18 08:46:16,001 - INFO - Train: [25/90][3300/3907]	eta 0:01:49 lr 0.03338261	time 0.1790 (0.1811)	loss 4.8588 (4.2524)	acc@1: 41.2368	acc@5: 63.5881	
2023-03-18 08:47:10,255 - INFO - Train: [25/90][3600/3907]	eta 0:00:55 lr 0.03338261	time 0.1785 (0.1811)	loss 5.9189 (4.2635)	acc@1: 24.6258	acc@5: 43.8273	
2023-03-18 08:48:04,586 - INFO - Train: [25/90][3900/3907]	eta 0:00:01 lr 0.03338261	time 0.1791 (0.1811)	loss 4.2848 (4.2708)	acc@1: 50.9159	acc@5: 66.9590	
2023-03-18 08:48:05,903 - INFO - EPOCH 25 training takes 0:11:47
2023-03-18 08:48:06,858 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/fold1_latest.pth saved !!!
2023-03-18 08:48:06,858 - INFO - **********Latest test***********
2023-03-18 08:48:06,858 - INFO - eval epoch 25
2023-03-18 08:48:07,488 - INFO - Test: [0/782]	Time 0.628 (0.628)	Loss 2.7936 (2.7936)	Acc@1 58.594 (58.594)	Acc@5 87.500 (87.500)
2023-03-18 08:50:06,854 - INFO - Test: [200/782]	Time 0.606 (0.597)	Loss 3.0965 (3.2222)	Acc@1 63.281 (56.141)	Acc@5 82.031 (79.590)
2023-03-18 08:52:06,131 - INFO - Test: [400/782]	Time 0.591 (0.597)	Loss 2.9873 (3.1838)	Acc@1 59.375 (56.969)	Acc@5 85.156 (80.399)
2023-03-18 08:54:05,460 - INFO - Test: [600/782]	Time 0.584 (0.597)	Loss 3.1886 (3.1469)	Acc@1 58.594 (57.709)	Acc@5 78.906 (80.980)
2023-03-18 08:55:51,467 - INFO -  * Acc@1 58.165 Acc@5 81.446
2023-03-18 08:55:51,468 - INFO - Max accuracy: 59.2360%
2023-03-18 08:55:51,468 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-18 08:55:54,331 - INFO - Train: [26/90][0/3907]	eta 3:06:11 lr 0.03285575	time 2.8592 (2.8592)	loss 4.0458 (4.0458)	acc@1: 54.4641	acc@5: 72.4808	
2023-03-18 08:56:48,556 - INFO - Train: [26/90][300/3907]	eta 0:11:24 lr 0.03285575	time 0.1785 (0.1896)	loss 2.7497 (4.0932)	acc@1: 68.2879	acc@5: 85.3651	
2023-03-18 08:57:42,841 - INFO - Train: [26/90][600/3907]	eta 0:10:12 lr 0.03285575	time 0.1787 (0.1853)	loss 2.8925 (4.1440)	acc@1: 67.6755	acc@5: 85.5648	
2023-03-18 08:58:37,071 - INFO - Train: [26/90][900/3907]	eta 0:09:12 lr 0.03285575	time 0.1822 (0.1838)	loss 3.4357 (4.1870)	acc@1: 62.2973	acc@5: 78.2906	
2023-03-18 08:59:31,314 - INFO - Train: [26/90][1200/3907]	eta 0:08:15 lr 0.03285575	time 0.1786 (0.1830)	loss 4.0294 (4.1920)	acc@1: 54.1438	acc@5: 70.7762	
2023-03-18 09:00:25,512 - INFO - Train: [26/90][1500/3907]	eta 0:07:19 lr 0.03285575	time 0.1862 (0.1826)	loss 4.9221 (4.1729)	acc@1: 39.9573	acc@5: 60.7172	
2023-03-18 09:01:19,779 - INFO - Train: [26/90][1800/3907]	eta 0:06:24 lr 0.03285575	time 0.1803 (0.1823)	loss 3.7951 (4.1637)	acc@1: 55.3631	acc@5: 72.1823	
2023-03-18 09:02:14,011 - INFO - Train: [26/90][2100/3907]	eta 0:05:29 lr 0.03285575	time 0.1822 (0.1821)	loss 3.6058 (4.1709)	acc@1: 61.8618	acc@5: 74.9620	
2023-03-18 09:03:08,163 - INFO - Train: [26/90][2400/3907]	eta 0:04:34 lr 0.03285575	time 0.1863 (0.1819)	loss 5.9852 (4.1755)	acc@1: 22.9762	acc@5: 40.3466	
2023-03-18 09:04:02,388 - INFO - Train: [26/90][2700/3907]	eta 0:03:39 lr 0.03285575	time 0.1809 (0.1817)	loss 2.5843 (4.1851)	acc@1: 69.4559	acc@5: 85.8442	
2023-03-18 09:04:56,675 - INFO - Train: [26/90][3000/3907]	eta 0:02:44 lr 0.03285575	time 0.1786 (0.1817)	loss 3.4223 (4.1847)	acc@1: 62.5579	acc@5: 79.2739	
2023-03-18 09:05:51,168 - INFO - Train: [26/90][3300/3907]	eta 0:01:50 lr 0.03285575	time 0.1786 (0.1817)	loss 6.3075 (4.2039)	acc@1: 17.0909	acc@5: 33.6932	
2023-03-18 09:06:45,509 - INFO - Train: [26/90][3600/3907]	eta 0:00:55 lr 0.03285575	time 0.1783 (0.1816)	loss 6.1109 (4.2058)	acc@1: 18.3265	acc@5: 34.8117	
2023-03-18 09:07:39,591 - INFO - Train: [26/90][3900/3907]	eta 0:00:01 lr 0.03285575	time 0.1784 (0.1815)	loss 4.0274 (4.2081)	acc@1: 54.6639	acc@5: 74.4436	
2023-03-18 09:07:40,879 - INFO - EPOCH 26 training takes 0:11:49
2023-03-18 09:07:41,951 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/fold1_latest.pth saved !!!
2023-03-18 09:07:41,952 - INFO - **********Latest test***********
2023-03-18 09:07:41,952 - INFO - eval epoch 26
2023-03-18 09:07:42,541 - INFO - Test: [0/782]	Time 0.588 (0.588)	Loss 2.6708 (2.6708)	Acc@1 67.188 (67.188)	Acc@5 85.938 (85.938)
2023-03-18 09:09:38,883 - INFO - Test: [200/782]	Time 0.599 (0.582)	Loss 3.0071 (3.1209)	Acc@1 63.281 (57.276)	Acc@5 78.125 (80.407)
2023-03-18 09:11:36,656 - INFO - Test: [400/782]	Time 0.607 (0.585)	Loss 2.9117 (3.0819)	Acc@1 64.062 (58.173)	Acc@5 82.031 (81.071)
2023-03-18 09:13:35,923 - INFO - Test: [600/782]	Time 0.578 (0.589)	Loss 3.2480 (3.0438)	Acc@1 53.906 (59.006)	Acc@5 76.562 (81.713)
2023-03-18 09:15:22,056 - INFO -  * Acc@1 59.571 Acc@5 82.275
2023-03-18 09:15:22,057 - INFO - Max accuracy: 59.5710%
2023-03-18 09:15:23,114 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/fold1_best.pth saved !!!
2023-03-18 09:15:23,114 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-18 09:15:26,020 - INFO - Train: [27/90][0/3907]	eta 3:08:54 lr 0.03231323	time 2.9011 (2.9011)	loss 3.0320 (3.0320)	acc@1: 62.7041	acc@5: 82.0573	
2023-03-18 09:16:20,138 - INFO - Train: [27/90][300/3907]	eta 0:11:23 lr 0.03231323	time 0.1860 (0.1894)	loss 5.1124 (4.2128)	acc@1: 39.9266	acc@5: 57.3936	
2023-03-18 09:17:14,377 - INFO - Train: [27/90][600/3907]	eta 0:10:12 lr 0.03231323	time 0.1787 (0.1851)	loss 4.6759 (4.2250)	acc@1: 40.3421	acc@5: 63.1017	
2023-03-18 09:18:08,583 - INFO - Train: [27/90][900/3907]	eta 0:09:12 lr 0.03231323	time 0.1783 (0.1836)	loss 2.7547 (4.2330)	acc@1: 65.5044	acc@5: 86.5608	
2023-03-18 09:19:02,654 - INFO - Train: [27/90][1200/3907]	eta 0:08:14 lr 0.03231323	time 0.1792 (0.1828)	loss 3.0194 (4.2125)	acc@1: 70.2483	acc@5: 78.8341	
2023-03-18 09:19:56,959 - INFO - Train: [27/90][1500/3907]	eta 0:07:19 lr 0.03231323	time 0.1786 (0.1824)	loss 3.1369 (4.1997)	acc@1: 63.5560	acc@5: 80.9514	
2023-03-18 09:20:51,196 - INFO - Train: [27/90][1800/3907]	eta 0:06:23 lr 0.03231323	time 0.1790 (0.1822)	loss 2.9261 (4.2059)	acc@1: 59.2421	acc@5: 84.9648	
2023-03-18 09:21:45,404 - INFO - Train: [27/90][2100/3907]	eta 0:05:28 lr 0.03231323	time 0.1789 (0.1819)	loss 5.2409 (4.1885)	acc@1: 38.5230	acc@5: 52.6661	
2023-03-18 09:22:39,609 - INFO - Train: [27/90][2400/3907]	eta 0:04:33 lr 0.03231323	time 0.1794 (0.1818)	loss 5.7928 (4.2028)	acc@1: 27.1912	acc@5: 44.8428	
2023-03-18 09:23:33,820 - INFO - Train: [27/90][2700/3907]	eta 0:03:39 lr 0.03231323	time 0.1792 (0.1817)	loss 6.0635 (4.2134)	acc@1: 20.8205	acc@5: 34.1970	
2023-03-18 09:24:27,959 - INFO - Train: [27/90][3000/3907]	eta 0:02:44 lr 0.03231323	time 0.1787 (0.1815)	loss 5.1765 (4.2210)	acc@1: 39.2069	acc@5: 54.7011	
2023-03-18 09:25:22,111 - INFO - Train: [27/90][3300/3907]	eta 0:01:50 lr 0.03231323	time 0.1805 (0.1815)	loss 6.3797 (4.2300)	acc@1: 17.2567	acc@5: 32.1091	
2023-03-18 09:26:16,325 - INFO - Train: [27/90][3600/3907]	eta 0:00:55 lr 0.03231323	time 0.1853 (0.1814)	loss 2.8636 (4.2375)	acc@1: 64.5640	acc@5: 85.5668	
2023-03-18 09:27:10,545 - INFO - Train: [27/90][3900/3907]	eta 0:00:01 lr 0.03231323	time 0.1784 (0.1813)	loss 2.9878 (4.2476)	acc@1: 57.4957	acc@5: 79.2491	
2023-03-18 09:27:11,824 - INFO - EPOCH 27 training takes 0:11:48
2023-03-18 09:27:12,909 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/fold1_latest.pth saved !!!
2023-03-18 09:27:12,909 - INFO - **********Latest test***********
2023-03-18 09:27:12,909 - INFO - eval epoch 27
2023-03-18 09:27:13,518 - INFO - Test: [0/782]	Time 0.608 (0.608)	Loss 2.8209 (2.8209)	Acc@1 61.719 (61.719)	Acc@5 82.812 (82.812)
2023-03-18 09:29:12,056 - INFO - Test: [200/782]	Time 0.596 (0.593)	Loss 3.0767 (3.1106)	Acc@1 57.031 (57.630)	Acc@5 79.688 (81.025)
2023-03-18 09:31:11,189 - INFO - Test: [400/782]	Time 0.602 (0.594)	Loss 2.7843 (3.0695)	Acc@1 64.062 (58.767)	Acc@5 83.594 (81.601)
2023-03-18 09:33:10,951 - INFO - Test: [600/782]	Time 0.579 (0.596)	Loss 3.1635 (3.0343)	Acc@1 51.562 (59.578)	Acc@5 81.250 (82.226)
2023-03-18 09:34:56,026 - INFO -  * Acc@1 60.054 Acc@5 82.697
2023-03-18 09:34:56,026 - INFO - Max accuracy: 60.0540%
2023-03-18 09:34:57,064 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/fold1_best.pth saved !!!
2023-03-18 09:34:57,064 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-18 09:34:59,934 - INFO - Train: [28/90][0/3907]	eta 3:06:14 lr 0.03175571	time 2.8602 (2.8602)	loss 4.7520 (4.7520)	acc@1: 43.3433	acc@5: 60.4057	
2023-03-18 09:35:54,224 - INFO - Train: [28/90][300/3907]	eta 0:11:24 lr 0.03175571	time 0.1787 (0.1899)	loss 6.0161 (4.0774)	acc@1: 18.9382	acc@5: 34.5632	
2023-03-18 09:36:48,456 - INFO - Train: [28/90][600/3907]	eta 0:10:12 lr 0.03175571	time 0.1788 (0.1853)	loss 5.4473 (4.1021)	acc@1: 32.7549	acc@5: 51.6433	
2023-03-18 09:37:42,731 - INFO - Train: [28/90][900/3907]	eta 0:09:12 lr 0.03175571	time 0.1820 (0.1839)	loss 5.0415 (4.1131)	acc@1: 39.7230	acc@5: 57.7789	
2023-03-18 09:38:36,879 - INFO - Train: [28/90][1200/3907]	eta 0:08:15 lr 0.03175571	time 0.1796 (0.1830)	loss 2.9448 (4.1200)	acc@1: 63.0360	acc@5: 81.7106	
2023-03-18 09:39:30,924 - INFO - Train: [28/90][1500/3907]	eta 0:07:19 lr 0.03175571	time 0.1844 (0.1824)	loss 4.0600 (4.1549)	acc@1: 50.6054	acc@5: 71.4902	
2023-03-18 09:40:24,990 - INFO - Train: [28/90][1800/3907]	eta 0:06:23 lr 0.03175571	time 0.1793 (0.1821)	loss 3.0544 (4.1796)	acc@1: 60.1387	acc@5: 78.8832	
2023-03-18 09:41:19,096 - INFO - Train: [28/90][2100/3907]	eta 0:05:28 lr 0.03175571	time 0.1789 (0.1818)	loss 3.1849 (4.1680)	acc@1: 62.1032	acc@5: 81.0848	
2023-03-18 09:42:13,262 - INFO - Train: [28/90][2400/3907]	eta 0:04:33 lr 0.03175571	time 0.1775 (0.1817)	loss 2.9324 (4.1772)	acc@1: 71.9591	acc@5: 87.8688	
2023-03-18 09:43:06,588 - INFO - Train: [28/90][2700/3907]	eta 0:03:38 lr 0.03175571	time 0.1699 (0.1812)	loss 3.2053 (4.1838)	acc@1: 60.8187	acc@5: 81.3660	
2023-03-18 09:43:58,449 - INFO - Train: [28/90][3000/3907]	eta 0:02:43 lr 0.03175571	time 0.1707 (0.1804)	loss 4.3691 (4.1911)	acc@1: 53.5212	acc@5: 71.8824	
2023-03-18 09:44:50,071 - INFO - Train: [28/90][3300/3907]	eta 0:01:49 lr 0.03175571	time 0.1698 (0.1796)	loss 3.2340 (4.1797)	acc@1: 62.3075	acc@5: 81.2971	
2023-03-18 09:45:41,741 - INFO - Train: [28/90][3600/3907]	eta 0:00:54 lr 0.03175571	time 0.1769 (0.1790)	loss 4.6496 (4.1812)	acc@1: 46.3877	acc@5: 64.4274	
2023-03-18 09:46:33,536 - INFO - Train: [28/90][3900/3907]	eta 0:00:01 lr 0.03175571	time 0.1692 (0.1785)	loss 6.1317 (4.1959)	acc@1: 19.8915	acc@5: 34.6538	
2023-03-18 09:46:34,788 - INFO - EPOCH 28 training takes 0:11:37
2023-03-18 09:46:35,864 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/fold1_latest.pth saved !!!
2023-03-18 09:46:35,864 - INFO - **********Latest test***********
2023-03-18 09:46:35,865 - INFO - eval epoch 28
2023-03-18 09:46:36,466 - INFO - Test: [0/782]	Time 0.598 (0.598)	Loss 2.7449 (2.7449)	Acc@1 65.625 (65.625)	Acc@5 86.719 (86.719)
2023-03-18 09:48:33,240 - INFO - Test: [200/782]	Time 0.589 (0.584)	Loss 2.8801 (3.0129)	Acc@1 62.500 (59.787)	Acc@5 83.594 (82.210)
2023-03-18 09:50:32,311 - INFO - Test: [400/782]	Time 0.599 (0.590)	Loss 2.6988 (2.9814)	Acc@1 65.625 (60.509)	Acc@5 88.281 (82.764)
2023-03-18 09:52:31,627 - INFO - Test: [600/782]	Time 0.593 (0.592)	Loss 3.0134 (2.9499)	Acc@1 60.938 (61.299)	Acc@5 82.812 (83.338)
2023-03-18 09:54:18,370 - INFO -  * Acc@1 61.803 Acc@5 83.789
2023-03-18 09:54:18,370 - INFO - Max accuracy: 61.8030%
2023-03-18 09:54:19,440 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/fold1_best.pth saved !!!
2023-03-18 09:54:19,441 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-18 09:54:21,740 - INFO - Train: [29/90][0/3907]	eta 2:29:17 lr 0.03118386	time 2.2927 (2.2927)	loss 3.2813 (3.2813)	acc@1: 66.7059	acc@5: 78.6980	
2023-03-18 09:55:16,141 - INFO - Train: [29/90][300/3907]	eta 0:11:19 lr 0.03118386	time 0.1899 (0.1883)	loss 3.3258 (3.9740)	acc@1: 62.8714	acc@5: 82.5941	
2023-03-18 09:56:10,485 - INFO - Train: [29/90][600/3907]	eta 0:10:10 lr 0.03118386	time 0.1824 (0.1847)	loss 6.0259 (3.9906)	acc@1: 21.1274	acc@5: 37.3217	
2023-03-18 09:57:04,874 - INFO - Train: [29/90][900/3907]	eta 0:09:12 lr 0.03118386	time 0.1798 (0.1836)	loss 3.6617 (4.0122)	acc@1: 58.7781	acc@5: 76.6982	
2023-03-18 09:57:59,400 - INFO - Train: [29/90][1200/3907]	eta 0:08:15 lr 0.03118386	time 0.1789 (0.1831)	loss 6.0123 (4.0308)	acc@1: 24.1288	acc@5: 38.0151	
2023-03-18 09:58:53,955 - INFO - Train: [29/90][1500/3907]	eta 0:07:20 lr 0.03118386	time 0.1796 (0.1829)	loss 4.7005 (4.0587)	acc@1: 48.2266	acc@5: 63.3450	
2023-03-18 09:59:48,097 - INFO - Train: [29/90][1800/3907]	eta 0:06:24 lr 0.03118386	time 0.1868 (0.1825)	loss 4.3962 (4.0914)	acc@1: 49.1060	acc@5: 67.0231	
2023-03-18 10:00:42,442 - INFO - Train: [29/90][2100/3907]	eta 0:05:29 lr 0.03118386	time 0.1827 (0.1823)	loss 5.0082 (4.1119)	acc@1: 39.4078	acc@5: 58.5422	
2023-03-18 10:01:36,797 - INFO - Train: [29/90][2400/3907]	eta 0:04:34 lr 0.03118386	time 0.1791 (0.1821)	loss 2.9716 (4.1364)	acc@1: 68.8992	acc@5: 85.1546	
2023-03-18 10:02:31,020 - INFO - Train: [29/90][2700/3907]	eta 0:03:39 lr 0.03118386	time 0.1791 (0.1820)	loss 5.9412 (4.1501)	acc@1: 25.2784	acc@5: 44.5302	
2023-03-18 10:03:25,241 - INFO - Train: [29/90][3000/3907]	eta 0:02:44 lr 0.03118386	time 0.1796 (0.1819)	loss 4.7763 (4.1635)	acc@1: 46.1933	acc@5: 62.1834	
2023-03-18 10:04:19,468 - INFO - Train: [29/90][3300/3907]	eta 0:01:50 lr 0.03118386	time 0.1815 (0.1818)	loss 2.7766 (4.1728)	acc@1: 67.1252	acc@5: 85.0771	
2023-03-18 10:05:13,791 - INFO - Train: [29/90][3600/3907]	eta 0:00:55 lr 0.03118386	time 0.1790 (0.1817)	loss 3.2287 (4.1804)	acc@1: 62.3948	acc@5: 77.6080	
2023-03-18 10:06:08,176 - INFO - Train: [29/90][3900/3907]	eta 0:00:01 lr 0.03118386	time 0.1780 (0.1817)	loss 3.3291 (4.1827)	acc@1: 57.2414	acc@5: 78.6047	
2023-03-18 10:06:09,419 - INFO - EPOCH 29 training takes 0:11:49
2023-03-18 10:06:10,484 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/fold1_latest.pth saved !!!
2023-03-18 10:06:10,485 - INFO - **********Latest test***********
2023-03-18 10:06:10,485 - INFO - eval epoch 29
2023-03-18 10:06:11,083 - INFO - Test: [0/782]	Time 0.597 (0.597)	Loss 2.7126 (2.7126)	Acc@1 66.406 (66.406)	Acc@5 89.062 (89.062)
2023-03-18 10:08:10,328 - INFO - Test: [200/782]	Time 0.586 (0.596)	Loss 3.0089 (3.0818)	Acc@1 60.156 (58.423)	Acc@5 81.250 (81.452)
2023-03-18 10:10:08,958 - INFO - Test: [400/782]	Time 0.601 (0.595)	Loss 2.8396 (3.0412)	Acc@1 63.281 (59.338)	Acc@5 85.156 (82.123)
2023-03-18 10:12:08,739 - INFO - Test: [600/782]	Time 0.583 (0.596)	Loss 3.0618 (3.0028)	Acc@1 60.156 (60.243)	Acc@5 82.031 (82.729)
2023-03-18 10:13:55,260 - INFO -  * Acc@1 60.657 Acc@5 83.206
2023-03-18 10:13:55,260 - INFO - Max accuracy: 61.8030%
2023-03-18 10:13:55,261 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-18 10:13:58,108 - INFO - Train: [30/90][0/3907]	eta 3:05:10 lr 0.03059839	time 2.8438 (2.8438)	loss 2.7709 (2.7709)	acc@1: 67.8176	acc@5: 87.0839	
2023-03-18 10:14:52,287 - INFO - Train: [30/90][300/3907]	eta 0:11:23 lr 0.03059839	time 0.1862 (0.1894)	loss 3.4142 (4.1636)	acc@1: 63.4441	acc@5: 80.9459	
2023-03-18 10:15:46,454 - INFO - Train: [30/90][600/3907]	eta 0:10:11 lr 0.03059839	time 0.1844 (0.1850)	loss 4.8019 (4.1057)	acc@1: 43.7270	acc@5: 64.0508	
2023-03-18 10:16:40,668 - INFO - Train: [30/90][900/3907]	eta 0:09:12 lr 0.03059839	time 0.1789 (0.1836)	loss 4.1728 (4.1221)	acc@1: 53.4348	acc@5: 70.5472	
2023-03-18 10:17:34,823 - INFO - Train: [30/90][1200/3907]	eta 0:08:14 lr 0.03059839	time 0.1827 (0.1828)	loss 5.7513 (4.1174)	acc@1: 27.1484	acc@5: 41.9868	
2023-03-18 10:18:29,056 - INFO - Train: [30/90][1500/3907]	eta 0:07:19 lr 0.03059839	time 0.1848 (0.1824)	loss 2.7965 (4.1278)	acc@1: 66.8851	acc@5: 85.5498	
2023-03-18 10:19:23,304 - INFO - Train: [30/90][1800/3907]	eta 0:06:23 lr 0.03059839	time 0.1795 (0.1821)	loss 2.9917 (4.1405)	acc@1: 61.4607	acc@5: 86.0450	
2023-03-18 10:20:17,559 - INFO - Train: [30/90][2100/3907]	eta 0:05:28 lr 0.03059839	time 0.1793 (0.1820)	loss 5.9896 (4.1515)	acc@1: 21.3711	acc@5: 37.6401	
2023-03-18 10:21:11,719 - INFO - Train: [30/90][2400/3907]	eta 0:04:33 lr 0.03059839	time 0.1793 (0.1818)	loss 5.5064 (4.1642)	acc@1: 36.3660	acc@5: 46.6975	
2023-03-18 10:22:05,821 - INFO - Train: [30/90][2700/3907]	eta 0:03:39 lr 0.03059839	time 0.1790 (0.1816)	loss 2.5889 (4.1611)	acc@1: 67.7741	acc@5: 92.7025	
2023-03-18 10:22:59,932 - INFO - Train: [30/90][3000/3907]	eta 0:02:44 lr 0.03059839	time 0.1787 (0.1815)	loss 4.7679 (4.1677)	acc@1: 49.3235	acc@5: 64.7206	
2023-03-18 10:23:53,975 - INFO - Train: [30/90][3300/3907]	eta 0:01:50 lr 0.03059839	time 0.1785 (0.1814)	loss 5.9384 (4.1682)	acc@1: 26.8593	acc@5: 39.5283	
2023-03-18 10:24:48,035 - INFO - Train: [30/90][3600/3907]	eta 0:00:55 lr 0.03059839	time 0.1792 (0.1813)	loss 5.5806 (4.1737)	acc@1: 33.4950	acc@5: 45.4021	
2023-03-18 10:25:42,166 - INFO - Train: [30/90][3900/3907]	eta 0:00:01 lr 0.03059839	time 0.1780 (0.1812)	loss 3.0851 (4.1761)	acc@1: 65.1949	acc@5: 84.9282	
2023-03-18 10:25:43,397 - INFO - EPOCH 30 training takes 0:11:48
2023-03-18 10:25:44,496 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/fold1_latest.pth saved !!!
2023-03-18 10:25:44,496 - INFO - **********Latest test***********
2023-03-18 10:25:44,496 - INFO - eval epoch 30
2023-03-18 10:25:45,117 - INFO - Test: [0/782]	Time 0.620 (0.620)	Loss 2.5806 (2.5806)	Acc@1 67.188 (67.188)	Acc@5 92.188 (92.188)
2023-03-18 10:27:43,197 - INFO - Test: [200/782]	Time 0.584 (0.591)	Loss 3.0692 (3.1620)	Acc@1 64.062 (57.676)	Acc@5 82.812 (80.648)
2023-03-18 10:29:41,498 - INFO - Test: [400/782]	Time 0.586 (0.591)	Loss 3.0315 (3.1238)	Acc@1 62.500 (58.485)	Acc@5 83.594 (81.332)
2023-03-18 10:31:40,157 - INFO - Test: [600/782]	Time 0.585 (0.592)	Loss 3.1675 (3.0895)	Acc@1 58.594 (59.298)	Acc@5 82.812 (82.018)
2023-03-18 10:33:25,515 - INFO -  * Acc@1 59.836 Acc@5 82.515
2023-03-18 10:33:25,515 - INFO - Max accuracy: 61.8030%
2023-03-18 10:33:25,515 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-18 10:33:28,440 - INFO - Train: [31/90][0/3907]	eta 3:10:11 lr 0.03000000	time 2.9209 (2.9209)	loss 4.2954 (4.2954)	acc@1: 50.3988	acc@5: 69.7480	
2023-03-18 10:34:22,549 - INFO - Train: [31/90][300/3907]	eta 0:11:23 lr 0.03000000	time 0.1783 (0.1895)	loss 4.6343 (4.0406)	acc@1: 43.4675	acc@5: 64.4920	
2023-03-18 10:35:16,369 - INFO - Train: [31/90][600/3907]	eta 0:10:09 lr 0.03000000	time 0.1796 (0.1844)	loss 3.2123 (4.0787)	acc@1: 60.2726	acc@5: 83.6282	
2023-03-18 10:36:10,419 - INFO - Train: [31/90][900/3907]	eta 0:09:10 lr 0.03000000	time 0.1788 (0.1830)	loss 4.1131 (4.1092)	acc@1: 54.3244	acc@5: 71.7619	
2023-03-18 10:37:04,474 - INFO - Train: [31/90][1200/3907]	eta 0:08:13 lr 0.03000000	time 0.1824 (0.1823)	loss 3.4382 (4.1331)	acc@1: 61.5102	acc@5: 79.0704	
2023-03-18 10:37:58,598 - INFO - Train: [31/90][1500/3907]	eta 0:07:17 lr 0.03000000	time 0.1885 (0.1819)	loss 5.5851 (4.1466)	acc@1: 32.7710	acc@5: 47.0347	
2023-03-18 10:38:52,716 - INFO - Train: [31/90][1800/3907]	eta 0:06:22 lr 0.03000000	time 0.1783 (0.1817)	loss 2.5864 (4.1633)	acc@1: 71.0593	acc@5: 89.8003	
2023-03-18 10:39:46,733 - INFO - Train: [31/90][2100/3907]	eta 0:05:27 lr 0.03000000	time 0.1813 (0.1814)	loss 2.9254 (4.1615)	acc@1: 65.6055	acc@5: 83.3645	
2023-03-18 10:40:40,773 - INFO - Train: [31/90][2400/3907]	eta 0:04:33 lr 0.03000000	time 0.1789 (0.1813)	loss 5.0546 (4.1609)	acc@1: 40.3619	acc@5: 54.5443	
2023-03-18 10:41:34,921 - INFO - Train: [31/90][2700/3907]	eta 0:03:38 lr 0.03000000	time 0.1864 (0.1812)	loss 3.1076 (4.1627)	acc@1: 60.6815	acc@5: 82.1975	
2023-03-18 10:42:29,301 - INFO - Train: [31/90][3000/3907]	eta 0:02:44 lr 0.03000000	time 0.1789 (0.1812)	loss 4.2348 (4.1539)	acc@1: 49.4028	acc@5: 70.0986	
2023-03-18 10:43:23,463 - INFO - Train: [31/90][3300/3907]	eta 0:01:49 lr 0.03000000	time 0.1796 (0.1811)	loss 2.9004 (4.1574)	acc@1: 61.7433	acc@5: 84.1252	
2023-03-18 10:44:17,596 - INFO - Train: [31/90][3600/3907]	eta 0:00:55 lr 0.03000000	time 0.1868 (0.1811)	loss 3.7094 (4.1651)	acc@1: 62.3829	acc@5: 75.8520	
2023-03-18 10:45:11,678 - INFO - Train: [31/90][3900/3907]	eta 0:00:01 lr 0.03000000	time 0.1787 (0.1810)	loss 6.1506 (4.1672)	acc@1: 20.1129	acc@5: 34.4026	
2023-03-18 10:45:12,953 - INFO - EPOCH 31 training takes 0:11:47
2023-03-18 10:45:14,028 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/fold1_latest.pth saved !!!
2023-03-18 10:45:14,028 - INFO - **********Latest test***********
2023-03-18 10:45:14,028 - INFO - eval epoch 31
2023-03-18 10:45:14,640 - INFO - Test: [0/782]	Time 0.610 (0.610)	Loss 2.6425 (2.6425)	Acc@1 66.406 (66.406)	Acc@5 89.062 (89.062)
2023-03-18 10:47:13,559 - INFO - Test: [200/782]	Time 0.592 (0.595)	Loss 2.8729 (3.0768)	Acc@1 66.406 (58.741)	Acc@5 82.031 (81.367)
2023-03-18 10:49:11,634 - INFO - Test: [400/782]	Time 0.583 (0.593)	Loss 2.8767 (3.0430)	Acc@1 61.719 (59.550)	Acc@5 82.812 (82.059)
2023-03-18 10:51:08,175 - INFO - Test: [600/782]	Time 0.567 (0.589)	Loss 3.1292 (3.0063)	Acc@1 57.031 (60.505)	Acc@5 78.906 (82.636)
2023-03-18 10:52:52,851 - INFO -  * Acc@1 61.003 Acc@5 83.103
2023-03-18 10:52:52,852 - INFO - Max accuracy: 61.8030%
2023-03-18 10:52:52,852 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-18 10:52:55,050 - INFO - Train: [32/90][0/3907]	eta 2:22:55 lr 0.02938943	time 2.1950 (2.1950)	loss 3.4538 (3.4538)	acc@1: 60.6804	acc@5: 81.6090	
2023-03-18 10:53:49,173 - INFO - Train: [32/90][300/3907]	eta 0:11:14 lr 0.02938943	time 0.1789 (0.1871)	loss 3.2251 (4.0906)	acc@1: 61.2575	acc@5: 74.8953	
2023-03-18 10:54:43,629 - INFO - Train: [32/90][600/3907]	eta 0:10:09 lr 0.02938943	time 0.1797 (0.1843)	loss 3.7299 (4.1364)	acc@1: 57.3868	acc@5: 77.4968	
2023-03-18 10:55:37,811 - INFO - Train: [32/90][900/3907]	eta 0:09:10 lr 0.02938943	time 0.1803 (0.1831)	loss 6.1679 (4.1330)	acc@1: 17.2523	acc@5: 33.7883	
2023-03-18 10:56:32,163 - INFO - Train: [32/90][1200/3907]	eta 0:08:14 lr 0.02938943	time 0.1794 (0.1826)	loss 4.7142 (4.1196)	acc@1: 48.7169	acc@5: 67.1580	
2023-03-18 10:57:26,703 - INFO - Train: [32/90][1500/3907]	eta 0:07:19 lr 0.02938943	time 0.1797 (0.1824)	loss 5.2932 (4.1381)	acc@1: 38.4866	acc@5: 54.2390	
2023-03-18 10:58:21,062 - INFO - Train: [32/90][1800/3907]	eta 0:06:23 lr 0.02938943	time 0.1795 (0.1822)	loss 6.0741 (4.1420)	acc@1: 23.1209	acc@5: 37.4367	
2023-03-18 10:59:15,187 - INFO - Train: [32/90][2100/3907]	eta 0:05:28 lr 0.02938943	time 0.1793 (0.1820)	loss 4.0545 (4.1547)	acc@1: 52.2283	acc@5: 72.9858	
2023-03-18 11:00:09,274 - INFO - Train: [32/90][2400/3907]	eta 0:04:33 lr 0.02938943	time 0.1796 (0.1818)	loss 3.1576 (4.1611)	acc@1: 68.0855	acc@5: 86.0243	
2023-03-18 11:01:03,569 - INFO - Train: [32/90][2700/3907]	eta 0:03:39 lr 0.02938943	time 0.1842 (0.1817)	loss 6.2974 (4.1695)	acc@1: 20.2649	acc@5: 34.5560	
2023-03-18 11:01:58,616 - INFO - Train: [32/90][3000/3907]	eta 0:02:44 lr 0.02938943	time 0.1815 (0.1819)	loss 4.1691 (4.1623)	acc@1: 55.3632	acc@5: 70.2167	
2023-03-18 11:02:53,037 - INFO - Train: [32/90][3300/3907]	eta 0:01:50 lr 0.02938943	time 0.1795 (0.1818)	loss 5.8606 (4.1703)	acc@1: 27.2441	acc@5: 38.0779	
2023-03-18 11:03:47,102 - INFO - Train: [32/90][3600/3907]	eta 0:00:55 lr 0.02938943	time 0.1857 (0.1817)	loss 5.8121 (4.1763)	acc@1: 28.9802	acc@5: 40.2731	
2023-03-18 11:04:41,226 - INFO - Train: [32/90][3900/3907]	eta 0:00:01 lr 0.02938943	time 0.1783 (0.1816)	loss 2.6376 (4.1787)	acc@1: 72.8185	acc@5: 89.6817	
2023-03-18 11:04:42,451 - INFO - EPOCH 32 training takes 0:11:49
2023-03-18 11:04:43,515 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/fold1_latest.pth saved !!!
2023-03-18 11:04:43,518 - INFO - **********Latest test***********
2023-03-18 11:04:43,518 - INFO - eval epoch 32
2023-03-18 11:04:44,150 - INFO - Test: [0/782]	Time 0.628 (0.628)	Loss 2.6704 (2.6704)	Acc@1 62.500 (62.500)	Acc@5 91.406 (91.406)
2023-03-18 11:06:42,117 - INFO - Test: [200/782]	Time 0.589 (0.590)	Loss 2.9164 (3.0623)	Acc@1 60.156 (59.398)	Acc@5 83.594 (81.915)
2023-03-18 11:08:40,342 - INFO - Test: [400/782]	Time 0.602 (0.591)	Loss 2.9444 (3.0261)	Acc@1 60.156 (60.184)	Acc@5 82.812 (82.659)
2023-03-18 11:10:40,970 - INFO - Test: [600/782]	Time 0.626 (0.595)	Loss 3.0693 (2.9885)	Acc@1 60.156 (61.087)	Acc@5 82.812 (83.208)
2023-03-18 11:12:27,533 - INFO -  * Acc@1 61.602 Acc@5 83.650
2023-03-18 11:12:27,533 - INFO - Max accuracy: 61.8030%
2023-03-18 11:12:27,533 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-18 11:12:29,677 - INFO - Train: [33/90][0/3907]	eta 2:19:16 lr 0.02876742	time 2.1389 (2.1389)	loss 2.7070 (2.7070)	acc@1: 69.4056	acc@5: 85.7819	
2023-03-18 11:13:23,637 - INFO - Train: [33/90][300/3907]	eta 0:11:12 lr 0.02876742	time 0.1811 (0.1864)	loss 2.8455 (3.9781)	acc@1: 65.3708	acc@5: 84.0512	
2023-03-18 11:14:17,797 - INFO - Train: [33/90][600/3907]	eta 0:10:06 lr 0.02876742	time 0.1796 (0.1835)	loss 4.0065 (4.0096)	acc@1: 56.3174	acc@5: 71.7069	
2023-03-18 11:15:12,057 - INFO - Train: [33/90][900/3907]	eta 0:09:09 lr 0.02876742	time 0.1794 (0.1826)	loss 2.7798 (4.0562)	acc@1: 76.2744	acc@5: 86.9475	
2023-03-18 11:16:06,285 - INFO - Train: [33/90][1200/3907]	eta 0:08:13 lr 0.02876742	time 0.1798 (0.1821)	loss 5.9046 (4.0446)	acc@1: 24.6805	acc@5: 38.6786	
2023-03-18 11:17:00,659 - INFO - Train: [33/90][1500/3907]	eta 0:07:17 lr 0.02876742	time 0.1792 (0.1820)	loss 6.2409 (4.0511)	acc@1: 19.9783	acc@5: 31.2626	
2023-03-18 11:17:54,910 - INFO - Train: [33/90][1800/3907]	eta 0:06:22 lr 0.02876742	time 0.1800 (0.1818)	loss 6.3390 (4.0603)	acc@1: 15.6088	acc@5: 28.4492	
2023-03-18 11:18:49,016 - INFO - Train: [33/90][2100/3907]	eta 0:05:28 lr 0.02876742	time 0.1791 (0.1816)	loss 2.8354 (4.0710)	acc@1: 68.6262	acc@5: 85.0026	
2023-03-18 11:19:43,097 - INFO - Train: [33/90][2400/3907]	eta 0:04:33 lr 0.02876742	time 0.1801 (0.1814)	loss 2.8172 (4.0909)	acc@1: 63.1811	acc@5: 85.8027	
2023-03-18 11:20:37,242 - INFO - Train: [33/90][2700/3907]	eta 0:03:38 lr 0.02876742	time 0.1859 (0.1813)	loss 5.3294 (4.1034)	acc@1: 39.2179	acc@5: 51.5590	
2023-03-18 11:21:31,540 - INFO - Train: [33/90][3000/3907]	eta 0:02:44 lr 0.02876742	time 0.1795 (0.1813)	loss 2.6615 (4.1024)	acc@1: 69.4149	acc@5: 88.1336	
2023-03-18 11:22:25,743 - INFO - Train: [33/90][3300/3907]	eta 0:01:49 lr 0.02876742	time 0.1795 (0.1812)	loss 4.8009 (4.1060)	acc@1: 44.9377	acc@5: 63.7366	
2023-03-18 11:23:19,846 - INFO - Train: [33/90][3600/3907]	eta 0:00:55 lr 0.02876742	time 0.1809 (0.1811)	loss 6.0206 (4.1275)	acc@1: 20.1252	acc@5: 35.8356	
2023-03-18 11:24:14,291 - INFO - Train: [33/90][3900/3907]	eta 0:00:01 lr 0.02876742	time 0.1852 (0.1812)	loss 3.8253 (4.1357)	acc@1: 58.7070	acc@5: 73.8780	
2023-03-18 11:24:15,513 - INFO - EPOCH 33 training takes 0:11:47
2023-03-18 11:24:16,451 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/fold1_latest.pth saved !!!
2023-03-18 11:24:16,451 - INFO - **********Latest test***********
2023-03-18 11:24:16,451 - INFO - eval epoch 33
2023-03-18 11:24:17,034 - INFO - Test: [0/782]	Time 0.581 (0.581)	Loss 2.6867 (2.6867)	Acc@1 62.500 (62.500)	Acc@5 90.625 (90.625)
2023-03-18 11:26:16,299 - INFO - Test: [200/782]	Time 0.607 (0.596)	Loss 3.0343 (3.0094)	Acc@1 57.812 (59.915)	Acc@5 82.031 (82.327)
2023-03-18 11:28:15,430 - INFO - Test: [400/782]	Time 0.597 (0.596)	Loss 2.9594 (2.9716)	Acc@1 61.719 (60.764)	Acc@5 78.125 (83.029)
2023-03-18 11:30:15,115 - INFO - Test: [600/782]	Time 0.591 (0.597)	Loss 2.9838 (2.9366)	Acc@1 63.281 (61.624)	Acc@5 83.594 (83.589)
2023-03-18 11:32:01,851 - INFO -  * Acc@1 62.138 Acc@5 84.087
2023-03-18 11:32:01,851 - INFO - Max accuracy: 62.1380%
2023-03-18 11:32:02,792 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/fold1_best.pth saved !!!
2023-03-18 11:32:02,793 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-18 11:32:05,673 - INFO - Train: [34/90][0/3907]	eta 3:07:12 lr 0.02813473	time 2.8751 (2.8751)	loss 2.7532 (2.7532)	acc@1: 68.6880	acc@5: 84.8952	
2023-03-18 11:32:59,847 - INFO - Train: [34/90][300/3907]	eta 0:11:23 lr 0.02813473	time 0.1859 (0.1895)	loss 5.4866 (4.0762)	acc@1: 36.1554	acc@5: 49.6014	
2023-03-18 11:33:54,194 - INFO - Train: [34/90][600/3907]	eta 0:10:12 lr 0.02813473	time 0.1801 (0.1853)	loss 3.6888 (4.0310)	acc@1: 58.6045	acc@5: 77.6686	
2023-03-18 11:34:48,488 - INFO - Train: [34/90][900/3907]	eta 0:09:12 lr 0.02813473	time 0.1800 (0.1839)	loss 2.7667 (4.0188)	acc@1: 64.7517	acc@5: 85.8166	
2023-03-18 11:35:42,739 - INFO - Train: [34/90][1200/3907]	eta 0:08:15 lr 0.02813473	time 0.1798 (0.1831)	loss 3.2601 (4.0375)	acc@1: 59.5907	acc@5: 78.4671	
2023-03-18 11:36:36,914 - INFO - Train: [34/90][1500/3907]	eta 0:07:19 lr 0.02813473	time 0.1800 (0.1826)	loss 3.0676 (4.0523)	acc@1: 64.7942	acc@5: 85.8900	
2023-03-18 11:37:31,030 - INFO - Train: [34/90][1800/3907]	eta 0:06:23 lr 0.02813473	time 0.1799 (0.1822)	loss 5.9037 (4.0665)	acc@1: 21.2060	acc@5: 37.4070	
2023-03-18 11:38:25,224 - INFO - Train: [34/90][2100/3907]	eta 0:05:28 lr 0.02813473	time 0.1792 (0.1820)	loss 4.0172 (4.0694)	acc@1: 52.0481	acc@5: 72.3499	
2023-03-18 11:39:19,395 - INFO - Train: [34/90][2400/3907]	eta 0:04:34 lr 0.02813473	time 0.1799 (0.1818)	loss 3.0539 (4.0718)	acc@1: 61.8077	acc@5: 81.9011	
2023-03-18 11:40:13,727 - INFO - Train: [34/90][2700/3907]	eta 0:03:39 lr 0.02813473	time 0.1903 (0.1818)	loss 6.0738 (4.0788)	acc@1: 22.2895	acc@5: 35.2596	
2023-03-18 11:41:07,973 - INFO - Train: [34/90][3000/3907]	eta 0:02:44 lr 0.02813473	time 0.1797 (0.1817)	loss 5.3364 (4.0907)	acc@1: 30.7066	acc@5: 52.6150	
2023-03-18 11:42:02,219 - INFO - Train: [34/90][3300/3907]	eta 0:01:50 lr 0.02813473	time 0.1793 (0.1816)	loss 5.4478 (4.1038)	acc@1: 32.1484	acc@5: 50.5814	
2023-03-18 11:42:56,511 - INFO - Train: [34/90][3600/3907]	eta 0:00:55 lr 0.02813473	time 0.1799 (0.1815)	loss 4.7664 (4.1138)	acc@1: 40.3234	acc@5: 63.3471	
2023-03-18 11:43:51,266 - INFO - Train: [34/90][3900/3907]	eta 0:00:01 lr 0.02813473	time 0.1785 (0.1816)	loss 5.3265 (4.1222)	acc@1: 36.6935	acc@5: 53.9070	
2023-03-18 11:43:52,469 - INFO - EPOCH 34 training takes 0:11:49
2023-03-18 11:43:53,549 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/fold1_latest.pth saved !!!
2023-03-18 11:43:53,549 - INFO - **********Latest test***********
2023-03-18 11:43:53,549 - INFO - eval epoch 34
2023-03-18 11:43:54,159 - INFO - Test: [0/782]	Time 0.608 (0.608)	Loss 2.6989 (2.6989)	Acc@1 66.406 (66.406)	Acc@5 85.156 (85.156)
2023-03-18 11:45:51,212 - INFO - Test: [200/782]	Time 0.582 (0.585)	Loss 3.0247 (3.0022)	Acc@1 59.375 (60.479)	Acc@5 78.125 (82.844)
2023-03-18 11:47:48,995 - INFO - Test: [400/782]	Time 0.612 (0.587)	Loss 2.8048 (2.9697)	Acc@1 66.406 (61.460)	Acc@5 84.375 (83.409)
2023-03-18 11:49:48,692 - INFO - Test: [600/782]	Time 0.583 (0.591)	Loss 2.9570 (2.9352)	Acc@1 64.844 (62.292)	Acc@5 85.156 (83.946)
2023-03-18 11:51:35,393 - INFO -  * Acc@1 62.852 Acc@5 84.342
2023-03-18 11:51:35,394 - INFO - Max accuracy: 62.8520%
2023-03-18 11:51:36,435 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/fold1_best.pth saved !!!
2023-03-18 11:51:36,435 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-18 11:51:38,571 - INFO - Train: [35/90][0/3907]	eta 2:18:45 lr 0.02749213	time 2.1310 (2.1310)	loss 2.8679 (2.8679)	acc@1: 64.0542	acc@5: 79.6772	
2023-03-18 11:52:33,438 - INFO - Train: [35/90][300/3907]	eta 0:11:23 lr 0.02749213	time 0.1786 (0.1894)	loss 3.1269 (3.9688)	acc@1: 64.2824	acc@5: 84.9710	
2023-03-18 11:53:28,121 - INFO - Train: [35/90][600/3907]	eta 0:10:14 lr 0.02749213	time 0.1796 (0.1858)	loss 3.0735 (4.0284)	acc@1: 64.8899	acc@5: 80.1450	
2023-03-18 11:54:22,617 - INFO - Train: [35/90][900/3907]	eta 0:09:14 lr 0.02749213	time 0.1794 (0.1844)	loss 6.1045 (3.9979)	acc@1: 22.1732	acc@5: 32.3376	
2023-03-18 11:55:16,910 - INFO - Train: [35/90][1200/3907]	eta 0:08:16 lr 0.02749213	time 0.1797 (0.1836)	loss 4.8225 (4.0250)	acc@1: 45.2324	acc@5: 61.7833	
2023-03-18 11:56:11,156 - INFO - Train: [35/90][1500/3907]	eta 0:07:20 lr 0.02749213	time 0.1800 (0.1830)	loss 2.6441 (4.0500)	acc@1: 76.2222	acc@5: 86.2282	
2023-03-18 11:57:05,562 - INFO - Train: [35/90][1800/3907]	eta 0:06:25 lr 0.02749213	time 0.1825 (0.1827)	loss 3.0934 (4.0501)	acc@1: 65.3160	acc@5: 83.1187	
2023-03-18 11:58:00,106 - INFO - Train: [35/90][2100/3907]	eta 0:05:29 lr 0.02749213	time 0.1855 (0.1826)	loss 2.9782 (4.0537)	acc@1: 66.5396	acc@5: 78.1454	
2023-03-18 11:58:54,324 - INFO - Train: [35/90][2400/3907]	eta 0:04:34 lr 0.02749213	time 0.1799 (0.1824)	loss 5.3283 (4.0656)	acc@1: 34.2108	acc@5: 53.7709	
2023-03-18 11:59:48,678 - INFO - Train: [35/90][2700/3907]	eta 0:03:39 lr 0.02749213	time 0.1795 (0.1822)	loss 2.6733 (4.0676)	acc@1: 69.4076	acc@5: 88.1243	
2023-03-18 12:00:43,203 - INFO - Train: [35/90][3000/3907]	eta 0:02:45 lr 0.02749213	time 0.1800 (0.1822)	loss 4.3839 (4.0830)	acc@1: 51.2104	acc@5: 70.6574	
2023-03-18 12:01:37,709 - INFO - Train: [35/90][3300/3907]	eta 0:01:50 lr 0.02749213	time 0.1794 (0.1821)	loss 2.7683 (4.0888)	acc@1: 69.5112	acc@5: 85.1319	
2023-03-18 12:02:32,135 - INFO - Train: [35/90][3600/3907]	eta 0:00:55 lr 0.02749213	time 0.1874 (0.1821)	loss 3.9048 (4.0853)	acc@1: 54.9055	acc@5: 71.7754	
2023-03-18 12:03:26,470 - INFO - Train: [35/90][3900/3907]	eta 0:00:01 lr 0.02749213	time 0.1787 (0.1820)	loss 5.5505 (4.0898)	acc@1: 33.0423	acc@5: 49.6514	
2023-03-18 12:03:27,709 - INFO - EPOCH 35 training takes 0:11:51
2023-03-18 12:03:28,651 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/fold1_latest.pth saved !!!
2023-03-18 12:03:28,652 - INFO - **********Latest test***********
2023-03-18 12:03:28,652 - INFO - eval epoch 35
2023-03-18 12:03:29,257 - INFO - Test: [0/782]	Time 0.605 (0.605)	Loss 2.6859 (2.6859)	Acc@1 65.625 (65.625)	Acc@5 88.281 (88.281)
2023-03-18 12:05:27,137 - INFO - Test: [200/782]	Time 0.571 (0.589)	Loss 3.0386 (3.0614)	Acc@1 61.719 (59.748)	Acc@5 85.938 (82.023)
2023-03-18 12:07:24,481 - INFO - Test: [400/782]	Time 0.593 (0.588)	Loss 2.9740 (3.0299)	Acc@1 60.938 (60.439)	Acc@5 79.688 (82.612)
2023-03-18 12:09:23,186 - INFO - Test: [600/782]	Time 0.600 (0.590)	Loss 3.0460 (2.9937)	Acc@1 59.375 (61.350)	Acc@5 83.594 (83.187)
2023-03-18 12:11:08,560 - INFO -  * Acc@1 61.752 Acc@5 83.600
2023-03-18 12:11:08,560 - INFO - Max accuracy: 62.8520%
2023-03-18 12:11:08,560 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-18 12:11:10,715 - INFO - Train: [36/90][0/3907]	eta 2:20:01 lr 0.02684040	time 2.1505 (2.1505)	loss 5.9487 (5.9487)	acc@1: 23.1656	acc@5: 35.2663	
2023-03-18 12:12:04,976 - INFO - Train: [36/90][300/3907]	eta 0:11:15 lr 0.02684040	time 0.1773 (0.1874)	loss 2.6968 (4.0155)	acc@1: 71.0937	acc@5: 86.7187	
2023-03-18 12:12:59,029 - INFO - Train: [36/90][600/3907]	eta 0:10:07 lr 0.02684040	time 0.1798 (0.1838)	loss 5.0994 (3.9395)	acc@1: 38.6841	acc@5: 59.7496	
2023-03-18 12:13:53,345 - INFO - Train: [36/90][900/3907]	eta 0:09:09 lr 0.02684040	time 0.1816 (0.1829)	loss 5.9459 (3.9779)	acc@1: 20.0975	acc@5: 37.9521	
2023-03-18 12:14:47,845 - INFO - Train: [36/90][1200/3907]	eta 0:08:14 lr 0.02684040	time 0.1797 (0.1826)	loss 4.6215 (4.0236)	acc@1: 48.9693	acc@5: 65.1424	
2023-03-18 12:15:42,358 - INFO - Train: [36/90][1500/3907]	eta 0:07:19 lr 0.02684040	time 0.1821 (0.1824)	loss 5.9919 (4.0304)	acc@1: 23.7541	acc@5: 37.7753	
2023-03-18 12:16:36,693 - INFO - Train: [36/90][1800/3907]	eta 0:06:23 lr 0.02684040	time 0.1900 (0.1822)	loss 3.0193 (4.0330)	acc@1: 66.6545	acc@5: 81.0459	
2023-03-18 12:17:31,719 - INFO - Train: [36/90][2100/3907]	eta 0:05:29 lr 0.02684040	time 0.1868 (0.1824)	loss 2.6538 (4.0408)	acc@1: 69.3616	acc@5: 88.8447	
2023-03-18 12:18:26,405 - INFO - Train: [36/90][2400/3907]	eta 0:04:34 lr 0.02684040	time 0.1876 (0.1824)	loss 4.7357 (4.0509)	acc@1: 45.7639	acc@5: 64.5709	
2023-03-18 12:19:21,081 - INFO - Train: [36/90][2700/3907]	eta 0:03:40 lr 0.02684040	time 0.1874 (0.1823)	loss 3.3233 (4.0562)	acc@1: 60.8291	acc@5: 81.3821	
2023-03-18 12:20:15,582 - INFO - Train: [36/90][3000/3907]	eta 0:02:45 lr 0.02684040	time 0.1829 (0.1823)	loss 2.9326 (4.0613)	acc@1: 68.6642	acc@5: 86.0455	
2023-03-18 12:21:10,199 - INFO - Train: [36/90][3300/3907]	eta 0:01:50 lr 0.02684040	time 0.1801 (0.1823)	loss 2.9232 (4.0726)	acc@1: 61.4704	acc@5: 85.5905	
2023-03-18 12:22:04,873 - INFO - Train: [36/90][3600/3907]	eta 0:00:55 lr 0.02684040	time 0.1843 (0.1823)	loss 3.8178 (4.0783)	acc@1: 60.8886	acc@5: 76.7209	
2023-03-18 12:22:58,969 - INFO - Train: [36/90][3900/3907]	eta 0:00:01 lr 0.02684040	time 0.1784 (0.1821)	loss 4.4662 (4.0868)	acc@1: 46.4030	acc@5: 64.5675	
2023-03-18 12:23:00,188 - INFO - EPOCH 36 training takes 0:11:51
2023-03-18 12:23:01,258 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/fold1_latest.pth saved !!!
2023-03-18 12:23:01,259 - INFO - **********Latest test***********
2023-03-18 12:23:01,259 - INFO - eval epoch 36
2023-03-18 12:23:01,861 - INFO - Test: [0/782]	Time 0.597 (0.597)	Loss 2.6409 (2.6409)	Acc@1 68.750 (68.750)	Acc@5 88.281 (88.281)
2023-03-18 12:25:00,624 - INFO - Test: [200/782]	Time 0.584 (0.594)	Loss 2.9120 (3.0059)	Acc@1 64.844 (60.343)	Acc@5 82.031 (82.560)
2023-03-18 12:26:58,545 - INFO - Test: [400/782]	Time 0.592 (0.592)	Loss 2.8030 (2.9636)	Acc@1 66.406 (61.407)	Acc@5 82.031 (83.167)
2023-03-18 12:28:58,408 - INFO - Test: [600/782]	Time 0.585 (0.594)	Loss 2.9963 (2.9328)	Acc@1 61.719 (62.166)	Acc@5 82.031 (83.691)
2023-03-18 12:30:45,780 - INFO -  * Acc@1 62.683 Acc@5 84.188
2023-03-18 12:30:45,780 - INFO - Max accuracy: 62.8520%
2023-03-18 12:30:45,780 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-18 12:30:48,573 - INFO - Train: [37/90][0/3907]	eta 3:01:29 lr 0.02618034	time 2.7872 (2.7872)	loss 5.3963 (5.3963)	acc@1: 35.6997	acc@5: 50.0785	
2023-03-18 12:31:42,848 - INFO - Train: [37/90][300/3907]	eta 0:11:23 lr 0.02618034	time 0.1889 (0.1896)	loss 4.8589 (3.9918)	acc@1: 46.6221	acc@5: 60.1625	
2023-03-18 12:32:37,076 - INFO - Train: [37/90][600/3907]	eta 0:10:12 lr 0.02618034	time 0.1814 (0.1852)	loss 5.2208 (4.0492)	acc@1: 39.4223	acc@5: 54.3685	
2023-03-18 12:33:31,424 - INFO - Train: [37/90][900/3907]	eta 0:09:12 lr 0.02618034	time 0.1792 (0.1838)	loss 3.0069 (4.0561)	acc@1: 60.5737	acc@5: 82.3227	
2023-03-18 12:34:25,723 - INFO - Train: [37/90][1200/3907]	eta 0:08:15 lr 0.02618034	time 0.1804 (0.1831)	loss 2.5502 (4.0523)	acc@1: 68.7445	acc@5: 88.2742	
2023-03-18 12:35:19,925 - INFO - Train: [37/90][1500/3907]	eta 0:07:19 lr 0.02618034	time 0.1796 (0.1826)	loss 6.2673 (4.0401)	acc@1: 19.3486	acc@5: 34.0845	
2023-03-18 12:36:14,386 - INFO - Train: [37/90][1800/3907]	eta 0:06:24 lr 0.02618034	time 0.1967 (0.1824)	loss 3.5918 (4.0443)	acc@1: 61.1289	acc@5: 78.3888	
2023-03-18 12:37:08,742 - INFO - Train: [37/90][2100/3907]	eta 0:05:29 lr 0.02618034	time 0.1795 (0.1823)	loss 4.9125 (4.0341)	acc@1: 45.1226	acc@5: 60.8840	
2023-03-18 12:38:03,040 - INFO - Train: [37/90][2400/3907]	eta 0:04:34 lr 0.02618034	time 0.1818 (0.1821)	loss 5.8599 (4.0425)	acc@1: 22.6149	acc@5: 42.6867	
2023-03-18 12:38:57,794 - INFO - Train: [37/90][2700/3907]	eta 0:03:39 lr 0.02618034	time 0.1817 (0.1822)	loss 3.0606 (4.0498)	acc@1: 60.6903	acc@5: 81.6984	
2023-03-18 12:39:52,263 - INFO - Train: [37/90][3000/3907]	eta 0:02:45 lr 0.02618034	time 0.1797 (0.1821)	loss 5.0111 (4.0596)	acc@1: 42.5024	acc@5: 58.9653	
2023-03-18 12:40:46,633 - INFO - Train: [37/90][3300/3907]	eta 0:01:50 lr 0.02618034	time 0.1797 (0.1820)	loss 5.6919 (4.0580)	acc@1: 24.5130	acc@5: 41.5475	
2023-03-18 12:41:41,126 - INFO - Train: [37/90][3600/3907]	eta 0:00:55 lr 0.02618034	time 0.1796 (0.1820)	loss 5.7816 (4.0609)	acc@1: 24.4676	acc@5: 41.6908	
2023-03-18 12:42:35,407 - INFO - Train: [37/90][3900/3907]	eta 0:00:01 lr 0.02618034	time 0.1789 (0.1819)	loss 2.9561 (4.0667)	acc@1: 63.1192	acc@5: 79.4834	
2023-03-18 12:42:36,648 - INFO - EPOCH 37 training takes 0:11:50
2023-03-18 12:42:37,725 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/fold1_latest.pth saved !!!
2023-03-18 12:42:37,726 - INFO - **********Latest test***********
2023-03-18 12:42:37,727 - INFO - eval epoch 37
2023-03-18 12:42:38,328 - INFO - Test: [0/782]	Time 0.598 (0.598)	Loss 2.6401 (2.6401)	Acc@1 66.406 (66.406)	Acc@5 89.844 (89.844)
2023-03-18 12:44:36,960 - INFO - Test: [200/782]	Time 0.598 (0.593)	Loss 2.8791 (2.9750)	Acc@1 60.938 (60.545)	Acc@5 81.250 (82.789)
2023-03-18 12:46:35,913 - INFO - Test: [400/782]	Time 0.596 (0.594)	Loss 2.7318 (2.9417)	Acc@1 67.969 (61.378)	Acc@5 85.938 (83.442)
2023-03-18 12:48:35,965 - INFO - Test: [600/782]	Time 0.581 (0.596)	Loss 2.9225 (2.9091)	Acc@1 56.250 (62.209)	Acc@5 81.250 (83.937)
2023-03-18 12:50:21,519 - INFO -  * Acc@1 62.774 Acc@5 84.476
2023-03-18 12:50:21,519 - INFO - Max accuracy: 62.8520%
2023-03-18 12:50:21,519 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-18 12:50:23,749 - INFO - Train: [38/90][0/3907]	eta 2:24:54 lr 0.02551275	time 2.2253 (2.2253)	loss 5.8484 (5.8484)	acc@1: 21.0938	acc@5: 37.5760	
2023-03-18 12:51:18,587 - INFO - Train: [38/90][300/3907]	eta 0:11:23 lr 0.02551275	time 0.1868 (0.1896)	loss 5.3619 (4.0502)	acc@1: 36.5980	acc@5: 53.0777	
2023-03-18 12:52:13,417 - INFO - Train: [38/90][600/3907]	eta 0:10:15 lr 0.02551275	time 0.1835 (0.1862)	loss 5.0924 (4.0175)	acc@1: 37.9078	acc@5: 55.9661	
2023-03-18 12:53:08,259 - INFO - Train: [38/90][900/3907]	eta 0:09:16 lr 0.02551275	time 0.1885 (0.1851)	loss 6.0188 (3.9937)	acc@1: 15.4648	acc@5: 33.0639	
2023-03-18 12:54:02,871 - INFO - Train: [38/90][1200/3907]	eta 0:08:18 lr 0.02551275	time 0.1797 (0.1843)	loss 2.5576 (3.9998)	acc@1: 72.6310	acc@5: 89.8124	
2023-03-18 12:54:57,534 - INFO - Train: [38/90][1500/3907]	eta 0:07:22 lr 0.02551275	time 0.1792 (0.1839)	loss 6.0791 (4.0130)	acc@1: 21.2398	acc@5: 36.3276	
2023-03-18 12:55:51,954 - INFO - Train: [38/90][1800/3907]	eta 0:06:26 lr 0.02551275	time 0.1797 (0.1835)	loss 2.5079 (4.0332)	acc@1: 71.0906	acc@5: 86.7148	
2023-03-18 12:56:46,540 - INFO - Train: [38/90][2100/3907]	eta 0:05:31 lr 0.02551275	time 0.1793 (0.1832)	loss 5.8976 (4.0459)	acc@1: 22.6448	acc@5: 40.3344	
2023-03-18 12:57:41,474 - INFO - Train: [38/90][2400/3907]	eta 0:04:36 lr 0.02551275	time 0.1834 (0.1832)	loss 4.6152 (4.0431)	acc@1: 49.6646	acc@5: 63.6067	
2023-03-18 12:58:36,322 - INFO - Train: [38/90][2700/3907]	eta 0:03:41 lr 0.02551275	time 0.1856 (0.1832)	loss 2.8569 (4.0445)	acc@1: 66.7635	acc@5: 88.2506	
2023-03-18 12:59:31,740 - INFO - Train: [38/90][3000/3907]	eta 0:02:46 lr 0.02551275	time 0.1844 (0.1833)	loss 2.7917 (4.0522)	acc@1: 66.3398	acc@5: 84.2911	
2023-03-18 13:00:26,964 - INFO - Train: [38/90][3300/3907]	eta 0:01:51 lr 0.02551275	time 0.1825 (0.1834)	loss 2.9510 (4.0644)	acc@1: 63.2009	acc@5: 83.2402	
2023-03-18 13:01:22,212 - INFO - Train: [38/90][3600/3907]	eta 0:00:56 lr 0.02551275	time 0.1798 (0.1835)	loss 2.8201 (4.0652)	acc@1: 70.2625	acc@5: 82.7536	
2023-03-18 13:02:17,336 - INFO - Train: [38/90][3900/3907]	eta 0:00:01 lr 0.02551275	time 0.1802 (0.1835)	loss 3.3265 (4.0762)	acc@1: 59.2055	acc@5: 78.4338	
2023-03-18 13:02:18,566 - INFO - EPOCH 38 training takes 0:11:57
2023-03-18 13:02:19,631 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/fold1_latest.pth saved !!!
2023-03-18 13:02:19,632 - INFO - **********Latest test***********
2023-03-18 13:02:19,632 - INFO - eval epoch 38
2023-03-18 13:02:20,228 - INFO - Test: [0/782]	Time 0.595 (0.595)	Loss 2.6216 (2.6216)	Acc@1 70.312 (70.312)	Acc@5 91.406 (91.406)
2023-03-18 13:04:19,072 - INFO - Test: [200/782]	Time 0.590 (0.594)	Loss 2.9170 (3.0081)	Acc@1 60.156 (60.514)	Acc@5 80.469 (82.572)
2023-03-18 13:06:19,164 - INFO - Test: [400/782]	Time 0.592 (0.597)	Loss 2.9324 (2.9786)	Acc@1 61.719 (61.195)	Acc@5 82.812 (83.247)
2023-03-18 13:08:19,766 - INFO - Test: [600/782]	Time 0.583 (0.599)	Loss 2.9348 (2.9452)	Acc@1 64.062 (61.972)	Acc@5 85.156 (83.743)
2023-03-18 13:10:05,199 - INFO -  * Acc@1 62.509 Acc@5 84.176
2023-03-18 13:10:05,199 - INFO - Max accuracy: 62.8520%
2023-03-18 13:10:05,199 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-18 13:10:07,265 - INFO - Train: [39/90][0/3907]	eta 2:14:18 lr 0.02483844	time 2.0626 (2.0626)	loss 2.4543 (2.4543)	acc@1: 77.7086	acc@5: 88.5866	
2023-03-18 13:11:01,868 - INFO - Train: [39/90][300/3907]	eta 0:11:19 lr 0.02483844	time 0.1786 (0.1883)	loss 3.0008 (3.8904)	acc@1: 71.8720	acc@5: 83.3355	
2023-03-18 13:11:56,715 - INFO - Train: [39/90][600/3907]	eta 0:10:13 lr 0.02483844	time 0.1802 (0.1855)	loss 5.4318 (3.9351)	acc@1: 34.3509	acc@5: 50.3254	
2023-03-18 13:12:51,702 - INFO - Train: [39/90][900/3907]	eta 0:09:15 lr 0.02483844	time 0.1882 (0.1848)	loss 2.5009 (3.9589)	acc@1: 75.4036	acc@5: 90.1726	
2023-03-18 13:13:46,976 - INFO - Train: [39/90][1200/3907]	eta 0:08:19 lr 0.02483844	time 0.1895 (0.1847)	loss 5.9278 (3.9619)	acc@1: 24.4284	acc@5: 38.3727	
2023-03-18 13:14:41,678 - INFO - Train: [39/90][1500/3907]	eta 0:07:23 lr 0.02483844	time 0.1850 (0.1842)	loss 5.8868 (3.9688)	acc@1: 22.5433	acc@5: 34.9311	
2023-03-18 13:15:36,686 - INFO - Train: [39/90][1800/3907]	eta 0:06:27 lr 0.02483844	time 0.1797 (0.1840)	loss 4.4357 (3.9721)	acc@1: 49.1143	acc@5: 66.2852	
2023-03-18 13:16:31,562 - INFO - Train: [39/90][2100/3907]	eta 0:05:32 lr 0.02483844	time 0.1843 (0.1839)	loss 2.9411 (3.9782)	acc@1: 68.1317	acc@5: 88.3369	
2023-03-18 13:17:25,685 - INFO - Train: [39/90][2400/3907]	eta 0:04:36 lr 0.02483844	time 0.1711 (0.1835)	loss 2.6347 (3.9837)	acc@1: 67.1874	acc@5: 85.1561	
2023-03-18 13:18:18,013 - INFO - Train: [39/90][2700/3907]	eta 0:03:40 lr 0.02483844	time 0.1712 (0.1825)	loss 2.6560 (3.9918)	acc@1: 69.4716	acc@5: 88.2055	
2023-03-18 13:19:10,368 - INFO - Train: [39/90][3000/3907]	eta 0:02:44 lr 0.02483844	time 0.1707 (0.1817)	loss 5.5546 (4.0063)	acc@1: 35.0956	acc@5: 47.9026	
2023-03-18 13:20:02,742 - INFO - Train: [39/90][3300/3907]	eta 0:01:49 lr 0.02483844	time 0.1724 (0.1810)	loss 3.0439 (4.0219)	acc@1: 63.8726	acc@5: 81.1392	
2023-03-18 13:20:55,004 - INFO - Train: [39/90][3600/3907]	eta 0:00:55 lr 0.02483844	time 0.1715 (0.1804)	loss 3.7046 (4.0291)	acc@1: 55.9426	acc@5: 77.6204	
2023-03-18 13:21:47,413 - INFO - Train: [39/90][3900/3907]	eta 0:00:01 lr 0.02483844	time 0.1709 (0.1800)	loss 6.0170 (4.0375)	acc@1: 18.7656	acc@5: 34.2879	
2023-03-18 13:21:48,569 - INFO - EPOCH 39 training takes 0:11:43
2023-03-18 13:21:49,664 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/fold1_latest.pth saved !!!
2023-03-18 13:21:49,665 - INFO - **********Latest test***********
2023-03-18 13:21:49,665 - INFO - eval epoch 39
2023-03-18 13:21:50,278 - INFO - Test: [0/782]	Time 0.612 (0.612)	Loss 2.6287 (2.6287)	Acc@1 69.531 (69.531)	Acc@5 90.625 (90.625)
2023-03-18 13:23:49,771 - INFO - Test: [200/782]	Time 0.599 (0.598)	Loss 2.9729 (3.0483)	Acc@1 60.938 (60.308)	Acc@5 82.812 (82.696)
2023-03-18 13:25:49,224 - INFO - Test: [400/782]	Time 0.578 (0.597)	Loss 2.8095 (3.0027)	Acc@1 62.500 (61.393)	Acc@5 86.719 (83.455)
2023-03-18 13:27:47,001 - INFO - Test: [600/782]	Time 0.582 (0.595)	Loss 3.0228 (2.9749)	Acc@1 57.812 (62.236)	Acc@5 82.812 (83.880)
2023-03-18 13:29:33,112 - INFO -  * Acc@1 62.858 Acc@5 84.451
2023-03-18 13:29:33,113 - INFO - Max accuracy: 62.8580%
2023-03-18 13:29:34,169 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/fold1_best.pth saved !!!
2023-03-18 13:29:34,170 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-18 13:29:36,228 - INFO - Train: [40/90][0/3907]	eta 2:13:30 lr 0.02415823	time 2.0502 (2.0502)	loss 2.7685 (2.7685)	acc@1: 71.0810	acc@5: 84.9865	
2023-03-18 13:30:31,485 - INFO - Train: [40/90][300/3907]	eta 0:11:26 lr 0.02415823	time 0.1841 (0.1904)	loss 3.2803 (4.1602)	acc@1: 67.1863	acc@5: 79.6011	
2023-03-18 13:31:27,067 - INFO - Train: [40/90][600/3907]	eta 0:10:21 lr 0.02415823	time 0.1816 (0.1878)	loss 6.1024 (4.0179)	acc@1: 20.3571	acc@5: 34.4643	
2023-03-18 13:32:22,612 - INFO - Train: [40/90][900/3907]	eta 0:09:22 lr 0.02415823	time 0.1828 (0.1869)	loss 2.9498 (4.0302)	acc@1: 64.4130	acc@5: 84.8970	
2023-03-18 13:33:17,336 - INFO - Train: [40/90][1200/3907]	eta 0:08:22 lr 0.02415823	time 0.1861 (0.1858)	loss 3.9756 (4.0121)	acc@1: 54.5329	acc@5: 73.5841	
2023-03-18 13:34:12,503 - INFO - Train: [40/90][1500/3907]	eta 0:07:26 lr 0.02415823	time 0.1809 (0.1854)	loss 3.8551 (3.9891)	acc@1: 60.3199	acc@5: 73.6464	
2023-03-18 13:35:07,747 - INFO - Train: [40/90][1800/3907]	eta 0:06:30 lr 0.02415823	time 0.1798 (0.1852)	loss 2.7027 (4.0140)	acc@1: 69.8826	acc@5: 88.3060	
2023-03-18 13:36:02,940 - INFO - Train: [40/90][2100/3907]	eta 0:05:34 lr 0.02415823	time 0.1799 (0.1850)	loss 5.1009 (4.0264)	acc@1: 38.4749	acc@5: 58.2781	
2023-03-18 13:36:58,514 - INFO - Train: [40/90][2400/3907]	eta 0:04:38 lr 0.02415823	time 0.1848 (0.1851)	loss 5.3836 (4.0342)	acc@1: 34.8578	acc@5: 51.8961	
2023-03-18 13:37:53,721 - INFO - Train: [40/90][2700/3907]	eta 0:03:43 lr 0.02415823	time 0.1797 (0.1849)	loss 4.1769 (4.0397)	acc@1: 58.4794	acc@5: 71.5926	
2023-03-18 13:38:48,874 - INFO - Train: [40/90][3000/3907]	eta 0:02:47 lr 0.02415823	time 0.1879 (0.1848)	loss 5.8066 (4.0294)	acc@1: 23.9296	acc@5: 40.7154	
2023-03-18 13:39:44,129 - INFO - Train: [40/90][3300/3907]	eta 0:01:52 lr 0.02415823	time 0.1854 (0.1848)	loss 5.0532 (4.0464)	acc@1: 45.4280	acc@5: 54.2897	
2023-03-18 13:40:39,145 - INFO - Train: [40/90][3600/3907]	eta 0:00:56 lr 0.02415823	time 0.1885 (0.1847)	loss 2.5580 (4.0464)	acc@1: 70.3036	acc@5: 89.0512	
2023-03-18 13:41:34,406 - INFO - Train: [40/90][3900/3907]	eta 0:00:01 lr 0.02415823	time 0.1800 (0.1846)	loss 4.1830 (4.0484)	acc@1: 50.3100	acc@5: 69.0506	
2023-03-18 13:41:35,609 - INFO - EPOCH 40 training takes 0:12:01
2023-03-18 13:41:36,692 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/fold1_latest.pth saved !!!
2023-03-18 13:41:36,692 - INFO - **********Latest test***********
2023-03-18 13:41:36,692 - INFO - eval epoch 40
2023-03-18 13:41:37,287 - INFO - Test: [0/782]	Time 0.594 (0.594)	Loss 2.6742 (2.6742)	Acc@1 66.406 (66.406)	Acc@5 87.500 (87.500)
2023-03-18 13:43:34,331 - INFO - Test: [200/782]	Time 0.578 (0.585)	Loss 3.0792 (3.0465)	Acc@1 60.156 (60.669)	Acc@5 80.469 (82.424)
2023-03-18 13:45:32,334 - INFO - Test: [400/782]	Time 0.601 (0.588)	Loss 2.8559 (3.0098)	Acc@1 65.625 (61.810)	Acc@5 83.594 (83.132)
2023-03-18 13:47:32,668 - INFO - Test: [600/782]	Time 0.571 (0.592)	Loss 3.0615 (2.9744)	Acc@1 57.031 (62.548)	Acc@5 82.031 (83.680)
2023-03-18 13:49:17,759 - INFO -  * Acc@1 63.041 Acc@5 84.139
2023-03-18 13:49:17,760 - INFO - Max accuracy: 63.0410%
2023-03-18 13:49:18,817 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/fold1_best.pth saved !!!
2023-03-18 13:49:18,818 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-18 13:49:21,022 - INFO - Train: [41/90][0/3907]	eta 2:23:16 lr 0.02347296	time 2.2002 (2.2002)	loss 2.5111 (2.5111)	acc@1: 78.5351	acc@5: 91.4972	
2023-03-18 13:50:15,944 - INFO - Train: [41/90][300/3907]	eta 0:11:24 lr 0.02347296	time 0.1861 (0.1898)	loss 3.1445 (3.8772)	acc@1: 68.9712	acc@5: 82.7654	
2023-03-18 13:51:10,795 - INFO - Train: [41/90][600/3907]	eta 0:10:16 lr 0.02347296	time 0.1810 (0.1863)	loss 5.6337 (3.9419)	acc@1: 27.5283	acc@5: 42.5325	
2023-03-18 13:52:06,124 - INFO - Train: [41/90][900/3907]	eta 0:09:18 lr 0.02347296	time 0.1819 (0.1857)	loss 5.9109 (3.9214)	acc@1: 25.0299	acc@5: 39.2015	
2023-03-18 13:53:01,132 - INFO - Train: [41/90][1200/3907]	eta 0:08:21 lr 0.02347296	time 0.1797 (0.1851)	loss 3.1063 (3.9301)	acc@1: 63.7923	acc@5: 84.2915	
2023-03-18 13:53:56,434 - INFO - Train: [41/90][1500/3907]	eta 0:07:25 lr 0.02347296	time 0.1833 (0.1849)	loss 5.6099 (3.9260)	acc@1: 28.8500	acc@5: 46.8511	
2023-03-18 13:54:51,542 - INFO - Train: [41/90][1800/3907]	eta 0:06:29 lr 0.02347296	time 0.1796 (0.1847)	loss 4.2847 (3.9184)	acc@1: 53.0984	acc@5: 73.3264	
2023-03-18 13:55:46,745 - INFO - Train: [41/90][2100/3907]	eta 0:05:33 lr 0.02347296	time 0.1805 (0.1846)	loss 5.7510 (3.9483)	acc@1: 26.0461	acc@5: 43.3876	
2023-03-18 13:56:41,980 - INFO - Train: [41/90][2400/3907]	eta 0:04:38 lr 0.02347296	time 0.1996 (0.1846)	loss 5.2843 (3.9560)	acc@1: 40.9737	acc@5: 50.3394	
2023-03-18 13:57:37,085 - INFO - Train: [41/90][2700/3907]	eta 0:03:42 lr 0.02347296	time 0.1800 (0.1845)	loss 5.6195 (3.9535)	acc@1: 30.2992	acc@5: 44.6552	
2023-03-18 13:58:31,801 - INFO - Train: [41/90][3000/3907]	eta 0:02:47 lr 0.02347296	time 0.1824 (0.1843)	loss 5.4177 (3.9592)	acc@1: 33.5461	acc@5: 49.6759	
2023-03-18 13:59:26,992 - INFO - Train: [41/90][3300/3907]	eta 0:01:51 lr 0.02347296	time 0.1835 (0.1842)	loss 2.6655 (3.9721)	acc@1: 69.9609	acc@5: 89.3922	
2023-03-18 14:00:22,174 - INFO - Train: [41/90][3600/3907]	eta 0:00:56 lr 0.02347296	time 0.1857 (0.1842)	loss 4.7953 (3.9770)	acc@1: 44.9087	acc@5: 62.8722	
2023-03-18 14:01:17,197 - INFO - Train: [41/90][3900/3907]	eta 0:00:01 lr 0.02347296	time 0.1858 (0.1841)	loss 2.8478 (3.9868)	acc@1: 65.9851	acc@5: 84.6147	
2023-03-18 14:01:18,404 - INFO - EPOCH 41 training takes 0:11:59
2023-03-18 14:01:19,481 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/fold1_latest.pth saved !!!
2023-03-18 14:01:19,481 - INFO - **********Latest test***********

2023-03-18 15:48:20,703 - INFO - eval epoch 41
2023-03-18 15:48:21,797 - INFO - Test: [0/782]	Time 1.093 (1.093)	Loss 2.5437 (2.5437)	Acc@1 71.875 (71.875)	Acc@5 92.188 (92.188)
2023-03-18 15:50:19,853 - INFO - Test: [200/782]	Time 0.584 (0.593)	Loss 2.8242 (2.9061)	Acc@1 67.188 (62.710)	Acc@5 82.812 (84.080)
2023-03-18 15:52:18,558 - INFO - Test: [400/782]	Time 0.589 (0.593)	Loss 2.7982 (2.8744)	Acc@1 64.844 (63.369)	Acc@5 85.156 (84.696)
2023-03-18 15:54:18,973 - INFO - Test: [600/782]	Time 0.581 (0.596)	Loss 2.9301 (2.8399)	Acc@1 63.281 (64.222)	Acc@5 84.375 (85.217)
2023-03-18 15:56:04,731 - INFO -  * Acc@1 64.701 Acc@5 85.608
2023-03-18 15:56:04,732 - INFO - Max accuracy: 64.7010%
2023-03-18 15:56:04,732 - INFO - Start training
2023-03-18 15:56:09,492 - INFO - Train: [42/90][0/3907]	eta 5:09:42 lr 0.02278346	time 4.7563 (4.7563)	loss 3.2071 (3.2071)	acc@1: 67.7426	acc@5: 81.0158	
2023-03-18 15:57:04,805 - INFO - Train: [42/90][300/3907]	eta 0:11:59 lr 0.02278346	time 0.1844 (0.1996)	loss 5.4817 (4.0160)	acc@1: 28.7120	acc@5: 46.4146	
2023-03-18 15:57:59,616 - INFO - Train: [42/90][600/3907]	eta 0:10:32 lr 0.02278346	time 0.1846 (0.1911)	loss 3.1840 (3.9977)	acc@1: 67.1348	acc@5: 82.3408	
2023-03-18 15:58:54,510 - INFO - Train: [42/90][900/3907]	eta 0:09:26 lr 0.02278346	time 0.1957 (0.1884)	loss 4.2231 (3.9712)	acc@1: 55.4223	acc@5: 70.8169	
2023-03-18 15:59:49,312 - INFO - Train: [42/90][1200/3907]	eta 0:08:26 lr 0.02278346	time 0.1850 (0.1870)	loss 3.4700 (3.9421)	acc@1: 63.0718	acc@5: 79.5395	
2023-03-18 16:00:44,228 - INFO - Train: [42/90][1500/3907]	eta 0:07:28 lr 0.02278346	time 0.1872 (0.1862)	loss 3.2029 (3.9472)	acc@1: 63.7580	acc@5: 80.0578	
2023-03-18 16:01:39,067 - INFO - Train: [42/90][1800/3907]	eta 0:06:31 lr 0.02278346	time 0.1882 (0.1856)	loss 2.9907 (3.9590)	acc@1: 67.7052	acc@5: 82.7443	
2023-03-18 16:02:33,972 - INFO - Train: [42/90][2100/3907]	eta 0:05:34 lr 0.02278346	time 0.1810 (0.1853)	loss 5.8010 (3.9547)	acc@1: 24.1478	acc@5: 41.7959	
2023-03-18 16:03:29,211 - INFO - Train: [42/90][2400/3907]	eta 0:04:38 lr 0.02278346	time 0.1872 (0.1851)	loss 4.5243 (3.9625)	acc@1: 48.2708	acc@5: 64.7339	
2023-03-18 16:04:24,418 - INFO - Train: [42/90][2700/3907]	eta 0:03:43 lr 0.02278346	time 0.1815 (0.1850)	loss 3.1919 (3.9782)	acc@1: 66.6269	acc@5: 83.4541	
2023-03-18 16:05:19,415 - INFO - Train: [42/90][3000/3907]	eta 0:02:47 lr 0.02278346	time 0.1810 (0.1848)	loss 3.8307 (3.9829)	acc@1: 56.9676	acc@5: 74.8128	
2023-03-18 16:06:14,529 - INFO - Train: [42/90][3300/3907]	eta 0:01:52 lr 0.02278346	time 0.1883 (0.1847)	loss 2.4765 (3.9923)	acc@1: 72.6342	acc@5: 89.0354	
2023-03-18 16:07:09,940 - INFO - Train: [42/90][3600/3907]	eta 0:00:56 lr 0.02278346	time 0.1806 (0.1847)	loss 5.4380 (3.9993)	acc@1: 30.6024	acc@5: 47.5215	
2023-03-18 16:08:05,197 - INFO - Train: [42/90][3900/3907]	eta 0:00:01 lr 0.02278346	time 0.1809 (0.1847)	loss 5.1378 (4.0045)	acc@1: 42.3502	acc@5: 56.3937	
2023-03-18 16:08:06,981 - INFO - EPOCH 42 training takes 0:12:02
2023-03-18 16:08:08,054 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Latest.pth saved !!!
2023-03-18 16:08:08,055 - INFO - **********Latest test***********
2023-03-18 16:08:08,055 - INFO - eval epoch 42
2023-03-18 16:08:08,647 - INFO - Test: [0/782]	Time 0.591 (0.591)	Loss 2.5211 (2.5211)	Acc@1 68.750 (68.750)	Acc@5 92.969 (92.969)
2023-03-18 16:10:06,624 - INFO - Test: [200/782]	Time 0.571 (0.590)	Loss 3.0068 (3.0501)	Acc@1 60.938 (59.911)	Acc@5 82.031 (81.985)
2023-03-18 16:12:03,741 - INFO - Test: [400/782]	Time 0.588 (0.588)	Loss 3.0072 (3.0142)	Acc@1 57.812 (60.897)	Acc@5 80.469 (82.772)
2023-03-18 16:14:03,209 - INFO - Test: [600/782]        Time 0.593 (0.591)      Loss 3.0162 (2.9771)    Acc@1 60.156 (61.706)   Acc@5 83.594 (83.318)                              
2023-03-18 16:15:49,953 - INFO -  * Acc@1 62.247 Acc@5 83.809                   
2023-03-18 16:15:49,954 - INFO - Max accuracy: 64.7010%                         
2023-03-18 16:15:50,984 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Best.pth saved !!!
2023-03-18 16:15:50,985 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d                             
2023-03-18 16:15:53,318 - INFO - Train: [43/90][0/3907] eta 2:31:39 lr 0.02209057       time 2.3291 (2.3291)    loss 4.4473 (4.4473)    acc@1: 55.9466  acc@5: 68.5048             
2023-03-18 16:16:47,641 - INFO - Train: [43/90][300/3907]       eta 0:11:18 lr 0.02209057       time 0.1799 (0.1882)    loss 5.5242 (3.8123)    acc@1: 28.0758  acc@5: 44.5194     
2023-03-18 16:17:42,272 - INFO - Train: [43/90][600/3907]       eta 0:10:12 lr 0.02209057       time 0.1803 (0.1852)    loss 6.2016 (3.8563)    acc@1: 18.5172  acc@5: 31.4508     
2023-03-18 16:18:36,839 - INFO - Train: [43/90][900/3907]       eta 0:09:13 lr 0.02209057       time 0.1804 (0.1841)    loss 4.2120 (3.8714)    acc@1: 53.0452  acc@5: 69.8039     
2023-03-18 16:19:32,048 - INFO - Train: [43/90][1200/3907]      eta 0:08:18 lr 0.02209057       time 0.1841 (0.1841)    loss 2.7947 (3.8681)    acc@1: 65.5430  acc@5: 84.8204     
2023-03-18 16:20:27,181 - INFO - Train: [43/90][1500/3907]      eta 0:07:22 lr 0.02209057       time 0.1879 (0.1840)    loss 2.7687 (3.9169)    acc@1: 66.3601  acc@5: 86.2050     
2023-03-18 16:21:22,550 - INFO - Train: [43/90][1800/3907]      eta 0:06:27 lr 0.02209057       time 0.1810 (0.1841)    loss 2.6105 (3.9094)    acc@1: 69.9426  acc@5: 89.3675     
2023-03-18 16:22:17,693 - INFO - Train: [43/90][2100/3907]      eta 0:05:32 lr 0.02209057       time 0.1823 (0.1841)    loss 3.7554 (3.9249)    acc@1: 61.1003  acc@5: 74.8092     
2023-03-18 16:23:11,224 - INFO - Train: [43/90][2400/3907]      eta 0:04:36 lr 0.02209057       time 0.1805 (0.1834)    loss 3.5977 (3.9368)    acc@1: 66.8164  acc@5: 76.7571     
2023-03-18 16:24:03,981 - INFO - Train: [43/90][2700/3907]      eta 0:03:40 lr 0.02209057       time 0.1750 (0.1825)    loss 5.8882 (3.9440)    acc@1: 22.1878  acc@5: 39.9557     
2023-03-18 16:24:56,733 - INFO - Train: [43/90][3000/3907]      eta 0:02:44 lr 0.02209057       time 0.1763 (0.1818)    loss 4.0678 (3.9628)    acc@1: 55.2321  acc@5: 72.9451     
2023-03-18 16:25:49,018 - INFO - Train: [43/90][3300/3907]      eta 0:01:49 lr 0.02209057       time 0.1864 (0.1812)    loss 4.1419 (3.9709)    acc@1: 54.6773  acc@5: 71.2689     
2023-03-18 16:26:41,463 - INFO - Train: [43/90][3600/3907]      eta 0:00:55 lr 0.02209057       time 0.1766 (0.1806)    loss 4.0867 (3.9812)    acc@1: 55.6825  acc@5: 69.0730     
2023-03-18 16:27:34,177 - INFO - Train: [43/90][3900/3907]      eta 0:00:01 lr 0.02209057       time 0.1735 (0.1803)    loss 4.3362 (3.9853)    acc@1: 48.2465  acc@5: 70.4205     
2023-03-18 16:27:35,343 - INFO - EPOCH 43 training takes 0:11:44                
2023-03-18 16:27:36,446 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Latest.pth saved !!! 
2023-03-18 16:27:36,446 - INFO - **********Latest test***********               
2023-03-18 16:27:36,447 - INFO - eval epoch 43 
2023-03-18 16:27:37,055 - INFO - Test: [0/782]  Time 0.607 (0.607)      Loss 2.6018 (2.6018)    Acc@1 65.625 (65.625)   Acc@5 89.062 (89.062)     
2023-03-18 16:29:39,253 - INFO - Test: [200/782]        Time 0.578 (0.611)      Loss 2.8362 (2.9039)    Acc@1 66.406 (62.924)   Acc@5 85.156 (84.239)                              
2023-03-18 16:31:43,556 - INFO - Test: [400/782]        Time 0.665 (0.616)      Loss 2.6166 (2.8675)    Acc@1 70.312 (63.611)   Acc@5 88.281 (84.856)                              
2023-03-18 16:33:43,343 - INFO - Test: [600/782]        Time 0.593 (0.610)      Loss 2.8956 (2.8322)    Acc@1 58.594 (64.511)   Acc@5 85.938 (85.373)                              
2023-03-18 16:35:29,795 - INFO -  * Acc@1 65.093 Acc@5 85.848                   
2023-03-18 16:35:29,795 - INFO - Max accuracy: 65.0930%                         
2023-03-18 16:35:30,739 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Best.pth saved !!!
2023-03-18 16:35:30,740 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d                             
2023-03-18 16:35:33,133 - INFO - Train: [44/90][0/3907] eta 2:35:34 lr 0.02139513       time 2.3891 (2.3891)    loss 3.5232 (3.5232)    acc@1: 60.5582  acc@5: 77.9488             
2023-03-18 16:36:28,353 - INFO - Train: [44/90][300/3907]       eta 0:11:30 lr 0.02139513       time 0.1797 (0.1914)    loss 3.5273 (3.8490)    acc@1: 63.3420  acc@5: 76.1385     
2023-03-18 16:37:23,227 - INFO - Train: [44/90][600/3907]       eta 0:10:18 lr 0.02139513       time 0.1883 (0.1872)    loss 3.2369 (3.8369)    acc@1: 66.7789  acc@5: 82.9233     
2023-03-18 16:38:17,819 - INFO - Train: [44/90][900/3907]       eta 0:09:17 lr 0.02139513       time 0.1812 (0.1854)    loss 2.9629 (3.8669)    acc@1: 69.1887  acc@5: 84.9818     
2023-03-18 16:39:13,011 - INFO - Train: [44/90][1200/3907]      eta 0:08:20 lr 0.02139513       time 0.1819 (0.1851)    loss 3.7806 (3.8970)    acc@1: 59.6711  acc@5: 77.9473     
2023-03-18 16:40:08,153 - INFO - Train: [44/90][1500/3907]      eta 0:07:24 lr 0.02139513       time 0.1814 (0.1848)    loss 2.6730 (3.9084)    acc@1: 71.2941  acc@5: 86.7992     
2023-03-18 16:41:03,029 - INFO - Train: [44/90][1800/3907]      eta 0:06:28 lr 0.02139513       time 0.1848 (0.1845)    loss 2.5654 (3.9029)    acc@1: 69.7597  acc@5: 89.1340     
2023-03-18 16:41:57,922 - INFO - Train: [44/90][2100/3907]      eta 0:05:32 lr 0.02139513       time 0.1897 (0.1843)    loss 3.5048 (3.9078)    acc@1: 63.0931  acc@5: 77.4026     
2023-03-18 16:42:53,128 - INFO - Train: [44/90][2400/3907]      eta 0:04:37 lr 0.02139513       time 0.1808 (0.1842)    loss 5.1947 (3.9304)    acc@1: 37.1946  acc@5: 54.6301     
2023-03-18 16:43:48,204 - INFO - Train: [44/90][2700/3907]      eta 0:03:42 lr 0.02139513       time 0.1820 (0.1842)    loss 3.1632 (3.9493)    acc@1: 60.6846  acc@5: 82.4112     
2023-03-18 16:44:43,158 - INFO - Train: [44/90][3000/3907]      eta 0:02:46 lr 0.02139513       time 0.1904 (0.1841)    loss 5.1771 (3.9436)    acc@1: 38.1201  acc@5: 55.6061     
2023-03-18 16:45:38,100 - INFO - Train: [44/90][3300/3907]      eta 0:01:51 lr 0.02139513       time 0.1891 (0.1840)    loss 3.6409 (3.9358)    acc@1: 59.3940  acc@5: 77.2637     
2023-03-18 16:46:33,389 - INFO - Train: [44/90][3600/3907]      eta 0:00:56 lr 0.02139513       time 0.1811 (0.1840)    loss 2.8826 (3.9398)    acc@1: 62.2076  acc@5: 86.3117     
2023-03-18 16:47:28,608 - INFO - Train: [44/90][3900/3907]      eta 0:00:01 lr 0.02139513       time 0.1797 (0.1840)    loss 3.0438 (3.9523)    acc@1: 68.1653  acc@5: 85.2067     
2023-03-18 16:47:29,826 - INFO - EPOCH 44 training takes 0:11:59                
2023-03-18 16:47:30,904 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Latest.pth saved !!!
 2023-03-18 16:47:30,904 - INFO - **********Latest test***********               
2023-03-18 16:47:30,904 - INFO - eval epoch 44 
2023-03-18 16:47:31,506 - INFO - Test: [0/782]  Time 0.601 (0.601)      Loss 2.5898 (2.5898)    Acc@1 70.312 (70.312)   Acc@5 92.188 (92.188)     
2023-03-18 16:49:28,772 - INFO - Test: [200/782]        Time 0.581 (0.586)      Loss 2.7553 (2.9183)    Acc@1 66.406 (62.737)   Acc@5 88.281 (84.235)                              
2023-03-18 16:51:26,911 - INFO - Test: [400/782]        Time 0.586 (0.589)      Loss 2.8499 (2.8872)    Acc@1 61.719 (63.611)   Acc@5 85.156 (84.936)                              
2023-03-18 16:53:25,931 - INFO - Test: [600/782]        Time 0.624 (0.591)      Loss 2.9424 (2.8529)    Acc@1 59.375 (64.411)   Acc@5 82.812 (85.463)                              
2023-03-18 16:55:12,135 - INFO -  * Acc@1 64.969 Acc@5 85.824                   
2023-03-18 16:55:12,135 - INFO - Max accuracy: 65.0930%                         
2023-03-18 16:55:12,135 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d                             
2023-03-18 16:55:14,494 - INFO - Train: [45/90][0/3907] eta 2:33:24 lr 0.02069799       time 2.3559 (2.3559)    loss 2.4960 (2.4960)    acc@1: 73.3755  acc@5: 90.5482             
2023-03-18 16:56:09,460 - INFO - Train: [45/90][300/3907]       eta 0:11:26 lr 0.02069799       time 0.1850 (0.1904)    loss 3.1472 (3.8164)    acc@1: 66.5530  acc@5: 81.5275     
2023-03-18 16:57:04,520 - INFO - Train: [45/90][600/3907]       eta 0:10:18 lr 0.02069799       time 0.1847 (0.1870)    loss 5.8019 (3.9115)    acc@1: 20.5917  acc@5: 41.2982     
2023-03-18 16:57:59,560 - INFO - Train: [45/90][900/3907]       eta 0:09:18 lr 0.02069799       time 0.1898 (0.1858)    loss 5.9529 (3.8928)    acc@1: 23.4461  acc@5: 37.5115     
2023-03-18 16:58:54,661 - INFO - Train: [45/90][1200/3907]      eta 0:08:21 lr 0.02069799       time 0.1851 (0.1853)    loss 3.8749 (3.8906)    acc@1: 58.5137  acc@5: 70.8849     
2023-03-18 16:59:49,576 - INFO - Train: [45/90][1500/3907]      eta 0:07:24 lr 0.02069799       time 0.1820 (0.1848)    loss 5.7513 (3.8673)    acc@1: 23.3611  acc@5: 42.7079     
2023-03-18 17:00:44,398 - INFO - Train: [45/90][1800/3907]      eta 0:06:28 lr 0.02069799       time 0.1833 (0.1845)    loss 2.4809 (3.8914)    acc@1: 73.2999  acc@5: 94.3536     
2023-03-18 17:01:39,291 - INFO - Train: [45/90][2100/3907]      eta 0:05:32 lr 0.02069799       time 0.1802 (0.1843)    loss 4.7285 (3.8911)    acc@1: 46.3424  acc@5: 62.1027     
2023-03-18 17:02:33,887 - INFO - Train: [45/90][2400/3907]      eta 0:04:37 lr 0.02069799       time 0.1808 (0.1840)    loss 3.8443 (3.8996)    acc@1: 61.3911  acc@5: 74.1865     
2023-03-18 17:03:28,717 - INFO - Train: [45/90][2700/3907]      eta 0:03:41 lr 0.02069799       time 0.1852 (0.1838)    loss 2.8693 (3.9101)    acc@1: 65.1953  acc@5: 87.4384     
2023-03-18 17:04:23,070 - INFO - Train: [45/90][3000/3907]      eta 0:02:46 lr 0.02069799       time 0.1724 (0.1836)    loss 2.7280 (3.9192)    acc@1: 65.6135  acc@5: 85.1413     
2023-03-18 17:05:15,424 - INFO - Train: [45/90][3300/3907]      eta 0:01:50 lr 0.02069799       time 0.1732 (0.1828)    loss 5.9348 (3.9268)    acc@1: 23.8662  acc@5: 37.5037     
2023-03-18 17:06:07,584 - INFO - Train: [45/90][3600/3907]      eta 0:00:55 lr 0.02069799       time 0.1712 (0.1820)    loss 3.5858 (3.9225)    acc@1: 62.7718  acc@5: 78.6139     
2023-03-18 17:06:59,815 - INFO - Train: [45/90][3900/3907]      eta 0:00:01 lr 0.02069799       time 0.1712 (0.1814)    loss 5.8774 (3.9267)    acc@1: 29.5014  acc@5: 43.5198     
2023-03-18 17:07:01,010 - INFO - EPOCH 45 training takes 0:11:48                
2023-03-18 17:07:02,087 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Latest.pth saved !!!
2023-03-18 17:07:02,087 - INFO - **********Latest test***********               
2023-03-18 17:07:02,087 - INFO - eval epoch 45 
2023-03-18 17:07:02,679 - INFO - Test: [0/782]  Time 0.591 (0.591)      Loss 2.5498 (2.5498)    Acc@1 68.750 (68.750)   Acc@5 91.406 (91.406)     
2023-03-18 17:08:59,048 - INFO - Test: [200/782]        Time 0.577 (0.582)      Loss 2.7036 (2.8881)    Acc@1 70.312 (64.000)   Acc@5 85.156 (84.639)                              
2023-03-18 17:10:55,820 - INFO - Test: [400/782]        Time 0.589 (0.583)      Loss 2.6748 (2.8550)    Acc@1 67.969 (64.737)   Acc@5 88.281 (85.156)                              
2023-03-18 17:12:53,933 - INFO - Test: [600/782]        Time 0.570 (0.585)      Loss 2.8303 (2.8168)    Acc@1 60.938 (65.534)   Acc@5 84.375 (85.800)                              
2023-03-18 17:14:38,391 - INFO -  * Acc@1 66.012 Acc@5 86.242                   
2023-03-18 17:14:38,392 - INFO - Max accuracy: 66.0120%                         
2023-03-18 17:14:39,547 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Best.pth saved !!!
2023-03-18 17:14:39,548 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d                             
2023-03-18 17:14:41,971 - INFO - Train: [46/90][0/3907] eta 2:37:30 lr 0.02000000       time 2.4190 (2.4190)    loss 2.2931 (2.2931)    acc@1: 85.8813  acc@5: 92.9079             
2023-03-18 17:15:36,615 - INFO - Train: [46/90][300/3907]       eta 0:11:23 lr 0.02000000       time 0.1804 (0.1896)    loss 3.5933 (3.7758)    acc@1: 59.6841  acc@5: 76.5361     
2023-03-18 17:16:31,654 - INFO - Train: [46/90][600/3907]       eta 0:10:16 lr 0.02000000       time 0.1804 (0.1865)    loss 4.1005 (3.8472)    acc@1: 61.1263  acc@5: 70.7079     
2023-03-18 17:17:26,530 - INFO - Train: [46/90][900/3907]       eta 0:09:17 lr 0.02000000       time 0.1802 (0.1853)    loss 2.6351 (3.8317)    acc@1: 72.2154  acc@5: 88.3457     
2023-03-18 17:18:21,314 - INFO - Train: [46/90][1200/3907]      eta 0:08:19 lr 0.02000000       time 0.1881 (0.1846)    loss 2.6187 (3.8648)    acc@1: 67.8048  acc@5: 87.2890     
2023-03-18 17:19:16,133 - INFO - Train: [46/90][1500/3907]      eta 0:07:23 lr 0.02000000       time 0.1888 (0.1843)    loss 5.8155 (3.8700)    acc@1: 18.8134  acc@5: 37.3153     
2023-03-18 17:20:10,924 - INFO - Train: [46/90][1800/3907]      eta 0:06:27 lr 0.02000000       time 0.1811 (0.1840)    loss 4.1715 (3.8675)    acc@1: 55.0010  acc@5: 71.5314     
2023-03-18 17:21:05,940 - INFO - Train: [46/90][2100/3907]      eta 0:05:32 lr 0.02000000       time 0.1813 (0.1839)    loss 5.6435 (3.8770)    acc@1: 22.9395  acc@5: 38.4357     
2023-03-18 17:22:00,896 - INFO - Train: [46/90][2400/3907]      eta 0:04:37 lr 0.02000000       time 0.1869 (0.1838)    loss 2.8213 (3.8930)    acc@1: 65.0791  acc@5: 83.4499     
2023-03-18 17:22:55,837 - INFO - Train: [46/90][2700/3907]      eta 0:03:41 lr 0.02000000       time 0.1809 (0.1837)    loss 2.7509 (3.8924)    acc@1: 72.1696  acc@5: 85.2191     
2023-03-18 17:23:50,670 - INFO - Train: [46/90][3000/3907]      eta 0:02:46 lr 0.02000000       time 0.1805 (0.1836)    loss 3.4937 (3.8946)    acc@1: 57.8443  acc@5: 75.4173     
2023-03-18 17:24:45,853 - INFO - Train: [46/90][3300/3907]      eta 0:01:51 lr 0.02000000       time 0.1807 (0.1837)    loss 2.4620 (3.9134)    acc@1: 71.0858  acc@5: 92.1772     
2023-03-18 17:25:40,711 - INFO - Train: [46/90][3600/3907]      eta 0:00:56 lr 0.02000000       time 0.1806 (0.1836)    loss 3.1064 (3.9110)    acc@1: 62.0644  acc@5: 85.9798     
2023-03-18 17:26:35,683 - INFO - Train: [46/90][3900/3907]      eta 0:00:01 lr 0.02000000       time 0.1798 (0.1836)    loss 3.0857 (3.9173)    acc@1: 70.1947  acc@5: 84.9725     
2023-03-18 17:26:36,905 - INFO - EPOCH 46 training takes 0:11:57                
2023-03-18 17:26:37,981 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Latest.pth saved !!! 
2023-03-18 17:26:37,982 - INFO - **********Latest test***********               
2023-03-18 17:26:37,982 - INFO - eval epoch 46 
2023-03-18 17:26:38,604 - INFO - Test: [0/782]  Time 0.621 (0.621)      Loss 2.4007 (2.4007)    Acc@1 71.875 (71.875)   Acc@5 92.969 (92.969)     
2023-03-18 17:28:35,634 - INFO - Test: [200/782]        Time 0.579 (0.585)      Loss 2.7864 (2.8498)    Acc@1 64.844 (63.775)   Acc@5 84.375 (84.841)                              
2023-03-18 17:30:32,248 - INFO - Test: [400/782]        Time 0.588 (0.584)      Loss 2.6227 (2.8130)    Acc@1 67.188 (64.799)   Acc@5 89.062 (85.478)                              
2023-03-18 17:32:29,843 - INFO - Test: [600/782]        Time 0.576 (0.585)      Loss 2.8480 (2.7780)    Acc@1 62.500 (65.734)   Acc@5 83.594 (86.071)                              
2023-03-18 17:34:13,930 - INFO -  * Acc@1 66.299 Acc@5 86.501                   
2023-03-18 17:34:13,931 - INFO - Max accuracy: 66.2990%                         
2023-03-18 17:34:14,983 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Best.pth saved !!!
2023-03-18 17:34:14,983 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d                             
2023-03-18 17:34:17,423 - INFO - Train: [47/90][0/3907] eta 2:38:38 lr 0.01930201       time 2.4362 (2.4362)    loss 3.2826 (3.2826)    acc@1: 69.8324  acc@5: 79.1830             
2023-03-18 17:35:12,701 - INFO - Train: [47/90][300/3907]       eta 0:11:31 lr 0.01930201       time 0.1803 (0.1917)    loss 2.6169 (3.8400)    acc@1: 72.7649  acc@5: 89.7933     
2023-03-18 17:36:07,772 - INFO - Train: [47/90][600/3907]       eta 0:10:20 lr 0.01930201       time 0.1817 (0.1877)    loss 3.8610 (3.8760)    acc@1: 64.3814  acc@5: 75.6227     
2023-03-18 17:37:03,214 - INFO - Train: [47/90][900/3907]       eta 0:09:21 lr 0.01930201       time 0.1858 (0.1867)    loss 5.8813 (3.8776)    acc@1: 19.3926  acc@5: 37.2228     
2023-03-18 17:37:58,144 - INFO - Train: [47/90][1200/3907]      eta 0:08:22 lr 0.01930201       time 0.1882 (0.1858)    loss 3.6647 (3.8689)    acc@1: 57.2137  acc@5: 80.0532     
2023-03-18 17:38:53,108 - INFO - Train: [47/90][1500/3907]      eta 0:07:25 lr 0.01930201       time 0.1836 (0.1853)    loss 2.6621 (3.8612)    acc@1: 66.8836  acc@5: 88.6584     
2023-03-18 17:39:47,885 - INFO - Train: [47/90][1800/3907]      eta 0:06:29 lr 0.01930201       time 0.1805 (0.1848)    loss 3.7095 (3.8732)    acc@1: 63.5244  acc@5: 78.5282     
2023-03-18 17:40:42,722 - INFO - Train: [47/90][2100/3907]      eta 0:05:33 lr 0.01930201       time 0.1830 (0.1845)    loss 3.4272 (3.8795)    acc@1: 60.6972  acc@5: 82.8338     
2023-03-18 17:41:37,722 - INFO - Train: [47/90][2400/3907]      eta 0:04:37 lr 0.01930201       time 0.1828 (0.1844)    loss 4.0238 (3.8949)    acc@1: 62.0610  acc@5: 75.2395     
2023-03-18 17:42:32,497 - INFO - Train: [47/90][2700/3907]      eta 0:03:42 lr 0.01930201       time 0.1853 (0.1842)    loss 3.5824 (3.8910)    acc@1: 59.6765  acc@5: 77.2049     
2023-03-18 17:43:27,182 - INFO - Train: [47/90][3000/3907]      eta 0:02:46 lr 0.01930201       time 0.1807 (0.1840)    loss 4.4127 (3.8957)    acc@1: 55.7918  acc@5: 67.1115     
2023-03-18 17:44:21,985 - INFO - Train: [47/90][3300/3907]      eta 0:01:51 lr 0.01930201       time 0.1862 (0.1839)    loss 4.0572 (3.8946)    acc@1: 58.2192  acc@5: 72.0836     
2023-03-18 17:45:16,728 - INFO - Train: [47/90][3600/3907]      eta 0:00:56 lr 0.01930201       time 0.1824 (0.1838)    loss 5.7699 (3.8953)    acc@1: 28.5127  acc@5: 42.7551     
2023-03-18 17:46:11,701 - INFO - Train: [47/90][3900/3907]      eta 0:00:01 lr 0.01930201       time 0.1826 (0.1837)    loss 5.2123 (3.9063)    acc@1: 34.3092  acc@5: 51.7798     
2023-03-18 17:46:12,922 - INFO - EPOCH 47 training takes 0:11:57                
2023-03-18 17:46:13,986 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Latest.pth saved !!! 
2023-03-18 17:46:13,987 - INFO - **********Latest test***********               
2023-03-18 17:46:13,987 - INFO - eval epoch 47 
2023-03-18 17:46:14,582 - INFO - Test: [0/782]  Time 0.594 (0.594)      Loss 2.4171 (2.4171)    Acc@1 75.000 (75.000)   Acc@5 92.969 (92.969)     
2023-03-18 17:48:11,123 - INFO - Test: [200/782]        Time 0.575 (0.583)      Loss 2.8819 (2.9151)    Acc@1 65.625 (63.056)   Acc@5 83.594 (84.181)                              
2023-03-18 17:50:07,224 - INFO - Test: [400/782]        Time 0.578 (0.582)      Loss 2.8395 (2.8814)    Acc@1 65.625 (63.922)   Acc@5 86.719 (84.813)                              
2023-03-18 17:52:04,337 - INFO - Test: [600/782]        Time 0.584 (0.583)      Loss 2.8169 (2.8478)    Acc@1 62.500 (64.758)   Acc@5 87.500 (85.314)                              
2023-03-18 17:53:48,294 - INFO -  * Acc@1 65.220 Acc@5 85.733                   
2023-03-18 17:53:48,295 - INFO - Max accuracy: 66.2990%                         
2023-03-18 17:53:48,295 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d                             
2023-03-18 17:53:50,530 - INFO - Train: [48/90][0/3907] eta 2:25:19 lr 0.01860487       time 2.2317 (2.2317)    loss 4.9504 (4.9504)    acc@1: 41.5124  acc@5: 57.9096             
2023-03-18 17:54:45,204 - INFO - Train: [48/90][300/3907]       eta 0:11:21 lr 0.01860487       time 0.1844 (0.1890)    loss 2.4551 (3.6460)    acc@1: 74.3433  acc@5: 88.2826     
2023-03-18 17:55:40,054 - INFO - Train: [48/90][600/3907]       eta 0:10:14 lr 0.01860487       time 0.1804 (0.1859)    loss 5.6277 (3.7465)    acc@1: 27.5363  acc@5: 43.2847     
2023-03-18 17:56:34,926 - INFO - Train: [48/90][900/3907]       eta 0:09:16 lr 0.01860487       time 0.1813 (0.1849)    loss 2.4613 (3.7692)    acc@1: 75.6715  acc@5: 90.4935     
2023-03-18 17:57:29,730 - INFO - Train: [48/90][1200/3907]      eta 0:08:19 lr 0.01860487       time 0.1804 (0.1844)    loss 2.6294 (3.8173)    acc@1: 72.6476  acc@5: 89.0519     
2023-03-18 17:58:24,488 - INFO - Train: [48/90][1500/3907]      eta 0:07:22 lr 0.01860487       time 0.1843 (0.1840)    loss 3.8210 (3.8337)    acc@1: 57.1772  acc@5: 74.0571     
2023-03-18 17:59:19,414 - INFO - Train: [48/90][1800/3907]      eta 0:06:27 lr 0.01860487       time 0.1888 (0.1838)    loss 4.8827 (3.8514)    acc@1: 41.6955  acc@5: 60.4522     
2023-03-18 18:00:14,627 - INFO - Train: [48/90][2100/3907]      eta 0:05:32 lr 0.01860487       time 0.1804 (0.1839)    loss 4.9990 (3.8793)    acc@1: 37.9006  acc@5: 55.0047     
2023-03-18 18:01:09,442 - INFO - Train: [48/90][2400/3907]      eta 0:04:36 lr 0.01860487       time 0.1808 (0.1837)    loss 2.5195 (3.8734)    acc@1: 74.0722  acc@5: 88.8866     
2023-03-18 18:02:04,218 - INFO - Train: [48/90][2700/3907]      eta 0:03:41 lr 0.01860487       time 0.1805 (0.1836)    loss 2.6663 (3.8742)    acc@1: 77.5457  acc@5: 88.2075     
2023-03-18 18:02:59,021 - INFO - Train: [48/90][3000/3907]      eta 0:02:46 lr 0.01860487       time 0.1802 (0.1835)    loss 3.0831 (3.8798)    acc@1: 67.7545  acc@5: 84.7271     
2023-03-18 18:03:53,736 - INFO - Train: [48/90][3300/3907]      eta 0:01:51 lr 0.01860487       time 0.1842 (0.1834)    loss 2.7759 (3.8759)    acc@1: 62.4107  acc@5: 84.2563     
2023-03-18 18:04:48,650 - INFO - Train: [48/90][3600/3907]      eta 0:00:56 lr 0.01860487       time 0.1805 (0.1834)    loss 2.6681 (3.8800)    acc@1: 75.7196  acc@5: 90.3983     
2023-03-18 18:05:43,357 - INFO - Train: [48/90][3900/3907]      eta 0:00:01 lr 0.01860487       time 0.1799 (0.1833)    loss 3.8619 (3.8829)    acc@1: 61.5575  acc@5: 74.5530     
2023-03-18 18:05:44,556 - INFO - EPOCH 48 training takes 0:11:56                
2023-03-18 18:05:45,635 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Latest.pth saved !!! 
2023-03-18 18:05:45,635 - INFO - **********Latest test***********               
2023-03-18 18:05:45,635 - INFO - eval epoch 48 
2023-03-18 18:05:46,232 - INFO - Test: [0/782]  Time 0.596 (0.596)      Loss 2.5073 (2.5073)    Acc@1 67.969 (67.969)   Acc@5 89.844 (89.844)     
2023-03-18 18:07:41,756 - INFO - Test: [200/782]        Time 0.570 (0.578)      Loss 2.9139 (2.9802)    Acc@1 62.500 (61.882)   Acc@5 82.031 (83.174)                              
2023-03-18 18:09:37,416 - INFO - Test: [400/782]        Time 0.591 (0.578)      Loss 2.8825 (2.9422)    Acc@1 61.719 (62.679)   Acc@5 85.156 (83.944)                              
2023-03-18 18:11:34,111 - INFO - Test: [600/782]        Time 0.574 (0.580)      Loss 2.9908 (2.9055)    Acc@1 60.938 (63.549)   Acc@5 80.469 (84.484)                              
2023-03-18 18:13:17,797 - INFO -  * Acc@1 64.159 Acc@5 84.979                   
2023-03-18 18:13:17,797 - INFO - Max accuracy: 66.2990%                         
2023-03-18 18:13:17,797 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d                             
2023-03-18 18:13:19,993 - INFO - Train: [49/90][0/3907] eta 2:22:44 lr 0.01790943       time 2.1920 (2.1920)    loss 4.3199 (4.3199)    acc@1: 52.3008  acc@5: 68.8379             
2023-03-18 18:14:14,443 - INFO - Train: [49/90][300/3907]       eta 0:11:18 lr 0.01790943       time 0.1830 (0.1882)    loss 5.4314 (3.7889)    acc@1: 34.2541  acc@5: 49.5633     
2023-03-18 18:15:09,639 - INFO - Train: [49/90][600/3907]       eta 0:10:15 lr 0.01790943       time 0.1806 (0.1861)    loss 2.4244 (3.7990)    acc@1: 76.5721  acc@5: 92.8147     
2023-03-18 18:16:04,531 - INFO - Train: [49/90][900/3907]       eta 0:09:16 lr 0.01790943       time 0.1800 (0.1850)    loss 3.1923 (3.7799)    acc@1: 67.0380  acc@5: 82.3280     
2023-03-18 18:16:59,220 - INFO - Train: [49/90][1200/3907]      eta 0:08:19 lr 0.01790943       time 0.1869 (0.1844)    loss 5.0098 (3.8002)    acc@1: 37.3086  acc@5: 56.2100     
2023-03-18 18:17:54,103 - INFO - Train: [49/90][1500/3907]      eta 0:07:23 lr 0.01790943       time 0.1806 (0.1841)    loss 2.8665 (3.8096)    acc@1: 71.1445  acc@5: 86.8711     
2023-03-18 18:18:48,823 - INFO - Train: [49/90][1800/3907]      eta 0:06:27 lr 0.01790943       time 0.1804 (0.1838)    loss 5.8224 (3.8161)    acc@1: 17.2800  acc@5: 36.8112     
2023-03-18 18:19:43,633 - INFO - Train: [49/90][2100/3907]      eta 0:05:31 lr 0.01790943       time 0.1803 (0.1836)    loss 2.8126 (3.8228)    acc@1: 70.2678  acc@5: 89.0151     
2023-03-18 18:20:38,345 - INFO - Train: [49/90][2400/3907]      eta 0:04:36 lr 0.01790943       time 0.1861 (0.1835)    loss 2.5324 (3.8183)    acc@1: 71.4705  acc@5: 90.9006     
2023-03-18 18:21:32,932 - INFO - Train: [49/90][2700/3907]      eta 0:03:41 lr 0.01790943       time 0.1815 (0.1833)    loss 4.2036 (3.8232)    acc@1: 53.9530  acc@5: 72.8040     
2023-03-18 18:22:27,944 - INFO - Train: [49/90][3000/3907]      eta 0:02:46 lr 0.01790943       time 0.1805 (0.1833)    loss 3.3189 (3.8263)    acc@1: 69.4576  acc@5: 82.8951     
2023-03-18 18:23:22,840 - INFO - Train: [49/90][3300/3907]      eta 0:01:51 lr 0.01790943       time 0.1808 (0.1833)    loss 5.3307 (3.8412)    acc@1: 34.4069  acc@5: 52.1475     
2023-03-18 18:24:17,576 - INFO - Train: [49/90][3600/3907]      eta 0:00:56 lr 0.01790943       time 0.1807 (0.1832)    loss 5.7284 (3.8524)    acc@1: 22.9685  acc@5: 42.1612     
2023-03-18 18:25:11,173 - INFO - Train: [49/90][3900/3907]      eta 0:00:01 lr 0.01790943       time 0.1757 (0.1829)    loss 2.6306 (3.8511)    acc@1: 69.8925  acc@5: 87.7527     
2023-03-18 18:25:12,369 - INFO - EPOCH 49 training takes 0:11:54                
2023-03-18 18:25:13,440 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Latest.pth saved !!! 
2023-03-18 18:25:13,441 - INFO - **********Latest test***********               
2023-03-18 18:25:13,441 - INFO - eval epoch 49 
2023-03-18 18:25:14,038 - INFO - Test: [0/782]  Time 0.596 (0.596)      Loss 2.5106 (2.5106)    Acc@1 69.531 (69.531)   Acc@5 92.969 (92.969)     
2023-03-18 18:27:09,832 - INFO - Test: [200/782]        Time 0.578 (0.579)      Loss 2.7283 (2.7960)    Acc@1 67.969 (65.345)   Acc@5 84.375 (85.743)                              
2023-03-18 18:29:05,274 - INFO - Test: [400/782]        Time 0.588 (0.578)      Loss 2.7502 (2.7618)    Acc@1 64.844 (66.245)   Acc@5 83.594 (86.364)                              
2023-03-18 18:31:01,959 - INFO - Test: [600/782]        Time 0.560 (0.580)      Loss 2.7538 (2.7280)    Acc@1 64.062 (67.039)   Acc@5 87.500 (86.798)                              
2023-03-18 18:32:45,706 - INFO -  * Acc@1 67.621 Acc@5 87.233                   
2023-03-18 18:32:45,706 - INFO - Max accuracy: 67.6210%                         
2023-03-18 18:32:46,650 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Best.pth saved !!!
2023-03-18 18:32:46,650 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d                             
2023-03-18 18:32:48,925 - INFO - Train: [50/90][0/3907] eta 2:27:51 lr 0.01721654       time 2.2708 (2.2708)    loss 3.7339 (3.7339)    acc@1: 63.6924  acc@5: 80.7645             
2023-03-18 18:33:43,346 - INFO - Train: [50/90][300/3907]       eta 0:11:19 lr 0.01721654       time 0.1865 (0.1883)    loss 5.6266 (3.6810)    acc@1: 25.2672  acc@5: 42.0473     
2023-03-18 18:34:35,478 - INFO - Train: [50/90][600/3907]       eta 0:09:58 lr 0.01721654       time 0.1776 (0.1811)    loss 4.5091 (3.7187)    acc@1: 44.2938  acc@5: 67.5339     
2023-03-18 18:35:27,679 - INFO - Train: [50/90][900/3907]       eta 0:08:57 lr 0.01721654       time 0.1719 (0.1787)    loss 5.2919 (3.7305)    acc@1: 38.5996  acc@5: 51.4866     
2023-03-18 18:36:19,757 - INFO - Train: [50/90][1200/3907]      eta 0:08:00 lr 0.01721654       time 0.1720 (0.1774)    loss 2.5302 (3.7583)    acc@1: 75.2194  acc@5: 89.9508     
2023-03-18 18:37:11,878 - INFO - Train: [50/90][1500/3907]      eta 0:07:05 lr 0.01721654       time 0.1744 (0.1767)    loss 2.9569 (3.7658)    acc@1: 68.4431  acc@5: 87.5777     
2023-03-18 18:38:04,094 - INFO - Train: [50/90][1800/3907]      eta 0:06:11 lr 0.01721654       time 0.1792 (0.1763)    loss 2.9163 (3.7734)    acc@1: 72.1644  acc@5: 84.5563     
2023-03-18 18:38:56,293 - INFO - Train: [50/90][2100/3907]      eta 0:05:17 lr 0.01721654       time 0.1793 (0.1759)    loss 3.6394 (3.7680)    acc@1: 62.5476  acc@5: 76.9597     
2023-03-18 18:39:48,324 - INFO - Train: [50/90][2400/3907]      eta 0:04:24 lr 0.01721654       time 0.1720 (0.1756)    loss 4.6131 (3.7722)    acc@1: 51.6141  acc@5: 63.7586     
2023-03-18 18:40:40,744 - INFO - Train: [50/90][2700/3907]      eta 0:03:31 lr 0.01721654       time 0.1736 (0.1755)    loss 4.2025 (3.7785)    acc@1: 52.3961  acc@5: 70.8694     
2023-03-18 18:41:33,282 - INFO - Train: [50/90][3000/3907]      eta 0:02:39 lr 0.01721654       time 0.1721 (0.1755)    loss 3.4808 (3.7783)    acc@1: 66.8004  acc@5: 80.0042     
2023-03-18 18:42:25,468 - INFO - Train: [50/90][3300/3907]      eta 0:01:46 lr 0.01721654       time 0.1727 (0.1753)    loss 3.4302 (3.7844)    acc@1: 67.0022  acc@5: 81.6406     
2023-03-18 18:43:17,662 - INFO - Train: [50/90][3600/3907]      eta 0:00:53 lr 0.01721654       time 0.1792 (0.1752)    loss 3.2062 (3.7820)    acc@1: 69.9453  acc@5: 82.1931     
2023-03-18 18:44:10,037 - INFO - Train: [50/90][3900/3907]      eta 0:00:01 lr 0.01721654       time 0.1714 (0.1752)    loss 2.3202 (3.7826)    acc@1: 79.1700  acc@5: 94.6935     
2023-03-18 18:44:11,196 - INFO - EPOCH 50 training takes 0:11:24                
2023-03-18 18:44:12,281 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Latest.pth saved !!! 
2023-03-18 18:44:12,282 - INFO - **********Latest test***********               

2023-03-19 17:58:50,143 - INFO - eval epoch 50
2023-03-19 17:58:51,191 - INFO - Test: [0/782]	Time 1.047 (1.047)	Loss 2.4381 (2.4381)	Acc@1 74.219 (74.219)	Acc@5 95.312 (95.312)
2023-03-19 18:00:47,520 - INFO - Test: [200/782]	Time 0.583 (0.584)	Loss 2.6486 (2.7628)	Acc@1 70.312 (66.461)	Acc@5 84.375 (86.361)
2023-03-19 18:02:44,322 - INFO - Test: [400/782]	Time 0.588 (0.584)	Loss 2.6183 (2.7280)	Acc@1 67.188 (67.285)	Acc@5 88.281 (86.941)
2023-03-19 18:04:42,205 - INFO - Test: [600/782]	Time 0.567 (0.586)	Loss 2.8283 (2.6952)	Acc@1 65.625 (68.101)	Acc@5 85.938 (87.379)
2023-03-19 18:06:26,585 - INFO -  * Acc@1 68.641 Acc@5 87.791
2023-03-19 18:06:26,585 - INFO - Max accuracy: 68.6410%
2023-03-19 18:06:26,585 - INFO - Start training
2023-03-19 18:06:30,979 - INFO - Train: [51/90][0/3907]	eta 4:45:56 lr 0.01652704	time 4.3913 (4.3913)	loss 3.1003 (3.1003)	acc@1: 70.7283	acc@5: 85.4247	
2023-03-19 18:07:25,704 - INFO - Train: [51/90][300/3907]	eta 0:11:48 lr 0.01652704	time 0.1845 (0.1964)	loss 5.3127 (3.8070)	acc@1: 31.2275	acc@5: 49.2349	
2023-03-19 18:08:20,970 - INFO - Train: [51/90][600/3907]	eta 0:10:29 lr 0.01652704	time 0.1793 (0.1903)	loss 2.9823 (3.7847)	acc@1: 71.4622	acc@5: 87.3294	
2023-03-19 18:09:15,943 - INFO - Train: [51/90][900/3907]	eta 0:09:25 lr 0.01652704	time 0.1800 (0.1880)	loss 3.9842 (3.7554)	acc@1: 60.9947	acc@5: 75.7539	
2023-03-19 18:10:10,854 - INFO - Train: [51/90][1200/3907]	eta 0:08:25 lr 0.01652704	time 0.1882 (0.1867)	loss 3.1939 (3.7235)	acc@1: 73.0956	acc@5: 85.2673	
2023-03-19 18:11:05,838 - INFO - Train: [51/90][1500/3907]	eta 0:07:27 lr 0.01652704	time 0.1847 (0.1860)	loss 3.0262 (3.7243)	acc@1: 65.9807	acc@5: 84.5032	
2023-03-19 18:12:00,794 - INFO - Train: [51/90][1800/3907]	eta 0:06:30 lr 0.01652704	time 0.1791 (0.1856)	loss 2.7724 (3.7336)	acc@1: 72.9689	acc@5: 86.5041	
2023-03-19 18:12:55,877 - INFO - Train: [51/90][2100/3907]	eta 0:05:34 lr 0.01652704	time 0.1888 (0.1853)	loss 5.4400 (3.7262)	acc@1: 29.0461	acc@5: 44.9209	
2023-03-19 18:13:50,922 - INFO - Train: [51/90][2400/3907]	eta 0:04:38 lr 0.01652704	time 0.1860 (0.1851)	loss 4.2274 (3.7313)	acc@1: 53.1883	acc@5: 69.0182	
2023-03-19 18:14:45,985 - INFO - Train: [51/90][2700/3907]	eta 0:03:43 lr 0.01652704	time 0.1843 (0.1849)	loss 3.0239 (3.7435)	acc@1: 70.2850	acc@5: 87.1122	
2023-03-19 18:15:40,889 - INFO - Train: [51/90][3000/3907]	eta 0:02:47 lr 0.01652704	time 0.1794 (0.1847)	loss 3.5809 (3.7462)	acc@1: 62.4584	acc@5: 79.6173	
2023-03-19 18:16:35,803 - INFO - Train: [51/90][3300/3907]	eta 0:01:52 lr 0.01652704	time 0.1798 (0.1846)	loss 2.2896 (3.7539)	acc@1: 76.5392	acc@5: 92.9405	
2023-03-19 18:17:30,769 - INFO - Train: [51/90][3600/3907]	eta 0:00:56 lr 0.01652704	time 0.1877 (0.1844)	loss 5.0715 (3.7593)	acc@1: 38.6713	acc@5: 50.7106	
2023-03-19 18:18:25,849 - INFO - Train: [51/90][3900/3907]	eta 0:00:01 lr 0.01652704	time 0.1795 (0.1844)	loss 4.8041 (3.7629)	acc@1: 49.3106	acc@5: 61.2039	
2023-03-19 18:18:27,647 - INFO - EPOCH 51 training takes 0:12:01
2023-03-19 18:18:28,769 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Latest.pth saved !!!
2023-03-19 18:18:28,770 - INFO - **********Latest test***********
2023-03-19 18:18:28,770 - INFO - eval epoch 51
2023-03-19 18:18:29,461 - INFO - Test: [0/782]	Time 0.690 (0.690)	Loss 2.3890 (2.3890)	Acc@1 74.219 (74.219)	Acc@5 93.750 (93.750)
2023-03-19 18:20:25,121 - INFO - Test: [200/782]	Time 0.576 (0.579)	Loss 2.8220 (2.8382)	Acc@1 63.281 (65.042)	Acc@5 85.156 (85.156)
2023-03-19 18:22:22,771 - INFO - Test: [400/782]	Time 0.604 (0.584)	Loss 2.8355 (2.8022)	Acc@1 62.500 (65.968)	Acc@5 83.594 (85.817)
2023-03-19 18:24:21,570 - INFO - Test: [600/782]	Time 0.565 (0.587)	Loss 2.8696 (2.7690)	Acc@1 62.500 (66.621)	Acc@5 83.594 (86.372)
2023-03-19 18:26:05,966 - INFO -  * Acc@1 67.180 Acc@5 86.855
2023-03-19 18:26:05,966 - INFO - Max accuracy: 68.6410%
2023-03-19 18:26:07,037 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Best.pth saved !!!
2023-03-19 18:26:07,038 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-19 18:26:08,946 - INFO - Train: [52/90][0/3907]	eta 2:03:59 lr 0.01584177	time 1.9042 (1.9042)	loss 4.2679 (4.2679)	acc@1: 60.9053	acc@5: 70.9841	
2023-03-19 18:27:03,611 - INFO - Train: [52/90][300/3907]	eta 0:11:17 lr 0.01584177	time 0.1813 (0.1879)	loss 5.1625 (3.5794)	acc@1: 31.0521	acc@5: 49.5294	
2023-03-19 18:27:58,506 - INFO - Train: [52/90][600/3907]	eta 0:10:13 lr 0.01584177	time 0.1846 (0.1855)	loss 5.9228 (3.6203)	acc@1: 24.0433	acc@5: 38.2205	
2023-03-19 18:28:53,497 - INFO - Train: [52/90][900/3907]	eta 0:09:15 lr 0.01584177	time 0.1793 (0.1847)	loss 4.0543 (3.6327)	acc@1: 55.6015	acc@5: 73.7806	
2023-03-19 18:29:48,494 - INFO - Train: [52/90][1200/3907]	eta 0:08:19 lr 0.01584177	time 0.1857 (0.1844)	loss 2.4870 (3.6284)	acc@1: 76.3383	acc@5: 89.4469	
2023-03-19 18:30:43,492 - INFO - Train: [52/90][1500/3907]	eta 0:07:23 lr 0.01584177	time 0.1817 (0.1842)	loss 2.5463 (3.6741)	acc@1: 75.5107	acc@5: 91.5428	
2023-03-19 18:31:38,429 - INFO - Train: [52/90][1800/3907]	eta 0:06:27 lr 0.01584177	time 0.1876 (0.1840)	loss 2.3768 (3.6647)	acc@1: 78.4853	acc@5: 93.2525	
2023-03-19 18:32:33,369 - INFO - Train: [52/90][2100/3907]	eta 0:05:32 lr 0.01584177	time 0.1850 (0.1839)	loss 3.4696 (3.6791)	acc@1: 67.9548	acc@5: 80.2928	
2023-03-19 18:33:28,491 - INFO - Train: [52/90][2400/3907]	eta 0:04:37 lr 0.01584177	time 0.1792 (0.1839)	loss 3.3983 (3.6945)	acc@1: 66.8164	acc@5: 79.5974	
2023-03-19 18:34:23,425 - INFO - Train: [52/90][2700/3907]	eta 0:03:41 lr 0.01584177	time 0.1876 (0.1838)	loss 5.6516 (3.7073)	acc@1: 25.2458	acc@5: 45.0986	
2023-03-19 18:35:18,495 - INFO - Train: [52/90][3000/3907]	eta 0:02:46 lr 0.01584177	time 0.1832 (0.1838)	loss 3.8997 (3.7313)	acc@1: 59.8244	acc@5: 74.9132	
2023-03-19 18:36:13,550 - INFO - Train: [52/90][3300/3907]	eta 0:01:51 lr 0.01584177	time 0.1821 (0.1837)	loss 3.9894 (3.7452)	acc@1: 57.3124	acc@5: 71.1464	
2023-03-19 18:37:08,556 - INFO - Train: [52/90][3600/3907]	eta 0:00:56 lr 0.01584177	time 0.1823 (0.1837)	loss 3.9798 (3.7596)	acc@1: 55.6825	acc@5: 72.4207	
2023-03-19 18:38:03,704 - INFO - Train: [52/90][3900/3907]	eta 0:00:01 lr 0.01584177	time 0.1794 (0.1837)	loss 4.0934 (3.7681)	acc@1: 54.3759	acc@5: 70.5332	
2023-03-19 18:38:04,904 - INFO - EPOCH 52 training takes 0:11:57
2023-03-19 18:38:06,002 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Latest.pth saved !!!
2023-03-19 18:38:06,002 - INFO - **********Latest test***********
2023-03-19 18:38:06,002 - INFO - eval epoch 52
2023-03-19 18:38:06,597 - INFO - Test: [0/782]	Time 0.594 (0.594)	Loss 2.4236 (2.4236)	Acc@1 75.781 (75.781)	Acc@5 92.969 (92.969)
2023-03-19 18:40:02,763 - INFO - Test: [200/782]	Time 0.572 (0.581)	Loss 2.8045 (2.8533)	Acc@1 63.281 (64.611)	Acc@5 85.938 (85.207)
2023-03-19 18:41:59,511 - INFO - Test: [400/782]	Time 0.582 (0.582)	Loss 2.6942 (2.8197)	Acc@1 69.531 (65.479)	Acc@5 85.156 (85.873)
2023-03-19 18:43:57,008 - INFO - Test: [600/782]	Time 0.580 (0.584)	Loss 2.9288 (2.7816)	Acc@1 68.750 (66.415)	Acc@5 81.250 (86.421)
2023-03-19 18:45:40,902 - INFO -  * Acc@1 66.980 Acc@5 86.815
2023-03-19 18:45:40,903 - INFO - Max accuracy: 68.6410%
2023-03-19 18:45:40,903 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-19 18:45:42,739 - INFO - Train: [53/90][0/3907]	eta 1:59:18 lr 0.01516156	time 1.8323 (1.8323)	loss 3.3562 (3.3562)	acc@1: 64.1555	acc@5: 80.1072	
2023-03-19 18:46:37,542 - INFO - Train: [53/90][300/3907]	eta 0:11:18 lr 0.01516156	time 0.1855 (0.1882)	loss 3.3435 (3.6254)	acc@1: 69.0293	acc@5: 80.5446	
2023-03-19 18:47:32,375 - INFO - Train: [53/90][600/3907]	eta 0:10:13 lr 0.01516156	time 0.1854 (0.1855)	loss 3.0303 (3.6109)	acc@1: 67.5128	acc@5: 86.5925	
2023-03-19 18:48:27,280 - INFO - Train: [53/90][900/3907]	eta 0:09:15 lr 0.01516156	time 0.1860 (0.1846)	loss 2.7177 (3.6368)	acc@1: 72.9489	acc@5: 90.2461	
2023-03-19 18:49:22,324 - INFO - Train: [53/90][1200/3907]	eta 0:08:19 lr 0.01516156	time 0.1816 (0.1844)	loss 3.5941 (3.6632)	acc@1: 65.7632	acc@5: 78.6242	
2023-03-19 18:50:17,385 - INFO - Train: [53/90][1500/3907]	eta 0:07:23 lr 0.01516156	time 0.1843 (0.1842)	loss 2.3680 (3.6720)	acc@1: 79.0435	acc@5: 93.7799	
2023-03-19 18:51:12,304 - INFO - Train: [53/90][1800/3907]	eta 0:06:27 lr 0.01516156	time 0.1835 (0.1840)	loss 2.4327 (3.6638)	acc@1: 75.1782	acc@5: 92.2338	
2023-03-19 18:52:07,214 - INFO - Train: [53/90][2100/3907]	eta 0:05:32 lr 0.01516156	time 0.1803 (0.1839)	loss 3.2423 (3.6669)	acc@1: 70.9633	acc@5: 83.1921	
2023-03-19 18:53:02,240 - INFO - Train: [53/90][2400/3907]	eta 0:04:36 lr 0.01516156	time 0.1849 (0.1838)	loss 4.9137 (3.6874)	acc@1: 42.9721	acc@5: 58.8654	
2023-03-19 18:53:57,282 - INFO - Train: [53/90][2700/3907]	eta 0:03:41 lr 0.01516156	time 0.1904 (0.1838)	loss 3.0121 (3.7044)	acc@1: 65.1798	acc@5: 83.9096	
2023-03-19 18:54:52,382 - INFO - Train: [53/90][3000/3907]	eta 0:02:46 lr 0.01516156	time 0.1864 (0.1838)	loss 4.8381 (3.6987)	acc@1: 44.2781	acc@5: 60.6153	
2023-03-19 18:55:47,473 - INFO - Train: [53/90][3300/3907]	eta 0:01:51 lr 0.01516156	time 0.1871 (0.1837)	loss 3.3151 (3.6900)	acc@1: 67.2567	acc@5: 82.9820	
2023-03-19 18:56:42,810 - INFO - Train: [53/90][3600/3907]	eta 0:00:56 lr 0.01516156	time 0.1795 (0.1838)	loss 2.5499 (3.6932)	acc@1: 70.7607	acc@5: 90.1994	
2023-03-19 18:57:38,174 - INFO - Train: [53/90][3900/3907]	eta 0:00:01 lr 0.01516156	time 0.1791 (0.1839)	loss 2.8640 (3.7045)	acc@1: 71.8700	acc@5: 85.9476	
2023-03-19 18:57:39,364 - INFO - EPOCH 53 training takes 0:11:58
2023-03-19 18:57:40,456 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Latest.pth saved !!!
2023-03-19 18:57:40,456 - INFO - **********Latest test***********
2023-03-19 18:57:40,457 - INFO - eval epoch 53
2023-03-19 18:57:41,056 - INFO - Test: [0/782]	Time 0.598 (0.598)	Loss 2.4317 (2.4317)	Acc@1 78.125 (78.125)	Acc@5 92.969 (92.969)
2023-03-19 18:59:38,171 - INFO - Test: [200/782]	Time 0.587 (0.586)	Loss 2.7382 (2.7964)	Acc@1 67.969 (65.955)	Acc@5 86.719 (86.046)
2023-03-19 19:01:35,251 - INFO - Test: [400/782]	Time 0.581 (0.586)	Loss 2.6941 (2.7653)	Acc@1 66.406 (66.845)	Acc@5 87.500 (86.713)
2023-03-19 19:03:32,796 - INFO - Test: [600/782]	Time 0.575 (0.586)	Loss 2.8587 (2.7308)	Acc@1 61.719 (67.675)	Acc@5 84.375 (87.209)
2023-03-19 19:05:17,268 - INFO -  * Acc@1 68.116 Acc@5 87.555
2023-03-19 19:05:17,268 - INFO - Max accuracy: 68.6410%
2023-03-19 19:05:18,533 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Best.pth saved !!!
2023-03-19 19:05:18,534 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-19 19:05:20,408 - INFO - Train: [54/90][0/3907]	eta 2:01:48 lr 0.01448725	time 1.8706 (1.8706)	loss 2.3455 (2.3455)	acc@1: 75.7172	acc@5: 91.3288	
2023-03-19 19:06:15,811 - INFO - Train: [54/90][300/3907]	eta 0:11:26 lr 0.01448725	time 0.1886 (0.1903)	loss 2.8745 (3.5840)	acc@1: 77.0454	acc@5: 87.5037	
2023-03-19 19:07:11,366 - INFO - Train: [54/90][600/3907]	eta 0:10:20 lr 0.01448725	time 0.1795 (0.1877)	loss 5.5562 (3.6736)	acc@1: 25.5156	acc@5: 43.6419	
2023-03-19 19:08:06,671 - INFO - Train: [54/90][900/3907]	eta 0:09:21 lr 0.01448725	time 0.1903 (0.1866)	loss 5.5766 (3.6561)	acc@1: 27.5244	acc@5: 42.5430	
2023-03-19 19:09:02,060 - INFO - Train: [54/90][1200/3907]	eta 0:08:23 lr 0.01448725	time 0.1838 (0.1861)	loss 3.6142 (3.6512)	acc@1: 65.3866	acc@5: 77.0705	
2023-03-19 19:09:57,430 - INFO - Train: [54/90][1500/3907]	eta 0:07:27 lr 0.01448725	time 0.1847 (0.1858)	loss 5.4109 (3.6275)	acc@1: 29.5149	acc@5: 45.3441	
2023-03-19 19:10:52,749 - INFO - Train: [54/90][1800/3907]	eta 0:06:30 lr 0.01448725	time 0.1818 (0.1856)	loss 2.2671 (3.6502)	acc@1: 80.3178	acc@5: 93.5739	
2023-03-19 19:11:47,892 - INFO - Train: [54/90][2100/3907]	eta 0:05:34 lr 0.01448725	time 0.1941 (0.1853)	loss 4.4856 (3.6477)	acc@1: 53.2078	acc@5: 66.6287	
2023-03-19 19:12:41,145 - INFO - Train: [54/90][2400/3907]	eta 0:04:37 lr 0.01448725	time 0.1765 (0.1843)	loss 3.7042 (3.6577)	acc@1: 68.1255	acc@5: 75.5334	
2023-03-19 19:13:33,874 - INFO - Train: [54/90][2700/3907]	eta 0:03:41 lr 0.01448725	time 0.1760 (0.1834)	loss 2.6712 (3.6710)	acc@1: 73.6323	acc@5: 86.6714	
2023-03-19 19:14:26,588 - INFO - Train: [54/90][3000/3907]	eta 0:02:45 lr 0.01448725	time 0.1742 (0.1826)	loss 2.5186 (3.6827)	acc@1: 73.4246	acc@5: 89.0468	
2023-03-19 19:15:19,254 - INFO - Train: [54/90][3300/3907]	eta 0:01:50 lr 0.01448725	time 0.1744 (0.1820)	loss 5.7836 (3.6962)	acc@1: 25.0737	acc@5: 40.6287	
2023-03-19 19:16:11,737 - INFO - Train: [54/90][3600/3907]	eta 0:00:55 lr 0.01448725	time 0.1708 (0.1814)	loss 3.4030 (3.6968)	acc@1: 71.7260	acc@5: 83.4354	
2023-03-19 19:17:04,608 - INFO - Train: [54/90][3900/3907]	eta 0:00:01 lr 0.01448725	time 0.1762 (0.1810)	loss 5.6757 (3.7053)	acc@1: 30.5610	acc@5: 44.8039	
2023-03-19 19:17:05,834 - INFO - EPOCH 54 training takes 0:11:47
2023-03-19 19:17:06,924 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Latest.pth saved !!!
2023-03-19 19:17:06,924 - INFO - **********Latest test***********
2023-03-19 19:17:06,924 - INFO - eval epoch 54
2023-03-19 19:17:07,569 - INFO - Test: [0/782]	Time 0.643 (0.643)	Loss 2.4356 (2.4356)	Acc@1 67.188 (67.188)	Acc@5 94.531 (94.531)
2023-03-19 19:19:04,748 - INFO - Test: [200/782]	Time 0.577 (0.586)	Loss 2.8211 (2.8117)	Acc@1 67.188 (66.224)	Acc@5 84.375 (85.875)
2023-03-19 19:21:02,062 - INFO - Test: [400/782]	Time 0.583 (0.586)	Loss 2.6582 (2.7803)	Acc@1 72.656 (66.675)	Acc@5 86.719 (86.434)
2023-03-19 19:23:00,673 - INFO - Test: [600/782]	Time 0.577 (0.589)	Loss 2.7103 (2.7447)	Acc@1 66.406 (67.510)	Acc@5 87.500 (86.993)
2023-03-19 19:24:46,043 - INFO -  * Acc@1 68.146 Acc@5 87.392
2023-03-19 19:24:46,044 - INFO - Max accuracy: 68.6410%
2023-03-19 19:24:47,395 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Best.pth saved !!!
2023-03-19 19:24:47,396 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-19 19:24:49,532 - INFO - Train: [55/90][0/3907]	eta 2:18:48 lr 0.01381966	time 2.1318 (2.1318)	loss 2.1508 (2.1508)	acc@1: 85.1005	acc@5: 96.0309	
2023-03-19 19:25:44,974 - INFO - Train: [55/90][300/3907]	eta 0:11:29 lr 0.01381966	time 0.1891 (0.1913)	loss 3.4699 (3.5558)	acc@1: 63.8971	acc@5: 80.8282	
2023-03-19 19:26:40,403 - INFO - Train: [55/90][600/3907]	eta 0:10:21 lr 0.01381966	time 0.1811 (0.1880)	loss 3.8706 (3.6218)	acc@1: 64.2693	acc@5: 76.3653	
2023-03-19 19:27:35,843 - INFO - Train: [55/90][900/3907]	eta 0:09:22 lr 0.01381966	time 0.1853 (0.1869)	loss 2.4101 (3.6026)	acc@1: 76.8240	acc@5: 92.1862	
2023-03-19 19:28:30,994 - INFO - Train: [55/90][1200/3907]	eta 0:08:23 lr 0.01381966	time 0.1797 (0.1862)	loss 2.3854 (3.6318)	acc@1: 75.5985	acc@5: 90.4064	
2023-03-19 19:29:26,122 - INFO - Train: [55/90][1500/3907]	eta 0:07:26 lr 0.01381966	time 0.1847 (0.1857)	loss 5.4015 (3.6340)	acc@1: 24.3771	acc@5: 47.0334	
2023-03-19 19:30:21,511 - INFO - Train: [55/90][1800/3907]	eta 0:06:30 lr 0.01381966	time 0.1811 (0.1855)	loss 3.9911 (3.6296)	acc@1: 56.3234	acc@5: 74.8375	
2023-03-19 19:31:17,151 - INFO - Train: [55/90][2100/3907]	eta 0:05:35 lr 0.01381966	time 0.1811 (0.1855)	loss 5.3291 (3.6373)	acc@1: 27.8245	acc@5: 44.9004	
2023-03-19 19:32:12,454 - INFO - Train: [55/90][2400/3907]	eta 0:04:39 lr 0.01381966	time 0.1809 (0.1854)	loss 2.5733 (3.6515)	acc@1: 71.2027	acc@5: 88.8081	
2023-03-19 19:33:05,813 - INFO - Train: [55/90][2700/3907]	eta 0:03:42 lr 0.01381966	time 0.1711 (0.1845)	loss 2.4843 (3.6544)	acc@1: 74.4588	acc@5: 89.8248	
2023-03-19 19:33:58,555 - INFO - Train: [55/90][3000/3907]	eta 0:02:46 lr 0.01381966	time 0.1736 (0.1837)	loss 3.1411 (3.6604)	acc@1: 68.0952	acc@5: 81.2749	
2023-03-19 19:34:51,310 - INFO - Train: [55/90][3300/3907]	eta 0:01:51 lr 0.01381966	time 0.1747 (0.1829)	loss 2.2116 (3.6825)	acc@1: 78.8974	acc@5: 94.5207	
2023-03-19 19:35:44,018 - INFO - Train: [55/90][3600/3907]	eta 0:00:55 lr 0.01381966	time 0.1739 (0.1823)	loss 2.9172 (3.6819)	acc@1: 68.0433	acc@5: 85.9798	
2023-03-19 19:36:36,907 - INFO - Train: [55/90][3900/3907]	eta 0:00:01 lr 0.01381966	time 0.1706 (0.1819)	loss 2.8133 (3.6886)	acc@1: 77.5836	acc@5: 87.1892	
2023-03-19 19:36:38,143 - INFO - EPOCH 55 training takes 0:11:50
2023-03-19 19:36:39,287 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Latest.pth saved !!!
2023-03-19 19:36:39,287 - INFO - **********Latest test***********
2023-03-19 19:36:39,287 - INFO - eval epoch 55
2023-03-19 19:36:39,877 - INFO - Test: [0/782]	Time 0.589 (0.589)	Loss 2.4390 (2.4390)	Acc@1 73.438 (73.438)	Acc@5 92.969 (92.969)
2023-03-19 19:38:38,342 - INFO - Test: [200/782]	Time 0.576 (0.592)	Loss 2.7807 (2.8160)	Acc@1 63.281 (65.442)	Acc@5 84.375 (85.743)
2023-03-19 19:40:36,024 - INFO - Test: [400/782]	Time 0.585 (0.590)	Loss 2.6799 (2.7790)	Acc@1 69.531 (66.430)	Acc@5 88.281 (86.364)
2023-03-19 19:42:35,230 - INFO - Test: [600/782]	Time 0.588 (0.592)	Loss 2.7929 (2.7400)	Acc@1 67.188 (67.429)	Acc@5 86.719 (87.053)
2023-03-19 19:44:21,172 - INFO -  * Acc@1 68.024 Acc@5 87.490
2023-03-19 19:44:21,172 - INFO - Max accuracy: 68.6410%
2023-03-19 19:44:21,172 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-19 19:44:23,320 - INFO - Train: [56/90][0/3907]	eta 2:19:35 lr 0.01315960	time 2.1436 (2.1436)	loss 3.0016 (3.0016)	acc@1: 71.9902	acc@5: 83.4987	
2023-03-19 19:45:18,704 - INFO - Train: [56/90][300/3907]	eta 0:11:29 lr 0.01315960	time 0.1848 (0.1911)	loss 2.4586 (3.6213)	acc@1: 78.9570	acc@5: 91.3413	
2023-03-19 19:46:14,248 - INFO - Train: [56/90][600/3907]	eta 0:10:22 lr 0.01315960	time 0.1838 (0.1881)	loss 3.6377 (3.6532)	acc@1: 67.6877	acc@5: 78.9290	
2023-03-19 19:47:09,353 - INFO - Train: [56/90][900/3907]	eta 0:09:21 lr 0.01315960	time 0.1795 (0.1867)	loss 5.5031 (3.6483)	acc@1: 23.8499	acc@5: 45.7707	
2023-03-19 19:48:04,440 - INFO - Train: [56/90][1200/3907]	eta 0:08:23 lr 0.01315960	time 0.1787 (0.1859)	loss 3.4054 (3.6370)	acc@1: 66.9561	acc@5: 83.5917	
2023-03-19 19:48:59,619 - INFO - Train: [56/90][1500/3907]	eta 0:07:26 lr 0.01315960	time 0.1841 (0.1855)	loss 2.3678 (3.6267)	acc@1: 80.8817	acc@5: 91.7691	
2023-03-19 19:49:54,992 - INFO - Train: [56/90][1800/3907]	eta 0:06:30 lr 0.01315960	time 0.1922 (0.1853)	loss 3.4975 (3.6360)	acc@1: 64.8884	acc@5: 80.6734	
2023-03-19 19:50:50,267 - INFO - Train: [56/90][2100/3907]	eta 0:05:34 lr 0.01315960	time 0.1811 (0.1852)	loss 3.2182 (3.6410)	acc@1: 67.8380	acc@5: 85.0432	
2023-03-19 19:51:45,341 - INFO - Train: [56/90][2400/3907]	eta 0:04:38 lr 0.01315960	time 0.1791 (0.1850)	loss 3.7908 (3.6541)	acc@1: 64.0378	acc@5: 77.2163	
2023-03-19 19:52:40,402 - INFO - Train: [56/90][2700/3907]	eta 0:03:43 lr 0.01315960	time 0.1992 (0.1848)	loss 3.2937 (3.6484)	acc@1: 70.8947	acc@5: 82.1128	
2023-03-19 19:53:35,564 - INFO - Train: [56/90][3000/3907]	eta 0:02:47 lr 0.01315960	time 0.1796 (0.1847)	loss 4.1468 (3.6504)	acc@1: 60.7511	acc@5: 70.2111	
2023-03-19 19:54:30,823 - INFO - Train: [56/90][3300/3907]	eta 0:01:52 lr 0.01315960	time 0.1843 (0.1847)	loss 3.8311 (3.6480)	acc@1: 64.1611	acc@5: 74.0642	
2023-03-19 19:55:26,292 - INFO - Train: [56/90][3600/3907]	eta 0:00:56 lr 0.01315960	time 0.2048 (0.1847)	loss 5.4962 (3.6468)	acc@1: 30.8565	acc@5: 43.6122	
2023-03-19 19:56:22,149 - INFO - Train: [56/90][3900/3907]	eta 0:00:01 lr 0.01315960	time 0.1826 (0.1848)	loss 4.9602 (3.6558)	acc@1: 39.6442	acc@5: 56.1474	
2023-03-19 19:56:23,483 - INFO - EPOCH 56 training takes 0:12:02
2023-03-19 19:56:24,869 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Latest.pth saved !!!
2023-03-19 19:56:24,870 - INFO - **********Latest test***********
2023-03-19 19:56:24,870 - INFO - eval epoch 56
2023-03-19 19:56:25,460 - INFO - Test: [0/782]	Time 0.589 (0.589)	Loss 2.4306 (2.4306)	Acc@1 74.219 (74.219)	Acc@5 93.750 (93.750)
2023-03-19 19:58:22,823 - INFO - Test: [200/782]	Time 0.588 (0.587)	Loss 2.8195 (2.8206)	Acc@1 64.062 (65.990)	Acc@5 86.719 (85.829)
2023-03-19 20:00:20,197 - INFO - Test: [400/782]	Time 0.579 (0.587)	Loss 2.7170 (2.7890)	Acc@1 66.406 (66.706)	Acc@5 85.938 (86.343)
2023-03-19 20:02:17,714 - INFO - Test: [600/782]	Time 0.581 (0.587)	Loss 2.8127 (2.7513)	Acc@1 67.188 (67.726)	Acc@5 85.938 (86.940)
2023-03-19 20:04:01,785 - INFO -  * Acc@1 68.170 Acc@5 87.367
2023-03-19 20:04:01,786 - INFO - Max accuracy: 68.6410%
2023-03-19 20:04:03,112 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Best.pth saved !!!
2023-03-19 20:04:03,112 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-19 20:04:05,239 - INFO - Train: [57/90][0/3907]	eta 2:18:11 lr 0.01250787	time 2.1221 (2.1221)	loss 4.7694 (4.7694)	acc@1: 44.2279	acc@5: 59.6056	
2023-03-19 20:05:00,477 - INFO - Train: [57/90][300/3907]	eta 0:11:27 lr 0.01250787	time 0.1858 (0.1906)	loss 2.2424 (3.4118)	acc@1: 81.3130	acc@5: 92.9291	
2023-03-19 20:05:55,699 - INFO - Train: [57/90][600/3907]	eta 0:10:19 lr 0.01250787	time 0.1853 (0.1873)	loss 5.3643 (3.5084)	acc@1: 32.7883	acc@5: 47.8096	
2023-03-19 20:06:51,012 - INFO - Train: [57/90][900/3907]	eta 0:09:20 lr 0.01250787	time 0.1852 (0.1863)	loss 2.1776 (3.5286)	acc@1: 81.1311	acc@5: 95.9543	
2023-03-19 20:07:46,597 - INFO - Train: [57/90][1200/3907]	eta 0:08:23 lr 0.01250787	time 0.1855 (0.1861)	loss 2.3171 (3.5729)	acc@1: 78.1157	acc@5: 92.1765	
2023-03-19 20:08:42,054 - INFO - Train: [57/90][1500/3907]	eta 0:07:27 lr 0.01250787	time 0.1860 (0.1858)	loss 3.5258 (3.5886)	acc@1: 62.7471	acc@5: 77.4533	
2023-03-19 20:09:37,387 - INFO - Train: [57/90][1800/3907]	eta 0:06:31 lr 0.01250787	time 0.1851 (0.1856)	loss 4.5765 (3.6044)	acc@1: 51.2544	acc@5: 65.0216	
2023-03-19 20:10:32,972 - INFO - Train: [57/90][2100/3907]	eta 0:05:35 lr 0.01250787	time 0.1795 (0.1856)	loss 4.6716 (3.6296)	acc@1: 41.2869	acc@5: 59.6506	
2023-03-19 20:11:28,171 - INFO - Train: [57/90][2400/3907]	eta 0:04:39 lr 0.01250787	time 0.1826 (0.1854)	loss 2.3214 (3.6216)	acc@1: 79.5301	acc@5: 92.0054	
2023-03-19 20:12:23,234 - INFO - Train: [57/90][2700/3907]	eta 0:03:43 lr 0.01250787	time 0.1856 (0.1852)	loss 2.4768 (3.6211)	acc@1: 79.8258	acc@5: 92.0077	
2023-03-19 20:13:18,357 - INFO - Train: [57/90][3000/3907]	eta 0:02:47 lr 0.01250787	time 0.1797 (0.1850)	loss 2.8544 (3.6251)	acc@1: 75.8502	acc@5: 88.4069	
2023-03-19 20:14:13,378 - INFO - Train: [57/90][3300/3907]	eta 0:01:52 lr 0.01250787	time 0.1802 (0.1849)	loss 2.5080 (3.6200)	acc@1: 71.7732	acc@5: 88.1569	
2023-03-19 20:15:06,372 - INFO - Train: [57/90][3600/3907]	eta 0:00:56 lr 0.01250787	time 0.1706 (0.1842)	loss 2.4097 (3.6278)	acc@1: 75.7196	acc@5: 94.2611	
2023-03-19 20:15:59,280 - INFO - Train: [57/90][3900/3907]	eta 0:00:01 lr 0.01250787	time 0.1707 (0.1836)	loss 3.6213 (3.6341)	acc@1: 65.6613	acc@5: 78.0701	
2023-03-19 20:16:00,488 - INFO - EPOCH 57 training takes 0:11:57
2023-03-19 20:16:01,856 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Latest.pth saved !!!
2023-03-19 20:16:01,856 - INFO - **********Latest test***********
2023-03-19 20:16:01,856 - INFO - eval epoch 57
2023-03-19 20:16:02,467 - INFO - Test: [0/782]	Time 0.610 (0.610)	Loss 2.4702 (2.4702)	Acc@1 70.312 (70.312)	Acc@5 92.969 (92.969)
2023-03-19 20:17:59,520 - INFO - Test: [200/782]	Time 0.581 (0.585)	Loss 2.8309 (2.8292)	Acc@1 63.281 (65.357)	Acc@5 85.156 (85.599)
2023-03-19 20:19:56,401 - INFO - Test: [400/782]	Time 0.578 (0.585)	Loss 2.6581 (2.7920)	Acc@1 67.969 (66.243)	Acc@5 89.062 (86.321)
2023-03-19 20:21:54,321 - INFO - Test: [600/782]	Time 0.581 (0.586)	Loss 2.7533 (2.7531)	Acc@1 69.531 (67.208)	Acc@5 83.594 (86.941)
2023-03-19 20:23:38,922 - INFO -  * Acc@1 67.943 Acc@5 87.435
2023-03-19 20:23:38,922 - INFO - Max accuracy: 68.6410%
2023-03-19 20:23:38,922 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-19 20:23:41,026 - INFO - Train: [58/90][0/3907]	eta 2:16:44 lr 0.01186527	time 2.1000 (2.1000)	loss 4.2257 (4.2257)	acc@1: 56.1171	acc@5: 69.4740	
2023-03-19 20:24:35,916 - INFO - Train: [58/90][300/3907]	eta 0:11:22 lr 0.01186527	time 0.1796 (0.1893)	loss 5.0757 (3.5673)	acc@1: 38.3004	acc@5: 54.4360	
2023-03-19 20:25:30,863 - INFO - Train: [58/90][600/3907]	eta 0:10:15 lr 0.01186527	time 0.1787 (0.1862)	loss 2.1683 (3.5696)	acc@1: 87.4005	acc@5: 96.6820	
2023-03-19 20:26:25,965 - INFO - Train: [58/90][900/3907]	eta 0:09:17 lr 0.01186527	time 0.1790 (0.1854)	loss 2.9881 (3.5445)	acc@1: 73.5908	acc@5: 84.5123	
2023-03-19 20:27:20,830 - INFO - Train: [58/90][1200/3907]	eta 0:08:20 lr 0.01186527	time 0.1789 (0.1848)	loss 4.7544 (3.5609)	acc@1: 44.2522	acc@5: 60.9374	
2023-03-19 20:28:15,862 - INFO - Train: [58/90][1500/3907]	eta 0:07:24 lr 0.01186527	time 0.1853 (0.1845)	loss 2.5845 (3.5672)	acc@1: 77.1356	acc@5: 92.1457	
2023-03-19 20:29:10,780 - INFO - Train: [58/90][1800/3907]	eta 0:06:28 lr 0.01186527	time 0.1800 (0.1843)	loss 5.5556 (3.5708)	acc@1: 22.6871	acc@5: 41.0927	
2023-03-19 20:30:06,032 - INFO - Train: [58/90][2100/3907]	eta 0:05:32 lr 0.01186527	time 0.1847 (0.1842)	loss 2.5719 (3.5746)	acc@1: 78.4866	acc@5: 90.5095	
2023-03-19 20:31:01,304 - INFO - Train: [58/90][2400/3907]	eta 0:04:37 lr 0.01186527	time 0.1875 (0.1842)	loss 2.2621 (3.5688)	acc@1: 80.7971	acc@5: 91.6775	
2023-03-19 20:31:54,873 - INFO - Train: [58/90][2700/3907]	eta 0:03:41 lr 0.01186527	time 0.1711 (0.1836)	loss 3.9894 (3.5738)	acc@1: 59.8033	acc@5: 74.1041	
2023-03-19 20:32:47,410 - INFO - Train: [58/90][3000/3907]	eta 0:02:45 lr 0.01186527	time 0.1746 (0.1828)	loss 3.1557 (3.5791)	acc@1: 70.1648	acc@5: 83.6024	
2023-03-19 20:33:40,048 - INFO - Train: [58/90][3300/3907]	eta 0:01:50 lr 0.01186527	time 0.1756 (0.1821)	loss 5.0891 (3.5952)	acc@1: 39.4442	acc@5: 53.6368	
2023-03-19 20:34:32,600 - INFO - Train: [58/90][3600/3907]	eta 0:00:55 lr 0.01186527	time 0.1758 (0.1815)	loss 5.5015 (3.6067)	acc@1: 27.9946	acc@5: 46.3713	
2023-03-19 20:35:25,260 - INFO - Train: [58/90][3900/3907]	eta 0:00:01 lr 0.01186527	time 0.1730 (0.1811)	loss 2.4072 (3.6079)	acc@1: 76.8813	acc@5: 88.5293	
2023-03-19 20:35:26,517 - INFO - EPOCH 58 training takes 0:11:47
2023-03-19 20:35:27,881 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Latest.pth saved !!!
2023-03-19 20:35:27,881 - INFO - **********Latest test***********
2023-03-19 20:35:27,881 - INFO - eval epoch 58
2023-03-19 20:35:28,494 - INFO - Test: [0/782]	Time 0.611 (0.611)	Loss 2.3413 (2.3413)	Acc@1 76.562 (76.562)	Acc@5 92.969 (92.969)
2023-03-19 20:37:26,129 - INFO - Test: [200/782]	Time 0.583 (0.588)	Loss 2.6542 (2.7192)	Acc@1 71.875 (67.899)	Acc@5 85.156 (87.057)
2023-03-19 20:39:23,747 - INFO - Test: [400/782]	Time 0.584 (0.588)	Loss 2.5897 (2.6904)	Acc@1 71.094 (68.604)	Acc@5 90.625 (87.590)
2023-03-19 20:41:22,675 - INFO - Test: [600/782]	Time 0.574 (0.590)	Loss 2.7494 (2.6591)	Acc@1 72.656 (69.444)	Acc@5 87.500 (88.051)
2023-03-19 20:43:07,745 - INFO -  * Acc@1 69.978 Acc@5 88.402
2023-03-19 20:43:07,745 - INFO - Max accuracy: 69.9780%
2023-03-19 20:43:09,101 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Best.pth saved !!!
2023-03-19 20:43:09,102 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-19 20:43:11,238 - INFO - Train: [59/90][0/3907]	eta 2:18:51 lr 0.01123258	time 2.1325 (2.1325)	loss 3.6238 (3.6238)	acc@1: 65.0056	acc@5: 80.1079	
2023-03-19 20:44:06,392 - INFO - Train: [59/90][300/3907]	eta 0:11:26 lr 0.01123258	time 0.1884 (0.1903)	loss 5.3539 (3.4460)	acc@1: 27.1368	acc@5: 45.1056	
2023-03-19 20:45:01,275 - INFO - Train: [59/90][600/3907]	eta 0:10:17 lr 0.01123258	time 0.1795 (0.1866)	loss 4.3330 (3.5284)	acc@1: 51.1562	acc@5: 67.0674	
2023-03-19 20:45:56,626 - INFO - Train: [59/90][900/3907]	eta 0:09:19 lr 0.01123258	time 0.1795 (0.1859)	loss 5.2533 (3.5560)	acc@1: 36.9828	acc@5: 49.8427	
2023-03-19 20:46:51,765 - INFO - Train: [59/90][1200/3907]	eta 0:08:21 lr 0.01123258	time 0.1923 (0.1854)	loss 2.3517 (3.5968)	acc@1: 81.4221	acc@5: 91.5015	
2023-03-19 20:47:46,896 - INFO - Train: [59/90][1500/3907]	eta 0:07:25 lr 0.01123258	time 0.1837 (0.1851)	loss 2.8112 (3.6113)	acc@1: 75.0666	acc@5: 89.0496	
2023-03-19 20:48:42,052 - INFO - Train: [59/90][1800/3907]	eta 0:06:29 lr 0.01123258	time 0.1787 (0.1849)	loss 2.8890 (3.6256)	acc@1: 75.8091	acc@5: 86.0141	
2023-03-19 20:49:37,027 - INFO - Train: [59/90][2100/3907]	eta 0:05:33 lr 0.01123258	time 0.1846 (0.1846)	loss 3.5995 (3.6271)	acc@1: 62.5476	acc@5: 79.0186	
2023-03-19 20:50:31,083 - INFO - Train: [59/90][2400/3907]	eta 0:04:37 lr 0.01123258	time 0.1716 (0.1841)	loss 4.4578 (3.6386)	acc@1: 54.6502	acc@5: 64.3658	
2023-03-19 20:51:24,053 - INFO - Train: [59/90][2700/3907]	eta 0:03:41 lr 0.01123258	time 0.1749 (0.1832)	loss 4.1228 (3.6518)	acc@1: 56.4032	acc@5: 68.6618	
2023-03-19 20:52:16,942 - INFO - Train: [59/90][3000/3907]	eta 0:02:45 lr 0.01123258	time 0.1756 (0.1825)	loss 3.5290 (3.6584)	acc@1: 66.1055	acc@5: 80.0906	
2023-03-19 20:53:09,663 - INFO - Train: [59/90][3300/3907]	eta 0:01:50 lr 0.01123258	time 0.1710 (0.1819)	loss 3.3742 (3.6698)	acc@1: 67.6993	acc@5: 83.7317	
2023-03-19 20:54:02,380 - INFO - Train: [59/90][3600/3907]	eta 0:00:55 lr 0.01123258	time 0.1789 (0.1814)	loss 3.0234 (3.6718)	acc@1: 74.2072	acc@5: 83.6340	
2023-03-19 20:54:55,316 - INFO - Train: [59/90][3900/3907]	eta 0:00:01 lr 0.01123258	time 0.1734 (0.1810)	loss 2.3057 (3.6762)	acc@1: 80.7224	acc@5: 93.9174	
2023-03-19 20:54:56,585 - INFO - EPOCH 59 training takes 0:11:47
2023-03-19 20:54:57,942 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Latest.pth saved !!!
2023-03-19 20:54:57,943 - INFO - **********Latest test***********
2023-03-19 20:54:57,943 - INFO - eval epoch 59
2023-03-19 20:54:58,555 - INFO - Test: [0/782]	Time 0.611 (0.611)	Loss 2.3210 (2.3210)	Acc@1 77.344 (77.344)	Acc@5 93.750 (93.750)
2023-03-19 20:56:56,870 - INFO - Test: [200/782]	Time 0.589 (0.592)	Loss 2.6726 (2.6879)	Acc@1 69.531 (69.007)	Acc@5 86.719 (87.519)
2023-03-19 20:58:56,766 - INFO - Test: [400/782]	Time 0.596 (0.596)	Loss 2.6095 (2.6558)	Acc@1 68.750 (69.751)	Acc@5 86.719 (88.065)
2023-03-19 21:00:57,951 - INFO - Test: [600/782]	Time 0.588 (0.599)	Loss 2.7432 (2.6249)	Acc@1 70.312 (70.502)	Acc@5 87.500 (88.528)
2023-03-19 21:02:45,415 - INFO -  * Acc@1 70.939 Acc@5 88.845
2023-03-19 21:02:45,416 - INFO - Max accuracy: 70.9390%
2023-03-19 21:02:46,647 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Best.pth saved !!!
2023-03-19 21:02:46,647 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-19 21:02:48,734 - INFO - Train: [60/90][0/3907]	eta 2:15:35 lr 0.01061057	time 2.0824 (2.0824)	loss 4.7153 (4.7153)	acc@1: 49.7917	acc@5: 63.4162	
2023-03-19 21:03:43,723 - INFO - Train: [60/90][300/3907]	eta 0:11:23 lr 0.01061057	time 0.1789 (0.1896)	loss 3.9065 (3.5966)	acc@1: 64.5871	acc@5: 75.1022	
2023-03-19 21:04:38,973 - INFO - Train: [60/90][600/3907]	eta 0:10:18 lr 0.01061057	time 0.1815 (0.1869)	loss 5.8127 (3.5878)	acc@1: 21.8329	acc@5: 38.4916	
2023-03-19 21:05:34,152 - INFO - Train: [60/90][900/3907]	eta 0:09:19 lr 0.01061057	time 0.1838 (0.1859)	loss 4.1337 (3.6001)	acc@1: 54.6612	acc@5: 70.6556	
2023-03-19 21:06:29,250 - INFO - Train: [60/90][1200/3907]	eta 0:08:21 lr 0.01061057	time 0.1795 (0.1853)	loss 5.4069 (3.6051)	acc@1: 24.5886	acc@5: 46.4962	
2023-03-19 21:07:24,439 - INFO - Train: [60/90][1500/3907]	eta 0:07:25 lr 0.01061057	time 0.1821 (0.1851)	loss 5.3836 (3.6172)	acc@1: 27.4340	acc@5: 47.5660	
2023-03-19 21:08:19,614 - INFO - Train: [60/90][1800/3907]	eta 0:06:29 lr 0.01061057	time 0.1795 (0.1849)	loss 5.1548 (3.6211)	acc@1: 36.8569	acc@5: 56.9006	
2023-03-19 21:09:14,733 - INFO - Train: [60/90][2100/3907]	eta 0:05:33 lr 0.01061057	time 0.1840 (0.1847)	loss 2.5815 (3.6219)	acc@1: 73.8153	acc@5: 87.7997	
2023-03-19 21:10:09,897 - INFO - Train: [60/90][2400/3907]	eta 0:04:38 lr 0.01061057	time 0.1799 (0.1846)	loss 2.4187 (3.6237)	acc@1: 78.9053	acc@5: 91.4052	
2023-03-19 21:11:04,890 - INFO - Train: [60/90][2700/3907]	eta 0:03:42 lr 0.01061057	time 0.1858 (0.1845)	loss 4.9399 (3.6325)	acc@1: 45.8804	acc@5: 56.2238	
2023-03-19 21:11:59,952 - INFO - Train: [60/90][3000/3907]	eta 0:02:47 lr 0.01061057	time 0.1796 (0.1844)	loss 5.4433 (3.6433)	acc@1: 36.6918	acc@5: 45.9641	
2023-03-19 21:12:55,365 - INFO - Train: [60/90][3300/3907]	eta 0:01:51 lr 0.01061057	time 0.1800 (0.1844)	loss 4.9828 (3.6466)	acc@1: 42.7491	acc@5: 57.4246	
2023-03-19 21:13:50,349 - INFO - Train: [60/90][3600/3907]	eta 0:00:56 lr 0.01061057	time 0.1800 (0.1843)	loss 3.6612 (3.6577)	acc@1: 64.9341	acc@5: 75.9867	
2023-03-19 21:14:42,771 - INFO - Train: [60/90][3900/3907]	eta 0:00:01 lr 0.01061057	time 0.1706 (0.1836)	loss 4.8406 (3.6639)	acc@1: 43.0791	acc@5: 58.5703	
2023-03-19 21:14:43,968 - INFO - EPOCH 60 training takes 0:11:57
2023-03-19 21:14:45,332 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Latest.pth saved !!!
2023-03-19 21:14:45,332 - INFO - **********Latest test***********
2023-03-19 21:14:45,332 - INFO - eval epoch 60
2023-03-19 21:14:45,926 - INFO - Test: [0/782]	Time 0.593 (0.593)	Loss 2.4096 (2.4096)	Acc@1 71.094 (71.094)	Acc@5 91.406 (91.406)
2023-03-19 21:16:43,687 - INFO - Test: [200/782]	Time 0.579 (0.589)	Loss 2.7597 (2.7705)	Acc@1 67.188 (67.463)	Acc@5 86.719 (86.734)
2023-03-19 21:18:40,972 - INFO - Test: [400/782]	Time 0.584 (0.588)	Loss 2.6911 (2.7384)	Acc@1 68.750 (68.405)	Acc@5 86.719 (87.317)
2023-03-19 21:20:39,487 - INFO - Test: [600/782]	Time 0.586 (0.589)	Loss 2.8148 (2.7135)	Acc@1 66.406 (69.046)	Acc@5 85.156 (87.768)
2023-03-19 21:22:24,921 - INFO -  * Acc@1 69.648 Acc@5 88.196
2023-03-19 21:22:24,922 - INFO - Max accuracy: 70.9390%
2023-03-19 21:22:24,922 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-19 21:22:26,922 - INFO - Train: [61/90][0/3907]	eta 2:10:01 lr 0.01000000	time 1.9967 (1.9967)	loss 5.5481 (5.5481)	acc@1: 24.1746	acc@5: 45.7201	
2023-03-19 21:23:21,542 - INFO - Train: [61/90][300/3907]	eta 0:11:18 lr 0.01000000	time 0.1800 (0.1881)	loss 2.4820 (3.5815)	acc@1: 78.1146	acc@5: 87.4884	
2023-03-19 21:24:16,353 - INFO - Train: [61/90][600/3907]	eta 0:10:13 lr 0.01000000	time 0.1849 (0.1854)	loss 5.3623 (3.6951)	acc@1: 34.0196	acc@5: 50.7744	
2023-03-19 21:25:11,310 - INFO - Train: [61/90][900/3907]	eta 0:09:15 lr 0.01000000	time 0.1866 (0.1847)	loss 2.6259 (3.6657)	acc@1: 78.9892	acc@5: 89.6224	
2023-03-19 21:26:06,217 - INFO - Train: [61/90][1200/3907]	eta 0:08:18 lr 0.01000000	time 0.1813 (0.1843)	loss 4.0782 (3.6703)	acc@1: 58.8158	acc@5: 71.2040	
2023-03-19 21:27:01,228 - INFO - Train: [61/90][1500/3907]	eta 0:07:23 lr 0.01000000	time 0.1856 (0.1841)	loss 2.9547 (3.6765)	acc@1: 70.4378	acc@5: 84.3691	
2023-03-19 21:27:56,287 - INFO - Train: [61/90][1800/3907]	eta 0:06:27 lr 0.01000000	time 0.1874 (0.1840)	loss 4.1075 (3.6741)	acc@1: 56.9746	acc@5: 70.4001	
2023-03-19 21:28:51,272 - INFO - Train: [61/90][2100/3907]	eta 0:05:32 lr 0.01000000	time 0.2023 (0.1839)	loss 2.6115 (3.6599)	acc@1: 70.4455	acc@5: 85.7563	
2023-03-19 21:29:46,386 - INFO - Train: [61/90][2400/3907]	eta 0:04:37 lr 0.01000000	time 0.1801 (0.1839)	loss 2.3706 (3.6540)	acc@1: 76.5496	acc@5: 91.3908	
2023-03-19 21:30:41,552 - INFO - Train: [61/90][2700/3907]	eta 0:03:41 lr 0.01000000	time 0.1871 (0.1839)	loss 2.5796 (3.6491)	acc@1: 77.0755	acc@5: 88.6337	
2023-03-19 21:31:36,939 - INFO - Train: [61/90][3000/3907]	eta 0:02:46 lr 0.01000000	time 0.1843 (0.1839)	loss 3.5026 (3.6465)	acc@1: 66.7462	acc@5: 80.4889	
2023-03-19 21:32:30,849 - INFO - Train: [61/90][3300/3907]	eta 0:01:51 lr 0.01000000	time 0.1702 (0.1836)	loss 2.6233 (3.6546)	acc@1: 72.8899	acc@5: 89.7806	
2023-03-19 21:33:23,554 - INFO - Train: [61/90][3600/3907]	eta 0:00:56 lr 0.01000000	time 0.1709 (0.1829)	loss 5.2681 (3.6648)	acc@1: 35.1344	acc@5: 52.2628	
2023-03-19 21:34:16,175 - INFO - Train: [61/90][3900/3907]	eta 0:00:01 lr 0.01000000	time 0.1710 (0.1823)	loss 4.0933 (3.6616)	acc@1: 61.2709	acc@5: 72.8766	
2023-03-19 21:34:17,335 - INFO - EPOCH 61 training takes 0:11:52
2023-03-19 21:34:18,319 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Latest.pth saved !!!
2023-03-19 21:34:18,319 - INFO - **********Latest test***********
2023-03-19 21:34:18,320 - INFO - eval epoch 61
2023-03-19 21:34:18,914 - INFO - Test: [0/782]	Time 0.593 (0.593)	Loss 2.3515 (2.3515)	Acc@1 71.094 (71.094)	Acc@5 95.312 (95.312)
2023-03-19 21:36:17,167 - INFO - Test: [200/782]	Time 0.594 (0.591)	Loss 2.6334 (2.6720)	Acc@1 67.969 (69.007)	Acc@5 86.719 (87.768)
2023-03-19 21:38:15,824 - INFO - Test: [400/782]	Time 0.589 (0.592)	Loss 2.5071 (2.6411)	Acc@1 74.219 (69.940)	Acc@5 87.500 (88.254)
2023-03-19 21:40:14,638 - INFO - Test: [600/782]	Time 0.612 (0.593)	Loss 2.7186 (2.6081)	Acc@1 67.188 (70.683)	Acc@5 88.281 (88.723)
2023-03-19 21:42:00,165 - INFO -  * Acc@1 71.114 Acc@5 89.076
2023-03-19 21:42:00,165 - INFO - Max accuracy: 71.1140%
2023-03-19 21:42:01,222 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Best.pth saved !!!
2023-03-19 21:42:01,223 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-19 21:42:03,331 - INFO - Train: [62/90][0/3907]	eta 2:17:05 lr 0.00940161	time 2.1054 (2.1054)	loss 5.6188 (5.6188)	acc@1: 25.0129	acc@5: 42.2391	
2023-03-19 21:42:58,664 - INFO - Train: [62/90][300/3907]	eta 0:11:28 lr 0.00940161	time 0.1792 (0.1908)	loss 2.3664 (3.4883)	acc@1: 76.3880	acc@5: 89.5117	
2023-03-19 21:43:53,776 - INFO - Train: [62/90][600/3907]	eta 0:10:19 lr 0.00940161	time 0.1799 (0.1873)	loss 2.3041 (3.4862)	acc@1: 80.9727	acc@5: 94.0810	
2023-03-19 21:44:49,145 - INFO - Train: [62/90][900/3907]	eta 0:09:20 lr 0.00940161	time 0.1802 (0.1864)	loss 2.3428 (3.5547)	acc@1: 82.4057	acc@5: 91.6462	
2023-03-19 21:45:43,922 - INFO - Train: [62/90][1200/3907]	eta 0:08:21 lr 0.00940161	time 0.1891 (0.1854)	loss 5.5563 (3.5665)	acc@1: 24.7792	acc@5: 43.4732	
2023-03-19 21:46:39,134 - INFO - Train: [62/90][1500/3907]	eta 0:07:25 lr 0.00940161	time 0.1927 (0.1851)	loss 5.3441 (3.6031)	acc@1: 31.0263	acc@5: 50.6927	
2023-03-19 21:47:34,259 - INFO - Train: [62/90][1800/3907]	eta 0:06:29 lr 0.00940161	time 0.1791 (0.1849)	loss 5.6840 (3.5976)	acc@1: 25.4763	acc@5: 40.1932	
2023-03-19 21:48:29,245 - INFO - Train: [62/90][2100/3907]	eta 0:05:33 lr 0.00940161	time 0.1872 (0.1847)	loss 2.2366 (3.6009)	acc@1: 80.4650	acc@5: 94.5268	
2023-03-19 21:49:24,289 - INFO - Train: [62/90][2400/3907]	eta 0:04:38 lr 0.00940161	time 0.1879 (0.1845)	loss 2.8878 (3.5953)	acc@1: 72.0613	acc@5: 83.9477	
2023-03-19 21:50:19,323 - INFO - Train: [62/90][2700/3907]	eta 0:03:42 lr 0.00940161	time 0.1872 (0.1844)	loss 5.4375 (3.6014)	acc@1: 30.0783	acc@5: 47.2925	
2023-03-19 21:51:14,286 - INFO - Train: [62/90][3000/3907]	eta 0:02:47 lr 0.00940161	time 0.1971 (0.1843)	loss 5.3313 (3.6069)	acc@1: 31.8960	acc@5: 49.4099	
2023-03-19 21:52:09,449 - INFO - Train: [62/90][3300/3907]	eta 0:01:51 lr 0.00940161	time 0.1790 (0.1842)	loss 5.3173 (3.6153)	acc@1: 32.5979	acc@5: 49.5477	
2023-03-19 21:53:04,355 - INFO - Train: [62/90][3600/3907]	eta 0:00:56 lr 0.00940161	time 0.1763 (0.1841)	loss 3.0982 (3.6241)	acc@1: 75.0213	acc@5: 83.5058	
2023-03-19 21:53:57,169 - INFO - Train: [62/90][3900/3907]	eta 0:00:01 lr 0.00940161	time 0.1707 (0.1835)	loss 2.3515 (3.6225)	acc@1: 80.1535	acc@5: 90.1714	
2023-03-19 21:53:58,386 - INFO - EPOCH 62 training takes 0:11:57
2023-03-19 21:53:59,469 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Latest.pth saved !!!
2023-03-19 21:53:59,470 - INFO - **********Latest test***********
2023-03-19 21:53:59,470 - INFO - eval epoch 62
2023-03-19 21:54:00,079 - INFO - Test: [0/782]	Time 0.608 (0.608)	Loss 2.4584 (2.4584)	Acc@1 74.219 (74.219)	Acc@5 89.844 (89.844)
2023-03-19 21:55:58,152 - INFO - Test: [200/782]	Time 0.605 (0.590)	Loss 2.6723 (2.7280)	Acc@1 71.094 (68.742)	Acc@5 85.938 (87.368)
2023-03-19 21:57:57,668 - INFO - Test: [400/782]	Time 0.606 (0.594)	Loss 2.6729 (2.6992)	Acc@1 69.531 (69.352)	Acc@5 86.719 (87.925)
2023-03-19 21:59:59,390 - INFO - Test: [600/782]	Time 0.617 (0.599)	Loss 2.7803 (2.6696)	Acc@1 67.969 (70.076)	Acc@5 85.156 (88.380)
2023-03-19 22:01:47,565 - INFO -  * Acc@1 70.625 Acc@5 88.805
2023-03-19 22:01:47,566 - INFO - Max accuracy: 71.1140%
2023-03-19 22:01:47,566 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-19 22:01:49,658 - INFO - Train: [63/90][0/3907]	eta 2:15:56 lr 0.00881614	time 2.0877 (2.0877)	loss 2.2276 (2.2276)	acc@1: 81.7410	acc@5: 92.6390	
2023-03-19 22:02:44,850 - INFO - Train: [63/90][300/3907]	eta 0:11:26 lr 0.00881614	time 0.1802 (0.1903)	loss 5.1395 (3.4833)	acc@1: 35.7453	acc@5: 51.6575	
2023-03-19 22:03:39,702 - INFO - Train: [63/90][600/3907]	eta 0:10:16 lr 0.00881614	time 0.1987 (0.1866)	loss 4.8789 (3.5159)	acc@1: 42.8718	acc@5: 58.0524	
2023-03-19 22:04:34,763 - INFO - Train: [63/90][900/3907]	eta 0:09:17 lr 0.00881614	time 0.1813 (0.1856)	loss 5.3879 (3.5374)	acc@1: 30.0484	acc@5: 51.1724	
2023-03-19 22:05:29,880 - INFO - Train: [63/90][1200/3907]	eta 0:08:21 lr 0.00881614	time 0.1854 (0.1851)	loss 2.2498 (3.5310)	acc@1: 81.2074	acc@5: 93.7013	
2023-03-19 22:06:24,828 - INFO - Train: [63/90][1500/3907]	eta 0:07:24 lr 0.00881614	time 0.1792 (0.1847)	loss 3.0680 (3.5523)	acc@1: 68.7032	acc@5: 81.8591	
2023-03-19 22:07:19,801 - INFO - Train: [63/90][1800/3907]	eta 0:06:28 lr 0.00881614	time 0.1819 (0.1845)	loss 3.0511 (3.5366)	acc@1: 73.8590	acc@5: 86.7435	
2023-03-19 22:08:14,926 - INFO - Train: [63/90][2100/3907]	eta 0:05:33 lr 0.00881614	time 0.1792 (0.1844)	loss 2.3611 (3.5466)	acc@1: 75.7360	acc@5: 91.3516	
2023-03-19 22:09:08,352 - INFO - Train: [63/90][2400/3907]	eta 0:04:36 lr 0.00881614	time 0.1864 (0.1836)	loss 3.2538 (3.5450)	acc@1: 71.5030	acc@5: 83.4066	
2023-03-19 22:10:01,284 - INFO - Train: [63/90][2700/3907]	eta 0:03:40 lr 0.00881614	time 0.1792 (0.1828)	loss 2.8082 (3.5489)	acc@1: 81.2932	acc@5: 87.8805	
2023-03-19 22:10:54,107 - INFO - Train: [63/90][3000/3907]	eta 0:02:45 lr 0.00881614	time 0.1758 (0.1821)	loss 2.3456 (3.5484)	acc@1: 77.0598	acc@5: 91.8491	
2023-03-19 22:11:46,830 - INFO - Train: [63/90][3300/3907]	eta 0:01:50 lr 0.00881614	time 0.1772 (0.1815)	loss 3.6264 (3.5644)	acc@1: 67.6097	acc@5: 78.6227	
2023-03-19 22:12:39,260 - INFO - Train: [63/90][3600/3907]	eta 0:00:55 lr 0.00881614	time 0.1722 (0.1810)	loss 5.6271 (3.5564)	acc@1: 25.1123	acc@5: 44.8306	
2023-03-19 22:13:31,780 - INFO - Train: [63/90][3900/3907]	eta 0:00:01 lr 0.00881614	time 0.1777 (0.1805)	loss 2.3694 (3.5672)	acc@1: 81.1923	acc@5: 88.0860	
2023-03-19 22:13:33,026 - INFO - EPOCH 63 training takes 0:11:45
2023-03-19 22:13:34,165 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Latest.pth saved !!!
2023-03-19 22:13:34,166 - INFO - **********Latest test***********
2023-03-19 22:13:34,166 - INFO - eval epoch 63
2023-03-19 22:13:34,778 - INFO - Test: [0/782]	Time 0.611 (0.611)	Loss 2.4072 (2.4072)	Acc@1 75.000 (75.000)	Acc@5 90.625 (90.625)
2023-03-19 22:15:31,529 - INFO - Test: [200/782]	Time 0.574 (0.584)	Loss 2.6514 (2.6975)	Acc@1 68.750 (69.034)	Acc@5 89.062 (87.729)
2023-03-19 22:17:28,185 - INFO - Test: [400/782]	Time 0.586 (0.584)	Loss 2.5740 (2.6647)	Acc@1 71.094 (69.917)	Acc@5 87.500 (88.316)
2023-03-19 22:19:25,585 - INFO - Test: [600/782]	Time 0.569 (0.585)	Loss 2.7130 (2.6378)	Acc@1 64.844 (70.704)	Acc@5 88.281 (88.782)
2023-03-19 22:21:10,055 - INFO -  * Acc@1 71.237 Acc@5 89.191
2023-03-19 22:21:10,056 - INFO - Max accuracy: 71.2370%
2023-03-19 22:21:11,127 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Best.pth saved !!!
2023-03-19 22:21:11,128 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-19 22:21:13,243 - INFO - Train: [64/90][0/3907]	eta 2:17:28 lr 0.00824429	time 2.1113 (2.1113)	loss 2.1268 (2.1268)	acc@1: 86.0731	acc@5: 96.1653	
2023-03-19 22:22:08,585 - INFO - Train: [64/90][300/3907]	eta 0:11:28 lr 0.00824429	time 0.1800 (0.1909)	loss 4.0582 (3.4782)	acc@1: 63.5936	acc@5: 72.8308	
2023-03-19 22:23:03,713 - INFO - Train: [64/90][600/3907]	eta 0:10:19 lr 0.00824429	time 0.1797 (0.1873)	loss 2.3317 (3.5024)	acc@1: 84.8845	acc@5: 93.2191	
2023-03-19 22:23:58,820 - INFO - Train: [64/90][900/3907]	eta 0:09:19 lr 0.00824429	time 0.1799 (0.1861)	loss 5.5254 (3.5203)	acc@1: 23.9603	acc@5: 41.4944	
2023-03-19 22:24:54,185 - INFO - Train: [64/90][1200/3907]	eta 0:08:22 lr 0.00824429	time 0.1875 (0.1857)	loss 2.4118 (3.5264)	acc@1: 78.8806	acc@5: 89.8145	
2023-03-19 22:25:49,225 - INFO - Train: [64/90][1500/3907]	eta 0:07:25 lr 0.00824429	time 0.1843 (0.1853)	loss 2.1527 (3.5078)	acc@1: 78.1026	acc@5: 95.2852	
2023-03-19 22:26:44,400 - INFO - Train: [64/90][1800/3907]	eta 0:06:29 lr 0.00824429	time 0.1839 (0.1850)	loss 3.7407 (3.5351)	acc@1: 66.4623	acc@5: 77.0774	
2023-03-19 22:27:38,991 - INFO - Train: [64/90][2100/3907]	eta 0:05:33 lr 0.00824429	time 0.1747 (0.1846)	loss 3.5348 (3.5290)	acc@1: 69.7319	acc@5: 83.3763	
2023-03-19 22:28:31,835 - INFO - Train: [64/90][2400/3907]	eta 0:04:36 lr 0.00824429	time 0.1716 (0.1835)	loss 2.4075 (3.5487)	acc@1: 71.6773	acc@5: 91.9333	
2023-03-19 22:29:24,713 - INFO - Train: [64/90][2700/3907]	eta 0:03:40 lr 0.00824429	time 0.1751 (0.1827)	loss 4.3362 (3.5712)	acc@1: 54.5730	acc@5: 66.2688	
2023-03-19 22:30:17,514 - INFO - Train: [64/90][3000/3907]	eta 0:02:45 lr 0.00824429	time 0.1713 (0.1821)	loss 2.2723 (3.5750)	acc@1: 82.4465	acc@5: 91.6928	
2023-03-19 22:31:10,516 - INFO - Train: [64/90][3300/3907]	eta 0:01:50 lr 0.00824429	time 0.1713 (0.1816)	loss 3.0655 (3.5699)	acc@1: 74.2184	acc@5: 84.9230	
2023-03-19 22:32:03,360 - INFO - Train: [64/90][3600/3907]	eta 0:00:55 lr 0.00824429	time 0.1712 (0.1811)	loss 5.4480 (3.5773)	acc@1: 29.2003	acc@5: 45.3771	
2023-03-19 22:32:56,332 - INFO - Train: [64/90][3900/3907]	eta 0:00:01 lr 0.00824429	time 0.1740 (0.1808)	loss 3.0505 (3.5910)	acc@1: 73.3355	acc@5: 85.4279	
2023-03-19 22:32:57,514 - INFO - EPOCH 64 training takes 0:11:46
2023-03-19 22:32:58,592 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Latest.pth saved !!!
2023-03-19 22:32:58,593 - INFO - **********Latest test***********
2023-03-19 22:32:58,593 - INFO - eval epoch 64
2023-03-19 22:32:59,182 - INFO - Test: [0/782]	Time 0.588 (0.588)	Loss 2.3670 (2.3670)	Acc@1 75.000 (75.000)	Acc@5 92.188 (92.188)
2023-03-19 22:34:56,681 - INFO - Test: [200/782]	Time 0.573 (0.587)	Loss 2.5939 (2.6607)	Acc@1 71.875 (69.213)	Acc@5 86.719 (87.706)
2023-03-19 22:36:53,851 - INFO - Test: [400/782]	Time 0.584 (0.587)	Loss 2.5538 (2.6305)	Acc@1 71.875 (70.085)	Acc@5 86.719 (88.328)
2023-03-19 22:38:51,756 - INFO - Test: [600/782]	Time 0.588 (0.588)	Loss 2.7167 (2.6031)	Acc@1 69.531 (70.797)	Acc@5 89.844 (88.875)
2023-03-19 22:40:37,090 - INFO -  * Acc@1 71.382 Acc@5 89.288
2023-03-19 22:40:37,091 - INFO - Max accuracy: 71.3820%
2023-03-19 22:40:38,043 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Best.pth saved !!!
2023-03-19 22:40:38,043 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-19 22:40:39,935 - INFO - Train: [65/90][0/3907]	eta 2:02:55 lr 0.00768677	time 1.8878 (1.8878)	loss 5.6704 (5.6704)	acc@1: 23.4760	acc@5: 41.4319	
2023-03-19 22:41:34,492 - INFO - Train: [65/90][300/3907]	eta 0:11:16 lr 0.00768677	time 0.1869 (0.1875)	loss 2.0514 (3.6118)	acc@1: 89.4603	acc@5: 93.3498	
2023-03-19 22:42:29,592 - INFO - Train: [65/90][600/3907]	eta 0:10:13 lr 0.00768677	time 0.1804 (0.1856)	loss 2.2668 (3.5754)	acc@1: 78.6570	acc@5: 91.1163	
2023-03-19 22:43:24,496 - INFO - Train: [65/90][900/3907]	eta 0:09:15 lr 0.00768677	time 0.1849 (0.1847)	loss 4.8380 (3.5941)	acc@1: 45.2004	acc@5: 58.1056	
2023-03-19 22:44:19,366 - INFO - Train: [65/90][1200/3907]	eta 0:08:18 lr 0.00768677	time 0.1809 (0.1843)	loss 3.2098 (3.5697)	acc@1: 71.4820	acc@5: 82.6821	
2023-03-19 22:45:14,165 - INFO - Train: [65/90][1500/3907]	eta 0:07:22 lr 0.00768677	time 0.1877 (0.1840)	loss 2.0229 (3.5684)	acc@1: 85.8283	acc@5: 96.7529	
2023-03-19 22:46:09,112 - INFO - Train: [65/90][1800/3907]	eta 0:06:27 lr 0.00768677	time 0.1848 (0.1838)	loss 2.0686 (3.5653)	acc@1: 84.9218	acc@5: 95.0498	
2023-03-19 22:47:04,045 - INFO - Train: [65/90][2100/3907]	eta 0:05:31 lr 0.00768677	time 0.1800 (0.1837)	loss 2.2934 (3.5644)	acc@1: 78.8921	acc@5: 89.8276	
2023-03-19 22:47:59,002 - INFO - Train: [65/90][2400/3907]	eta 0:04:36 lr 0.00768677	time 0.1860 (0.1836)	loss 2.0979 (3.5705)	acc@1: 85.0547	acc@5: 94.4185	
2023-03-19 22:48:54,093 - INFO - Train: [65/90][2700/3907]	eta 0:03:41 lr 0.00768677	time 0.1848 (0.1836)	loss 3.3447 (3.5576)	acc@1: 68.6892	acc@5: 83.0735	
2023-03-19 22:49:47,178 - INFO - Train: [65/90][3000/3907]	eta 0:02:45 lr 0.00768677	time 0.1729 (0.1830)	loss 5.4947 (3.5675)	acc@1: 28.8501	acc@5: 44.1834	
2023-03-19 22:50:39,617 - INFO - Train: [65/90][3300/3907]	eta 0:01:50 lr 0.00768677	time 0.1715 (0.1822)	loss 5.4386 (3.5584)	acc@1: 27.4762	acc@5: 45.4891	
2023-03-19 22:51:31,858 - INFO - Train: [65/90][3600/3907]	eta 0:00:55 lr 0.00768677	time 0.1714 (0.1816)	loss 2.2959 (3.5670)	acc@1: 81.5890	acc@5: 92.2592	
2023-03-19 22:52:24,108 - INFO - Train: [65/90][3900/3907]	eta 0:00:01 lr 0.00768677	time 0.1790 (0.1810)	loss 4.0522 (3.5710)	acc@1: 56.8845	acc@5: 69.4360	
2023-03-19 22:52:25,256 - INFO - EPOCH 65 training takes 0:11:47
2023-03-19 22:52:26,345 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Latest.pth saved !!!
2023-03-19 22:52:26,345 - INFO - **********Latest test***********
2023-03-19 22:52:26,345 - INFO - eval epoch 65
2023-03-19 22:52:26,949 - INFO - Test: [0/782]	Time 0.602 (0.602)	Loss 2.3858 (2.3858)	Acc@1 74.219 (74.219)	Acc@5 92.969 (92.969)
2023-03-19 22:54:23,667 - INFO - Test: [200/782]	Time 0.574 (0.584)	Loss 2.5953 (2.6840)	Acc@1 65.625 (69.687)	Acc@5 89.844 (88.079)
2023-03-19 22:56:20,876 - INFO - Test: [400/782]	Time 0.586 (0.585)	Loss 2.5432 (2.6545)	Acc@1 72.656 (70.392)	Acc@5 88.281 (88.585)
2023-03-19 22:58:18,865 - INFO - Test: [600/782]	Time 0.583 (0.587)	Loss 2.8113 (2.6316)	Acc@1 66.406 (70.944)	Acc@5 86.719 (88.996)
2023-03-19 23:00:03,443 - INFO -  * Acc@1 71.445 Acc@5 89.369
2023-03-19 23:00:03,443 - INFO - Max accuracy: 71.4450%
2023-03-19 23:00:04,381 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Best.pth saved !!!
2023-03-19 23:00:04,382 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-19 23:00:06,413 - INFO - Train: [66/90][0/3907]	eta 2:11:59 lr 0.00714425	time 2.0269 (2.0269)	loss 3.1732 (3.1732)	acc@1: 69.6606	acc@5: 83.0298	
2023-03-19 23:01:01,063 - INFO - Train: [66/90][300/3907]	eta 0:11:19 lr 0.00714425	time 0.1834 (0.1883)	loss 2.6457 (3.4423)	acc@1: 78.4059	acc@5: 88.8458	
2023-03-19 23:01:55,856 - INFO - Train: [66/90][600/3907]	eta 0:10:13 lr 0.00714425	time 0.1795 (0.1855)	loss 2.7399 (3.4582)	acc@1: 76.8409	acc@5: 84.2907	
2023-03-19 23:02:50,716 - INFO - Train: [66/90][900/3907]	eta 0:09:15 lr 0.00714425	time 0.1805 (0.1846)	loss 2.7841 (3.5223)	acc@1: 78.9771	acc@5: 86.3939	
2023-03-19 23:03:45,734 - INFO - Train: [66/90][1200/3907]	eta 0:08:18 lr 0.00714425	time 0.1885 (0.1843)	loss 4.8172 (3.5215)	acc@1: 46.7715	acc@5: 58.8702	
2023-03-19 23:04:40,684 - INFO - Train: [66/90][1500/3907]	eta 0:07:23 lr 0.00714425	time 0.1821 (0.1841)	loss 2.9063 (3.5239)	acc@1: 71.0853	acc@5: 85.8947	
2023-03-19 23:05:35,753 - INFO - Train: [66/90][1800/3907]	eta 0:06:27 lr 0.00714425	time 0.1876 (0.1840)	loss 5.5405 (3.5127)	acc@1: 28.6020	acc@5: 41.5444	
2023-03-19 23:06:29,777 - INFO - Train: [66/90][2100/3907]	eta 0:05:31 lr 0.00714425	time 0.1733 (0.1834)	loss 2.3497 (3.5177)	acc@1: 81.5475	acc@5: 92.1150	
2023-03-19 23:07:22,433 - INFO - Train: [66/90][2400/3907]	eta 0:04:34 lr 0.00714425	time 0.1786 (0.1824)	loss 2.4715 (3.5164)	acc@1: 79.6680	acc@5: 92.5592	
2023-03-19 23:08:15,218 - INFO - Train: [66/90][2700/3907]	eta 0:03:39 lr 0.00714425	time 0.1747 (0.1817)	loss 5.0301 (3.5208)	acc@1: 41.0493	acc@5: 53.9760	
2023-03-19 23:09:07,832 - INFO - Train: [66/90][3000/3907]	eta 0:02:44 lr 0.00714425	time 0.1731 (0.1811)	loss 4.6089 (3.5044)	acc@1: 49.1088	acc@5: 60.9475	
2023-03-19 23:09:59,911 - INFO - Train: [66/90][3300/3907]	eta 0:01:49 lr 0.00714425	time 0.1714 (0.1804)	loss 2.1146 (3.5041)	acc@1: 84.3736	acc@5: 93.7485	
2023-03-19 23:10:52,421 - INFO - Train: [66/90][3600/3907]	eta 0:00:55 lr 0.00714425	time 0.1709 (0.1800)	loss 3.0858 (3.5096)	acc@1: 71.5535	acc@5: 85.1231	
2023-03-19 23:11:45,024 - INFO - Train: [66/90][3900/3907]	eta 0:00:01 lr 0.00714425	time 0.1749 (0.1796)	loss 4.2144 (3.5118)	acc@1: 54.0714	acc@5: 70.6097	
2023-03-19 23:11:46,162 - INFO - EPOCH 66 training takes 0:11:41
2023-03-19 23:11:47,267 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Latest.pth saved !!!
2023-03-19 23:11:47,267 - INFO - **********Latest test***********
2023-03-19 23:11:47,267 - INFO - eval epoch 66
2023-03-19 23:11:47,850 - INFO - Test: [0/782]	Time 0.582 (0.582)	Loss 2.1782 (2.1782)	Acc@1 79.688 (79.688)	Acc@5 96.094 (96.094)
2023-03-19 23:13:43,482 - INFO - Test: [200/782]	Time 0.576 (0.578)	Loss 2.5385 (2.5998)	Acc@1 71.094 (70.620)	Acc@5 87.500 (88.448)
2023-03-19 23:15:40,028 - INFO - Test: [400/782]	Time 0.581 (0.580)	Loss 2.4537 (2.5672)	Acc@1 71.875 (71.524)	Acc@5 89.844 (89.031)
2023-03-19 23:17:37,990 - INFO - Test: [600/782]	Time 0.589 (0.584)	Loss 2.6290 (2.5346)	Acc@1 72.656 (72.382)	Acc@5 88.281 (89.540)
2023-03-19 23:19:22,337 - INFO -  * Acc@1 72.861 Acc@5 89.928
2023-03-19 23:19:22,337 - INFO - Max accuracy: 72.8610%
2023-03-19 23:19:23,397 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Best.pth saved !!!
2023-03-19 23:19:23,398 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-19 23:19:25,496 - INFO - Train: [67/90][0/3907]	eta 2:16:20 lr 0.00661739	time 2.0938 (2.0938)	loss 5.1290 (5.1290)	acc@1: 40.4086	acc@5: 53.9974	
2023-03-19 23:20:20,821 - INFO - Train: [67/90][300/3907]	eta 0:11:28 lr 0.00661739	time 0.1800 (0.1908)	loss 3.3718 (3.4224)	acc@1: 69.6231	acc@5: 79.1793	
2023-03-19 23:21:16,151 - INFO - Train: [67/90][600/3907]	eta 0:10:20 lr 0.00661739	time 0.1817 (0.1876)	loss 3.6839 (3.4552)	acc@1: 65.7403	acc@5: 78.2309	
2023-03-19 23:22:11,503 - INFO - Train: [67/90][900/3907]	eta 0:09:21 lr 0.00661739	time 0.1798 (0.1866)	loss 4.6798 (3.4465)	acc@1: 47.4823	acc@5: 57.8383	
2023-03-19 23:23:06,694 - INFO - Train: [67/90][1200/3907]	eta 0:08:23 lr 0.00661739	time 0.1800 (0.1859)	loss 2.6754 (3.4749)	acc@1: 80.2288	acc@5: 88.3962	
2023-03-19 23:24:02,232 - INFO - Train: [67/90][1500/3907]	eta 0:07:27 lr 0.00661739	time 0.1810 (0.1858)	loss 5.3357 (3.4824)	acc@1: 32.5329	acc@5: 46.9737	
2023-03-19 23:24:57,311 - INFO - Train: [67/90][1800/3907]	eta 0:06:30 lr 0.00661739	time 0.1821 (0.1854)	loss 2.0444 (3.4812)	acc@1: 86.6569	acc@5: 96.8063	
2023-03-19 23:25:52,461 - INFO - Train: [67/90][2100/3907]	eta 0:05:34 lr 0.00661739	time 0.1805 (0.1852)	loss 5.1344 (3.4979)	acc@1: 37.6774	acc@5: 50.0788	
2023-03-19 23:26:47,399 - INFO - Train: [67/90][2400/3907]	eta 0:04:38 lr 0.00661739	time 0.1876 (0.1849)	loss 5.0177 (3.4921)	acc@1: 38.9615	acc@5: 57.0067	
2023-03-19 23:27:41,139 - INFO - Train: [67/90][2700/3907]	eta 0:03:42 lr 0.00661739	time 0.1855 (0.1843)	loss 4.3200 (3.4839)	acc@1: 55.2378	acc@5: 67.8002	
2023-03-19 23:28:34,075 - INFO - Train: [67/90][3000/3907]	eta 0:02:46 lr 0.00661739	time 0.1710 (0.1835)	loss 5.0283 (3.4850)	acc@1: 39.3151	acc@5: 54.8470	
2023-03-19 23:29:26,881 - INFO - Train: [67/90][3300/3907]	eta 0:01:50 lr 0.00661739	time 0.1844 (0.1828)	loss 5.4228 (3.4900)	acc@1: 25.3874	acc@5: 42.9644	
2023-03-19 23:30:19,694 - INFO - Train: [67/90][3600/3907]	eta 0:00:55 lr 0.00661739	time 0.1726 (0.1822)	loss 4.0607 (3.4965)	acc@1: 59.4409	acc@5: 73.1143	
2023-03-19 23:31:12,716 - INFO - Train: [67/90][3900/3907]	eta 0:00:01 lr 0.00661739	time 0.1732 (0.1818)	loss 2.0761 (3.5045)	acc@1: 86.7115	acc@5: 96.8669	
2023-03-19 23:31:13,888 - INFO - EPOCH 67 training takes 0:11:50
2023-03-19 23:31:14,969 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Latest.pth saved !!!
2023-03-19 23:31:14,970 - INFO - **********Latest test***********
2023-03-19 23:31:14,970 - INFO - eval epoch 67
2023-03-19 23:31:15,571 - INFO - Test: [0/782]	Time 0.600 (0.600)	Loss 2.2540 (2.2540)	Acc@1 79.688 (79.688)	Acc@5 95.312 (95.312)
2023-03-19 23:33:12,726 - INFO - Test: [200/782]	Time 0.572 (0.586)	Loss 2.6411 (2.6140)	Acc@1 70.312 (70.845)	Acc@5 87.500 (88.787)
2023-03-19 23:35:10,049 - INFO - Test: [400/782]	Time 0.592 (0.586)	Loss 2.5709 (2.5814)	Acc@1 70.312 (71.846)	Acc@5 88.281 (89.294)
2023-03-19 23:37:08,343 - INFO - Test: [600/782]	Time 0.591 (0.588)	Loss 2.6135 (2.5509)	Acc@1 72.656 (72.608)	Acc@5 89.844 (89.718)
2023-03-19 23:38:53,197 - INFO -  * Acc@1 73.124 Acc@5 90.077
2023-03-19 23:38:53,197 - INFO - Max accuracy: 73.1240%
2023-03-19 23:38:54,251 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Best.pth saved !!!
2023-03-19 23:38:54,252 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-19 23:38:56,256 - INFO - Train: [68/90][0/3907]	eta 2:10:16 lr 0.00610683	time 2.0007 (2.0007)	loss 4.1780 (4.1780)	acc@1: 58.3156	acc@5: 71.9259	
2023-03-19 23:39:51,365 - INFO - Train: [68/90][300/3907]	eta 0:11:24 lr 0.00610683	time 0.1878 (0.1897)	loss 2.0927 (3.5030)	acc@1: 91.8675	acc@5: 95.7100	
2023-03-19 23:40:46,819 - INFO - Train: [68/90][600/3907]	eta 0:10:19 lr 0.00610683	time 0.1858 (0.1873)	loss 2.0872 (3.4970)	acc@1: 84.9234	acc@5: 96.5025	
2023-03-19 23:41:42,115 - INFO - Train: [68/90][900/3907]	eta 0:09:20 lr 0.00610683	time 0.1801 (0.1863)	loss 4.3608 (3.5223)	acc@1: 54.9220	acc@5: 65.0001	
2023-03-19 23:42:37,209 - INFO - Train: [68/90][1200/3907]	eta 0:08:22 lr 0.00610683	time 0.1801 (0.1856)	loss 2.3362 (3.4893)	acc@1: 82.5015	acc@5: 93.0949	
2023-03-19 23:43:32,240 - INFO - Train: [68/90][1500/3907]	eta 0:07:25 lr 0.00610683	time 0.1804 (0.1852)	loss 4.6794 (3.4862)	acc@1: 47.0720	acc@5: 61.6166	
2023-03-19 23:44:27,638 - INFO - Train: [68/90][1800/3907]	eta 0:06:30 lr 0.00610683	time 0.1799 (0.1851)	loss 4.0203 (3.4832)	acc@1: 58.9258	acc@5: 72.3471	
2023-03-19 23:45:22,906 - INFO - Train: [68/90][2100/3907]	eta 0:05:34 lr 0.00610683	time 0.1793 (0.1850)	loss 4.2647 (3.4897)	acc@1: 58.8712	acc@5: 65.1561	
2023-03-19 23:46:18,080 - INFO - Train: [68/90][2400/3907]	eta 0:04:38 lr 0.00610683	time 0.1812 (0.1848)	loss 2.7377 (3.4956)	acc@1: 80.6441	acc@5: 88.7037	
2023-03-19 23:47:13,223 - INFO - Train: [68/90][2700/3907]	eta 0:03:42 lr 0.00610683	time 0.1798 (0.1847)	loss 2.9250 (3.4888)	acc@1: 75.5243	acc@5: 87.2562	
2023-03-19 23:48:06,100 - INFO - Train: [68/90][3000/3907]	eta 0:02:46 lr 0.00610683	time 0.1791 (0.1839)	loss 2.0443 (3.4788)	acc@1: 86.5872	acc@5: 97.5081	
2023-03-19 23:48:58,799 - INFO - Train: [68/90][3300/3907]	eta 0:01:51 lr 0.00610683	time 0.1765 (0.1831)	loss 5.0925 (3.4837)	acc@1: 35.9600	acc@5: 52.0252	
2023-03-19 23:49:51,596 - INFO - Train: [68/90][3600/3907]	eta 0:00:56 lr 0.00610683	time 0.1857 (0.1825)	loss 2.8877 (3.4806)	acc@1: 69.6492	acc@5: 86.6910	
2023-03-19 23:50:44,327 - INFO - Train: [68/90][3900/3907]	eta 0:00:01 lr 0.00610683	time 0.1708 (0.1820)	loss 5.8333 (3.4820)	acc@1: 20.8526	acc@5: 38.8485	
2023-03-19 23:50:45,506 - INFO - EPOCH 68 training takes 0:11:51
2023-03-19 23:50:46,588 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Latest.pth saved !!!
2023-03-19 23:50:46,588 - INFO - **********Latest test***********
2023-03-19 23:50:46,589 - INFO - eval epoch 68
2023-03-19 23:50:47,176 - INFO - Test: [0/782]	Time 0.587 (0.587)	Loss 2.3559 (2.3559)	Acc@1 76.562 (76.562)	Acc@5 94.531 (94.531)
2023-03-19 23:52:43,758 - INFO - Test: [200/782]	Time 0.572 (0.583)	Loss 2.6570 (2.6694)	Acc@1 67.969 (70.215)	Acc@5 85.938 (88.487)
2023-03-19 23:54:40,450 - INFO - Test: [400/782]	Time 0.586 (0.583)	Loss 2.5887 (2.6414)	Acc@1 74.219 (70.946)	Acc@5 89.844 (88.975)
2023-03-19 23:56:38,029 - INFO - Test: [600/782]	Time 0.576 (0.585)	Loss 2.7400 (2.6134)	Acc@1 69.531 (71.683)	Acc@5 89.062 (89.374)
2023-03-19 23:58:22,548 - INFO -  * Acc@1 72.232 Acc@5 89.733
2023-03-19 23:58:22,548 - INFO - Max accuracy: 73.1240%
2023-03-19 23:58:22,548 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-19 23:58:24,541 - INFO - Train: [69/90][0/3907]	eta 2:09:36 lr 0.00561320	time 1.9903 (1.9903)	loss 2.7882 (2.7882)	acc@1: 76.1609	acc@5: 86.7141	
2023-03-19 23:59:19,550 - INFO - Train: [69/90][300/3907]	eta 0:11:23 lr 0.00561320	time 0.1782 (0.1894)	loss 2.2950 (3.4767)	acc@1: 79.4373	acc@5: 89.5617	
2023-03-20 00:00:14,610 - INFO - Train: [69/90][600/3907]	eta 0:10:16 lr 0.00561320	time 0.1879 (0.1864)	loss 5.1971 (3.4908)	acc@1: 36.9515	acc@5: 49.8030	
2023-03-20 00:01:09,630 - INFO - Train: [69/90][900/3907]	eta 0:09:17 lr 0.00561320	time 0.1789 (0.1854)	loss 5.2559 (3.4982)	acc@1: 33.7580	acc@5: 48.3254	
2023-03-20 00:02:04,717 - INFO - Train: [69/90][1200/3907]	eta 0:08:20 lr 0.00561320	time 0.1880 (0.1850)	loss 4.4814 (3.4958)	acc@1: 50.5000	acc@5: 65.6994	
2023-03-20 00:02:59,815 - INFO - Train: [69/90][1500/3907]	eta 0:07:24 lr 0.00561320	time 0.1827 (0.1847)	loss 4.9782 (3.4691)	acc@1: 39.9734	acc@5: 56.3635	
2023-03-20 00:03:54,899 - INFO - Train: [69/90][1800/3907]	eta 0:06:28 lr 0.00561320	time 0.1829 (0.1845)	loss 2.5325 (3.4567)	acc@1: 80.8833	acc@5: 90.6193	
2023-03-20 00:04:49,950 - INFO - Train: [69/90][2100/3907]	eta 0:05:33 lr 0.00561320	time 0.1814 (0.1844)	loss 2.3983 (3.4541)	acc@1: 80.6997	acc@5: 90.5969	
2023-03-20 00:05:44,965 - INFO - Train: [69/90][2400/3907]	eta 0:04:37 lr 0.00561320	time 0.1842 (0.1843)	loss 2.9310 (3.4632)	acc@1: 75.4317	acc@5: 87.7527	
2023-03-20 00:06:39,906 - INFO - Train: [69/90][2700/3907]	eta 0:03:42 lr 0.00561320	time 0.1802 (0.1841)	loss 2.0105 (3.4620)	acc@1: 84.8890	acc@5: 95.7946	
2023-03-20 00:07:34,737 - INFO - Train: [69/90][3000/3907]	eta 0:02:46 lr 0.00561320	time 0.1803 (0.1840)	loss 4.8262 (3.4692)	acc@1: 41.4748	acc@5: 56.7693	
2023-03-20 00:08:29,744 - INFO - Train: [69/90][3300/3907]	eta 0:01:51 lr 0.00561320	time 0.1803 (0.1839)	loss 3.0090 (3.4702)	acc@1: 73.4429	acc@5: 82.1688	
2023-03-20 00:09:24,757 - INFO - Train: [69/90][3600/3907]	eta 0:00:56 lr 0.00561320	time 0.1797 (0.1839)	loss 4.8902 (3.4725)	acc@1: 45.6594	acc@5: 56.3239	
2023-03-20 00:10:19,639 - INFO - Train: [69/90][3900/3907]	eta 0:00:01 lr 0.00561320	time 0.1828 (0.1838)	loss 2.2045 (3.4734)	acc@1: 80.9365	acc@5: 93.3913	
2023-03-20 00:10:20,852 - INFO - EPOCH 69 training takes 0:11:58
2023-03-20 00:10:21,927 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Latest.pth saved !!!
2023-03-20 00:10:21,927 - INFO - **********Latest test***********
2023-03-20 00:10:21,927 - INFO - eval epoch 69
2023-03-20 00:10:22,539 - INFO - Test: [0/782]	Time 0.611 (0.611)	Loss 2.2746 (2.2746)	Acc@1 79.688 (79.688)	Acc@5 95.312 (95.312)
2023-03-20 00:12:20,793 - INFO - Test: [200/782]	Time 0.581 (0.591)	Loss 2.5997 (2.6176)	Acc@1 71.094 (71.152)	Acc@5 85.156 (88.965)
2023-03-20 00:14:18,502 - INFO - Test: [400/782]	Time 0.588 (0.590)	Loss 2.5272 (2.5894)	Acc@1 75.000 (72.039)	Acc@5 89.844 (89.372)
2023-03-20 00:16:17,090 - INFO - Test: [600/782]	Time 0.574 (0.591)	Loss 2.6002 (2.5606)	Acc@1 73.438 (72.773)	Acc@5 89.062 (89.789)
2023-03-20 00:18:03,094 - INFO -  * Acc@1 73.225 Acc@5 90.143
2023-03-20 00:18:03,094 - INFO - Max accuracy: 73.2250%
2023-03-20 00:18:04,164 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Best.pth saved !!!
2023-03-20 00:18:04,164 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-20 00:18:06,240 - INFO - Train: [70/90][0/3907]	eta 2:14:53 lr 0.00513710	time 2.0716 (2.0716)	loss 2.8341 (2.8341)	acc@1: 77.0359	acc@5: 86.0070	
2023-03-20 00:19:01,287 - INFO - Train: [70/90][300/3907]	eta 0:11:24 lr 0.00513710	time 0.1875 (0.1898)	loss 4.1058 (3.3448)	acc@1: 57.0590	acc@5: 71.5958	
2023-03-20 00:19:56,252 - INFO - Train: [70/90][600/3907]	eta 0:10:16 lr 0.00513710	time 0.1794 (0.1865)	loss 2.7785 (3.3703)	acc@1: 78.6808	acc@5: 87.4889	
2023-03-20 00:20:51,372 - INFO - Train: [70/90][900/3907]	eta 0:09:18 lr 0.00513710	time 0.1797 (0.1856)	loss 2.6151 (3.3700)	acc@1: 75.4238	acc@5: 88.8531	
2023-03-20 00:21:46,209 - INFO - Train: [70/90][1200/3907]	eta 0:08:20 lr 0.00513710	time 0.1857 (0.1849)	loss 5.1490 (3.3841)	acc@1: 30.6762	acc@5: 50.7690	
2023-03-20 00:22:41,147 - INFO - Train: [70/90][1500/3907]	eta 0:07:24 lr 0.00513710	time 0.1872 (0.1845)	loss 5.2089 (3.3867)	acc@1: 38.8885	acc@5: 49.7116	
2023-03-20 00:23:36,119 - INFO - Train: [70/90][1800/3907]	eta 0:06:28 lr 0.00513710	time 0.1794 (0.1843)	loss 5.0512 (3.4112)	acc@1: 38.7512	acc@5: 53.6888	
2023-03-20 00:24:30,977 - INFO - Train: [70/90][2100/3907]	eta 0:05:32 lr 0.00513710	time 0.1799 (0.1841)	loss 2.7012 (3.4299)	acc@1: 74.7857	acc@5: 88.1065	
2023-03-20 00:25:25,875 - INFO - Train: [70/90][2400/3907]	eta 0:04:37 lr 0.00513710	time 0.1798 (0.1840)	loss 2.1444 (3.4494)	acc@1: 90.1224	acc@5: 93.9738	
2023-03-20 00:26:18,930 - INFO - Train: [70/90][2700/3907]	eta 0:03:41 lr 0.00513710	time 0.1738 (0.1832)	loss 2.1963 (3.4504)	acc@1: 80.1043	acc@5: 94.1025	
2023-03-20 00:27:11,489 - INFO - Train: [70/90][3000/3907]	eta 0:02:45 lr 0.00513710	time 0.1788 (0.1824)	loss 2.3086 (3.4561)	acc@1: 78.4910	acc@5: 91.5827	
2023-03-20 00:28:03,930 - INFO - Train: [70/90][3300/3907]	eta 0:01:50 lr 0.00513710	time 0.1701 (0.1817)	loss 3.4659 (3.4548)	acc@1: 66.4243	acc@5: 75.4071	
2023-03-20 00:28:56,617 - INFO - Train: [70/90][3600/3907]	eta 0:00:55 lr 0.00513710	time 0.1790 (0.1812)	loss 2.5699 (3.4492)	acc@1: 77.9220	acc@5: 87.7757	
2023-03-20 00:29:49,201 - INFO - Train: [70/90][3900/3907]	eta 0:00:01 lr 0.00513710	time 0.1705 (0.1807)	loss 4.8555 (3.4504)	acc@1: 42.6342	acc@5: 56.4542	
2023-03-20 00:29:50,368 - INFO - EPOCH 70 training takes 0:11:46
2023-03-20 00:29:51,457 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Latest.pth saved !!!
2023-03-20 00:29:51,458 - INFO - **********Latest test***********
2023-03-20 00:29:51,458 - INFO - eval epoch 70
2023-03-20 00:29:52,067 - INFO - Test: [0/782]	Time 0.608 (0.608)	Loss 2.2258 (2.2258)	Acc@1 82.812 (82.812)	Acc@5 95.312 (95.312)
2023-03-20 00:31:47,401 - INFO - Test: [200/782]	Time 0.566 (0.577)	Loss 2.5991 (2.5937)	Acc@1 69.531 (71.995)	Acc@5 87.500 (89.284)
2023-03-20 00:33:42,673 - INFO - Test: [400/782]	Time 0.577 (0.577)	Loss 2.4695 (2.5665)	Acc@1 76.562 (72.625)	Acc@5 89.844 (89.600)
2023-03-20 00:35:39,631 - INFO - Test: [600/782]	Time 0.577 (0.579)	Loss 2.6173 (2.5353)	Acc@1 71.094 (73.308)	Acc@5 87.500 (90.043)
2023-03-20 00:37:24,120 - INFO -  * Acc@1 73.758 Acc@5 90.407
2023-03-20 00:37:24,120 - INFO - Max accuracy: 73.7580%
2023-03-20 00:37:25,336 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Best.pth saved !!!
2023-03-20 00:37:25,337 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-20 00:37:27,426 - INFO - Train: [71/90][0/3907]	eta 2:15:46 lr 0.00467911	time 2.0851 (2.0851)	loss 2.1555 (2.1555)	acc@1: 82.6325	acc@5: 91.9871	
2023-03-20 00:38:22,307 - INFO - Train: [71/90][300/3907]	eta 0:11:22 lr 0.00467911	time 0.1908 (0.1893)	loss 2.3310 (3.4383)	acc@1: 83.3282	acc@5: 93.8341	
2023-03-20 00:39:17,231 - INFO - Train: [71/90][600/3907]	eta 0:10:15 lr 0.00467911	time 0.1789 (0.1862)	loss 5.2954 (3.3421)	acc@1: 30.1591	acc@5: 48.9877	
2023-03-20 00:40:12,176 - INFO - Train: [71/90][900/3907]	eta 0:09:16 lr 0.00467911	time 0.1875 (0.1852)	loss 2.7209 (3.3713)	acc@1: 80.6785	acc@5: 88.7316	
2023-03-20 00:41:07,240 - INFO - Train: [71/90][1200/3907]	eta 0:08:20 lr 0.00467911	time 0.1984 (0.1848)	loss 3.5738 (3.3881)	acc@1: 66.1797	acc@5: 75.7314	
2023-03-20 00:42:02,078 - INFO - Train: [71/90][1500/3907]	eta 0:07:23 lr 0.00467911	time 0.1920 (0.1844)	loss 5.1085 (3.3665)	acc@1: 37.2519	acc@5: 52.1027	
2023-03-20 00:42:57,178 - INFO - Train: [71/90][1800/3907]	eta 0:06:28 lr 0.00467911	time 0.1796 (0.1842)	loss 4.3435 (3.3866)	acc@1: 50.4499	acc@5: 69.5759	
2023-03-20 00:43:52,093 - INFO - Train: [71/90][2100/3907]	eta 0:05:32 lr 0.00467911	time 0.1801 (0.1841)	loss 2.9179 (3.3914)	acc@1: 75.0060	acc@5: 86.4013	
2023-03-20 00:44:47,086 - INFO - Train: [71/90][2400/3907]	eta 0:04:37 lr 0.00467911	time 0.1801 (0.1840)	loss 2.4947 (3.3875)	acc@1: 79.3957	acc@5: 90.0787	
2023-03-20 00:45:42,104 - INFO - Train: [71/90][2700/3907]	eta 0:03:41 lr 0.00467911	time 0.1849 (0.1839)	loss 2.6777 (3.3799)	acc@1: 78.3522	acc@5: 87.8595	
2023-03-20 00:46:37,134 - INFO - Train: [71/90][3000/3907]	eta 0:02:46 lr 0.00467911	time 0.1807 (0.1839)	loss 3.7942 (3.3919)	acc@1: 64.2424	acc@5: 74.9377	
2023-03-20 00:47:31,920 - INFO - Train: [71/90][3300/3907]	eta 0:01:51 lr 0.00467911	time 0.1718 (0.1838)	loss 4.6731 (3.3962)	acc@1: 46.0632	acc@5: 59.9189	
2023-03-20 00:48:24,265 - INFO - Train: [71/90][3600/3907]	eta 0:00:56 lr 0.00467911	time 0.1719 (0.1830)	loss 3.2349 (3.3998)	acc@1: 73.8696	acc@5: 82.1438	
2023-03-20 00:49:16,996 - INFO - Train: [71/90][3900/3907]	eta 0:00:01 lr 0.00467911	time 0.1710 (0.1824)	loss 2.2973 (3.4097)	acc@1: 78.6143	acc@5: 91.0706	
2023-03-20 00:49:18,191 - INFO - EPOCH 71 training takes 0:11:52
2023-03-20 00:49:19,296 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Latest.pth saved !!!
2023-03-20 00:49:19,297 - INFO - **********Latest test***********
2023-03-20 00:49:19,297 - INFO - eval epoch 71
2023-03-20 00:49:19,896 - INFO - Test: [0/782]	Time 0.598 (0.598)	Loss 2.2326 (2.2326)	Acc@1 76.562 (76.562)	Acc@5 93.750 (93.750)
2023-03-20 00:51:16,162 - INFO - Test: [200/782]	Time 0.577 (0.581)	Loss 2.5255 (2.5583)	Acc@1 74.219 (72.229)	Acc@5 87.500 (89.463)
2023-03-20 00:53:13,609 - INFO - Test: [400/782]	Time 0.583 (0.584)	Loss 2.4746 (2.5284)	Acc@1 75.000 (73.052)	Acc@5 90.625 (89.961)
2023-03-20 00:55:11,483 - INFO - Test: [600/782]	Time 0.586 (0.586)	Loss 2.5697 (2.4980)	Acc@1 72.656 (73.911)	Acc@5 91.406 (90.403)
2023-03-20 00:56:55,888 - INFO -  * Acc@1 74.352 Acc@5 90.746
2023-03-20 00:56:55,888 - INFO - Max accuracy: 74.3520%
2023-03-20 00:56:56,931 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Best.pth saved !!!
2023-03-20 00:56:56,931 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-20 00:56:58,806 - INFO - Train: [72/90][0/3907]	eta 2:01:52 lr 0.00423978	time 1.8716 (1.8716)	loss 2.6434 (2.6434)	acc@1: 81.3853	acc@5: 90.1784	
2023-03-20 00:57:53,456 - INFO - Train: [72/90][300/3907]	eta 0:11:17 lr 0.00423978	time 0.1871 (0.1878)	loss 2.2045 (3.2978)	acc@1: 84.3672	acc@5: 92.1789	
2023-03-20 00:58:48,126 - INFO - Train: [72/90][600/3907]	eta 0:10:11 lr 0.00423978	time 0.1830 (0.1850)	loss 2.2630 (3.3951)	acc@1: 83.5730	acc@5: 93.6327	
2023-03-20 00:59:42,866 - INFO - Train: [72/90][900/3907]	eta 0:09:13 lr 0.00423978	time 0.1867 (0.1842)	loss 3.1532 (3.4001)	acc@1: 74.5658	acc@5: 84.2285	
2023-03-20 01:00:37,568 - INFO - Train: [72/90][1200/3907]	eta 0:08:17 lr 0.00423978	time 0.1822 (0.1837)	loss 5.2365 (3.3669)	acc@1: 29.4731	acc@5: 47.3851	
2023-03-20 01:01:32,338 - INFO - Train: [72/90][1500/3907]	eta 0:07:21 lr 0.00423978	time 0.1881 (0.1835)	loss 2.5312 (3.3653)	acc@1: 81.3666	acc@5: 91.0667	
2023-03-20 01:02:27,016 - INFO - Train: [72/90][1800/3907]	eta 0:06:26 lr 0.00423978	time 0.1826 (0.1833)	loss 3.4631 (3.3962)	acc@1: 70.3729	acc@5: 78.9890	
2023-03-20 01:03:21,868 - INFO - Train: [72/90][2100/3907]	eta 0:05:31 lr 0.00423978	time 0.1872 (0.1832)	loss 3.6141 (3.3951)	acc@1: 69.0479	acc@5: 76.2684	
2023-03-20 01:04:16,771 - INFO - Train: [72/90][2400/3907]	eta 0:04:36 lr 0.00423978	time 0.1847 (0.1832)	loss 3.2738 (3.3888)	acc@1: 73.4936	acc@5: 84.4691	
2023-03-20 01:05:09,414 - INFO - Train: [72/90][2700/3907]	eta 0:03:40 lr 0.00423978	time 0.1715 (0.1823)	loss 3.2056 (3.4020)	acc@1: 73.3031	acc@5: 83.0743	
2023-03-20 01:06:01,731 - INFO - Train: [72/90][3000/3907]	eta 0:02:44 lr 0.00423978	time 0.1712 (0.1815)	loss 4.4443 (3.4030)	acc@1: 50.1493	acc@5: 66.2585	
2023-03-20 01:06:54,161 - INFO - Train: [72/90][3300/3907]	eta 0:01:49 lr 0.00423978	time 0.1711 (0.1809)	loss 5.0930 (3.3983)	acc@1: 35.1442	acc@5: 50.0118	
2023-03-20 01:07:46,793 - INFO - Train: [72/90][3600/3907]	eta 0:00:55 lr 0.00423978	time 0.1713 (0.1805)	loss 2.9495 (3.3957)	acc@1: 75.8616	acc@5: 85.2540	
2023-03-20 01:08:39,340 - INFO - Train: [72/90][3900/3907]	eta 0:00:01 lr 0.00423978	time 0.1714 (0.1801)	loss 4.0132 (3.3954)	acc@1: 62.9280	acc@5: 69.0909	
2023-03-20 01:08:40,510 - INFO - EPOCH 72 training takes 0:11:43
2023-03-20 01:08:41,586 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Latest.pth saved !!!
2023-03-20 01:08:41,587 - INFO - **********Latest test***********
2023-03-20 01:08:41,587 - INFO - eval epoch 72
2023-03-20 01:08:42,194 - INFO - Test: [0/782]	Time 0.606 (0.606)	Loss 2.2251 (2.2251)	Acc@1 82.031 (82.031)	Acc@5 94.531 (94.531)
2023-03-20 01:10:38,256 - INFO - Test: [200/782]	Time 0.581 (0.580)	Loss 2.5140 (2.5404)	Acc@1 71.094 (72.512)	Acc@5 89.062 (89.758)
2023-03-20 01:12:35,394 - INFO - Test: [400/782]	Time 0.589 (0.583)	Loss 2.4853 (2.5138)	Acc@1 73.438 (73.387)	Acc@5 91.406 (90.169)
2023-03-20 01:14:33,936 - INFO - Test: [600/782]	Time 0.585 (0.586)	Loss 2.5567 (2.4822)	Acc@1 75.000 (74.256)	Acc@5 87.500 (90.586)
2023-03-20 01:16:19,163 - INFO -  * Acc@1 74.681 Acc@5 90.890
2023-03-20 01:16:19,164 - INFO - Max accuracy: 74.6810%
2023-03-20 01:16:20,201 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Best.pth saved !!!
2023-03-20 01:16:20,202 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-20 01:16:22,211 - INFO - Train: [73/90][0/3907]	eta 2:10:36 lr 0.00381966	time 2.0058 (2.0058)	loss 2.0614 (2.0614)	acc@1: 82.7756	acc@5: 93.7082	
2023-03-20 01:17:16,901 - INFO - Train: [73/90][300/3907]	eta 0:11:19 lr 0.00381966	time 0.1845 (0.1883)	loss 2.0755 (3.2515)	acc@1: 86.4916	acc@5: 95.0624	
2023-03-20 01:18:11,544 - INFO - Train: [73/90][600/3907]	eta 0:10:12 lr 0.00381966	time 0.1800 (0.1853)	loss 4.0594 (3.3051)	acc@1: 62.5872	acc@5: 70.7764	
2023-03-20 01:19:06,458 - INFO - Train: [73/90][900/3907]	eta 0:09:14 lr 0.00381966	time 0.1870 (0.1845)	loss 2.7139 (3.3085)	acc@1: 80.5137	acc@5: 88.5650	
2023-03-20 01:20:01,539 - INFO - Train: [73/90][1200/3907]	eta 0:08:18 lr 0.00381966	time 0.1846 (0.1843)	loss 4.1458 (3.3359)	acc@1: 60.3636	acc@5: 69.5450	
2023-03-20 01:20:56,328 - INFO - Train: [73/90][1500/3907]	eta 0:07:22 lr 0.00381966	time 0.1798 (0.1840)	loss 3.4273 (3.3475)	acc@1: 69.4083	acc@5: 80.7660	
2023-03-20 01:21:51,112 - INFO - Train: [73/90][1800/3907]	eta 0:06:27 lr 0.00381966	time 0.1805 (0.1837)	loss 4.9033 (3.3462)	acc@1: 35.9018	acc@5: 53.7032	
2023-03-20 01:22:46,219 - INFO - Train: [73/90][2100/3907]	eta 0:05:31 lr 0.00381966	time 0.1847 (0.1837)	loss 2.4868 (3.3453)	acc@1: 77.5628	acc@5: 89.7295	
2023-03-20 01:23:41,023 - INFO - Train: [73/90][2400/3907]	eta 0:04:36 lr 0.00381966	time 0.1867 (0.1836)	loss 5.2612 (3.3531)	acc@1: 31.1764	acc@5: 48.1488	
2023-03-20 01:24:35,529 - INFO - Train: [73/90][2700/3907]	eta 0:03:41 lr 0.00381966	time 0.1889 (0.1834)	loss 5.2318 (3.3545)	acc@1: 30.4988	acc@5: 47.0189	
2023-03-20 01:25:30,412 - INFO - Train: [73/90][3000/3907]	eta 0:02:46 lr 0.00381966	time 0.1797 (0.1833)	loss 3.9103 (3.3633)	acc@1: 62.8975	acc@5: 70.5806	
2023-03-20 01:26:25,016 - INFO - Train: [73/90][3300/3907]	eta 0:01:51 lr 0.00381966	time 0.1795 (0.1832)	loss 3.6470 (3.3526)	acc@1: 64.7488	acc@5: 78.7417	
2023-03-20 01:27:18,312 - INFO - Train: [73/90][3600/3907]	eta 0:00:56 lr 0.00381966	time 0.1788 (0.1828)	loss 4.3507 (3.3697)	acc@1: 53.2247	acc@5: 67.3021	
2023-03-20 01:28:10,722 - INFO - Train: [73/90][3900/3907]	eta 0:00:01 lr 0.00381966	time 0.1707 (0.1821)	loss 2.0067 (3.3747)	acc@1: 88.0744	acc@5: 97.3444	
2023-03-20 01:28:11,848 - INFO - EPOCH 73 training takes 0:11:51
2023-03-20 01:28:12,914 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Latest.pth saved !!!
2023-03-20 01:28:12,915 - INFO - **********Latest test***********
2023-03-20 01:28:12,915 - INFO - eval epoch 73
2023-03-20 01:28:13,530 - INFO - Test: [0/782]	Time 0.614 (0.614)	Loss 2.1739 (2.1739)	Acc@1 80.469 (80.469)	Acc@5 95.312 (95.312)
2023-03-20 01:30:12,059 - INFO - Test: [200/782]	Time 0.617 (0.593)	Loss 2.4208 (2.5051)	Acc@1 75.781 (73.426)	Acc@5 89.844 (90.058)
2023-03-20 01:32:09,656 - INFO - Test: [400/782]	Time 0.586 (0.590)	Loss 2.4083 (2.4798)	Acc@1 76.562 (74.135)	Acc@5 92.188 (90.381)
2023-03-20 01:34:07,819 - INFO - Test: [600/782]	Time 0.580 (0.591)	Loss 2.5424 (2.4489)	Acc@1 73.438 (74.857)	Acc@5 89.062 (90.842)
2023-03-20 01:35:52,512 - INFO -  * Acc@1 75.243 Acc@5 91.154
2023-03-20 01:35:52,512 - INFO - Max accuracy: 75.2430%
2023-03-20 01:35:53,561 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Best.pth saved !!!
2023-03-20 01:35:53,561 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-20 01:35:55,372 - INFO - Train: [74/90][0/3907]	eta 1:57:38 lr 0.00341925	time 1.8066 (1.8066)	loss 2.4892 (2.4892)	acc@1: 83.1955	acc@5: 93.5901	
2023-03-20 01:36:49,859 - INFO - Train: [74/90][300/3907]	eta 0:11:14 lr 0.00341925	time 0.1790 (0.1870)	loss 3.2532 (3.4219)	acc@1: 75.8001	acc@5: 82.0941	
2023-03-20 01:37:45,051 - INFO - Train: [74/90][600/3907]	eta 0:10:13 lr 0.00341925	time 0.1800 (0.1855)	loss 4.8725 (3.3766)	acc@1: 42.4314	acc@5: 54.8977	
2023-03-20 01:38:39,758 - INFO - Train: [74/90][900/3907]	eta 0:09:14 lr 0.00341925	time 0.1801 (0.1844)	loss 2.4717 (3.3274)	acc@1: 77.3193	acc@5: 88.8000	
2023-03-20 01:39:34,491 - INFO - Train: [74/90][1200/3907]	eta 0:08:17 lr 0.00341925	time 0.1842 (0.1839)	loss 4.1200 (3.3708)	acc@1: 57.8317	acc@5: 68.7073	
2023-03-20 01:40:29,156 - INFO - Train: [74/90][1500/3907]	eta 0:07:21 lr 0.00341925	time 0.1797 (0.1836)	loss 2.2902 (3.3714)	acc@1: 80.8602	acc@5: 92.3000	
2023-03-20 01:41:23,926 - INFO - Train: [74/90][1800/3907]	eta 0:06:26 lr 0.00341925	time 0.1873 (0.1834)	loss 3.4490 (3.3700)	acc@1: 70.4589	acc@5: 78.4354	
2023-03-20 01:42:18,966 - INFO - Train: [74/90][2100/3907]	eta 0:05:31 lr 0.00341925	time 0.1800 (0.1834)	loss 5.1746 (3.3702)	acc@1: 35.5947	acc@5: 49.3721	
2023-03-20 01:43:13,767 - INFO - Train: [74/90][2400/3907]	eta 0:04:36 lr 0.00341925	time 0.1800 (0.1833)	loss 1.9530 (3.3630)	acc@1: 88.1792	acc@5: 95.9825	
2023-03-20 01:44:08,400 - INFO - Train: [74/90][2700/3907]	eta 0:03:41 lr 0.00341925	time 0.1795 (0.1832)	loss 1.8403 (3.3763)	acc@1: 89.0625	acc@5: 97.6562	
2023-03-20 01:45:00,721 - INFO - Train: [74/90][3000/3907]	eta 0:02:45 lr 0.00341925	time 0.1886 (0.1823)	loss 2.5957 (3.3649)	acc@1: 79.5588	acc@5: 91.2372	
2023-03-20 01:45:53,009 - INFO - Train: [74/90][3300/3907]	eta 0:01:50 lr 0.00341925	time 0.1713 (0.1816)	loss 2.4345 (3.3526)	acc@1: 81.8965	acc@5: 90.8266	
2023-03-20 01:46:45,531 - INFO - Train: [74/90][3600/3907]	eta 0:00:55 lr 0.00341925	time 0.1804 (0.1810)	loss 4.4109 (3.3507)	acc@1: 53.0054	acc@5: 66.5821	
2023-03-20 01:47:37,829 - INFO - Train: [74/90][3900/3907]	eta 0:00:01 lr 0.00341925	time 0.1712 (0.1805)	loss 2.4626 (3.3511)	acc@1: 86.1108	acc@5: 91.3523	
2023-03-20 01:47:38,962 - INFO - EPOCH 74 training takes 0:11:45
2023-03-20 01:47:40,038 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Latest.pth saved !!!
2023-03-20 01:47:40,039 - INFO - **********Latest test***********
2023-03-20 01:47:40,039 - INFO - eval epoch 74
2023-03-20 01:47:40,646 - INFO - Test: [0/782]	Time 0.606 (0.606)	Loss 2.2411 (2.2411)	Acc@1 75.781 (75.781)	Acc@5 94.531 (94.531)
2023-03-20 01:49:35,990 - INFO - Test: [200/782]	Time 0.596 (0.577)	Loss 2.4490 (2.5276)	Acc@1 71.875 (73.064)	Acc@5 88.281 (89.980)
2023-03-20 01:51:31,982 - INFO - Test: [400/782]	Time 0.577 (0.578)	Loss 2.4655 (2.5008)	Acc@1 75.781 (73.923)	Acc@5 91.406 (90.354)
2023-03-20 01:53:31,192 - INFO - Test: [600/782]	Time 0.585 (0.584)	Loss 2.5666 (2.4700)	Acc@1 75.781 (74.727)	Acc@5 91.406 (90.811)
2023-03-20 01:55:16,728 - INFO -  * Acc@1 75.151 Acc@5 91.131
2023-03-20 01:55:16,728 - INFO - Max accuracy: 75.2430%
2023-03-20 01:55:16,728 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-20 01:55:18,532 - INFO - Train: [75/90][0/3907]	eta 1:57:13 lr 0.00303904	time 1.8002 (1.8002)	loss 5.4294 (5.4294)	acc@1: 28.8006	acc@5: 45.9881	
2023-03-20 01:56:13,163 - INFO - Train: [75/90][300/3907]	eta 0:11:16 lr 0.00303904	time 0.1792 (0.1875)	loss 2.1168 (3.3833)	acc@1: 86.1428	acc@5: 94.6020	
2023-03-20 01:57:07,741 - INFO - Train: [75/90][600/3907]	eta 0:10:10 lr 0.00303904	time 0.1798 (0.1847)	loss 3.1099 (3.3452)	acc@1: 76.1899	acc@5: 83.2048	
2023-03-20 01:58:02,483 - INFO - Train: [75/90][900/3907]	eta 0:09:13 lr 0.00303904	time 0.1796 (0.1840)	loss 3.8352 (3.3694)	acc@1: 61.4965	acc@5: 73.2847	
2023-03-20 01:58:57,080 - INFO - Train: [75/90][1200/3907]	eta 0:08:16 lr 0.00303904	time 0.1830 (0.1835)	loss 5.5214 (3.3792)	acc@1: 24.8103	acc@5: 39.9533	
2023-03-20 01:59:51,933 - INFO - Train: [75/90][1500/3907]	eta 0:07:21 lr 0.00303904	time 0.1797 (0.1833)	loss 3.0187 (3.3737)	acc@1: 77.9942	acc@5: 82.9782	
2023-03-20 02:00:46,546 - INFO - Train: [75/90][1800/3907]	eta 0:06:25 lr 0.00303904	time 0.1856 (0.1831)	loss 2.0987 (3.3741)	acc@1: 84.3735	acc@5: 93.7483	
2023-03-20 02:01:41,206 - INFO - Train: [75/90][2100/3907]	eta 0:05:30 lr 0.00303904	time 0.1803 (0.1830)	loss 2.3245 (3.3687)	acc@1: 81.1817	acc@5: 92.6674	
2023-03-20 02:02:35,828 - INFO - Train: [75/90][2400/3907]	eta 0:04:35 lr 0.00303904	time 0.1803 (0.1829)	loss 2.1018 (3.3629)	acc@1: 86.7347	acc@5: 93.7045	
2023-03-20 02:03:30,328 - INFO - Train: [75/90][2700/3907]	eta 0:03:40 lr 0.00303904	time 0.1798 (0.1827)	loss 2.0980 (3.3563)	acc@1: 85.0737	acc@5: 92.8793	
2023-03-20 02:04:24,410 - INFO - Train: [75/90][3000/3907]	eta 0:02:45 lr 0.00303904	time 0.1800 (0.1825)	loss 2.0390 (3.3503)	acc@1: 86.1517	acc@5: 93.9131	
2023-03-20 02:05:19,228 - INFO - Train: [75/90][3300/3907]	eta 0:01:50 lr 0.00303904	time 0.1797 (0.1825)	loss 3.6346 (3.3423)	acc@1: 68.5166	acc@5: 77.9857	
2023-03-20 02:06:13,839 - INFO - Train: [75/90][3600/3907]	eta 0:00:56 lr 0.00303904	time 0.1855 (0.1825)	loss 4.9400 (3.3492)	acc@1: 42.7906	acc@5: 56.8234	
2023-03-20 02:07:08,511 - INFO - Train: [75/90][3900/3907]	eta 0:00:01 lr 0.00303904	time 0.1801 (0.1825)	loss 3.5352 (3.3513)	acc@1: 67.1846	acc@5: 78.6612	
2023-03-20 02:07:09,737 - INFO - EPOCH 75 training takes 0:11:53
2023-03-20 02:07:10,820 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Latest.pth saved !!!
2023-03-20 02:07:10,821 - INFO - **********Latest test***********
2023-03-20 02:07:10,821 - INFO - eval epoch 75
2023-03-20 02:07:11,423 - INFO - Test: [0/782]	Time 0.601 (0.601)	Loss 2.2131 (2.2131)	Acc@1 77.344 (77.344)	Acc@5 96.094 (96.094)
2023-03-20 02:09:07,922 - INFO - Test: [200/782]	Time 0.575 (0.583)	Loss 2.5006 (2.5670)	Acc@1 73.438 (73.064)	Acc@5 86.719 (89.704)
2023-03-20 02:11:03,735 - INFO - Test: [400/782]	Time 0.586 (0.581)	Loss 2.4589 (2.5405)	Acc@1 78.125 (73.702)	Acc@5 89.062 (90.183)
2023-03-20 02:13:00,907 - INFO - Test: [600/782]	Time 0.587 (0.583)	Loss 2.5803 (2.5119)	Acc@1 72.656 (74.383)	Acc@5 89.062 (90.585)
2023-03-20 02:14:45,293 - INFO -  * Acc@1 74.806 Acc@5 90.897
2023-03-20 02:14:45,293 - INFO - Max accuracy: 75.2430%
2023-03-20 02:14:45,293 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-20 02:14:47,735 - INFO - Train: [76/90][0/3907]	eta 2:38:40 lr 0.00267949	time 2.4367 (2.4367)	loss 3.2232 (3.2232)	acc@1: 71.6996	acc@5: 81.3514	
2023-03-20 02:15:42,349 - INFO - Train: [76/90][300/3907]	eta 0:11:23 lr 0.00267949	time 0.1800 (0.1895)	loss 2.0410 (3.2372)	acc@1: 86.9171	acc@5: 96.2291	
2023-03-20 02:16:36,896 - INFO - Train: [76/90][600/3907]	eta 0:10:14 lr 0.00267949	time 0.1806 (0.1857)	loss 2.0194 (3.2748)	acc@1: 88.6726	acc@5: 95.6762	
2023-03-20 02:17:31,548 - INFO - Train: [76/90][900/3907]	eta 0:09:14 lr 0.00267949	time 0.1875 (0.1845)	loss 2.8709 (3.3106)	acc@1: 76.8419	acc@5: 85.5345	
2023-03-20 02:18:26,474 - INFO - Train: [76/90][1200/3907]	eta 0:08:18 lr 0.00267949	time 0.1876 (0.1842)	loss 3.1842 (3.3118)	acc@1: 74.8461	acc@5: 80.5667	
2023-03-20 02:19:21,248 - INFO - Train: [76/90][1500/3907]	eta 0:07:22 lr 0.00267949	time 0.1857 (0.1838)	loss 3.9047 (3.2892)	acc@1: 63.5684	acc@5: 75.1692	
2023-03-20 02:20:15,963 - INFO - Train: [76/90][1800/3907]	eta 0:06:26 lr 0.00267949	time 0.1865 (0.1836)	loss 3.0257 (3.2770)	acc@1: 77.7887	acc@5: 85.5779	
2023-03-20 02:21:10,587 - INFO - Train: [76/90][2100/3907]	eta 0:05:31 lr 0.00267949	time 0.1797 (0.1834)	loss 2.5563 (3.2785)	acc@1: 83.0211	acc@5: 91.7545	
2023-03-20 02:22:05,376 - INFO - Train: [76/90][2400/3907]	eta 0:04:36 lr 0.00267949	time 0.1803 (0.1833)	loss 4.8140 (3.2777)	acc@1: 40.0890	acc@5: 57.6255	
2023-03-20 02:23:00,056 - INFO - Train: [76/90][2700/3907]	eta 0:03:41 lr 0.00267949	time 0.1894 (0.1832)	loss 2.2370 (3.2810)	acc@1: 82.7226	acc@5: 90.5265	
2023-03-20 02:23:54,743 - INFO - Train: [76/90][3000/3907]	eta 0:02:46 lr 0.00267949	time 0.1857 (0.1831)	loss 2.7650 (3.2752)	acc@1: 74.9132	acc@5: 85.8695	
2023-03-20 02:24:48,018 - INFO - Train: [76/90][3300/3907]	eta 0:01:50 lr 0.00267949	time 0.1712 (0.1826)	loss 5.0820 (3.2906)	acc@1: 34.6072	acc@5: 53.5532	
2023-03-20 02:25:40,341 - INFO - Train: [76/90][3600/3907]	eta 0:00:55 lr 0.00267949	time 0.1765 (0.1819)	loss 5.0250 (3.2886)	acc@1: 29.3429	acc@5: 48.4638	
2023-03-20 02:26:32,630 - INFO - Train: [76/90][3900/3907]	eta 0:00:01 lr 0.00267949	time 0.1713 (0.1813)	loss 3.1327 (3.2862)	acc@1: 72.2982	acc@5: 85.3565	
2023-03-20 02:26:33,802 - INFO - EPOCH 76 training takes 0:11:48
2023-03-20 02:26:34,907 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Latest.pth saved !!!
2023-03-20 02:26:34,908 - INFO - **********Latest test***********
2023-03-20 02:26:34,908 - INFO - eval epoch 76
2023-03-20 02:26:35,514 - INFO - Test: [0/782]	Time 0.605 (0.605)	Loss 2.1608 (2.1608)	Acc@1 80.469 (80.469)	Acc@5 94.531 (94.531)
2023-03-20 02:28:33,251 - INFO - Test: [200/782]	Time 0.576 (0.589)	Loss 2.4363 (2.4881)	Acc@1 74.219 (74.048)	Acc@5 89.844 (90.489)
2023-03-20 02:30:30,720 - INFO - Test: [400/782]	Time 0.581 (0.588)	Loss 2.4201 (2.4619)	Acc@1 78.125 (74.737)	Acc@5 91.406 (90.843)
2023-03-20 02:32:29,326 - INFO - Test: [600/782]	Time 0.579 (0.590)	Loss 2.4728 (2.4297)	Acc@1 76.562 (75.512)	Acc@5 90.625 (91.311)
2023-03-20 02:34:15,470 - INFO -  * Acc@1 76.009 Acc@5 91.605
2023-03-20 02:34:15,471 - INFO - Max accuracy: 76.0090%
2023-03-20 02:34:16,558 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Best.pth saved !!!
2023-03-20 02:34:16,558 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-20 02:34:19,004 - INFO - Train: [77/90][0/3907]	eta 2:38:56 lr 0.00234105	time 2.4408 (2.4408)	loss 1.9647 (1.9647)	acc@1: 92.1280	acc@5: 95.9987	
2023-03-20 02:35:13,626 - INFO - Train: [77/90][300/3907]	eta 0:11:23 lr 0.00234105	time 0.1810 (0.1896)	loss 4.0103 (3.3724)	acc@1: 57.3936	acc@5: 71.8410	
2023-03-20 02:36:08,612 - INFO - Train: [77/90][600/3907]	eta 0:10:16 lr 0.00234105	time 0.1840 (0.1864)	loss 3.7344 (3.3714)	acc@1: 66.2414	acc@5: 75.9673	
2023-03-20 02:37:03,281 - INFO - Train: [77/90][900/3907]	eta 0:09:16 lr 0.00234105	time 0.1795 (0.1850)	loss 1.9435 (3.3642)	acc@1: 87.3406	acc@5: 97.4782	
2023-03-20 02:37:57,900 - INFO - Train: [77/90][1200/3907]	eta 0:08:18 lr 0.00234105	time 0.1820 (0.1843)	loss 1.9991 (3.3327)	acc@1: 85.0776	acc@5: 96.0050	
2023-03-20 02:38:52,584 - INFO - Train: [77/90][1500/3907]	eta 0:07:22 lr 0.00234105	time 0.1862 (0.1839)	loss 2.3009 (3.3110)	acc@1: 87.0518	acc@5: 93.1024	
2023-03-20 02:39:47,266 - INFO - Train: [77/90][1800/3907]	eta 0:06:26 lr 0.00234105	time 0.1800 (0.1836)	loss 1.8515 (3.3121)	acc@1: 92.7578	acc@5: 96.6570	
2023-03-20 02:40:41,774 - INFO - Train: [77/90][2100/3907]	eta 0:05:31 lr 0.00234105	time 0.1886 (0.1833)	loss 4.3240 (3.2881)	acc@1: 53.6567	acc@5: 65.2064	
2023-03-20 02:41:36,355 - INFO - Train: [77/90][2400/3907]	eta 0:04:36 lr 0.00234105	time 0.1790 (0.1832)	loss 4.6311 (3.2964)	acc@1: 45.9707	acc@5: 59.5750	
2023-03-20 02:42:28,511 - INFO - Train: [77/90][2700/3907]	eta 0:03:39 lr 0.00234105	time 0.1799 (0.1821)	loss 4.9255 (3.3009)	acc@1: 37.0488	acc@5: 54.3569	
2023-03-20 02:43:20,774 - INFO - Train: [77/90][3000/3907]	eta 0:02:44 lr 0.00234105	time 0.1777 (0.1813)	loss 4.0200 (3.3034)	acc@1: 61.6800	acc@5: 69.7632	
2023-03-20 02:44:13,007 - INFO - Train: [77/90][3300/3907]	eta 0:01:49 lr 0.00234105	time 0.1710 (0.1807)	loss 5.2784 (3.3070)	acc@1: 28.9495	acc@5: 48.8671	
2023-03-20 02:45:05,261 - INFO - Train: [77/90][3600/3907]	eta 0:00:55 lr 0.00234105	time 0.1718 (0.1801)	loss 1.9606 (3.3100)	acc@1: 91.0153	acc@5: 96.4605	
2023-03-20 02:45:57,885 - INFO - Train: [77/90][3900/3907]	eta 0:00:01 lr 0.00234105	time 0.1713 (0.1798)	loss 2.1011 (3.3162)	acc@1: 83.1337	acc@5: 92.4566	
2023-03-20 02:45:59,085 - INFO - EPOCH 77 training takes 0:11:42
2023-03-20 02:46:00,186 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Latest.pth saved !!!
2023-03-20 02:46:00,187 - INFO - **********Latest test***********
2023-03-20 02:46:00,187 - INFO - eval epoch 77
2023-03-20 02:46:00,798 - INFO - Test: [0/782]	Time 0.610 (0.610)	Loss 2.1956 (2.1956)	Acc@1 80.469 (80.469)	Acc@5 95.312 (95.312)
2023-03-20 02:48:00,479 - INFO - Test: [200/782]	Time 0.600 (0.598)	Loss 2.5011 (2.5117)	Acc@1 72.656 (73.655)	Acc@5 87.500 (90.252)
2023-03-20 02:49:59,608 - INFO - Test: [400/782]	Time 0.606 (0.597)	Loss 2.4781 (2.4852)	Acc@1 76.562 (74.414)	Acc@5 88.281 (90.602)
2023-03-20 02:52:00,635 - INFO - Test: [600/782]	Time 0.585 (0.600)	Loss 2.5587 (2.4531)	Acc@1 72.656 (75.226)	Acc@5 87.500 (91.084)
2023-03-20 02:53:47,796 - INFO -  * Acc@1 75.711 Acc@5 91.426
2023-03-20 02:53:47,797 - INFO - Max accuracy: 76.0090%
2023-03-20 02:53:47,797 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-20 02:53:50,312 - INFO - Train: [78/90][0/3907]	eta 2:43:33 lr 0.00202412	time 2.5117 (2.5117)	loss 4.0936 (4.0936)	acc@1: 58.0619	acc@5: 69.2024	
2023-03-20 02:54:45,479 - INFO - Train: [78/90][300/3907]	eta 0:11:31 lr 0.00202412	time 0.1876 (0.1916)	loss 5.3006 (3.2403)	acc@1: 27.4470	acc@5: 47.6655	
2023-03-20 02:55:40,495 - INFO - Train: [78/90][600/3907]	eta 0:10:20 lr 0.00202412	time 0.1860 (0.1875)	loss 4.5291 (3.2483)	acc@1: 49.5321	acc@5: 62.6644	
2023-03-20 02:56:35,700 - INFO - Train: [78/90][900/3907]	eta 0:09:20 lr 0.00202412	time 0.1878 (0.1863)	loss 4.0426 (3.2520)	acc@1: 60.3657	acc@5: 69.6888	
2023-03-20 02:57:30,583 - INFO - Train: [78/90][1200/3907]	eta 0:08:22 lr 0.00202412	time 0.1801 (0.1855)	loss 1.9186 (3.2477)	acc@1: 90.2635	acc@5: 96.4883	
2023-03-20 02:58:25,754 - INFO - Train: [78/90][1500/3907]	eta 0:07:25 lr 0.00202412	time 0.1808 (0.1852)	loss 2.9268 (3.2716)	acc@1: 82.0647	acc@5: 87.6105	
2023-03-20 02:59:20,726 - INFO - Train: [78/90][1800/3907]	eta 0:06:29 lr 0.00202412	time 0.1810 (0.1849)	loss 1.8360 (3.2903)	acc@1: 89.0362	acc@5: 96.8464	
2023-03-20 03:00:15,587 - INFO - Train: [78/90][2100/3907]	eta 0:05:33 lr 0.00202412	time 0.1803 (0.1846)	loss 2.4003 (3.2718)	acc@1: 84.0665	acc@5: 90.8827	
2023-03-20 03:01:10,299 - INFO - Train: [78/90][2400/3907]	eta 0:04:37 lr 0.00202412	time 0.1882 (0.1843)	loss 2.1577 (3.2771)	acc@1: 90.0139	acc@5: 94.5524	
2023-03-20 03:02:05,314 - INFO - Train: [78/90][2700/3907]	eta 0:03:42 lr 0.00202412	time 0.1839 (0.1842)	loss 2.2476 (3.2772)	acc@1: 83.6467	acc@5: 93.5298	
2023-03-20 03:03:00,109 - INFO - Train: [78/90][3000/3907]	eta 0:02:46 lr 0.00202412	time 0.1800 (0.1840)	loss 3.5819 (3.2769)	acc@1: 67.7155	acc@5: 75.0078	
2023-03-20 03:03:53,933 - INFO - Train: [78/90][3300/3907]	eta 0:01:51 lr 0.00202412	time 0.1775 (0.1836)	loss 2.2033 (3.2614)	acc@1: 85.8330	acc@5: 93.4288	
2023-03-20 03:04:46,189 - INFO - Train: [78/90][3600/3907]	eta 0:00:56 lr 0.00202412	time 0.1875 (0.1828)	loss 3.6986 (3.2597)	acc@1: 64.7013	acc@5: 76.4353	
2023-03-20 03:05:38,353 - INFO - Train: [78/90][3900/3907]	eta 0:00:01 lr 0.00202412	time 0.1714 (0.1821)	loss 5.2401 (3.2685)	acc@1: 27.3575	acc@5: 48.2001	
2023-03-20 03:05:39,565 - INFO - EPOCH 78 training takes 0:11:51
2023-03-20 03:05:40,650 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Latest.pth saved !!!
2023-03-20 03:05:40,650 - INFO - **********Latest test***********
2023-03-20 03:05:40,651 - INFO - eval epoch 78
2023-03-20 03:05:41,303 - INFO - Test: [0/782]	Time 0.651 (0.651)	Loss 2.2242 (2.2242)	Acc@1 75.781 (75.781)	Acc@5 95.312 (95.312)
2023-03-20 03:07:39,143 - INFO - Test: [200/782]	Time 0.583 (0.590)	Loss 2.4574 (2.4862)	Acc@1 75.000 (74.576)	Acc@5 87.500 (90.473)
2023-03-20 03:09:35,854 - INFO - Test: [400/782]	Time 0.586 (0.587)	Loss 2.4284 (2.4597)	Acc@1 74.219 (75.226)	Acc@5 89.844 (90.849)
2023-03-20 03:11:33,403 - INFO - Test: [600/782]	Time 0.572 (0.587)	Loss 2.4932 (2.4309)	Acc@1 75.000 (75.915)	Acc@5 90.625 (91.285)
2023-03-20 03:13:16,690 - INFO -  * Acc@1 76.323 Acc@5 91.600
2023-03-20 03:13:16,690 - INFO - Max accuracy: 76.3230%
2023-03-20 03:13:17,755 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Best.pth saved !!!
2023-03-20 03:13:17,755 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-20 03:13:20,250 - INFO - Train: [79/90][0/3907]	eta 2:42:02 lr 0.00172909	time 2.4884 (2.4884)	loss 2.2772 (2.2772)	acc@1: 89.9723	acc@5: 93.7199	
2023-03-20 03:14:14,673 - INFO - Train: [79/90][300/3907]	eta 0:11:21 lr 0.00172909	time 0.1817 (0.1891)	loss 2.5840 (3.1537)	acc@1: 81.0824	acc@5: 89.8481	
2023-03-20 03:15:09,299 - INFO - Train: [79/90][600/3907]	eta 0:10:13 lr 0.00172909	time 0.1804 (0.1856)	loss 5.0295 (3.1466)	acc@1: 32.5951	acc@5: 52.0427	
2023-03-20 03:16:03,861 - INFO - Train: [79/90][900/3907]	eta 0:09:14 lr 0.00172909	time 0.1845 (0.1843)	loss 2.9847 (3.1568)	acc@1: 75.9814	acc@5: 84.5831	
2023-03-20 03:16:58,727 - INFO - Train: [79/90][1200/3907]	eta 0:08:18 lr 0.00172909	time 0.1869 (0.1840)	loss 5.0778 (3.1604)	acc@1: 35.8575	acc@5: 51.6587	
2023-03-20 03:17:53,430 - INFO - Train: [79/90][1500/3907]	eta 0:07:22 lr 0.00172909	time 0.1802 (0.1837)	loss 3.7677 (3.1779)	acc@1: 67.7791	acc@5: 75.6684	
2023-03-20 03:18:47,945 - INFO - Train: [79/90][1800/3907]	eta 0:06:26 lr 0.00172909	time 0.1797 (0.1833)	loss 3.4682 (3.1998)	acc@1: 70.3411	acc@5: 79.6314	
2023-03-20 03:19:42,596 - INFO - Train: [79/90][2100/3907]	eta 0:05:30 lr 0.00172909	time 0.1803 (0.1832)	loss 3.8914 (3.2103)	acc@1: 60.3895	acc@5: 72.7044	
2023-03-20 03:20:35,339 - INFO - Train: [79/90][2400/3907]	eta 0:04:34 lr 0.00172909	time 0.1712 (0.1822)	loss 1.9333 (3.2295)	acc@1: 89.7918	acc@5: 97.5325	
2023-03-20 03:21:27,449 - INFO - Train: [79/90][2700/3907]	eta 0:03:38 lr 0.00172909	time 0.1767 (0.1813)	loss 4.8048 (3.2387)	acc@1: 41.6284	acc@5: 59.3738	
2023-03-20 03:22:19,354 - INFO - Train: [79/90][3000/3907]	eta 0:02:43 lr 0.00172909	time 0.1711 (0.1805)	loss 3.7672 (3.2457)	acc@1: 65.3814	acc@5: 74.3359	
2023-03-20 03:23:11,372 - INFO - Train: [79/90][3300/3907]	eta 0:01:49 lr 0.00172909	time 0.1708 (0.1798)	loss 1.9003 (3.2489)	acc@1: 89.7602	acc@5: 96.0043	
2023-03-20 03:24:03,151 - INFO - Train: [79/90][3600/3907]	eta 0:00:55 lr 0.00172909	time 0.1802 (0.1792)	loss 2.1897 (3.2507)	acc@1: 87.4760	acc@5: 93.5613	
2023-03-20 03:24:55,051 - INFO - Train: [79/90][3900/3907]	eta 0:00:01 lr 0.00172909	time 0.1708 (0.1787)	loss 2.0632 (3.2503)	acc@1: 88.5051	acc@5: 93.8459	
2023-03-20 03:24:56,225 - INFO - EPOCH 79 training takes 0:11:38
2023-03-20 03:24:57,306 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Latest.pth saved !!!
2023-03-20 03:24:57,306 - INFO - **********Latest test***********
2023-03-20 03:24:57,306 - INFO - eval epoch 79
2023-03-20 03:24:57,897 - INFO - Test: [0/782]	Time 0.590 (0.590)	Loss 2.1467 (2.1467)	Acc@1 78.906 (78.906)	Acc@5 96.094 (96.094)
2023-03-20 03:26:54,615 - INFO - Test: [200/782]	Time 0.578 (0.584)	Loss 2.4517 (2.4763)	Acc@1 69.531 (74.541)	Acc@5 89.062 (90.516)
2023-03-20 03:28:51,186 - INFO - Test: [400/782]	Time 0.583 (0.583)	Loss 2.4476 (2.4503)	Acc@1 76.562 (75.294)	Acc@5 89.844 (90.931)
2023-03-20 03:30:48,747 - INFO - Test: [600/782]	Time 0.584 (0.585)	Loss 2.5259 (2.4162)	Acc@1 76.562 (76.087)	Acc@5 89.844 (91.413)
2023-03-20 03:32:33,302 - INFO -  * Acc@1 76.500 Acc@5 91.707
2023-03-20 03:32:33,303 - INFO - Max accuracy: 76.5000%
2023-03-20 03:32:34,363 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Best.pth saved !!!
2023-03-20 03:32:34,363 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-20 03:32:36,816 - INFO - Train: [80/90][0/3907]	eta 2:39:19 lr 0.00145632	time 2.4467 (2.4467)	loss 2.1700 (2.1700)	acc@1: 88.6358	acc@5: 92.4891	
2023-03-20 03:33:31,351 - INFO - Train: [80/90][300/3907]	eta 0:11:22 lr 0.00145632	time 0.1865 (0.1893)	loss 2.6050 (3.3051)	acc@1: 81.8311	acc@5: 89.1236	
2023-03-20 03:34:26,254 - INFO - Train: [80/90][600/3907]	eta 0:10:15 lr 0.00145632	time 0.1884 (0.1862)	loss 3.8900 (3.2485)	acc@1: 64.2162	acc@5: 73.6197	
2023-03-20 03:35:20,881 - INFO - Train: [80/90][900/3907]	eta 0:09:15 lr 0.00145632	time 0.1804 (0.1848)	loss 3.5264 (3.2539)	acc@1: 72.5217	acc@5: 77.2520	
2023-03-20 03:36:15,498 - INFO - Train: [80/90][1200/3907]	eta 0:08:18 lr 0.00145632	time 0.1800 (0.1841)	loss 5.0423 (3.2415)	acc@1: 33.0922	acc@5: 51.0556	
2023-03-20 03:37:10,102 - INFO - Train: [80/90][1500/3907]	eta 0:07:22 lr 0.00145632	time 0.1800 (0.1837)	loss 2.1056 (3.2464)	acc@1: 81.6649	acc@5: 94.8892	
2023-03-20 03:38:04,599 - INFO - Train: [80/90][1800/3907]	eta 0:06:26 lr 0.00145632	time 0.1846 (0.1834)	loss 2.1376 (3.2518)	acc@1: 87.5816	acc@5: 95.2642	
2023-03-20 03:38:59,452 - INFO - Train: [80/90][2100/3907]	eta 0:05:31 lr 0.00145632	time 0.1818 (0.1833)	loss 5.2009 (3.2555)	acc@1: 33.8561	acc@5: 50.3697	
2023-03-20 03:39:54,013 - INFO - Train: [80/90][2400/3907]	eta 0:04:35 lr 0.00145632	time 0.1800 (0.1831)	loss 4.4920 (3.2611)	acc@1: 50.7352	acc@5: 63.5686	
2023-03-20 03:40:48,482 - INFO - Train: [80/90][2700/3907]	eta 0:03:40 lr 0.00145632	time 0.1804 (0.1829)	loss 1.9543 (3.2552)	acc@1: 88.0285	acc@5: 94.2606	
2023-03-20 03:41:40,928 - INFO - Train: [80/90][3000/3907]	eta 0:02:45 lr 0.00145632	time 0.1711 (0.1821)	loss 3.9703 (3.2557)	acc@1: 58.7055	acc@5: 70.2516	
2023-03-20 03:42:32,807 - INFO - Train: [80/90][3300/3907]	eta 0:01:50 lr 0.00145632	time 0.1708 (0.1813)	loss 4.5047 (3.2514)	acc@1: 46.2672	acc@5: 60.3297	
2023-03-20 03:43:24,741 - INFO - Train: [80/90][3600/3907]	eta 0:00:55 lr 0.00145632	time 0.1714 (0.1806)	loss 4.3846 (3.2511)	acc@1: 53.5205	acc@5: 63.9780	
2023-03-20 03:44:16,649 - INFO - Train: [80/90][3900/3907]	eta 0:00:01 lr 0.00145632	time 0.1703 (0.1800)	loss 2.3016 (3.2495)	acc@1: 84.9282	acc@5: 90.9928	
2023-03-20 03:44:17,805 - INFO - EPOCH 80 training takes 0:11:43
2023-03-20 03:44:18,885 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Latest.pth saved !!!
2023-03-20 03:44:18,885 - INFO - **********Latest test***********
2023-03-20 03:44:18,885 - INFO - eval epoch 80
2023-03-20 03:44:19,531 - INFO - Test: [0/782]	Time 0.644 (0.644)	Loss 2.1795 (2.1795)	Acc@1 78.125 (78.125)	Acc@5 96.875 (96.875)
2023-03-20 03:46:16,656 - INFO - Test: [200/782]	Time 0.579 (0.586)	Loss 2.4015 (2.4717)	Acc@1 74.219 (74.592)	Acc@5 89.844 (90.676)
2023-03-20 03:48:14,551 - INFO - Test: [400/782]	Time 0.594 (0.588)	Loss 2.4042 (2.4469)	Acc@1 80.469 (75.296)	Acc@5 91.406 (91.030)
2023-03-20 03:50:12,174 - INFO - Test: [600/782]	Time 0.575 (0.588)	Loss 2.4954 (2.4159)	Acc@1 76.562 (76.036)	Acc@5 89.062 (91.434)
2023-03-20 03:51:56,836 - INFO -  * Acc@1 76.493 Acc@5 91.737
2023-03-20 03:51:56,836 - INFO - Max accuracy: 76.5000%
2023-03-20 03:51:56,837 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-20 03:51:59,220 - INFO - Train: [81/90][0/3907]	eta 2:34:58 lr 0.00120615	time 2.3800 (2.3800)	loss 3.4327 (3.4327)	acc@1: 72.4006	acc@5: 81.0214	
2023-03-20 03:52:53,750 - INFO - Train: [81/90][300/3907]	eta 0:11:21 lr 0.00120615	time 0.1829 (0.1891)	loss 3.6078 (3.1923)	acc@1: 71.5002	acc@5: 78.7967	
2023-03-20 03:53:48,264 - INFO - Train: [81/90][600/3907]	eta 0:10:13 lr 0.00120615	time 0.1820 (0.1854)	loss 2.4908 (3.2192)	acc@1: 82.1492	acc@5: 88.9578	
2023-03-20 03:54:42,765 - INFO - Train: [81/90][900/3907]	eta 0:09:13 lr 0.00120615	time 0.1797 (0.1842)	loss 3.2307 (3.2425)	acc@1: 77.1273	acc@5: 82.8244	
2023-03-20 03:55:37,233 - INFO - Train: [81/90][1200/3907]	eta 0:08:16 lr 0.00120615	time 0.1797 (0.1835)	loss 2.6390 (3.2562)	acc@1: 76.2429	acc@5: 88.0488	
2023-03-20 03:56:31,820 - INFO - Train: [81/90][1500/3907]	eta 0:07:20 lr 0.00120615	time 0.1877 (0.1832)	loss 4.5802 (3.2629)	acc@1: 45.4075	acc@5: 61.0486	
2023-03-20 03:57:26,885 - INFO - Train: [81/90][1800/3907]	eta 0:06:26 lr 0.00120615	time 0.1805 (0.1833)	loss 1.9604 (3.2731)	acc@1: 89.8003	acc@5: 93.7046	
2023-03-20 03:58:21,701 - INFO - Train: [81/90][2100/3907]	eta 0:05:30 lr 0.00120615	time 0.1842 (0.1832)	loss 2.1473 (3.2652)	acc@1: 83.3549	acc@5: 92.6155	
2023-03-20 03:59:16,177 - INFO - Train: [81/90][2400/3907]	eta 0:04:35 lr 0.00120615	time 0.1825 (0.1830)	loss 4.2040 (3.2602)	acc@1: 58.1444	acc@5: 68.5683	
2023-03-20 04:00:10,789 - INFO - Train: [81/90][2700/3907]	eta 0:03:40 lr 0.00120615	time 0.1798 (0.1829)	loss 2.3093 (3.2558)	acc@1: 81.4163	acc@5: 89.8770	
2023-03-20 04:01:05,567 - INFO - Train: [81/90][3000/3907]	eta 0:02:45 lr 0.00120615	time 0.1802 (0.1828)	loss 3.2450 (3.2422)	acc@1: 76.1071	acc@5: 80.3400	
2023-03-20 04:01:59,929 - INFO - Train: [81/90][3300/3907]	eta 0:01:50 lr 0.00120615	time 0.1707 (0.1827)	loss 1.9316 (3.2404)	acc@1: 89.5278	acc@5: 98.0175	
2023-03-20 04:02:51,777 - INFO - Train: [81/90][3600/3907]	eta 0:00:55 lr 0.00120615	time 0.1708 (0.1819)	loss 2.8714 (3.2443)	acc@1: 76.1414	acc@5: 86.7748	
2023-03-20 04:03:43,735 - INFO - Train: [81/90][3900/3907]	eta 0:00:01 lr 0.00120615	time 0.1699 (0.1812)	loss 5.1076 (3.2416)	acc@1: 29.8217	acc@5: 50.0344	
2023-03-20 04:03:44,894 - INFO - EPOCH 81 training takes 0:11:48
2023-03-20 04:03:45,996 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Latest.pth saved !!!
2023-03-20 04:03:45,996 - INFO - **********Latest test***********
2023-03-20 04:03:45,997 - INFO - eval epoch 81
2023-03-20 04:03:46,589 - INFO - Test: [0/782]	Time 0.591 (0.591)	Loss 2.2001 (2.2001)	Acc@1 80.469 (80.469)	Acc@5 96.094 (96.094)
2023-03-20 04:05:42,436 - INFO - Test: [200/782]	Time 0.589 (0.579)	Loss 2.4285 (2.5103)	Acc@1 72.656 (74.572)	Acc@5 90.625 (90.551)
2023-03-20 04:07:38,725 - INFO - Test: [400/782]	Time 0.582 (0.580)	Loss 2.4677 (2.4841)	Acc@1 77.344 (75.203)	Acc@5 88.281 (90.867)
2023-03-20 04:09:35,557 - INFO - Test: [600/782]	Time 0.576 (0.582)	Loss 2.5143 (2.4539)	Acc@1 75.781 (75.874)	Acc@5 88.281 (91.300)
2023-03-20 04:11:19,931 - INFO -  * Acc@1 76.331 Acc@5 91.637
2023-03-20 04:11:19,932 - INFO - Max accuracy: 76.5000%
2023-03-20 04:11:19,932 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-20 04:11:22,211 - INFO - Train: [82/90][0/3907]	eta 2:28:12 lr 0.00097887	time 2.2760 (2.2760)	loss 2.7043 (2.7043)	acc@1: 81.5495	acc@5: 88.8258	
2023-03-20 04:12:16,890 - INFO - Train: [82/90][300/3907]	eta 0:11:22 lr 0.00097887	time 0.1801 (0.1892)	loss 2.3079 (3.2555)	acc@1: 86.9705	acc@5: 92.2644	
2023-03-20 04:13:11,324 - INFO - Train: [82/90][600/3907]	eta 0:10:12 lr 0.00097887	time 0.1796 (0.1853)	loss 2.9801 (3.2886)	acc@1: 78.0052	acc@5: 85.5987	
2023-03-20 04:14:06,046 - INFO - Train: [82/90][900/3907]	eta 0:09:14 lr 0.00097887	time 0.1802 (0.1844)	loss 5.0894 (3.2749)	acc@1: 34.9764	acc@5: 49.8201	
2023-03-20 04:15:00,717 - INFO - Train: [82/90][1200/3907]	eta 0:08:17 lr 0.00097887	time 0.1801 (0.1838)	loss 3.9273 (3.2547)	acc@1: 64.0211	acc@5: 73.3278	
2023-03-20 04:15:55,419 - INFO - Train: [82/90][1500/3907]	eta 0:07:21 lr 0.00097887	time 0.1801 (0.1835)	loss 4.3599 (3.2648)	acc@1: 51.9201	acc@5: 65.6052	
2023-03-20 04:16:50,366 - INFO - Train: [82/90][1800/3907]	eta 0:06:26 lr 0.00097887	time 0.1844 (0.1835)	loss 4.9419 (3.2599)	acc@1: 38.9254	acc@5: 49.7362	
2023-03-20 04:17:45,140 - INFO - Train: [82/90][2100/3907]	eta 0:05:31 lr 0.00097887	time 0.1802 (0.1833)	loss 3.3945 (3.2624)	acc@1: 72.9858	acc@5: 80.3513	
2023-03-20 04:18:39,903 - INFO - Train: [82/90][2400/3907]	eta 0:04:36 lr 0.00097887	time 0.1874 (0.1832)	loss 2.3011 (3.2647)	acc@1: 85.9567	acc@5: 93.4312	
2023-03-20 04:19:34,448 - INFO - Train: [82/90][2700/3907]	eta 0:03:40 lr 0.00097887	time 0.1816 (0.1831)	loss 4.9588 (3.2651)	acc@1: 34.0320	acc@5: 52.2771	
2023-03-20 04:20:28,937 - INFO - Train: [82/90][3000/3907]	eta 0:02:45 lr 0.00097887	time 0.1802 (0.1829)	loss 3.3726 (3.2529)	acc@1: 73.5925	acc@5: 81.1253	
2023-03-20 04:21:23,525 - INFO - Train: [82/90][3300/3907]	eta 0:01:50 lr 0.00097887	time 0.1805 (0.1828)	loss 4.7925 (3.2552)	acc@1: 37.6160	acc@5: 53.7029	
2023-03-20 04:22:18,072 - INFO - Train: [82/90][3600/3907]	eta 0:00:56 lr 0.00097887	time 0.1801 (0.1828)	loss 4.8449 (3.2543)	acc@1: 38.9238	acc@5: 54.9758	
2023-03-20 04:23:12,584 - INFO - Train: [82/90][3900/3907]	eta 0:00:01 lr 0.00097887	time 0.1828 (0.1827)	loss 2.0383 (3.2522)	acc@1: 86.6304	acc@5: 95.8286	
2023-03-20 04:23:13,819 - INFO - EPOCH 82 training takes 0:11:53
2023-03-20 04:23:14,745 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Latest.pth saved !!!
2023-03-20 04:23:14,746 - INFO - **********Latest test***********
2023-03-20 04:23:14,746 - INFO - eval epoch 82
2023-03-20 04:23:15,364 - INFO - Test: [0/782]	Time 0.618 (0.618)	Loss 2.2055 (2.2055)	Acc@1 79.688 (79.688)	Acc@5 95.312 (95.312)
2023-03-20 04:25:11,261 - INFO - Test: [200/782]	Time 0.584 (0.580)	Loss 2.4246 (2.5100)	Acc@1 73.438 (74.689)	Acc@5 89.844 (90.524)
2023-03-20 04:27:08,217 - INFO - Test: [400/782]	Time 0.587 (0.582)	Loss 2.4266 (2.4839)	Acc@1 78.125 (75.279)	Acc@5 89.844 (90.909)
2023-03-20 04:29:06,173 - INFO - Test: [600/782]	Time 0.579 (0.585)	Loss 2.5294 (2.4536)	Acc@1 75.781 (75.980)	Acc@5 88.281 (91.345)
2023-03-20 04:30:51,002 - INFO -  * Acc@1 76.379 Acc@5 91.640
2023-03-20 04:30:51,003 - INFO - Max accuracy: 76.5000%
2023-03-20 04:30:51,003 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-20 04:30:53,471 - INFO - Train: [83/90][0/3907]	eta 2:40:28 lr 0.00077477	time 2.4645 (2.4645)	loss 1.8748 (1.8748)	acc@1: 94.3628	acc@5: 95.9224	
2023-03-20 04:31:47,761 - INFO - Train: [83/90][300/3907]	eta 0:11:20 lr 0.00077477	time 0.1820 (0.1885)	loss 1.8568 (3.1457)	acc@1: 91.0552	acc@5: 96.5058	
2023-03-20 04:32:42,436 - INFO - Train: [83/90][600/3907]	eta 0:10:13 lr 0.00077477	time 0.1818 (0.1854)	loss 3.1524 (3.1650)	acc@1: 78.3980	acc@5: 83.1939	
2023-03-20 04:33:37,053 - INFO - Train: [83/90][900/3907]	eta 0:09:14 lr 0.00077477	time 0.1874 (0.1843)	loss 2.1810 (3.1950)	acc@1: 86.9664	acc@5: 92.3030	
2023-03-20 04:34:31,762 - INFO - Train: [83/90][1200/3907]	eta 0:08:17 lr 0.00077477	time 0.1803 (0.1838)	loss 5.0936 (3.1782)	acc@1: 34.6462	acc@5: 52.4458	
2023-03-20 04:35:26,243 - INFO - Train: [83/90][1500/3907]	eta 0:07:21 lr 0.00077477	time 0.1802 (0.1834)	loss 5.2080 (3.1786)	acc@1: 33.6440	acc@5: 49.6282	
2023-03-20 04:36:20,834 - INFO - Train: [83/90][1800/3907]	eta 0:06:25 lr 0.00077477	time 0.1804 (0.1831)	loss 5.1875 (3.1815)	acc@1: 28.1088	acc@5: 46.8588	
2023-03-20 04:37:15,393 - INFO - Train: [83/90][2100/3907]	eta 0:05:30 lr 0.00077477	time 0.1803 (0.1829)	loss 1.7524 (3.1849)	acc@1: 92.0210	acc@5: 99.0409	
2023-03-20 04:38:09,956 - INFO - Train: [83/90][2400/3907]	eta 0:04:35 lr 0.00077477	time 0.1827 (0.1828)	loss 1.9270 (3.1955)	acc@1: 88.9215	acc@5: 99.0617	
2023-03-20 04:39:04,170 - INFO - Train: [83/90][2700/3907]	eta 0:03:40 lr 0.00077477	time 0.1772 (0.1826)	loss 4.1536 (3.2012)	acc@1: 53.2609	acc@5: 67.0997	
2023-03-20 04:39:56,292 - INFO - Train: [83/90][3000/3907]	eta 0:02:44 lr 0.00077477	time 0.1792 (0.1817)	loss 1.8801 (3.1955)	acc@1: 88.1349	acc@5: 94.3744	
2023-03-20 04:40:48,290 - INFO - Train: [83/90][3300/3907]	eta 0:01:49 lr 0.00077477	time 0.1713 (0.1809)	loss 3.9057 (3.1951)	acc@1: 61.8899	acc@5: 71.9520	
2023-03-20 04:41:40,177 - INFO - Train: [83/90][3600/3907]	eta 0:00:55 lr 0.00077477	time 0.1796 (0.1803)	loss 5.1321 (3.2105)	acc@1: 31.1685	acc@5: 47.9979	
2023-03-20 04:42:32,379 - INFO - Train: [83/90][3900/3907]	eta 0:00:01 lr 0.00077477	time 0.1703 (0.1798)	loss 3.0078 (3.2139)	acc@1: 79.3947	acc@5: 84.2219	
2023-03-20 04:42:33,552 - INFO - EPOCH 83 training takes 0:11:42
2023-03-20 04:42:34,644 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Latest.pth saved !!!
2023-03-20 04:42:34,645 - INFO - **********Latest test***********
2023-03-20 04:42:34,645 - INFO - eval epoch 83
2023-03-20 04:42:35,240 - INFO - Test: [0/782]	Time 0.594 (0.594)	Loss 2.1075 (2.1075)	Acc@1 82.812 (82.812)	Acc@5 94.531 (94.531)
2023-03-20 04:44:31,181 - INFO - Test: [200/782]	Time 0.577 (0.580)	Loss 2.3461 (2.3965)	Acc@1 72.656 (75.750)	Acc@5 91.406 (91.181)
2023-03-20 04:46:27,405 - INFO - Test: [400/782]	Time 0.583 (0.580)	Loss 2.3339 (2.3713)	Acc@1 79.688 (76.364)	Acc@5 89.844 (91.525)
2023-03-20 04:48:24,745 - INFO - Test: [600/782]	Time 0.585 (0.583)	Loss 2.4535 (2.3396)	Acc@1 75.000 (77.146)	Acc@5 89.062 (91.952)
2023-03-20 04:50:09,217 - INFO -  * Acc@1 77.581 Acc@5 92.262
2023-03-20 04:50:09,218 - INFO - Max accuracy: 77.5810%
2023-03-20 04:50:10,135 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Best.pth saved !!!
2023-03-20 04:50:10,136 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-20 04:50:12,569 - INFO - Train: [84/90][0/3907]	eta 2:38:12 lr 0.00059409	time 2.4295 (2.4295)	loss 1.9776 (1.9776)	acc@1: 88.7636	acc@5: 95.7096	
2023-03-20 04:51:06,915 - INFO - Train: [84/90][300/3907]	eta 0:11:20 lr 0.00059409	time 0.1817 (0.1886)	loss 4.4088 (3.2582)	acc@1: 52.0392	acc@5: 62.9532	
2023-03-20 04:52:01,394 - INFO - Train: [84/90][600/3907]	eta 0:10:12 lr 0.00059409	time 0.1826 (0.1851)	loss 2.7642 (3.2090)	acc@1: 84.0233	acc@5: 87.5537	
2023-03-20 04:52:55,942 - INFO - Train: [84/90][900/3907]	eta 0:09:13 lr 0.00059409	time 0.1877 (0.1840)	loss 1.8760 (3.1845)	acc@1: 92.0566	acc@5: 96.7374	
2023-03-20 04:53:50,400 - INFO - Train: [84/90][1200/3907]	eta 0:08:16 lr 0.00059409	time 0.1802 (0.1834)	loss 2.1881 (3.1906)	acc@1: 88.2141	acc@5: 94.2458	
2023-03-20 04:54:44,884 - INFO - Train: [84/90][1500/3907]	eta 0:07:20 lr 0.00059409	time 0.1812 (0.1830)	loss 2.1969 (3.1920)	acc@1: 86.6435	acc@5: 94.1777	
2023-03-20 04:55:39,950 - INFO - Train: [84/90][1800/3907]	eta 0:06:25 lr 0.00059409	time 0.1827 (0.1831)	loss 4.5951 (3.1990)	acc@1: 43.5107	acc@5: 62.1736	
2023-03-20 04:56:34,487 - INFO - Train: [84/90][2100/3907]	eta 0:05:30 lr 0.00059409	time 0.1817 (0.1829)	loss 2.8786 (3.1953)	acc@1: 79.8070	acc@5: 86.1888	
2023-03-20 04:57:29,134 - INFO - Train: [84/90][2400/3907]	eta 0:04:35 lr 0.00059409	time 0.1804 (0.1828)	loss 1.9957 (3.1905)	acc@1: 89.6172	acc@5: 95.0246	
2023-03-20 04:58:23,697 - INFO - Train: [84/90][2700/3907]	eta 0:03:40 lr 0.00059409	time 0.1806 (0.1827)	loss 4.8597 (3.1930)	acc@1: 36.3934	acc@5: 55.0259	
2023-03-20 04:59:18,426 - INFO - Train: [84/90][3000/3907]	eta 0:02:45 lr 0.00059409	time 0.1834 (0.1827)	loss 4.4144 (3.1991)	acc@1: 54.2646	acc@5: 63.5826	
2023-03-20 05:00:13,206 - INFO - Train: [84/90][3300/3907]	eta 0:01:50 lr 0.00059409	time 0.1887 (0.1827)	loss 4.3061 (3.2049)	acc@1: 54.5179	acc@5: 66.1725	
2023-03-20 05:01:07,936 - INFO - Train: [84/90][3600/3907]	eta 0:00:56 lr 0.00059409	time 0.1820 (0.1827)	loss 3.7494 (3.2077)	acc@1: 66.7274	acc@5: 75.2496	
2023-03-20 05:02:02,520 - INFO - Train: [84/90][3900/3907]	eta 0:00:01 lr 0.00059409	time 0.1793 (0.1826)	loss 4.2003 (3.2101)	acc@1: 56.3881	acc@5: 68.3044	
2023-03-20 05:02:03,726 - INFO - EPOCH 84 training takes 0:11:53
2023-03-20 05:02:04,834 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Latest.pth saved !!!
2023-03-20 05:02:04,834 - INFO - **********Latest test***********
2023-03-20 05:02:04,834 - INFO - eval epoch 84
2023-03-20 05:02:05,431 - INFO - Test: [0/782]	Time 0.594 (0.594)	Loss 2.1383 (2.1383)	Acc@1 78.906 (78.906)	Acc@5 96.875 (96.875)
2023-03-20 05:04:00,273 - INFO - Test: [200/782]	Time 0.567 (0.574)	Loss 2.3920 (2.4361)	Acc@1 73.438 (75.459)	Acc@5 90.625 (91.212)
2023-03-20 05:05:55,620 - INFO - Test: [400/782]	Time 0.587 (0.576)	Loss 2.3662 (2.4101)	Acc@1 78.906 (76.227)	Acc@5 91.406 (91.535)
2023-03-20 05:07:52,417 - INFO - Test: [600/782]	Time 0.576 (0.578)	Loss 2.4824 (2.3790)	Acc@1 75.000 (76.947)	Acc@5 89.844 (91.913)
2023-03-20 05:09:36,144 - INFO -  * Acc@1 77.368 Acc@5 92.192
2023-03-20 05:09:36,145 - INFO - Max accuracy: 77.5810%
2023-03-20 05:09:36,145 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-20 05:09:38,665 - INFO - Train: [85/90][0/3907]	eta 2:43:51 lr 0.00043705	time 2.5164 (2.5164)	loss 1.9029 (1.9029)	acc@1: 88.2699	acc@5: 96.0815	
2023-03-20 05:10:33,113 - INFO - Train: [85/90][300/3907]	eta 0:11:22 lr 0.00043705	time 0.1833 (0.1892)	loss 2.4696 (3.1360)	acc@1: 85.7099	acc@5: 88.6654	
2023-03-20 05:11:27,653 - INFO - Train: [85/90][600/3907]	eta 0:10:13 lr 0.00043705	time 0.1804 (0.1855)	loss 2.2116 (3.1971)	acc@1: 83.9033	acc@5: 91.5309	
2023-03-20 05:12:22,191 - INFO - Train: [85/90][900/3907]	eta 0:09:14 lr 0.00043705	time 0.1802 (0.1843)	loss 5.0246 (3.1587)	acc@1: 34.0370	acc@5: 52.7144	
2023-03-20 05:13:16,509 - INFO - Train: [85/90][1200/3907]	eta 0:08:16 lr 0.00043705	time 0.1803 (0.1835)	loss 3.7917 (3.1744)	acc@1: 65.2477	acc@5: 73.1426	
2023-03-20 05:14:10,927 - INFO - Train: [85/90][1500/3907]	eta 0:07:20 lr 0.00043705	time 0.1877 (0.1831)	loss 2.0189 (3.1908)	acc@1: 90.0535	acc@5: 95.4413	
2023-03-20 05:15:05,502 - INFO - Train: [85/90][1800/3907]	eta 0:06:25 lr 0.00043705	time 0.1800 (0.1829)	loss 2.2869 (3.1831)	acc@1: 87.5694	acc@5: 92.7618	
2023-03-20 05:16:00,033 - INFO - Train: [85/90][2100/3907]	eta 0:05:30 lr 0.00043705	time 0.1821 (0.1827)	loss 1.8844 (3.1828)	acc@1: 92.8535	acc@5: 95.9484	
2023-03-20 05:16:55,075 - INFO - Train: [85/90][2400/3907]	eta 0:04:35 lr 0.00043705	time 0.1852 (0.1828)	loss 4.2115 (3.1871)	acc@1: 59.4614	acc@5: 68.5567	
2023-03-20 05:17:49,885 - INFO - Train: [85/90][2700/3907]	eta 0:03:40 lr 0.00043705	time 0.1805 (0.1828)	loss 2.0464 (3.1814)	acc@1: 88.1243	acc@5: 94.3632	
2023-03-20 05:18:44,531 - INFO - Train: [85/90][3000/3907]	eta 0:02:45 lr 0.00043705	time 0.1803 (0.1827)	loss 3.4303 (3.1898)	acc@1: 71.9539	acc@5: 79.2175	
2023-03-20 05:19:39,128 - INFO - Train: [85/90][3300/3907]	eta 0:01:50 lr 0.00043705	time 0.1803 (0.1827)	loss 1.9602 (3.1915)	acc@1: 88.2560	acc@5: 94.5041	
2023-03-20 05:20:33,593 - INFO - Train: [85/90][3600/3907]	eta 0:00:56 lr 0.00043705	time 0.1801 (0.1826)	loss 2.8715 (3.1837)	acc@1: 79.5857	acc@5: 85.9120	
2023-03-20 05:21:28,246 - INFO - Train: [85/90][3900/3907]	eta 0:00:01 lr 0.00043705	time 0.1877 (0.1825)	loss 4.7395 (3.1829)	acc@1: 41.1828	acc@5: 57.1612	
2023-03-20 05:21:29,487 - INFO - EPOCH 85 training takes 0:11:53
2023-03-20 05:21:30,570 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Latest.pth saved !!!
2023-03-20 05:21:30,571 - INFO - **********Latest test***********
2023-03-20 05:21:30,571 - INFO - eval epoch 85
2023-03-20 05:21:31,164 - INFO - Test: [0/782]	Time 0.592 (0.592)	Loss 2.1964 (2.1964)	Acc@1 79.688 (79.688)	Acc@5 96.094 (96.094)
2023-03-20 05:23:27,917 - INFO - Test: [200/782]	Time 0.578 (0.584)	Loss 2.4088 (2.5003)	Acc@1 74.219 (74.903)	Acc@5 91.406 (90.765)
2023-03-20 05:25:24,888 - INFO - Test: [400/782]	Time 0.590 (0.584)	Loss 2.4208 (2.4750)	Acc@1 75.781 (75.666)	Acc@5 89.844 (91.122)
2023-03-20 05:27:23,066 - INFO - Test: [600/782]	Time 0.586 (0.587)	Loss 2.5242 (2.4447)	Acc@1 75.781 (76.392)	Acc@5 88.281 (91.553)
2023-03-20 05:29:07,326 - INFO -  * Acc@1 76.813 Acc@5 91.846
2023-03-20 05:29:07,326 - INFO - Max accuracy: 77.5810%
2023-03-20 05:29:07,326 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-20 05:29:09,604 - INFO - Train: [86/90][0/3907]	eta 2:28:07 lr 0.00030384	time 2.2747 (2.2747)	loss 4.8020 (4.8020)	acc@1: 31.8462	acc@5: 53.4261	
2023-03-20 05:30:04,159 - INFO - Train: [86/90][300/3907]	eta 0:11:20 lr 0.00030384	time 0.1797 (0.1888)	loss 1.8432 (3.1898)	acc@1: 92.1875	acc@5: 94.5312	
2023-03-20 05:30:58,803 - INFO - Train: [86/90][600/3907]	eta 0:10:13 lr 0.00030384	time 0.1801 (0.1855)	loss 4.1145 (3.1178)	acc@1: 57.1852	acc@5: 68.8028	
2023-03-20 05:31:53,368 - INFO - Train: [86/90][900/3907]	eta 0:09:14 lr 0.00030384	time 0.1805 (0.1843)	loss 5.0634 (3.1474)	acc@1: 33.7436	acc@5: 52.8965	
2023-03-20 05:32:47,865 - INFO - Train: [86/90][1200/3907]	eta 0:08:17 lr 0.00030384	time 0.1828 (0.1836)	loss 3.9629 (3.1797)	acc@1: 61.1172	acc@5: 73.1462	
2023-03-20 05:33:42,417 - INFO - Train: [86/90][1500/3907]	eta 0:07:21 lr 0.00030384	time 0.1808 (0.1833)	loss 4.6611 (3.1781)	acc@1: 40.0442	acc@5: 56.5085	
2023-03-20 05:34:37,101 - INFO - Train: [86/90][1800/3907]	eta 0:06:25 lr 0.00030384	time 0.1807 (0.1831)	loss 2.4031 (3.1741)	acc@1: 83.3658	acc@5: 90.1827	
2023-03-20 05:35:31,569 - INFO - Train: [86/90][2100/3907]	eta 0:05:30 lr 0.00030384	time 0.1803 (0.1829)	loss 1.8891 (3.1781)	acc@1: 90.4014	acc@5: 96.6360	
2023-03-20 05:36:26,093 - INFO - Train: [86/90][2400/3907]	eta 0:04:35 lr 0.00030384	time 0.1824 (0.1827)	loss 3.6272 (3.1819)	acc@1: 65.8248	acc@5: 78.4981	
2023-03-20 05:37:20,606 - INFO - Train: [86/90][2700/3907]	eta 0:03:40 lr 0.00030384	time 0.1806 (0.1826)	loss 2.5906 (3.1820)	acc@1: 82.1634	acc@5: 90.2676	
2023-03-20 05:38:15,180 - INFO - Train: [86/90][3000/3907]	eta 0:02:45 lr 0.00030384	time 0.1802 (0.1826)	loss 2.2617 (3.1831)	acc@1: 88.3626	acc@5: 92.1353	
2023-03-20 05:39:09,766 - INFO - Train: [86/90][3300/3907]	eta 0:01:50 lr 0.00030384	time 0.1882 (0.1825)	loss 1.9875 (3.1881)	acc@1: 87.9215	acc@5: 96.4802	
2023-03-20 05:40:04,561 - INFO - Train: [86/90][3600/3907]	eta 0:00:56 lr 0.00030384	time 0.1860 (0.1825)	loss 3.0913 (3.1887)	acc@1: 76.1339	acc@5: 83.6595	
2023-03-20 05:40:57,710 - INFO - Train: [86/90][3900/3907]	eta 0:00:01 lr 0.00030384	time 0.1707 (0.1821)	loss 3.5809 (3.1927)	acc@1: 68.6092	acc@5: 76.4144	
2023-03-20 05:40:58,869 - INFO - EPOCH 86 training takes 0:11:51
2023-03-20 05:40:59,968 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Latest.pth saved !!!
2023-03-20 05:40:59,969 - INFO - **********Latest test***********
2023-03-20 05:40:59,969 - INFO - eval epoch 86
2023-03-20 05:41:00,613 - INFO - Test: [0/782]	Time 0.643 (0.643)	Loss 2.1634 (2.1634)	Acc@1 79.688 (79.688)	Acc@5 96.094 (96.094)
2023-03-20 05:42:56,509 - INFO - Test: [200/782]	Time 0.583 (0.580)	Loss 2.3960 (2.4545)	Acc@1 71.875 (75.540)	Acc@5 91.406 (91.064)
2023-03-20 05:44:52,469 - INFO - Test: [400/782]	Time 0.588 (0.580)	Loss 2.3741 (2.4294)	Acc@1 81.250 (76.237)	Acc@5 90.625 (91.445)
2023-03-20 05:46:49,600 - INFO - Test: [600/782]	Time 0.569 (0.582)	Loss 2.4867 (2.3988)	Acc@1 77.344 (76.967)	Acc@5 89.062 (91.847)
2023-03-20 05:48:33,563 - INFO -  * Acc@1 77.355 Acc@5 92.163
2023-03-20 05:48:33,563 - INFO - Max accuracy: 77.5810%
2023-03-20 05:48:33,563 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-20 05:48:36,079 - INFO - Train: [87/90][0/3907]	eta 2:43:34 lr 0.00019464	time 2.5120 (2.5120)	loss 4.4357 (4.4357)	acc@1: 53.8166	acc@5: 64.2991	
2023-03-20 05:49:30,518 - INFO - Train: [87/90][300/3907]	eta 0:11:22 lr 0.00019464	time 0.1801 (0.1892)	loss 4.1033 (3.1893)	acc@1: 58.1541	acc@5: 68.9671	
2023-03-20 05:50:25,037 - INFO - Train: [87/90][600/3907]	eta 0:10:13 lr 0.00019464	time 0.1862 (0.1855)	loss 3.9929 (3.2360)	acc@1: 61.3462	acc@5: 70.0960	
2023-03-20 05:51:19,561 - INFO - Train: [87/90][900/3907]	eta 0:09:13 lr 0.00019464	time 0.1804 (0.1842)	loss 2.0460 (3.2337)	acc@1: 90.0886	acc@5: 94.7481	
2023-03-20 05:52:14,186 - INFO - Train: [87/90][1200/3907]	eta 0:08:17 lr 0.00019464	time 0.1855 (0.1837)	loss 1.9129 (3.2202)	acc@1: 89.0553	acc@5: 96.0860	
2023-03-20 05:53:08,551 - INFO - Train: [87/90][1500/3907]	eta 0:07:20 lr 0.00019464	time 0.1806 (0.1832)	loss 4.9215 (3.2004)	acc@1: 35.9045	acc@5: 51.8288	
2023-03-20 05:54:03,066 - INFO - Train: [87/90][1800/3907]	eta 0:06:25 lr 0.00019464	time 0.1802 (0.1829)	loss 2.6687 (3.1985)	acc@1: 82.7038	acc@5: 89.1763	
2023-03-20 05:54:57,621 - INFO - Train: [87/90][2100/3907]	eta 0:05:30 lr 0.00019464	time 0.1804 (0.1828)	loss 3.8177 (3.1839)	acc@1: 63.8800	acc@5: 74.1424	
2023-03-20 05:55:52,233 - INFO - Train: [87/90][2400/3907]	eta 0:04:35 lr 0.00019464	time 0.1802 (0.1827)	loss 4.7588 (3.1848)	acc@1: 38.8885	acc@5: 55.0206	
2023-03-20 05:56:46,837 - INFO - Train: [87/90][2700/3907]	eta 0:03:40 lr 0.00019464	time 0.1835 (0.1826)	loss 1.8690 (3.1847)	acc@1: 87.9294	acc@5: 96.4883	
2023-03-20 05:57:41,422 - INFO - Train: [87/90][3000/3907]	eta 0:02:45 lr 0.00019464	time 0.1883 (0.1826)	loss 4.0184 (3.1897)	acc@1: 59.9721	acc@5: 70.8050	
2023-03-20 05:58:36,039 - INFO - Train: [87/90][3300/3907]	eta 0:01:50 lr 0.00019464	time 0.1803 (0.1825)	loss 4.5013 (3.1838)	acc@1: 45.3858	acc@5: 59.9294	
2023-03-20 05:59:30,882 - INFO - Train: [87/90][3600/3907]	eta 0:00:56 lr 0.00019464	time 0.1804 (0.1825)	loss 4.3560 (3.1813)	acc@1: 49.5744	acc@5: 63.4594	
2023-03-20 06:00:25,539 - INFO - Train: [87/90][3900/3907]	eta 0:00:01 lr 0.00019464	time 0.1799 (0.1825)	loss 1.7654 (3.1815)	acc@1: 94.2891	acc@5: 97.4061	
2023-03-20 06:00:26,782 - INFO - EPOCH 87 training takes 0:11:53
2023-03-20 06:00:27,730 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Latest.pth saved !!!
2023-03-20 06:00:27,730 - INFO - **********Latest test***********
2023-03-20 06:00:27,730 - INFO - eval epoch 87
2023-03-20 06:00:28,321 - INFO - Test: [0/782]	Time 0.590 (0.590)	Loss 2.1518 (2.1518)	Acc@1 81.250 (81.250)	Acc@5 95.312 (95.312)
2023-03-20 06:02:25,478 - INFO - Test: [200/782]	Time 0.580 (0.586)	Loss 2.3897 (2.4440)	Acc@1 71.875 (75.595)	Acc@5 92.188 (91.255)
2023-03-20 06:04:22,424 - INFO - Test: [400/782]	Time 0.592 (0.585)	Loss 2.3636 (2.4194)	Acc@1 78.906 (76.331)	Acc@5 90.625 (91.613)
2023-03-20 06:06:19,781 - INFO - Test: [600/782]	Time 0.583 (0.586)	Loss 2.4891 (2.3892)	Acc@1 75.781 (77.093)	Acc@5 89.844 (91.972)
2023-03-20 06:08:05,202 - INFO -  * Acc@1 77.511 Acc@5 92.265
2023-03-20 06:08:05,202 - INFO - Max accuracy: 77.5810%
2023-03-20 06:08:05,203 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-20 06:08:07,508 - INFO - Train: [88/90][0/3907]	eta 2:29:54 lr 0.00010956	time 2.3022 (2.3022)	loss 4.8772 (4.8772)	acc@1: 29.8648	acc@5: 56.0240	
2023-03-20 06:09:01,892 - INFO - Train: [88/90][300/3907]	eta 0:11:19 lr 0.00010956	time 0.1797 (0.1883)	loss 4.1797 (3.2624)	acc@1: 57.4976	acc@5: 67.7488	
2023-03-20 06:09:56,615 - INFO - Train: [88/90][600/3907]	eta 0:10:13 lr 0.00010956	time 0.1803 (0.1854)	loss 4.1158 (3.2279)	acc@1: 58.0567	acc@5: 68.9479	
2023-03-20 06:10:51,336 - INFO - Train: [88/90][900/3907]	eta 0:09:14 lr 0.00010956	time 0.1804 (0.1844)	loss 4.8945 (3.1898)	acc@1: 34.7101	acc@5: 54.8970	
2023-03-20 06:11:45,838 - INFO - Train: [88/90][1200/3907]	eta 0:08:17 lr 0.00010956	time 0.1825 (0.1837)	loss 1.7606 (3.1827)	acc@1: 92.9360	acc@5: 97.6219	
2023-03-20 06:12:40,820 - INFO - Train: [88/90][1500/3907]	eta 0:07:21 lr 0.00010956	time 0.1801 (0.1836)	loss 4.9099 (3.1907)	acc@1: 36.1566	acc@5: 55.8344	
2023-03-20 06:13:35,386 - INFO - Train: [88/90][1800/3907]	eta 0:06:26 lr 0.00010956	time 0.1803 (0.1833)	loss 1.8265 (3.2000)	acc@1: 95.3083	acc@5: 97.6519	
2023-03-20 06:14:29,909 - INFO - Train: [88/90][2100/3907]	eta 0:05:30 lr 0.00010956	time 0.1807 (0.1831)	loss 4.8001 (3.2034)	acc@1: 36.8972	acc@5: 54.3523	
2023-03-20 06:15:24,508 - INFO - Train: [88/90][2400/3907]	eta 0:04:35 lr 0.00010956	time 0.1803 (0.1830)	loss 3.7985 (3.1944)	acc@1: 66.7403	acc@5: 74.4068	
2023-03-20 06:16:18,947 - INFO - Train: [88/90][2700/3907]	eta 0:03:40 lr 0.00010956	time 0.1802 (0.1828)	loss 1.9803 (3.1903)	acc@1: 89.0318	acc@5: 95.1710	
2023-03-20 06:17:13,486 - INFO - Train: [88/90][3000/3907]	eta 0:02:45 lr 0.00010956	time 0.1802 (0.1827)	loss 1.7847 (3.1909)	acc@1: 92.0941	acc@5: 96.7769	
2023-03-20 06:18:08,371 - INFO - Train: [88/90][3300/3907]	eta 0:01:50 lr 0.00010956	time 0.1803 (0.1827)	loss 1.8670 (3.1979)	acc@1: 94.0306	acc@5: 95.5721	
2023-03-20 06:19:03,120 - INFO - Train: [88/90][3600/3907]	eta 0:00:56 lr 0.00010956	time 0.1807 (0.1827)	loss 1.7802 (3.1924)	acc@1: 92.1224	acc@5: 99.1487	
2023-03-20 06:19:57,732 - INFO - Train: [88/90][3900/3907]	eta 0:00:01 lr 0.00010956	time 0.1799 (0.1826)	loss 2.4508 (3.1974)	acc@1: 85.1314	acc@5: 89.5687	
2023-03-20 06:19:58,980 - INFO - EPOCH 88 training takes 0:11:53
2023-03-20 06:20:00,051 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Latest.pth saved !!!
2023-03-20 06:20:00,053 - INFO - **********Latest test***********
2023-03-20 06:20:00,054 - INFO - eval epoch 88
2023-03-20 06:20:00,676 - INFO - Test: [0/782]	Time 0.620 (0.620)	Loss 2.1485 (2.1485)	Acc@1 80.469 (80.469)	Acc@5 96.094 (96.094)
2023-03-20 06:21:56,485 - INFO - Test: [200/782]	Time 0.585 (0.579)	Loss 2.3982 (2.4486)	Acc@1 72.656 (75.424)	Acc@5 90.625 (91.146)
2023-03-20 06:23:53,396 - INFO - Test: [400/782]	Time 0.590 (0.582)	Loss 2.3768 (2.4235)	Acc@1 77.344 (76.206)	Acc@5 91.406 (91.510)
2023-03-20 06:25:51,843 - INFO - Test: [600/782]	Time 0.581 (0.585)	Loss 2.4933 (2.3934)	Acc@1 77.344 (76.968)	Acc@5 89.062 (91.917)
2023-03-20 06:27:36,652 - INFO -  * Acc@1 77.382 Acc@5 92.218
2023-03-20 06:27:36,652 - INFO - Max accuracy: 77.5810%
2023-03-20 06:27:36,652 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-20 06:27:39,151 - INFO - Train: [89/90][0/3907]	eta 2:42:28 lr 0.00004872	time 2.4950 (2.4950)	loss 2.0632 (2.0632)	acc@1: 87.8053	acc@5: 94.8026	
2023-03-20 06:28:33,599 - INFO - Train: [89/90][300/3907]	eta 0:11:22 lr 0.00004872	time 0.1798 (0.1892)	loss 1.9943 (3.1206)	acc@1: 90.2816	acc@5: 96.3955	
2023-03-20 06:29:28,118 - INFO - Train: [89/90][600/3907]	eta 0:10:13 lr 0.00004872	time 0.1828 (0.1855)	loss 4.5655 (3.1636)	acc@1: 49.2876	acc@5: 60.7614	
2023-03-20 06:30:22,823 - INFO - Train: [89/90][900/3907]	eta 0:09:14 lr 0.00004872	time 0.1800 (0.1844)	loss 1.9443 (3.1763)	acc@1: 88.6141	acc@5: 95.6099	
2023-03-20 06:31:17,263 - INFO - Train: [89/90][1200/3907]	eta 0:08:17 lr 0.00004872	time 0.1803 (0.1837)	loss 5.1689 (3.1696)	acc@1: 34.2416	acc@5: 49.1959	
2023-03-20 06:32:11,786 - INFO - Train: [89/90][1500/3907]	eta 0:07:21 lr 0.00004872	time 0.1803 (0.1833)	loss 4.9304 (3.1689)	acc@1: 37.6101	acc@5: 53.0117	
2023-03-20 06:33:06,226 - INFO - Train: [89/90][1800/3907]	eta 0:06:25 lr 0.00004872	time 0.1881 (0.1830)	loss 3.6604 (3.1652)	acc@1: 65.5040	acc@5: 75.6246	
2023-03-20 06:34:00,613 - INFO - Train: [89/90][2100/3907]	eta 0:05:30 lr 0.00004872	time 0.1804 (0.1827)	loss 2.3757 (3.1626)	acc@1: 85.3435	acc@5: 90.5819	
2023-03-20 06:34:55,080 - INFO - Train: [89/90][2400/3907]	eta 0:04:35 lr 0.00004872	time 0.1803 (0.1826)	loss 1.8831 (3.1595)	acc@1: 92.1873	acc@5: 96.8748	
2023-03-20 06:35:49,726 - INFO - Train: [89/90][2700/3907]	eta 0:03:40 lr 0.00004872	time 0.1804 (0.1825)	loss 1.9060 (3.1586)	acc@1: 87.4249	acc@5: 95.2307	
2023-03-20 06:36:44,274 - INFO - Train: [89/90][3000/3907]	eta 0:02:45 lr 0.00004872	time 0.1882 (0.1825)	loss 4.6735 (3.1643)	acc@1: 46.3401	acc@5: 59.9753	
2023-03-20 06:37:38,893 - INFO - Train: [89/90][3300/3907]	eta 0:01:50 lr 0.00004872	time 0.1805 (0.1824)	loss 2.3791 (3.1717)	acc@1: 84.8929	acc@5: 89.3972	
2023-03-20 06:38:33,393 - INFO - Train: [89/90][3600/3907]	eta 0:00:55 lr 0.00004872	time 0.1803 (0.1824)	loss 3.0198 (3.1737)	acc@1: 78.3196	acc@5: 84.6952	
2023-03-20 06:39:27,977 - INFO - Train: [89/90][3900/3907]	eta 0:00:01 lr 0.00004872	time 0.1796 (0.1823)	loss 4.9985 (3.1775)	acc@1: 34.4009	acc@5: 51.0334	
2023-03-20 06:39:29,213 - INFO - EPOCH 89 training takes 0:11:52
2023-03-20 06:39:30,151 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Latest.pth saved !!!
2023-03-20 06:39:30,151 - INFO - **********Latest test***********
2023-03-20 06:39:30,151 - INFO - eval epoch 89
2023-03-20 06:39:30,778 - INFO - Test: [0/782]	Time 0.626 (0.626)	Loss 2.1721 (2.1721)	Acc@1 81.250 (81.250)	Acc@5 96.094 (96.094)
2023-03-20 06:41:28,487 - INFO - Test: [200/782]	Time 0.579 (0.589)	Loss 2.3951 (2.4643)	Acc@1 74.219 (75.369)	Acc@5 91.406 (91.029)
2023-03-20 06:43:26,715 - INFO - Test: [400/782]	Time 0.591 (0.590)	Loss 2.3891 (2.4393)	Acc@1 78.906 (76.083)	Acc@5 90.625 (91.377)
2023-03-20 06:45:25,356 - INFO - Test: [600/782]	Time 0.581 (0.591)	Loss 2.5027 (2.4094)	Acc@1 77.344 (76.812)	Acc@5 88.281 (91.792)
2023-03-20 06:47:10,775 - INFO -  * Acc@1 77.239 Acc@5 92.098
2023-03-20 06:47:10,775 - INFO - Max accuracy: 77.5810%
2023-03-20 06:47:10,775 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-20 06:47:13,116 - INFO - Train: [90/90][0/3907]	eta 2:32:12 lr 0.00001218	time 2.3375 (2.3375)	loss 1.9167 (1.9167)	acc@1: 92.7204	acc@5: 96.5830	
2023-03-20 06:48:07,623 - INFO - Train: [90/90][300/3907]	eta 0:11:21 lr 0.00001218	time 0.1796 (0.1888)	loss 2.5091 (3.3717)	acc@1: 83.3545	acc@5: 89.9271	
2023-03-20 06:49:02,069 - INFO - Train: [90/90][600/3907]	eta 0:10:12 lr 0.00001218	time 0.1821 (0.1852)	loss 4.7573 (3.2306)	acc@1: 36.0268	acc@5: 57.6367	
2023-03-20 06:49:56,545 - INFO - Train: [90/90][900/3907]	eta 0:09:13 lr 0.00001218	time 0.1803 (0.1840)	loss 2.3677 (3.2339)	acc@1: 81.8424	acc@5: 89.4204	
2023-03-20 06:50:50,985 - INFO - Train: [90/90][1200/3907]	eta 0:08:16 lr 0.00001218	time 0.1801 (0.1833)	loss 3.0604 (3.2145)	acc@1: 79.3298	acc@5: 84.0926	
2023-03-20 06:51:45,330 - INFO - Train: [90/90][1500/3907]	eta 0:07:20 lr 0.00001218	time 0.1815 (0.1829)	loss 3.0495 (3.1847)	acc@1: 75.8304	acc@5: 83.5457	
2023-03-20 06:52:39,803 - INFO - Train: [90/90][1800/3907]	eta 0:06:24 lr 0.00001218	time 0.1822 (0.1827)	loss 1.9391 (3.2048)	acc@1: 91.3494	acc@5: 94.4200	
2023-03-20 06:53:34,533 - INFO - Train: [90/90][2100/3907]	eta 0:05:30 lr 0.00001218	time 0.1860 (0.1826)	loss 4.2793 (3.2120)	acc@1: 58.5741	acc@5: 65.3094	
2023-03-20 06:54:29,028 - INFO - Train: [90/90][2400/3907]	eta 0:04:35 lr 0.00001218	time 0.1799 (0.1825)	loss 4.4332 (3.2127)	acc@1: 50.5428	acc@5: 62.9105	
2023-03-20 06:55:23,399 - INFO - Train: [90/90][2700/3907]	eta 0:03:40 lr 0.00001218	time 0.1859 (0.1824)	loss 3.6972 (3.2114)	acc@1: 68.1887	acc@5: 74.7453	
2023-03-20 06:56:17,854 - INFO - Train: [90/90][3000/3907]	eta 0:02:45 lr 0.00001218	time 0.1795 (0.1823)	loss 4.7366 (3.1958)	acc@1: 44.5638	acc@5: 56.7969	
2023-03-20 06:57:12,199 - INFO - Train: [90/90][3300/3907]	eta 0:01:50 lr 0.00001218	time 0.1797 (0.1822)	loss 4.0743 (3.2067)	acc@1: 61.0118	acc@5: 67.0227	
2023-03-20 06:58:06,681 - INFO - Train: [90/90][3600/3907]	eta 0:00:55 lr 0.00001218	time 0.1797 (0.1821)	loss 1.8854 (3.2020)	acc@1: 89.0512	acc@5: 96.8628	
2023-03-20 06:59:01,298 - INFO - Train: [90/90][3900/3907]	eta 0:00:01 lr 0.00001218	time 0.1789 (0.1821)	loss 3.1926 (3.1978)	acc@1: 74.4051	acc@5: 81.8794	
2023-03-20 06:59:02,506 - INFO - EPOCH 90 training takes 0:11:51
2023-03-20 06:59:03,604 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Latest.pth saved !!!
2023-03-20 06:59:03,605 - INFO - **********Latest test***********
2023-03-20 06:59:03,605 - INFO - eval epoch 90
2023-03-20 06:59:04,213 - INFO - Test: [0/782]	Time 0.606 (0.606)	Loss 2.1857 (2.1857)	Acc@1 80.469 (80.469)	Acc@5 95.312 (95.312)
2023-03-20 07:01:01,946 - INFO - Test: [200/782]	Time 0.587 (0.589)	Loss 2.4119 (2.4873)	Acc@1 71.875 (74.911)	Acc@5 88.281 (90.784)
2023-03-20 07:02:59,618 - INFO - Test: [400/782]	Time 0.602 (0.589)	Loss 2.4074 (2.4619)	Acc@1 78.125 (75.676)	Acc@5 90.625 (91.163)
2023-03-20 07:04:59,023 - INFO - Test: [600/782]	Time 0.584 (0.591)	Loss 2.5091 (2.4314)	Acc@1 77.344 (76.482)	Acc@5 88.281 (91.570)
2023-03-20 07:06:45,089 - INFO -  * Acc@1 76.897 Acc@5 91.898
2023-03-20 07:06:45,089 - INFO - Max accuracy: 77.5810%
2023-03-20 07:06:45,089 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-20 07:06:45,090 - INFO - Training time 13:00:18

2023-03-22 01:09:48,629 - INFO - Start training
2023-03-22 01:09:53,307 - INFO - Train: [91/120][0/3907]	eta 5:04:24 lr 0.00585786	time 4.6747 (4.6747)	loss 2.6135 (2.6135)	acc@1: 82.4854	acc@5: 86.1595	
2023-03-22 01:10:47,977 - INFO - Train: [91/120][300/3907]	eta 0:11:51 lr 0.00585786	time 0.1880 (0.1972)	loss 4.8134 (3.3879)	acc@1: 39.4167	acc@5: 56.1996	
2023-03-22 01:11:42,784 - INFO - Train: [91/120][600/3907]	eta 0:10:28 lr 0.00585786	time 0.1799 (0.1899)	loss 2.7299 (3.3785)	acc@1: 80.1171	acc@5: 88.8319	
2023-03-22 01:12:37,571 - INFO - Train: [91/120][900/3907]	eta 0:09:23 lr 0.00585786	time 0.1819 (0.1875)	loss 3.5640 (3.3569)	acc@1: 69.4003	acc@5: 76.5351	
2023-03-22 01:13:32,418 - INFO - Train: [91/120][1200/3907]	eta 0:08:24 lr 0.00585786	time 0.1798 (0.1863)	loss 2.8500 (3.3288)	acc@1: 79.5395	acc@5: 86.6993	
2023-03-22 01:14:27,248 - INFO - Train: [91/120][1500/3907]	eta 0:07:26 lr 0.00585786	time 0.1799 (0.1856)	loss 2.6612 (3.3339)	acc@1: 80.7987	acc@5: 87.4668	
2023-03-22 01:15:22,190 - INFO - Train: [91/120][1800/3907]	eta 0:06:30 lr 0.00585786	time 0.1865 (0.1852)	loss 2.4521 (3.3459)	acc@1: 81.9924	acc@5: 88.0080	
2023-03-22 01:16:16,827 - INFO - Train: [91/120][2100/3907]	eta 0:05:33 lr 0.00585786	time 0.1799 (0.1848)	loss 4.9829 (3.3412)	acc@1: 37.0694	acc@5: 53.0770	
2023-03-22 01:17:10,778 - INFO - Train: [91/120][2400/3907]	eta 0:04:37 lr 0.00585786	time 0.1768 (0.1841)	loss 3.9344 (3.3481)	acc@1: 60.1535	acc@5: 73.8947	
2023-03-22 01:18:03,011 - INFO - Train: [91/120][2700/3907]	eta 0:03:40 lr 0.00585786	time 0.1707 (0.1830)	loss 2.6845 (3.3640)	acc@1: 79.7961	acc@5: 89.3071	
2023-03-22 01:18:55,343 - INFO - Train: [91/120][3000/3907]	eta 0:02:45 lr 0.00585786	time 0.1751 (0.1822)	loss 3.2824 (3.3688)	acc@1: 70.0083	acc@5: 83.1440	
2023-03-22 01:19:47,479 - INFO - Train: [91/120][3300/3907]	eta 0:01:50 lr 0.00585786	time 0.1755 (0.1814)	loss 1.9546 (3.3769)	acc@1: 85.1303	acc@5: 97.6265	
2023-03-22 01:20:39,687 - INFO - Train: [91/120][3600/3907]	eta 0:00:55 lr 0.00585786	time 0.1778 (0.1808)	loss 4.7403 (3.3824)	acc@1: 40.8401	acc@5: 59.2577	
2023-03-22 01:21:31,817 - INFO - Train: [91/120][3900/3907]	eta 0:00:01 lr 0.00585786	time 0.1697 (0.1803)	loss 4.4789 (3.3862)	acc@1: 53.4623	acc@5: 64.6712	
2023-03-22 01:21:33,503 - INFO - EPOCH 91 training takes 0:11:44
2023-03-22 01:21:34,600 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Latest.pth saved !!!
2023-03-22 01:21:34,601 - INFO - **********Latest test***********
2023-03-22 01:21:34,601 - INFO - eval epoch 91
2023-03-22 01:21:35,186 - INFO - Test: [0/782]	Time 0.584 (0.584)	Loss 2.2732 (2.2732)	Acc@1 82.031 (82.031)	Acc@5 94.531 (94.531)
2023-03-22 01:23:30,440 - INFO - Test: [200/782]	Time 0.573 (0.576)	Loss 2.6572 (2.6627)	Acc@1 68.750 (70.243)	Acc@5 88.281 (88.476)
2023-03-22 01:25:25,978 - INFO - Test: [400/782]	Time 0.586 (0.577)	Loss 2.5971 (2.6291)	Acc@1 73.438 (71.230)	Acc@5 88.281 (89.010)
2023-03-22 01:27:22,244 - INFO - Test: [600/782]	Time 0.566 (0.578)	Loss 2.6705 (2.6019)	Acc@1 71.094 (71.953)	Acc@5 88.281 (89.452)
2023-03-22 01:29:05,220 - INFO -  * Acc@1 72.498 Acc@5 89.855
2023-03-22 01:29:05,220 - INFO - Max accuracy: 77.5810%
2023-03-22 01:29:06,257 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Best.pth saved !!!
2023-03-22 01:29:06,258 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-22 01:29:08,260 - INFO - Train: [92/120][0/3907]	eta 2:10:07 lr 0.00549251	time 1.9984 (1.9984)	loss 3.9716 (3.9716)	acc@1: 61.5252	acc@5: 74.7031	
2023-03-22 01:30:02,772 - INFO - Train: [92/120][300/3907]	eta 0:11:17 lr 0.00549251	time 0.1838 (0.1877)	loss 4.7883 (3.2511)	acc@1: 38.2694	acc@5: 56.7219	
2023-03-22 01:30:57,473 - INFO - Train: [92/120][600/3907]	eta 0:10:11 lr 0.00549251	time 0.1855 (0.1850)	loss 5.5391 (3.2885)	acc@1: 26.0107	acc@5: 42.0407	
2023-03-22 01:31:52,316 - INFO - Train: [92/120][900/3907]	eta 0:09:14 lr 0.00549251	time 0.1798 (0.1843)	loss 3.6968 (3.2988)	acc@1: 62.6316	acc@5: 77.7573	
2023-03-22 01:32:47,008 - INFO - Train: [92/120][1200/3907]	eta 0:08:17 lr 0.00549251	time 0.1803 (0.1838)	loss 2.1843 (3.2919)	acc@1: 82.5071	acc@5: 94.0735	
2023-03-22 01:33:41,893 - INFO - Train: [92/120][1500/3907]	eta 0:07:21 lr 0.00549251	time 0.1877 (0.1836)	loss 2.2273 (3.3349)	acc@1: 85.4238	acc@5: 92.3054	
2023-03-22 01:34:36,760 - INFO - Train: [92/120][1800/3907]	eta 0:06:26 lr 0.00549251	time 0.1848 (0.1835)	loss 1.9950 (3.3240)	acc@1: 87.8135	acc@5: 95.5835	
2023-03-22 01:35:31,796 - INFO - Train: [92/120][2100/3907]	eta 0:05:31 lr 0.00549251	time 0.1857 (0.1835)	loss 3.2263 (3.3359)	acc@1: 74.8092	acc@5: 82.3491	
2023-03-22 01:36:24,770 - INFO - Train: [92/120][2400/3907]	eta 0:04:35 lr 0.00549251	time 0.1746 (0.1826)	loss 3.0194 (3.3441)	acc@1: 76.0471	acc@5: 83.8577	
2023-03-22 01:37:16,890 - INFO - Train: [92/120][2700/3907]	eta 0:03:39 lr 0.00549251	time 0.1730 (0.1816)	loss 5.0904 (3.3489)	acc@1: 33.7726	acc@5: 53.8218	
2023-03-22 01:38:09,115 - INFO - Train: [92/120][3000/3907]	eta 0:02:44 lr 0.00549251	time 0.1714 (0.1809)	loss 3.5682 (3.3654)	acc@1: 66.3847	acc@5: 78.9746	
2023-03-22 01:39:01,626 - INFO - Train: [92/120][3300/3907]	eta 0:01:49 lr 0.00549251	time 0.1779 (0.1804)	loss 3.5692 (3.3722)	acc@1: 66.6575	acc@5: 77.4427	
2023-03-22 01:39:53,780 - INFO - Train: [92/120][3600/3907]	eta 0:00:55 lr 0.00549251	time 0.1731 (0.1798)	loss 3.5154 (3.3807)	acc@1: 65.7254	acc@5: 81.1245	
2023-03-22 01:40:45,978 - INFO - Train: [92/120][3900/3907]	eta 0:00:01 lr 0.00549251	time 0.1719 (0.1794)	loss 3.6316 (3.3839)	acc@1: 67.8591	acc@5: 80.7865	
2023-03-22 01:40:47,172 - INFO - EPOCH 92 training takes 0:11:40
2023-03-22 01:40:48,260 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Latest.pth saved !!!
2023-03-22 01:40:48,260 - INFO - **********Latest test***********
2023-03-22 01:40:48,260 - INFO - eval epoch 92
2023-03-22 01:40:48,890 - INFO - Test: [0/782]	Time 0.629 (0.629)	Loss 2.3825 (2.3825)	Acc@1 75.781 (75.781)	Acc@5 94.531 (94.531)
2023-03-22 01:42:45,098 - INFO - Test: [200/782]	Time 0.577 (0.581)	Loss 2.6724 (2.6523)	Acc@1 71.094 (71.024)	Acc@5 85.938 (88.969)
2023-03-22 01:44:41,405 - INFO - Test: [400/782]	Time 0.592 (0.581)	Loss 2.4953 (2.6241)	Acc@1 76.562 (71.822)	Acc@5 89.844 (89.298)
2023-03-22 01:46:39,673 - INFO - Test: [600/782]	Time 0.581 (0.585)	Loss 2.7076 (2.5945)	Acc@1 71.094 (72.616)	Acc@5 86.719 (89.706)
2023-03-22 01:48:23,769 - INFO -  * Acc@1 73.081 Acc@5 90.093
2023-03-22 01:48:23,769 - INFO - Max accuracy: 77.5810%
2023-03-22 01:48:24,819 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Best.pth saved !!!
2023-03-22 01:48:24,820 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-22 01:48:26,780 - INFO - Train: [93/120][0/3907]	eta 2:07:23 lr 0.00513710	time 1.9562 (1.9562)	loss 2.9663 (2.9663)	acc@1: 72.1313	acc@5: 83.7045	
2023-03-22 01:49:21,318 - INFO - Train: [93/120][300/3907]	eta 0:11:16 lr 0.00513710	time 0.1789 (0.1877)	loss 2.9852 (3.2845)	acc@1: 76.9197	acc@5: 83.3883	
2023-03-22 01:50:15,800 - INFO - Train: [93/120][600/3907]	eta 0:10:10 lr 0.00513710	time 0.1800 (0.1846)	loss 2.6339 (3.2704)	acc@1: 82.9233	acc@5: 89.5278	
2023-03-22 01:51:10,522 - INFO - Train: [93/120][900/3907]	eta 0:09:12 lr 0.00513710	time 0.1799 (0.1839)	loss 2.4530 (3.2961)	acc@1: 81.2215	acc@5: 90.9982	
2023-03-22 01:52:05,513 - INFO - Train: [93/120][1200/3907]	eta 0:08:17 lr 0.00513710	time 0.1881 (0.1838)	loss 3.2412 (3.3198)	acc@1: 73.2090	acc@5: 80.7592	
2023-03-22 01:53:00,298 - INFO - Train: [93/120][1500/3907]	eta 0:07:21 lr 0.00513710	time 0.1857 (0.1835)	loss 2.1278 (3.3271)	acc@1: 84.4681	acc@5: 93.0050	
2023-03-22 01:53:55,058 - INFO - Train: [93/120][1800/3907]	eta 0:06:26 lr 0.00513710	time 0.1797 (0.1834)	loss 2.1183 (3.3184)	acc@1: 82.1592	acc@5: 93.0088	
2023-03-22 01:54:49,924 - INFO - Train: [93/120][2100/3907]	eta 0:05:31 lr 0.00513710	time 0.1822 (0.1833)	loss 2.9525 (3.3190)	acc@1: 78.1180	acc@5: 82.4767	
2023-03-22 01:55:44,355 - INFO - Train: [93/120][2400/3907]	eta 0:04:35 lr 0.00513710	time 0.1708 (0.1831)	loss 4.5789 (3.3362)	acc@1: 49.0787	acc@5: 61.8673	
2023-03-22 01:56:36,350 - INFO - Train: [93/120][2700/3907]	eta 0:03:39 lr 0.00513710	time 0.1708 (0.1820)	loss 2.6384 (3.3530)	acc@1: 77.1669	acc@5: 89.1539	
2023-03-22 01:57:28,607 - INFO - Train: [93/120][3000/3907]	eta 0:02:44 lr 0.00513710	time 0.1707 (0.1812)	loss 4.4529 (3.3468)	acc@1: 50.5970	acc@5: 65.2109	
2023-03-22 01:58:20,536 - INFO - Train: [93/120][3300/3907]	eta 0:01:49 lr 0.00513710	time 0.1709 (0.1805)	loss 2.8927 (3.3370)	acc@1: 76.5489	acc@5: 87.2708	
2023-03-22 01:59:12,564 - INFO - Train: [93/120][3600/3907]	eta 0:00:55 lr 0.00513710	time 0.1774 (0.1799)	loss 2.1608 (3.3391)	acc@1: 81.6464	acc@5: 93.3096	
2023-03-22 02:00:04,700 - INFO - Train: [93/120][3900/3907]	eta 0:00:01 lr 0.00513710	time 0.1725 (0.1794)	loss 2.6289 (3.3489)	acc@1: 80.0202	acc@5: 88.1704	
2023-03-22 02:00:05,877 - INFO - EPOCH 93 training takes 0:11:41
2023-03-22 02:00:06,950 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Latest.pth saved !!!
2023-03-22 02:00:06,951 - INFO - **********Latest test***********
2023-03-22 02:00:06,951 - INFO - eval epoch 93
2023-03-22 02:00:07,542 - INFO - Test: [0/782]	Time 0.590 (0.590)	Loss 2.3089 (2.3089)	Acc@1 78.906 (78.906)	Acc@5 93.750 (93.750)
2023-03-22 02:02:03,775 - INFO - Test: [200/782]	Time 0.565 (0.581)	Loss 2.6185 (2.5965)	Acc@1 71.875 (71.887)	Acc@5 85.938 (89.160)
2023-03-22 02:03:59,209 - INFO - Test: [400/782]	Time 0.591 (0.579)	Loss 2.4914 (2.5689)	Acc@1 75.781 (72.549)	Acc@5 91.406 (89.668)
2023-03-22 02:05:57,330 - INFO - Test: [600/782]	Time 0.579 (0.583)	Loss 2.6022 (2.5372)	Acc@1 71.094 (73.232)	Acc@5 90.625 (90.049)
2023-03-22 02:07:41,200 - INFO -  * Acc@1 73.611 Acc@5 90.389
2023-03-22 02:07:41,200 - INFO - Max accuracy: 77.5810%
2023-03-22 02:07:42,247 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Best.pth saved !!!
2023-03-22 02:07:42,248 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-22 02:07:44,382 - INFO - Train: [94/120][0/3907]	eta 2:18:42 lr 0.00479188	time 2.1300 (2.1300)	loss 2.0973 (2.0973)	acc@1: 83.5230	acc@5: 93.6705	
2023-03-22 02:08:38,686 - INFO - Train: [94/120][300/3907]	eta 0:11:16 lr 0.00479188	time 0.1794 (0.1875)	loss 2.5837 (3.2639)	acc@1: 77.7924	acc@5: 88.9977	
2023-03-22 02:09:33,303 - INFO - Train: [94/120][600/3907]	eta 0:10:11 lr 0.00479188	time 0.1855 (0.1848)	loss 5.1258 (3.3471)	acc@1: 29.8091	acc@5: 51.5332	
2023-03-22 02:10:28,165 - INFO - Train: [94/120][900/3907]	eta 0:09:13 lr 0.00479188	time 0.1881 (0.1841)	loss 5.1877 (3.3236)	acc@1: 31.6901	acc@5: 48.4461	
2023-03-22 02:11:23,003 - INFO - Train: [94/120][1200/3907]	eta 0:08:17 lr 0.00479188	time 0.1802 (0.1838)	loss 3.3725 (3.3137)	acc@1: 69.5103	acc@5: 78.5391	
2023-03-22 02:12:17,882 - INFO - Train: [94/120][1500/3907]	eta 0:07:21 lr 0.00479188	time 0.1841 (0.1836)	loss 4.9962 (3.2875)	acc@1: 38.4091	acc@5: 54.8193	
2023-03-22 02:13:12,675 - INFO - Train: [94/120][1800/3907]	eta 0:06:26 lr 0.00479188	time 0.1801 (0.1835)	loss 1.9491 (3.3061)	acc@1: 89.6750	acc@5: 96.6930	
2023-03-22 02:14:07,525 - INFO - Train: [94/120][2100/3907]	eta 0:05:31 lr 0.00479188	time 0.1802 (0.1834)	loss 4.0420 (3.3012)	acc@1: 62.1027	acc@5: 72.5601	
2023-03-22 02:15:00,366 - INFO - Train: [94/120][2400/3907]	eta 0:04:34 lr 0.00479188	time 0.1704 (0.1825)	loss 3.4005 (3.3111)	acc@1: 70.8193	acc@5: 79.1162	
2023-03-22 02:15:52,354 - INFO - Train: [94/120][2700/3907]	eta 0:03:39 lr 0.00479188	time 0.1795 (0.1814)	loss 2.3315 (3.3247)	acc@1: 82.0694	acc@5: 92.8074	
2023-03-22 02:16:44,418 - INFO - Train: [94/120][3000/3907]	eta 0:02:43 lr 0.00479188	time 0.1758 (0.1807)	loss 2.1315 (3.3354)	acc@1: 84.3602	acc@5: 95.2957	
2023-03-22 02:17:36,480 - INFO - Train: [94/120][3300/3907]	eta 0:01:49 lr 0.00479188	time 0.1749 (0.1800)	loss 5.3623 (3.3444)	acc@1: 28.8374	acc@5: 45.8124	
2023-03-22 02:18:28,626 - INFO - Train: [94/120][3600/3907]	eta 0:00:55 lr 0.00479188	time 0.1789 (0.1795)	loss 3.1253 (3.3423)	acc@1: 75.8587	acc@5: 84.8130	
2023-03-22 02:19:20,607 - INFO - Train: [94/120][3900/3907]	eta 0:00:01 lr 0.00479188	time 0.1701 (0.1790)	loss 5.2340 (3.3477)	acc@1: 38.4906	acc@5: 49.4377	
2023-03-22 02:19:21,781 - INFO - EPOCH 94 training takes 0:11:39
2023-03-22 02:19:22,707 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Latest.pth saved !!!
2023-03-22 02:19:22,708 - INFO - **********Latest test***********
2023-03-22 02:19:22,708 - INFO - eval epoch 94
2023-03-22 02:19:23,287 - INFO - Test: [0/782]	Time 0.578 (0.578)	Loss 2.2774 (2.2774)	Acc@1 81.250 (81.250)	Acc@5 93.750 (93.750)
2023-03-22 02:21:18,115 - INFO - Test: [200/782]	Time 0.574 (0.574)	Loss 2.6215 (2.6617)	Acc@1 71.875 (70.845)	Acc@5 85.156 (88.577)
2023-03-22 02:23:12,678 - INFO - Test: [400/782]	Time 0.574 (0.573)	Loss 2.5315 (2.6323)	Acc@1 75.000 (71.645)	Acc@5 89.062 (89.154)
2023-03-22 02:25:08,927 - INFO - Test: [600/782]	Time 0.567 (0.576)	Loss 2.6561 (2.5992)	Acc@1 71.875 (72.452)	Acc@5 89.062 (89.585)
2023-03-22 02:26:52,034 - INFO -  * Acc@1 72.963 Acc@5 89.923
2023-03-22 02:26:52,034 - INFO - Max accuracy: 77.5810%
2023-03-22 02:26:52,034 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-22 02:26:54,059 - INFO - Train: [95/120][0/3907]	eta 2:11:37 lr 0.00445708	time 2.0213 (2.0213)	loss 1.8256 (1.8256)	acc@1: 92.9079	acc@5: 98.3731	
2023-03-22 02:27:48,611 - INFO - Train: [95/120][300/3907]	eta 0:11:17 lr 0.00445708	time 0.1852 (0.1879)	loss 3.1214 (3.2158)	acc@1: 75.1318	acc@5: 82.9347	
2023-03-22 02:28:43,313 - INFO - Train: [95/120][600/3907]	eta 0:10:12 lr 0.00445708	time 0.1805 (0.1851)	loss 3.5504 (3.2800)	acc@1: 71.9651	acc@5: 78.3857	
2023-03-22 02:29:37,995 - INFO - Train: [95/120][900/3907]	eta 0:09:13 lr 0.00445708	time 0.1858 (0.1842)	loss 2.1616 (3.2626)	acc@1: 82.2008	acc@5: 95.2586	
2023-03-22 02:30:32,836 - INFO - Train: [95/120][1200/3907]	eta 0:08:17 lr 0.00445708	time 0.1803 (0.1838)	loss 2.0183 (3.2863)	acc@1: 87.2890	acc@5: 96.6414	
2023-03-22 02:31:27,660 - INFO - Train: [95/120][1500/3907]	eta 0:07:21 lr 0.00445708	time 0.1801 (0.1836)	loss 4.9582 (3.2866)	acc@1: 30.2207	acc@5: 53.3467	
2023-03-22 02:32:22,387 - INFO - Train: [95/120][1800/3907]	eta 0:06:26 lr 0.00445708	time 0.1797 (0.1834)	loss 3.5120 (3.2799)	acc@1: 66.9029	acc@5: 78.8048	
2023-03-22 02:33:17,077 - INFO - Train: [95/120][2100/3907]	eta 0:05:31 lr 0.00445708	time 0.1802 (0.1833)	loss 4.9435 (3.2844)	acc@1: 31.7307	acc@5: 51.7513	
2023-03-22 02:34:10,082 - INFO - Train: [95/120][2400/3907]	eta 0:04:34 lr 0.00445708	time 0.1786 (0.1824)	loss 2.2164 (3.2970)	acc@1: 84.9808	acc@5: 94.9317	
2023-03-22 02:35:02,086 - INFO - Train: [95/120][2700/3907]	eta 0:03:38 lr 0.00445708	time 0.1772 (0.1814)	loss 2.2412 (3.2994)	acc@1: 82.9162	acc@5: 92.1276	
2023-03-22 02:35:54,073 - INFO - Train: [95/120][3000/3907]	eta 0:02:43 lr 0.00445708	time 0.1791 (0.1806)	loss 2.8320 (3.3039)	acc@1: 73.2206	acc@5: 85.6682	
2023-03-22 02:36:46,614 - INFO - Train: [95/120][3300/3907]	eta 0:01:49 lr 0.00445708	time 0.1705 (0.1801)	loss 1.8465 (3.3227)	acc@1: 92.9584	acc@5: 97.6453	
2023-03-22 02:37:38,592 - INFO - Train: [95/120][3600/3907]	eta 0:00:55 lr 0.00445708	time 0.1713 (0.1795)	loss 2.5085 (3.3207)	acc@1: 81.4957	acc@5: 92.7060	
2023-03-22 02:38:30,715 - INFO - Train: [95/120][3900/3907]	eta 0:00:01 lr 0.00445708	time 0.1710 (0.1791)	loss 2.6250 (3.3262)	acc@1: 80.5392	acc@5: 88.6670	
2023-03-22 02:38:31,870 - INFO - EPOCH 95 training takes 0:11:39
2023-03-22 02:38:32,965 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Latest.pth saved !!!
2023-03-22 02:38:32,965 - INFO - **********Latest test***********
2023-03-22 02:38:32,965 - INFO - eval epoch 95
2023-03-22 02:38:33,582 - INFO - Test: [0/782]	Time 0.615 (0.615)	Loss 2.2359 (2.2359)	Acc@1 76.562 (76.562)	Acc@5 94.531 (94.531)
2023-03-22 02:40:29,771 - INFO - Test: [200/782]	Time 0.558 (0.581)	Loss 2.5558 (2.5406)	Acc@1 68.750 (72.792)	Acc@5 89.062 (89.743)
2023-03-22 02:42:25,317 - INFO - Test: [400/782]	Time 0.596 (0.579)	Loss 2.4598 (2.5170)	Acc@1 78.125 (73.432)	Acc@5 88.281 (90.175)
2023-03-22 02:44:22,399 - INFO - Test: [600/782]	Time 0.574 (0.581)	Loss 2.5177 (2.4848)	Acc@1 74.219 (74.215)	Acc@5 90.625 (90.593)
2023-03-22 02:46:05,509 - INFO -  * Acc@1 74.677 Acc@5 90.958
2023-03-22 02:46:05,509 - INFO - Max accuracy: 77.5810%
2023-03-22 02:46:06,575 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Best.pth saved !!!
2023-03-22 02:46:06,575 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-22 02:46:08,607 - INFO - Train: [96/120][0/3907]	eta 2:12:01 lr 0.00413293	time 2.0276 (2.0276)	loss 2.8234 (2.8234)	acc@1: 81.3409	acc@5: 86.3759	
2023-03-22 02:47:03,026 - INFO - Train: [96/120][300/3907]	eta 0:11:16 lr 0.00413293	time 0.1853 (0.1875)	loss 2.1015 (3.2822)	acc@1: 88.2452	acc@5: 94.4374	
2023-03-22 02:47:57,523 - INFO - Train: [96/120][600/3907]	eta 0:10:10 lr 0.00413293	time 0.1809 (0.1846)	loss 3.4005 (3.3119)	acc@1: 69.6715	acc@5: 79.0490	
2023-03-22 02:48:52,204 - INFO - Train: [96/120][900/3907]	eta 0:09:12 lr 0.00413293	time 0.1870 (0.1838)	loss 5.0118 (3.3080)	acc@1: 30.4218	acc@5: 52.2498	
2023-03-22 02:49:46,892 - INFO - Train: [96/120][1200/3907]	eta 0:08:16 lr 0.00413293	time 0.1800 (0.1834)	loss 3.1243 (3.2957)	acc@1: 78.0771	acc@5: 85.7516	
2023-03-22 02:50:41,668 - INFO - Train: [96/120][1500/3907]	eta 0:07:21 lr 0.00413293	time 0.1813 (0.1833)	loss 2.0317 (3.2854)	acc@1: 87.8808	acc@5: 94.1021	
2023-03-22 02:51:36,503 - INFO - Train: [96/120][1800/3907]	eta 0:06:25 lr 0.00413293	time 0.1858 (0.1832)	loss 3.1473 (3.2913)	acc@1: 71.1256	acc@5: 84.0834	
2023-03-22 02:52:31,323 - INFO - Train: [96/120][2100/3907]	eta 0:05:30 lr 0.00413293	time 0.1907 (0.1831)	loss 2.8834 (3.2938)	acc@1: 79.3306	acc@5: 87.8996	
2023-03-22 02:53:26,207 - INFO - Train: [96/120][2400/3907]	eta 0:04:35 lr 0.00413293	time 0.1801 (0.1831)	loss 3.4857 (3.3045)	acc@1: 71.9449	acc@5: 78.6564	
2023-03-22 02:54:20,882 - INFO - Train: [96/120][2700/3907]	eta 0:03:40 lr 0.00413293	time 0.1723 (0.1830)	loss 3.1023 (3.2974)	acc@1: 76.5038	acc@5: 84.9174	
2023-03-22 02:55:12,893 - INFO - Train: [96/120][3000/3907]	eta 0:02:45 lr 0.00413293	time 0.1754 (0.1820)	loss 3.7887 (3.3000)	acc@1: 66.4916	acc@5: 75.1958	
2023-03-22 02:56:04,829 - INFO - Train: [96/120][3300/3907]	eta 0:01:50 lr 0.00413293	time 0.1797 (0.1812)	loss 3.4662 (3.2982)	acc@1: 68.1223	acc@5: 81.4475	
2023-03-22 02:56:57,109 - INFO - Train: [96/120][3600/3907]	eta 0:00:55 lr 0.00413293	time 0.1703 (0.1806)	loss 5.1009 (3.2967)	acc@1: 35.0185	acc@5: 52.8214	
2023-03-22 02:57:49,109 - INFO - Train: [96/120][3900/3907]	eta 0:00:01 lr 0.00413293	time 0.1700 (0.1801)	loss 4.6039 (3.3046)	acc@1: 44.5624	acc@5: 60.5596	
2023-03-22 02:57:50,288 - INFO - EPOCH 96 training takes 0:11:43
2023-03-22 02:57:51,347 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Latest.pth saved !!!
2023-03-22 02:57:51,347 - INFO - **********Latest test***********
2023-03-22 02:57:51,347 - INFO - eval epoch 96
2023-03-22 02:57:51,939 - INFO - Test: [0/782]	Time 0.591 (0.591)	Loss 2.2763 (2.2763)	Acc@1 78.125 (78.125)	Acc@5 96.094 (96.094)
2023-03-22 02:59:47,769 - INFO - Test: [200/782]	Time 0.572 (0.579)	Loss 2.5533 (2.5811)	Acc@1 70.312 (72.097)	Acc@5 89.844 (89.303)
2023-03-22 03:01:44,058 - INFO - Test: [400/782]	Time 0.584 (0.580)	Loss 2.5290 (2.5525)	Acc@1 73.438 (72.960)	Acc@5 88.281 (89.744)
2023-03-22 03:03:42,363 - INFO - Test: [600/782]	Time 0.574 (0.584)	Loss 2.5766 (2.5180)	Acc@1 74.219 (73.805)	Acc@5 89.844 (90.239)
2023-03-22 03:05:26,073 - INFO -  * Acc@1 74.294 Acc@5 90.640
2023-03-22 03:05:26,073 - INFO - Max accuracy: 77.5810%
2023-03-22 03:05:26,073 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-22 03:05:28,082 - INFO - Train: [97/120][0/3907]	eta 2:10:33 lr 0.00381966	time 2.0049 (2.0049)	loss 4.4277 (4.4277)	acc@1: 48.8107	acc@5: 64.2263	
2023-03-22 03:06:22,738 - INFO - Train: [97/120][300/3907]	eta 0:11:18 lr 0.00381966	time 0.1793 (0.1882)	loss 1.9834 (3.1002)	acc@1: 88.2826	acc@5: 95.2523	
2023-03-22 03:07:17,455 - INFO - Train: [97/120][600/3907]	eta 0:10:12 lr 0.00381966	time 0.1813 (0.1853)	loss 4.8884 (3.1860)	acc@1: 39.1542	acc@5: 55.5679	
2023-03-22 03:08:12,354 - INFO - Train: [97/120][900/3907]	eta 0:09:14 lr 0.00381966	time 0.1876 (0.1845)	loss 1.9172 (3.2032)	acc@1: 87.3731	acc@5: 95.9543	
2023-03-22 03:09:06,951 - INFO - Train: [97/120][1200/3907]	eta 0:08:17 lr 0.00381966	time 0.1794 (0.1839)	loss 1.9494 (3.2425)	acc@1: 89.0519	acc@5: 96.0823	
2023-03-22 03:10:01,534 - INFO - Train: [97/120][1500/3907]	eta 0:07:21 lr 0.00381966	time 0.1793 (0.1835)	loss 3.1420 (3.2541)	acc@1: 71.8833	acc@5: 85.1970	
2023-03-22 03:10:56,417 - INFO - Train: [97/120][1800/3907]	eta 0:06:26 lr 0.00381966	time 0.1880 (0.1834)	loss 4.1938 (3.2677)	acc@1: 60.3932	acc@5: 69.2890	
2023-03-22 03:11:50,902 - INFO - Train: [97/120][2100/3907]	eta 0:05:30 lr 0.00381966	time 0.1873 (0.1832)	loss 4.3054 (3.2896)	acc@1: 53.0947	acc@5: 66.1174	
2023-03-22 03:12:44,023 - INFO - Train: [97/120][2400/3907]	eta 0:04:34 lr 0.00381966	time 0.1711 (0.1824)	loss 2.0392 (3.2805)	acc@1: 84.9881	acc@5: 95.9039	
2023-03-22 03:13:35,575 - INFO - Train: [97/120][2700/3907]	eta 0:03:38 lr 0.00381966	time 0.1704 (0.1812)	loss 2.2444 (3.2800)	acc@1: 86.6662	acc@5: 94.2879	
2023-03-22 03:14:27,794 - INFO - Train: [97/120][3000/3907]	eta 0:02:43 lr 0.00381966	time 0.1784 (0.1805)	loss 2.6351 (3.2828)	acc@1: 81.7832	acc@5: 87.6710	
2023-03-22 03:15:19,992 - INFO - Train: [97/120][3300/3907]	eta 0:01:49 lr 0.00381966	time 0.1708 (0.1799)	loss 2.2482 (3.2776)	acc@1: 81.9159	acc@5: 89.7171	
2023-03-22 03:16:12,143 - INFO - Train: [97/120][3600/3907]	eta 0:00:55 lr 0.00381966	time 0.1706 (0.1794)	loss 2.1427 (3.2835)	acc@1: 82.6727	acc@5: 94.2611	
2023-03-22 03:17:04,314 - INFO - Train: [97/120][3900/3907]	eta 0:00:01 lr 0.00381966	time 0.1750 (0.1790)	loss 3.3995 (3.2879)	acc@1: 69.7652	acc@5: 77.3861	
2023-03-22 03:17:05,444 - INFO - EPOCH 97 training takes 0:11:39
2023-03-22 03:17:06,523 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Latest.pth saved !!!
2023-03-22 03:17:06,524 - INFO - **********Latest test***********
2023-03-22 03:17:06,524 - INFO - eval epoch 97
2023-03-22 03:17:07,127 - INFO - Test: [0/782]	Time 0.602 (0.602)	Loss 2.2158 (2.2158)	Acc@1 77.344 (77.344)	Acc@5 94.531 (94.531)
2023-03-22 03:19:03,238 - INFO - Test: [200/782]	Time 0.569 (0.581)	Loss 2.5088 (2.5417)	Acc@1 70.312 (72.866)	Acc@5 86.719 (89.782)
2023-03-22 03:20:59,579 - INFO - Test: [400/782]	Time 0.594 (0.581)	Loss 2.4477 (2.5140)	Acc@1 74.219 (73.599)	Acc@5 91.406 (90.230)
2023-03-22 03:22:56,370 - INFO - Test: [600/782]	Time 0.570 (0.582)	Loss 2.5639 (2.4813)	Acc@1 71.875 (74.414)	Acc@5 89.844 (90.637)
2023-03-22 03:24:39,375 - INFO -  * Acc@1 74.862 Acc@5 90.914
2023-03-22 03:24:39,375 - INFO - Max accuracy: 77.5810%
2023-03-22 03:24:40,294 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Best.pth saved !!!
2023-03-22 03:24:40,294 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-22 03:24:42,325 - INFO - Train: [98/120][0/3907]	eta 2:11:58 lr 0.00351748	time 2.0267 (2.0267)	loss 3.7976 (3.7976)	acc@1: 63.7496	acc@5: 76.6157	
2023-03-22 03:25:36,658 - INFO - Train: [98/120][300/3907]	eta 0:11:15 lr 0.00351748	time 0.1797 (0.1872)	loss 4.6309 (3.2396)	acc@1: 46.1628	acc@5: 60.1802	
2023-03-22 03:26:31,250 - INFO - Train: [98/120][600/3907]	eta 0:10:10 lr 0.00351748	time 0.1797 (0.1846)	loss 1.9373 (3.2392)	acc@1: 90.4943	acc@5: 97.4554	
2023-03-22 03:27:25,727 - INFO - Train: [98/120][900/3907]	eta 0:09:12 lr 0.00351748	time 0.1798 (0.1836)	loss 2.7062 (3.2124)	acc@1: 80.8718	acc@5: 88.1527	
2023-03-22 03:28:20,253 - INFO - Train: [98/120][1200/3907]	eta 0:08:15 lr 0.00351748	time 0.1821 (0.1831)	loss 4.3386 (3.2275)	acc@1: 48.7324	acc@5: 66.1192	
2023-03-22 03:29:14,915 - INFO - Train: [98/120][1500/3907]	eta 0:07:20 lr 0.00351748	time 0.1801 (0.1830)	loss 2.2757 (3.2319)	acc@1: 86.9035	acc@5: 94.3924	
2023-03-22 03:30:09,547 - INFO - Train: [98/120][1800/3907]	eta 0:06:25 lr 0.00351748	time 0.1796 (0.1828)	loss 5.0278 (3.2328)	acc@1: 28.3099	acc@5: 48.6533	
2023-03-22 03:31:04,275 - INFO - Train: [98/120][2100/3907]	eta 0:05:30 lr 0.00351748	time 0.1727 (0.1828)	loss 2.2846 (3.2345)	acc@1: 88.2339	acc@5: 93.4981	
2023-03-22 03:31:56,766 - INFO - Train: [98/120][2400/3907]	eta 0:04:33 lr 0.00351748	time 0.1729 (0.1818)	loss 1.9414 (3.2276)	acc@1: 89.3469	acc@5: 97.1155	
2023-03-22 03:32:48,635 - INFO - Train: [98/120][2700/3907]	eta 0:03:38 lr 0.00351748	time 0.1710 (0.1808)	loss 3.6569 (3.2331)	acc@1: 66.9537	acc@5: 77.3542	
2023-03-22 03:33:40,831 - INFO - Train: [98/120][3000/3907]	eta 0:02:43 lr 0.00351748	time 0.1862 (0.1801)	loss 2.9275 (3.2391)	acc@1: 76.5300	acc@5: 86.5054	
2023-03-22 03:34:32,869 - INFO - Train: [98/120][3300/3907]	eta 0:01:48 lr 0.00351748	time 0.1743 (0.1795)	loss 4.7208 (3.2548)	acc@1: 44.6932	acc@5: 57.2582	
2023-03-22 03:35:24,998 - INFO - Train: [98/120][3600/3907]	eta 0:00:54 lr 0.00351748	time 0.1706 (0.1790)	loss 5.0665 (3.2655)	acc@1: 30.4078	acc@5: 53.8800	
2023-03-22 03:36:17,289 - INFO - Train: [98/120][3900/3907]	eta 0:00:01 lr 0.00351748	time 0.1763 (0.1787)	loss 2.0589 (3.2652)	acc@1: 86.9762	acc@5: 95.5180	
2023-03-22 03:36:18,450 - INFO - EPOCH 98 training takes 0:11:38
2023-03-22 03:36:19,552 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Latest.pth saved !!!
2023-03-22 03:36:19,552 - INFO - **********Latest test***********
2023-03-22 03:36:19,552 - INFO - eval epoch 98
2023-03-22 03:36:20,144 - INFO - Test: [0/782]	Time 0.591 (0.591)	Loss 2.2402 (2.2402)	Acc@1 78.906 (78.906)	Acc@5 96.875 (96.875)
2023-03-22 03:38:15,510 - INFO - Test: [200/782]	Time 0.580 (0.577)	Loss 2.4866 (2.5554)	Acc@1 75.000 (72.866)	Acc@5 89.844 (89.782)
2023-03-22 03:40:12,152 - INFO - Test: [400/782]	Time 0.603 (0.580)	Loss 2.4714 (2.5260)	Acc@1 73.438 (73.621)	Acc@5 89.844 (90.212)
2023-03-22 03:42:10,274 - INFO - Test: [600/782]	Time 0.571 (0.584)	Loss 2.5792 (2.4962)	Acc@1 75.000 (74.386)	Acc@5 89.062 (90.617)
2023-03-22 03:43:54,220 - INFO -  * Acc@1 74.827 Acc@5 90.932
2023-03-22 03:43:54,220 - INFO - Max accuracy: 77.5810%
2023-03-22 03:43:54,220 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-22 03:43:56,328 - INFO - Train: [99/120][0/3907]	eta 2:16:59 lr 0.00322659	time 2.1037 (2.1037)	loss 3.2636 (3.2636)	acc@1: 75.6362	acc@5: 83.5156	
2023-03-22 03:44:50,981 - INFO - Train: [99/120][300/3907]	eta 0:11:20 lr 0.00322659	time 0.1797 (0.1886)	loss 4.9210 (3.1360)	acc@1: 31.0431	acc@5: 49.8264	
2023-03-22 03:45:45,758 - INFO - Train: [99/120][600/3907]	eta 0:10:13 lr 0.00322659	time 0.1797 (0.1856)	loss 3.9322 (3.1742)	acc@1: 59.4238	acc@5: 73.4634	
2023-03-22 03:46:40,332 - INFO - Train: [99/120][900/3907]	eta 0:09:14 lr 0.00322659	time 0.1847 (0.1844)	loss 4.7482 (3.1857)	acc@1: 43.0086	acc@5: 55.3386	
2023-03-22 03:47:35,104 - INFO - Train: [99/120][1200/3907]	eta 0:08:17 lr 0.00322659	time 0.1872 (0.1839)	loss 2.0542 (3.2156)	acc@1: 86.8495	acc@5: 96.9288	
2023-03-22 03:48:29,702 - INFO - Train: [99/120][1500/3907]	eta 0:07:21 lr 0.00322659	time 0.1795 (0.1835)	loss 2.5162 (3.2235)	acc@1: 83.1620	acc@5: 92.7293	
2023-03-22 03:49:24,484 - INFO - Train: [99/120][1800/3907]	eta 0:06:26 lr 0.00322659	time 0.1813 (0.1834)	loss 2.4657 (3.2318)	acc@1: 86.7431	acc@5: 92.5745	
2023-03-22 03:50:19,150 - INFO - Train: [99/120][2100/3907]	eta 0:05:31 lr 0.00322659	time 0.1878 (0.1832)	loss 3.1334 (3.2286)	acc@1: 76.9597	acc@5: 85.2902	
2023-03-22 03:51:13,084 - INFO - Train: [99/120][2400/3907]	eta 0:04:35 lr 0.00322659	time 0.1752 (0.1828)	loss 4.0813 (3.2385)	acc@1: 56.4719	acc@5: 71.5673	
2023-03-22 03:52:05,120 - INFO - Train: [99/120][2700/3907]	eta 0:03:39 lr 0.00322659	time 0.1705 (0.1817)	loss 3.7425 (3.2540)	acc@1: 62.8551	acc@5: 74.8766	
2023-03-22 03:52:57,221 - INFO - Train: [99/120][3000/3907]	eta 0:02:44 lr 0.00322659	time 0.1712 (0.1809)	loss 3.1691 (3.2623)	acc@1: 73.0549	acc@5: 84.1739	
2023-03-22 03:53:49,474 - INFO - Train: [99/120][3300/3907]	eta 0:01:49 lr 0.00322659	time 0.1740 (0.1803)	loss 3.0565 (3.2752)	acc@1: 77.4582	acc@5: 85.1259	
2023-03-22 03:54:41,583 - INFO - Train: [99/120][3600/3907]	eta 0:00:55 lr 0.00322659	time 0.1708 (0.1798)	loss 2.7338 (3.2786)	acc@1: 79.9709	acc@5: 85.8561	
2023-03-22 03:55:33,857 - INFO - Train: [99/120][3900/3907]	eta 0:00:01 lr 0.00322659	time 0.1694 (0.1793)	loss 1.9586 (3.2841)	acc@1: 87.7079	acc@5: 97.0221	
2023-03-22 03:55:34,984 - INFO - EPOCH 99 training takes 0:11:40
2023-03-22 03:55:36,069 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Latest.pth saved !!!
2023-03-22 03:55:36,070 - INFO - **********Latest test***********
2023-03-22 03:55:36,070 - INFO - eval epoch 99
2023-03-22 03:55:36,695 - INFO - Test: [0/782]	Time 0.624 (0.624)	Loss 2.1976 (2.1976)	Acc@1 81.250 (81.250)	Acc@5 96.094 (96.094)
2023-03-22 03:57:32,505 - INFO - Test: [200/782]	Time 0.572 (0.579)	Loss 2.4837 (2.5094)	Acc@1 73.438 (73.908)	Acc@5 89.844 (90.190)
2023-03-22 03:59:29,392 - INFO - Test: [400/782]	Time 0.578 (0.582)	Loss 2.3969 (2.4833)	Acc@1 77.344 (74.542)	Acc@5 90.625 (90.570)
2023-03-22 04:01:26,464 - INFO - Test: [600/782]	Time 0.579 (0.583)	Loss 2.5769 (2.4544)	Acc@1 71.875 (75.295)	Acc@5 87.500 (90.942)
2023-03-22 04:03:09,698 - INFO -  * Acc@1 75.646 Acc@5 91.222
2023-03-22 04:03:09,698 - INFO - Max accuracy: 77.5810%
2023-03-22 04:03:10,748 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Best.pth saved !!!
2023-03-22 04:03:10,749 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-22 04:03:12,619 - INFO - Train: [100/120][0/3907]	eta 2:01:32 lr 0.00294720	time 1.8666 (1.8666)	loss 4.2174 (4.2174)	acc@1: 56.4992	acc@5: 67.0558	
2023-03-22 04:04:07,136 - INFO - Train: [100/120][300/3907]	eta 0:11:15 lr 0.00294720	time 0.1793 (0.1873)	loss 3.5740 (3.2205)	acc@1: 69.9864	acc@5: 77.7295	
2023-03-22 04:05:01,864 - INFO - Train: [100/120][600/3907]	eta 0:10:11 lr 0.00294720	time 0.1875 (0.1849)	loss 5.1895 (3.2037)	acc@1: 30.1833	acc@5: 50.6641	
2023-03-22 04:05:56,548 - INFO - Train: [100/120][900/3907]	eta 0:09:13 lr 0.00294720	time 0.1856 (0.1840)	loss 3.6624 (3.2110)	acc@1: 64.1694	acc@5: 78.0704	
2023-03-22 04:06:51,527 - INFO - Train: [100/120][1200/3907]	eta 0:08:17 lr 0.00294720	time 0.1800 (0.1838)	loss 4.8442 (3.2125)	acc@1: 34.4532	acc@5: 57.1225	
2023-03-22 04:07:46,231 - INFO - Train: [100/120][1500/3907]	eta 0:07:21 lr 0.00294720	time 0.1806 (0.1835)	loss 4.9005 (3.2213)	acc@1: 35.1111	acc@5: 55.3785	
2023-03-22 04:08:40,989 - INFO - Train: [100/120][1800/3907]	eta 0:06:26 lr 0.00294720	time 0.1842 (0.1834)	loss 4.6029 (3.2227)	acc@1: 47.4093	acc@5: 63.1215	
2023-03-22 04:09:35,536 - INFO - Train: [100/120][2100/3907]	eta 0:05:30 lr 0.00294720	time 0.1799 (0.1831)	loss 2.2111 (3.2217)	acc@1: 80.8075	acc@5: 92.4655	
2023-03-22 04:10:30,451 - INFO - Train: [100/120][2400/3907]	eta 0:04:35 lr 0.00294720	time 0.1883 (0.1831)	loss 1.9653 (3.2219)	acc@1: 90.6239	acc@5: 94.5301	
2023-03-22 04:11:22,696 - INFO - Train: [100/120][2700/3907]	eta 0:03:39 lr 0.00294720	time 0.1750 (0.1821)	loss 4.4873 (3.2290)	acc@1: 52.3370	acc@5: 63.2551	
2023-03-22 04:12:14,763 - INFO - Train: [100/120][3000/3907]	eta 0:02:44 lr 0.00294720	time 0.1797 (0.1813)	loss 4.9445 (3.2390)	acc@1: 37.9853	acc@5: 56.3636	
2023-03-22 04:13:06,948 - INFO - Train: [100/120][3300/3907]	eta 0:01:49 lr 0.00294720	time 0.1708 (0.1806)	loss 4.5277 (3.2413)	acc@1: 47.3525	acc@5: 60.9359	
2023-03-22 04:13:59,090 - INFO - Train: [100/120][3600/3907]	eta 0:00:55 lr 0.00294720	time 0.1752 (0.1800)	loss 3.2928 (3.2503)	acc@1: 73.2235	acc@5: 80.1314	
2023-03-22 04:14:51,195 - INFO - Train: [100/120][3900/3907]	eta 0:00:01 lr 0.00294720	time 0.1695 (0.1796)	loss 4.3679 (3.2579)	acc@1: 52.6972	acc@5: 63.1230	
2023-03-22 04:14:52,347 - INFO - EPOCH 100 training takes 0:11:41
2023-03-22 04:14:53,416 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Latest.pth saved !!!
2023-03-22 04:14:53,416 - INFO - **********Latest test***********
2023-03-22 04:14:53,416 - INFO - eval epoch 100
2023-03-22 04:14:54,016 - INFO - Test: [0/782]	Time 0.598 (0.598)	Loss 2.2883 (2.2883)	Acc@1 76.562 (76.562)	Acc@5 93.750 (93.750)
2023-03-22 04:16:49,719 - INFO - Test: [200/782]	Time 0.572 (0.579)	Loss 2.4842 (2.5310)	Acc@1 71.875 (73.371)	Acc@5 92.188 (90.050)
2023-03-22 04:18:45,569 - INFO - Test: [400/782]	Time 0.594 (0.579)	Loss 2.4714 (2.5052)	Acc@1 78.125 (74.045)	Acc@5 89.844 (90.428)
2023-03-22 04:20:42,073 - INFO - Test: [600/782]	Time 0.566 (0.580)	Loss 2.5617 (2.4736)	Acc@1 74.219 (74.873)	Acc@5 87.500 (90.867)
2023-03-22 04:22:25,290 - INFO -  * Acc@1 75.292 Acc@5 91.176
2023-03-22 04:22:25,291 - INFO - Max accuracy: 77.5810%
2023-03-22 04:22:25,291 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-22 04:22:27,370 - INFO - Train: [101/120][0/3907]	eta 2:15:09 lr 0.00267949	time 2.0755 (2.0755)	loss 5.1049 (5.1049)	acc@1: 29.3988	acc@5: 51.3961	
2023-03-22 04:23:21,790 - INFO - Train: [101/120][300/3907]	eta 0:11:16 lr 0.00267949	time 0.1788 (0.1877)	loss 2.1083 (3.2091)	acc@1: 83.5826	acc@5: 91.3941	
2023-03-22 04:24:16,473 - INFO - Train: [101/120][600/3907]	eta 0:10:11 lr 0.00267949	time 0.1798 (0.1850)	loss 4.7827 (3.3150)	acc@1: 41.2508	acc@5: 57.0244	
2023-03-22 04:25:11,086 - INFO - Train: [101/120][900/3907]	eta 0:09:13 lr 0.00267949	time 0.1870 (0.1840)	loss 2.3391 (3.2842)	acc@1: 83.5463	acc@5: 90.3819	
2023-03-22 04:26:05,695 - INFO - Train: [101/120][1200/3907]	eta 0:08:16 lr 0.00267949	time 0.1794 (0.1835)	loss 3.6439 (3.2868)	acc@1: 66.5537	acc@5: 77.2803	
2023-03-22 04:27:00,407 - INFO - Train: [101/120][1500/3907]	eta 0:07:21 lr 0.00267949	time 0.1807 (0.1833)	loss 2.5839 (3.2897)	acc@1: 80.7030	acc@5: 89.5017	
2023-03-22 04:27:55,172 - INFO - Train: [101/120][1800/3907]	eta 0:06:25 lr 0.00267949	time 0.1853 (0.1832)	loss 3.7216 (3.2855)	acc@1: 65.2483	acc@5: 74.6170	
2023-03-22 04:28:49,856 - INFO - Train: [101/120][2100/3907]	eta 0:05:30 lr 0.00267949	time 0.1807 (0.1830)	loss 2.2114 (3.2692)	acc@1: 82.6942	acc@5: 93.4118	
2023-03-22 04:29:43,326 - INFO - Train: [101/120][2400/3907]	eta 0:04:34 lr 0.00267949	time 0.1710 (0.1824)	loss 1.9862 (3.2618)	acc@1: 88.2663	acc@5: 95.2964	
2023-03-22 04:30:35,221 - INFO - Train: [101/120][2700/3907]	eta 0:03:38 lr 0.00267949	time 0.1765 (0.1814)	loss 2.2105 (3.2553)	acc@1: 84.0104	acc@5: 94.0275	
2023-03-22 04:31:27,143 - INFO - Train: [101/120][3000/3907]	eta 0:02:43 lr 0.00267949	time 0.1708 (0.1806)	loss 3.1214 (3.2513)	acc@1: 75.6790	acc@5: 83.9246	
2023-03-22 04:32:18,974 - INFO - Train: [101/120][3300/3907]	eta 0:01:49 lr 0.00267949	time 0.1706 (0.1798)	loss 2.2906 (3.2595)	acc@1: 82.1094	acc@5: 91.3148	
2023-03-22 04:33:11,080 - INFO - Train: [101/120][3600/3907]	eta 0:00:55 lr 0.00267949	time 0.1708 (0.1793)	loss 4.8512 (3.2725)	acc@1: 41.5307	acc@5: 57.0188	
2023-03-22 04:34:03,330 - INFO - Train: [101/120][3900/3907]	eta 0:00:01 lr 0.00267949	time 0.1694 (0.1789)	loss 3.7483 (3.2724)	acc@1: 67.2905	acc@5: 76.4938	
2023-03-22 04:34:04,522 - INFO - EPOCH 101 training takes 0:11:39
2023-03-22 04:34:05,596 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Latest.pth saved !!!
2023-03-22 04:34:05,596 - INFO - **********Latest test***********
2023-03-22 04:34:05,596 - INFO - eval epoch 101
2023-03-22 04:34:06,199 - INFO - Test: [0/782]	Time 0.601 (0.601)	Loss 2.2169 (2.2169)	Acc@1 78.906 (78.906)	Acc@5 96.094 (96.094)
2023-03-22 04:36:01,796 - INFO - Test: [200/782]	Time 0.573 (0.578)	Loss 2.4866 (2.5131)	Acc@1 75.000 (73.690)	Acc@5 88.281 (90.120)
2023-03-22 04:37:58,078 - INFO - Test: [400/782]	Time 0.595 (0.580)	Loss 2.4085 (2.4874)	Acc@1 78.906 (74.451)	Acc@5 90.625 (90.496)
2023-03-22 04:39:56,139 - INFO - Test: [600/782]	Time 0.562 (0.583)	Loss 2.5645 (2.4591)	Acc@1 76.562 (75.260)	Acc@5 87.500 (90.903)
2023-03-22 04:41:39,839 - INFO -  * Acc@1 75.766 Acc@5 91.242
2023-03-22 04:41:39,839 - INFO - Max accuracy: 77.5810%
2023-03-22 04:41:40,899 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Best.pth saved !!!
2023-03-22 04:41:40,899 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-22 04:41:42,825 - INFO - Train: [102/120][0/3907]	eta 2:05:07 lr 0.00242366	time 1.9216 (1.9216)	loss 5.1175 (5.1175)	acc@1: 28.9062	acc@5: 48.0662	
2023-03-22 04:42:37,279 - INFO - Train: [102/120][300/3907]	eta 0:11:15 lr 0.00242366	time 0.1786 (0.1873)	loss 2.0941 (3.1353)	acc@1: 85.6448	acc@5: 92.5972	
2023-03-22 04:43:31,958 - INFO - Train: [102/120][600/3907]	eta 0:10:11 lr 0.00242366	time 0.1801 (0.1848)	loss 2.0452 (3.1311)	acc@1: 85.5992	acc@5: 94.0810	
2023-03-22 04:44:26,779 - INFO - Train: [102/120][900/3907]	eta 0:09:13 lr 0.00242366	time 0.1858 (0.1841)	loss 2.0785 (3.1922)	acc@1: 83.9458	acc@5: 93.9564	
2023-03-22 04:45:21,543 - INFO - Train: [102/120][1200/3907]	eta 0:08:17 lr 0.00242366	time 0.1861 (0.1837)	loss 4.9988 (3.1999)	acc@1: 32.1170	acc@5: 51.1736	
2023-03-22 04:46:16,210 - INFO - Train: [102/120][1500/3907]	eta 0:07:21 lr 0.00242366	time 0.1860 (0.1834)	loss 4.8365 (3.2300)	acc@1: 40.0424	acc@5: 56.9427	
2023-03-22 04:47:10,793 - INFO - Train: [102/120][1800/3907]	eta 0:06:25 lr 0.00242366	time 0.1823 (0.1832)	loss 5.0871 (3.2215)	acc@1: 35.7833	acc@5: 48.9891	
2023-03-22 04:48:05,250 - INFO - Train: [102/120][2100/3907]	eta 0:05:30 lr 0.00242366	time 0.1788 (0.1829)	loss 1.9172 (3.2224)	acc@1: 88.2771	acc@5: 95.3080	
2023-03-22 04:48:57,288 - INFO - Train: [102/120][2400/3907]	eta 0:04:33 lr 0.00242366	time 0.1705 (0.1817)	loss 2.4820 (3.2155)	acc@1: 82.4619	acc@5: 90.6722	
2023-03-22 04:49:49,408 - INFO - Train: [102/120][2700/3907]	eta 0:03:38 lr 0.00242366	time 0.1762 (0.1809)	loss 4.8828 (3.2203)	acc@1: 37.5979	acc@5: 53.3916	
2023-03-22 04:50:41,456 - INFO - Train: [102/120][3000/3907]	eta 0:02:43 lr 0.00242366	time 0.1782 (0.1801)	loss 4.7684 (3.2237)	acc@1: 41.6148	acc@5: 60.0384	
2023-03-22 04:51:33,638 - INFO - Train: [102/120][3300/3907]	eta 0:01:48 lr 0.00242366	time 0.1704 (0.1796)	loss 4.8747 (3.2294)	acc@1: 37.5854	acc@5: 55.4976	
2023-03-22 04:52:25,906 - INFO - Train: [102/120][3600/3907]	eta 0:00:54 lr 0.00242366	time 0.1819 (0.1791)	loss 2.8451 (3.2368)	acc@1: 79.9706	acc@5: 86.3340	
2023-03-22 04:53:18,108 - INFO - Train: [102/120][3900/3907]	eta 0:00:01 lr 0.00242366	time 0.1710 (0.1787)	loss 2.0577 (3.2369)	acc@1: 86.3184	acc@5: 95.5656	
2023-03-22 04:53:19,270 - INFO - EPOCH 102 training takes 0:11:38
2023-03-22 04:53:20,235 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Latest.pth saved !!!
2023-03-22 04:53:20,236 - INFO - **********Latest test***********
2023-03-22 04:53:20,236 - INFO - eval epoch 102
2023-03-22 04:53:20,821 - INFO - Test: [0/782]	Time 0.584 (0.584)	Loss 2.2591 (2.2591)	Acc@1 78.906 (78.906)	Acc@5 96.094 (96.094)
2023-03-22 04:55:16,593 - INFO - Test: [200/782]	Time 0.567 (0.579)	Loss 2.5333 (2.5463)	Acc@1 71.875 (73.527)	Acc@5 89.844 (90.104)
2023-03-22 04:57:11,983 - INFO - Test: [400/782]	Time 0.575 (0.578)	Loss 2.4083 (2.5194)	Acc@1 78.125 (74.176)	Acc@5 89.844 (90.528)
2023-03-22 04:59:08,748 - INFO - Test: [600/782]	Time 0.572 (0.580)	Loss 2.5455 (2.4906)	Acc@1 75.781 (74.875)	Acc@5 87.500 (90.875)
2023-03-22 05:00:52,129 - INFO -  * Acc@1 75.306 Acc@5 91.204
2023-03-22 05:00:52,129 - INFO - Max accuracy: 77.5810%
2023-03-22 05:00:52,129 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-22 05:00:54,139 - INFO - Train: [103/120][0/3907]	eta 2:10:38 lr 0.00217987	time 2.0063 (2.0063)	loss 1.9385 (1.9385)	acc@1: 87.9684	acc@5: 96.5312	
2023-03-22 05:01:48,723 - INFO - Train: [103/120][300/3907]	eta 0:11:18 lr 0.00217987	time 0.1867 (0.1880)	loss 4.6021 (3.1404)	acc@1: 46.2256	acc@5: 58.9615	
2023-03-22 05:02:43,407 - INFO - Train: [103/120][600/3907]	eta 0:10:12 lr 0.00217987	time 0.1847 (0.1851)	loss 4.4267 (3.1692)	acc@1: 53.6218	acc@5: 66.2903	
2023-03-22 05:03:37,978 - INFO - Train: [103/120][900/3907]	eta 0:09:13 lr 0.00217987	time 0.1796 (0.1841)	loss 4.9448 (3.1849)	acc@1: 37.9211	acc@5: 59.0600	
2023-03-22 05:04:32,613 - INFO - Train: [103/120][1200/3907]	eta 0:08:16 lr 0.00217987	time 0.1798 (0.1836)	loss 1.9932 (3.1760)	acc@1: 90.5779	acc@5: 95.2634	
2023-03-22 05:05:27,323 - INFO - Train: [103/120][1500/3907]	eta 0:07:21 lr 0.00217987	time 0.1799 (0.1833)	loss 2.6920 (3.1921)	acc@1: 76.7429	acc@5: 86.2444	
2023-03-22 05:06:22,164 - INFO - Train: [103/120][1800/3907]	eta 0:06:26 lr 0.00217987	time 0.1801 (0.1832)	loss 2.7339 (3.1739)	acc@1: 83.8803	acc@5: 87.4593	
2023-03-22 05:07:16,163 - INFO - Train: [103/120][2100/3907]	eta 0:05:30 lr 0.00217987	time 0.1763 (0.1828)	loss 1.9971 (3.1810)	acc@1: 86.6669	acc@5: 94.4747	
2023-03-22 05:08:08,093 - INFO - Train: [103/120][2400/3907]	eta 0:04:33 lr 0.00217987	time 0.1720 (0.1816)	loss 2.9354 (3.1831)	acc@1: 77.8049	acc@5: 85.5883	
2023-03-22 05:09:00,220 - INFO - Train: [103/120][2700/3907]	eta 0:03:38 lr 0.00217987	time 0.1709 (0.1807)	loss 2.4793 (3.1911)	acc@1: 87.1486	acc@5: 91.5402	
2023-03-22 05:09:52,210 - INFO - Train: [103/120][3000/3907]	eta 0:02:43 lr 0.00217987	time 0.1706 (0.1800)	loss 2.0124 (3.1937)	acc@1: 87.1788	acc@5: 94.9655	
2023-03-22 05:10:44,190 - INFO - Train: [103/120][3300/3907]	eta 0:01:48 lr 0.00217987	time 0.1717 (0.1794)	loss 3.3421 (3.2118)	acc@1: 69.8472	acc@5: 79.4040	
2023-03-22 05:11:36,155 - INFO - Train: [103/120][3600/3907]	eta 0:00:54 lr 0.00217987	time 0.1722 (0.1788)	loss 5.1621 (3.2066)	acc@1: 33.4089	acc@5: 49.4433	
2023-03-22 05:12:28,210 - INFO - Train: [103/120][3900/3907]	eta 0:00:01 lr 0.00217987	time 0.1733 (0.1784)	loss 2.0755 (3.2193)	acc@1: 86.5540	acc@5: 94.9797	
2023-03-22 05:12:29,360 - INFO - EPOCH 103 training takes 0:11:37
2023-03-22 05:12:30,469 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Latest.pth saved !!!
2023-03-22 05:12:30,470 - INFO - **********Latest test***********
2023-03-22 05:12:30,470 - INFO - eval epoch 103
2023-03-22 05:12:31,062 - INFO - Test: [0/782]	Time 0.591 (0.591)	Loss 2.2727 (2.2727)	Acc@1 78.125 (78.125)	Acc@5 94.531 (94.531)
2023-03-22 05:14:25,745 - INFO - Test: [200/782]	Time 0.567 (0.574)	Loss 2.4999 (2.5419)	Acc@1 70.312 (73.570)	Acc@5 89.844 (90.011)
2023-03-22 05:16:20,851 - INFO - Test: [400/782]	Time 0.578 (0.575)	Loss 2.4581 (2.5140)	Acc@1 76.562 (74.310)	Acc@5 91.406 (90.422)
2023-03-22 05:18:16,969 - INFO - Test: [600/782]	Time 0.561 (0.577)	Loss 2.5481 (2.4857)	Acc@1 74.219 (75.026)	Acc@5 89.844 (90.790)
2023-03-22 05:19:59,788 - INFO -  * Acc@1 75.439 Acc@5 91.150
2023-03-22 05:19:59,788 - INFO - Max accuracy: 77.5810%
2023-03-22 05:19:59,788 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-22 05:20:01,916 - INFO - Train: [104/120][0/3907]	eta 2:18:18 lr 0.00194829	time 2.1241 (2.1241)	loss 1.8551 (1.8551)	acc@1: 91.5127	acc@5: 96.9408	
2023-03-22 05:20:56,246 - INFO - Train: [104/120][300/3907]	eta 0:11:16 lr 0.00194829	time 0.1795 (0.1875)	loss 3.6722 (3.1365)	acc@1: 68.5201	acc@5: 74.1083	
2023-03-22 05:21:50,685 - INFO - Train: [104/120][600/3907]	eta 0:10:10 lr 0.00194829	time 0.1796 (0.1845)	loss 2.0296 (3.1534)	acc@1: 92.4614	acc@5: 95.4921	
2023-03-22 05:22:45,611 - INFO - Train: [104/120][900/3907]	eta 0:09:13 lr 0.00194829	time 0.1810 (0.1840)	loss 4.9622 (3.1683)	acc@1: 30.5216	acc@5: 49.6710	
2023-03-22 05:23:40,300 - INFO - Train: [104/120][1200/3907]	eta 0:08:17 lr 0.00194829	time 0.1822 (0.1836)	loss 2.0012 (3.1700)	acc@1: 87.4715	acc@5: 95.2815	
2023-03-22 05:24:35,082 - INFO - Train: [104/120][1500/3907]	eta 0:07:21 lr 0.00194829	time 0.1809 (0.1834)	loss 1.8041 (3.1501)	acc@1: 90.5991	acc@5: 98.4093	
2023-03-22 05:25:29,530 - INFO - Train: [104/120][1800/3907]	eta 0:06:25 lr 0.00194829	time 0.1876 (0.1831)	loss 3.4018 (3.1733)	acc@1: 70.3251	acc@5: 78.6399	
2023-03-22 05:26:24,377 - INFO - Train: [104/120][2100/3907]	eta 0:05:30 lr 0.00194829	time 0.1799 (0.1830)	loss 3.2623 (3.1664)	acc@1: 73.1169	acc@5: 81.3452	
2023-03-22 05:27:19,253 - INFO - Train: [104/120][2400/3907]	eta 0:04:35 lr 0.00194829	time 0.1817 (0.1830)	loss 2.1021 (3.1885)	acc@1: 84.9216	acc@5: 93.4914	
2023-03-22 05:28:14,090 - INFO - Train: [104/120][2700/3907]	eta 0:03:40 lr 0.00194829	time 0.1823 (0.1830)	loss 4.0267 (3.2130)	acc@1: 55.7857	acc@5: 71.6444	
2023-03-22 05:29:08,680 - INFO - Train: [104/120][3000/3907]	eta 0:02:45 lr 0.00194829	time 0.1800 (0.1829)	loss 2.0589 (3.2192)	acc@1: 87.8402	acc@5: 95.5454	
2023-03-22 05:30:01,719 - INFO - Train: [104/120][3300/3907]	eta 0:01:50 lr 0.00194829	time 0.1743 (0.1823)	loss 2.7738 (3.2169)	acc@1: 79.9275	acc@5: 87.0639	
2023-03-22 05:30:53,786 - INFO - Train: [104/120][3600/3907]	eta 0:00:55 lr 0.00194829	time 0.1710 (0.1816)	loss 4.9290 (3.2255)	acc@1: 33.0503	acc@5: 53.1333	
2023-03-22 05:31:45,826 - INFO - Train: [104/120][3900/3907]	eta 0:00:01 lr 0.00194829	time 0.1701 (0.1810)	loss 2.7953 (3.2399)	acc@1: 80.4487	acc@5: 88.9845	
2023-03-22 05:31:46,997 - INFO - EPOCH 104 training takes 0:11:47
2023-03-22 05:31:48,061 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Latest.pth saved !!!
2023-03-22 05:31:48,061 - INFO - **********Latest test***********
2023-03-22 05:31:48,061 - INFO - eval epoch 104
2023-03-22 05:31:48,644 - INFO - Test: [0/782]	Time 0.582 (0.582)	Loss 2.1586 (2.1586)	Acc@1 79.688 (79.688)	Acc@5 96.094 (96.094)
2023-03-22 05:33:43,933 - INFO - Test: [200/782]	Time 0.572 (0.576)	Loss 2.4224 (2.4873)	Acc@1 75.781 (74.359)	Acc@5 90.625 (90.454)
2023-03-22 05:35:39,183 - INFO - Test: [400/782]	Time 0.575 (0.576)	Loss 2.4057 (2.4614)	Acc@1 76.562 (75.023)	Acc@5 91.406 (90.867)
2023-03-22 05:37:35,350 - INFO - Test: [600/782]	Time 0.569 (0.578)	Loss 2.5163 (2.4298)	Acc@1 73.438 (75.835)	Acc@5 88.281 (91.296)
2023-03-22 05:39:18,399 - INFO -  * Acc@1 76.290 Acc@5 91.622
2023-03-22 05:39:18,399 - INFO - Max accuracy: 77.5810%
2023-03-22 05:39:19,457 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Best.pth saved !!!
2023-03-22 05:39:19,457 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-22 05:39:21,464 - INFO - Train: [105/120][0/3907]	eta 2:10:24 lr 0.00172909	time 2.0027 (2.0027)	loss 5.1345 (5.1345)	acc@1: 30.1359	acc@5: 50.0385	
2023-03-22 05:40:15,778 - INFO - Train: [105/120][300/3907]	eta 0:11:14 lr 0.00172909	time 0.1789 (0.1871)	loss 1.8379 (3.2654)	acc@1: 91.0161	acc@5: 94.9057	
2023-03-22 05:41:10,462 - INFO - Train: [105/120][600/3907]	eta 0:10:10 lr 0.00172909	time 0.1836 (0.1847)	loss 1.9692 (3.2284)	acc@1: 85.6654	acc@5: 95.0098	
2023-03-22 05:42:05,221 - INFO - Train: [105/120][900/3907]	eta 0:09:13 lr 0.00172909	time 0.1848 (0.1840)	loss 4.3731 (3.2431)	acc@1: 50.0905	acc@5: 64.1177	
2023-03-22 05:42:59,989 - INFO - Train: [105/120][1200/3907]	eta 0:08:17 lr 0.00172909	time 0.1801 (0.1836)	loss 2.9082 (3.2175)	acc@1: 77.7820	acc@5: 84.1633	
2023-03-22 05:43:54,666 - INFO - Train: [105/120][1500/3907]	eta 0:07:21 lr 0.00172909	time 0.1824 (0.1833)	loss 1.7329 (3.2142)	acc@1: 93.6319	acc@5: 99.8739	
2023-03-22 05:44:49,335 - INFO - Train: [105/120][1800/3907]	eta 0:06:25 lr 0.00172909	time 0.1799 (0.1832)	loss 1.8182 (3.2096)	acc@1: 92.7126	acc@5: 96.6080	
2023-03-22 05:45:44,320 - INFO - Train: [105/120][2100/3907]	eta 0:05:30 lr 0.00172909	time 0.1877 (0.1832)	loss 1.8989 (3.2072)	acc@1: 89.8276	acc@5: 97.6387	
2023-03-22 05:46:39,086 - INFO - Train: [105/120][2400/3907]	eta 0:04:35 lr 0.00172909	time 0.1807 (0.1831)	loss 1.8360 (3.2105)	acc@1: 89.7366	acc@5: 96.7595	
2023-03-22 05:47:32,539 - INFO - Train: [105/120][2700/3907]	eta 0:03:40 lr 0.00172909	time 0.1709 (0.1825)	loss 3.0023 (3.1965)	acc@1: 76.9088	acc@5: 86.4983	
2023-03-22 05:48:24,595 - INFO - Train: [105/120][3000/3907]	eta 0:02:44 lr 0.00172909	time 0.1757 (0.1816)	loss 5.0273 (3.2073)	acc@1: 31.1092	acc@5: 51.9113	
2023-03-22 05:49:16,652 - INFO - Train: [105/120][3300/3907]	eta 0:01:49 lr 0.00172909	time 0.1782 (0.1809)	loss 5.0512 (3.2011)	acc@1: 34.1499	acc@5: 49.7308	
2023-03-22 05:50:08,635 - INFO - Train: [105/120][3600/3907]	eta 0:00:55 lr 0.00172909	time 0.1706 (0.1803)	loss 2.0691 (3.2119)	acc@1: 88.4484	acc@5: 94.5457	
2023-03-22 05:51:00,700 - INFO - Train: [105/120][3900/3907]	eta 0:00:01 lr 0.00172909	time 0.1699 (0.1798)	loss 3.7869 (3.2177)	acc@1: 63.9950	acc@5: 72.2914	
2023-03-22 05:51:01,887 - INFO - EPOCH 105 training takes 0:11:42
2023-03-22 05:51:02,940 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Latest.pth saved !!!
2023-03-22 05:51:02,940 - INFO - **********Latest test***********
2023-03-22 05:51:02,940 - INFO - eval epoch 105
2023-03-22 05:51:03,544 - INFO - Test: [0/782]	Time 0.603 (0.603)	Loss 2.2185 (2.2185)	Acc@1 78.125 (78.125)	Acc@5 96.875 (96.875)
2023-03-22 05:52:59,961 - INFO - Test: [200/782]	Time 0.577 (0.582)	Loss 2.4443 (2.4975)	Acc@1 74.219 (74.300)	Acc@5 89.062 (90.271)
2023-03-22 05:54:56,335 - INFO - Test: [400/782]	Time 0.586 (0.582)	Loss 2.3750 (2.4714)	Acc@1 79.688 (74.945)	Acc@5 91.406 (90.769)
2023-03-22 05:56:53,556 - INFO - Test: [600/782]	Time 0.583 (0.583)	Loss 2.5807 (2.4398)	Acc@1 74.219 (75.721)	Acc@5 89.062 (91.210)
2023-03-22 05:58:37,903 - INFO -  * Acc@1 76.197 Acc@5 91.494
2023-03-22 05:58:37,904 - INFO - Max accuracy: 77.5810%
2023-03-22 05:58:37,904 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-22 05:58:40,054 - INFO - Train: [106/120][0/3907]	eta 2:19:45 lr 0.00152241	time 2.1462 (2.1462)	loss 2.8809 (2.8809)	acc@1: 81.6225	acc@5: 86.5480	
2023-03-22 05:59:34,769 - INFO - Train: [106/120][300/3907]	eta 0:11:21 lr 0.00152241	time 0.1794 (0.1889)	loss 2.3364 (3.1180)	acc@1: 84.3716	acc@5: 93.3201	
2023-03-22 06:00:29,867 - INFO - Train: [106/120][600/3907]	eta 0:10:16 lr 0.00152241	time 0.1831 (0.1863)	loss 2.4622 (3.1290)	acc@1: 82.8007	acc@5: 90.2504	
2023-03-22 06:01:24,866 - INFO - Train: [106/120][900/3907]	eta 0:09:17 lr 0.00152241	time 0.1800 (0.1853)	loss 2.5247 (3.1838)	acc@1: 84.1820	acc@5: 90.0803	
2023-03-22 06:02:19,771 - INFO - Train: [106/120][1200/3907]	eta 0:08:20 lr 0.00152241	time 0.1797 (0.1847)	loss 4.2992 (3.1822)	acc@1: 54.5034	acc@5: 66.4821	
2023-03-22 06:03:15,198 - INFO - Train: [106/120][1500/3907]	eta 0:07:24 lr 0.00152241	time 0.1897 (0.1847)	loss 2.5894 (3.1800)	acc@1: 81.4519	acc@5: 88.8566	
2023-03-22 06:04:11,884 - INFO - Train: [106/120][1800/3907]	eta 0:06:30 lr 0.00152241	time 0.2047 (0.1854)	loss 5.0153 (3.1669)	acc@1: 34.9211	acc@5: 50.9194	
2023-03-22 06:05:08,286 - INFO - Train: [106/120][2100/3907]	eta 0:05:35 lr 0.00152241	time 0.1907 (0.1858)	loss 2.1862 (3.1733)	acc@1: 86.8312	acc@5: 92.1150	
2023-03-22 06:06:03,785 - INFO - Train: [106/120][2400/3907]	eta 0:04:39 lr 0.00152241	time 0.1795 (0.1857)	loss 2.2094 (3.1784)	acc@1: 86.4927	acc@5: 94.8341	
2023-03-22 06:06:58,450 - INFO - Train: [106/120][2700/3907]	eta 0:03:43 lr 0.00152241	time 0.1792 (0.1853)	loss 4.7180 (3.1881)	acc@1: 47.1367	acc@5: 55.9811	
2023-03-22 06:07:53,263 - INFO - Train: [106/120][3000/3907]	eta 0:02:47 lr 0.00152241	time 0.1735 (0.1851)	loss 4.3400 (3.1765)	acc@1: 53.3943	acc@5: 63.5279	
2023-03-22 06:08:45,702 - INFO - Train: [106/120][3300/3907]	eta 0:01:51 lr 0.00152241	time 0.1711 (0.1841)	loss 1.8831 (3.1805)	acc@1: 92.9672	acc@5: 95.3109	
2023-03-22 06:09:38,813 - INFO - Train: [106/120][3600/3907]	eta 0:00:56 lr 0.00152241	time 0.1921 (0.1835)	loss 2.8139 (3.1896)	acc@1: 76.5528	acc@5: 87.2657	
2023-03-22 06:10:32,036 - INFO - Train: [106/120][3900/3907]	eta 0:00:01 lr 0.00152241	time 0.1740 (0.1831)	loss 3.9079 (3.1951)	acc@1: 64.0406	acc@5: 72.0035	
2023-03-22 06:10:33,228 - INFO - EPOCH 106 training takes 0:11:55
2023-03-22 06:10:34,297 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Latest.pth saved !!!
2023-03-22 06:10:34,298 - INFO - **********Latest test***********
2023-03-22 06:10:34,298 - INFO - eval epoch 106
2023-03-22 06:10:34,887 - INFO - Test: [0/782]	Time 0.588 (0.588)	Loss 2.1956 (2.1956)	Acc@1 77.344 (77.344)	Acc@5 96.875 (96.875)
2023-03-22 06:12:36,868 - INFO - Test: [200/782]	Time 0.594 (0.610)	Loss 2.4018 (2.4634)	Acc@1 71.875 (74.712)	Acc@5 91.406 (90.563)
2023-03-22 06:14:51,679 - INFO - Test: [400/782]	Time 0.596 (0.642)	Loss 2.3585 (2.4365)	Acc@1 77.344 (75.417)	Acc@5 90.625 (91.020)
2023-03-22 06:16:57,567 - INFO - Test: [600/782]	Time 0.588 (0.638)	Loss 2.5041 (2.4058)	Acc@1 76.562 (76.199)	Acc@5 90.625 (91.435)
2023-03-22 06:19:33,907 - INFO -  * Acc@1 76.631 Acc@5 91.734
2023-03-22 06:19:33,907 - INFO - Max accuracy: 77.5810%
2023-03-22 06:19:35,237 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Best.pth saved !!!
2023-03-22 06:19:35,239 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-22 06:19:38,621 - INFO - Train: [107/120][0/3907]	eta 3:39:27 lr 0.00132839	time 3.3701 (3.3701)	loss 4.6403 (4.6403)	acc@1: 47.4784	acc@5: 60.7854	
2023-03-22 06:20:38,544 - INFO - Train: [107/120][300/3907]	eta 0:12:38 lr 0.00132839	time 0.2011 (0.2103)	loss 3.0675 (3.1124)	acc@1: 77.1315	acc@5: 86.1037	
2023-03-22 06:21:38,545 - INFO - Train: [107/120][600/3907]	eta 0:11:18 lr 0.00132839	time 0.2076 (0.2051)	loss 3.3844 (3.1376)	acc@1: 71.7807	acc@5: 80.4508	
2023-03-22 06:22:38,162 - INFO - Train: [107/120][900/3907]	eta 0:10:10 lr 0.00132839	time 0.1954 (0.2030)	loss 4.2722 (3.1255)	acc@1: 53.1508	acc@5: 64.9362	
2023-03-22 06:23:37,951 - INFO - Train: [107/120][1200/3907]	eta 0:09:07 lr 0.00132839	time 0.1992 (0.2021)	loss 2.4162 (3.1482)	acc@1: 85.4262	acc@5: 89.8812	
2023-03-22 06:24:37,830 - INFO - Train: [107/120][1500/3907]	eta 0:08:05 lr 0.00132839	time 0.1916 (0.2016)	loss 4.8763 (3.1519)	acc@1: 39.9425	acc@5: 53.5526	
2023-03-22 06:25:37,484 - INFO - Train: [107/120][1800/3907]	eta 0:07:03 lr 0.00132839	time 0.1932 (0.2011)	loss 1.7681 (3.1481)	acc@1: 95.2444	acc@5: 98.3677	
2023-03-22 06:26:37,460 - INFO - Train: [107/120][2100/3907]	eta 0:06:03 lr 0.00132839	time 0.1903 (0.2009)	loss 4.7366 (3.1617)	acc@1: 42.9490	acc@5: 56.9129	
2023-03-22 06:27:37,460 - INFO - Train: [107/120][2400/3907]	eta 0:05:02 lr 0.00132839	time 0.1937 (0.2008)	loss 4.5821 (3.1544)	acc@1: 44.0089	acc@5: 64.0379	
2023-03-22 06:28:36,342 - INFO - Train: [107/120][2700/3907]	eta 0:04:01 lr 0.00132839	time 0.2023 (0.2003)	loss 4.0504 (3.1479)	acc@1: 61.1362	acc@5: 70.1440	
2023-03-22 06:29:31,431 - INFO - Train: [107/120][3000/3907]	eta 0:03:00 lr 0.00132839	time 0.1778 (0.1987)	loss 4.6587 (3.1523)	acc@1: 44.0343	acc@5: 60.5346	
2023-03-22 06:30:23,887 - INFO - Train: [107/120][3300/3907]	eta 0:01:59 lr 0.00132839	time 0.1732 (0.1965)	loss 5.0365 (3.1596)	acc@1: 30.4622	acc@5: 49.9978	
2023-03-22 06:31:16,457 - INFO - Train: [107/120][3600/3907]	eta 0:00:59 lr 0.00132839	time 0.1703 (0.1947)	loss 3.7462 (3.1682)	acc@1: 66.5317	acc@5: 73.8171	
2023-03-22 06:32:09,015 - INFO - Train: [107/120][3900/3907]	eta 0:00:01 lr 0.00132839	time 0.1717 (0.1932)	loss 1.8374 (3.1777)	acc@1: 91.3987	acc@5: 97.6481	
2023-03-22 06:32:10,246 - INFO - EPOCH 107 training takes 0:12:34
2023-03-22 06:32:11,339 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Latest.pth saved !!!
2023-03-22 06:32:11,339 - INFO - **********Latest test***********
2023-03-22 06:32:11,339 - INFO - eval epoch 107
2023-03-22 06:32:11,929 - INFO - Test: [0/782]	Time 0.589 (0.589)	Loss 2.1267 (2.1267)	Acc@1 80.469 (80.469)	Acc@5 96.875 (96.875)
2023-03-22 06:34:16,262 - INFO - Test: [200/782]	Time 0.825 (0.622)	Loss 2.4113 (2.4386)	Acc@1 71.094 (75.334)	Acc@5 91.406 (90.932)
2023-03-22 06:36:38,624 - INFO - Test: [400/782]	Time 0.886 (0.667)	Loss 2.3602 (2.4131)	Acc@1 78.125 (75.968)	Acc@5 90.625 (91.307)
2023-03-22 06:39:14,364 - INFO - Test: [600/782]	Time 0.735 (0.704)	Loss 2.4924 (2.3834)	Acc@1 74.219 (76.783)	Acc@5 90.625 (91.681)
2023-03-22 06:41:32,495 - INFO -  * Acc@1 77.171 Acc@5 91.968
2023-03-22 06:41:32,495 - INFO - Max accuracy: 77.5810%
2023-03-22 06:41:33,951 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Best.pth saved !!!
2023-03-22 06:41:33,951 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-22 06:41:37,059 - INFO - Train: [108/120][0/3907]	eta 3:22:10 lr 0.00114717	time 3.1047 (3.1047)	loss 3.7913 (3.7913)	acc@1: 66.3581	acc@5: 74.2697	
2023-03-22 06:42:34,620 - INFO - Train: [108/120][300/3907]	eta 0:12:06 lr 0.00114717	time 0.1906 (0.2015)	loss 1.9119 (3.1882)	acc@1: 94.1634	acc@5: 96.4753	
2023-03-22 06:43:32,524 - INFO - Train: [108/120][600/3907]	eta 0:10:52 lr 0.00114717	time 0.1893 (0.1973)	loss 1.9096 (3.1808)	acc@1: 88.0111	acc@5: 97.2745	
2023-03-22 06:44:29,850 - INFO - Train: [108/120][900/3907]	eta 0:09:47 lr 0.00114717	time 0.1929 (0.1952)	loss 4.0300 (3.2018)	acc@1: 58.6780	acc@5: 69.1287	
2023-03-22 06:45:28,967 - INFO - Train: [108/120][1200/3907]	eta 0:08:49 lr 0.00114717	time 0.2091 (0.1957)	loss 2.1144 (3.1704)	acc@1: 89.3116	acc@5: 94.6082	
2023-03-22 06:46:27,718 - INFO - Train: [108/120][1500/3907]	eta 0:07:51 lr 0.00114717	time 0.1881 (0.1957)	loss 4.2964 (3.1641)	acc@1: 50.5617	acc@5: 67.1245	
2023-03-22 06:47:25,983 - INFO - Train: [108/120][1800/3907]	eta 0:06:51 lr 0.00114717	time 0.1819 (0.1955)	loss 3.6510 (3.1595)	acc@1: 67.7739	acc@5: 78.1844	
2023-03-22 06:48:23,649 - INFO - Train: [108/120][2100/3907]	eta 0:05:52 lr 0.00114717	time 0.1802 (0.1950)	loss 3.9327 (3.1637)	acc@1: 58.8712	acc@5: 71.0678	
2023-03-22 06:49:18,331 - INFO - Train: [108/120][2400/3907]	eta 0:04:51 lr 0.00114717	time 0.1834 (0.1934)	loss 2.5400 (3.1689)	acc@1: 85.0402	acc@5: 89.4363	
2023-03-22 06:50:13,142 - INFO - Train: [108/120][2700/3907]	eta 0:03:51 lr 0.00114717	time 0.1761 (0.1922)	loss 2.6599 (3.1618)	acc@1: 79.1905	acc@5: 86.5230	
2023-03-22 06:51:07,628 - INFO - Train: [108/120][3000/3907]	eta 0:02:53 lr 0.00114717	time 0.1781 (0.1912)	loss 1.7812 (3.1563)	acc@1: 91.2676	acc@5: 98.2881	
2023-03-22 06:52:01,943 - INFO - Train: [108/120][3300/3907]	eta 0:01:55 lr 0.00114717	time 0.1831 (0.1902)	loss 4.6839 (3.1645)	acc@1: 42.9583	acc@5: 56.7018	
2023-03-22 06:52:56,646 - INFO - Train: [108/120][3600/3907]	eta 0:00:58 lr 0.00114717	time 0.1754 (0.1896)	loss 2.6410 (3.1641)	acc@1: 77.7996	acc@5: 88.9139	
2023-03-22 06:53:51,378 - INFO - Train: [108/120][3900/3907]	eta 0:00:01 lr 0.00114717	time 0.1735 (0.1890)	loss 5.4762 (3.1678)	acc@1: 25.9714	acc@5: 42.3505	
2023-03-22 06:53:52,757 - INFO - EPOCH 108 training takes 0:12:18
2023-03-22 06:53:54,157 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Latest.pth saved !!!
2023-03-22 06:53:54,158 - INFO - **********Latest test***********
2023-03-22 06:53:54,158 - INFO - eval epoch 108
2023-03-22 06:53:55,069 - INFO - Test: [0/782]	Time 0.909 (0.909)	Loss 2.2332 (2.2332)	Acc@1 80.469 (80.469)	Acc@5 96.094 (96.094)
2023-03-22 06:56:36,864 - INFO - Test: [200/782]	Time 0.719 (0.809)	Loss 2.4973 (2.5520)	Acc@1 71.875 (73.698)	Acc@5 90.625 (90.104)
2023-03-22 06:59:23,624 - INFO - Test: [400/782]	Time 0.775 (0.822)	Loss 2.4605 (2.5247)	Acc@1 78.125 (74.417)	Acc@5 89.844 (90.522)
2023-03-22 07:02:14,760 - INFO - Test: [600/782]	Time 0.889 (0.833)	Loss 2.5817 (2.4942)	Acc@1 76.562 (75.263)	Acc@5 86.719 (90.928)
2023-03-22 07:04:46,061 - INFO -  * Acc@1 75.662 Acc@5 91.257
2023-03-22 07:04:46,062 - INFO - Max accuracy: 77.5810%
2023-03-22 07:04:46,062 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-22 07:04:49,145 - INFO - Train: [109/120][0/3907]	eta 3:20:31 lr 0.00097887	time 3.0796 (3.0796)	loss 2.4996 (2.4996)	acc@1: 79.9299	acc@5: 90.4830	
2023-03-22 07:05:47,013 - INFO - Train: [109/120][300/3907]	eta 0:12:10 lr 0.00097887	time 0.1898 (0.2025)	loss 2.0784 (3.1722)	acc@1: 88.7829	acc@5: 91.1193	
2023-03-22 07:06:45,709 - INFO - Train: [109/120][600/3907]	eta 0:10:58 lr 0.00097887	time 0.1860 (0.1991)	loss 4.7633 (3.1838)	acc@1: 41.0335	acc@5: 55.5745	
2023-03-22 07:07:44,127 - INFO - Train: [109/120][900/3907]	eta 0:09:54 lr 0.00097887	time 0.1824 (0.1976)	loss 4.8477 (3.1905)	acc@1: 39.0803	acc@5: 55.0474	
2023-03-22 07:08:42,585 - INFO - Train: [109/120][1200/3907]	eta 0:08:53 lr 0.00097887	time 0.1815 (0.1969)	loss 4.1725 (3.1876)	acc@1: 52.7493	acc@5: 68.9189	
2023-03-22 07:09:41,037 - INFO - Train: [109/120][1500/3907]	eta 0:07:52 lr 0.00097887	time 0.1857 (0.1965)	loss 4.5855 (3.1614)	acc@1: 45.2913	acc@5: 60.1350	
2023-03-22 07:10:39,255 - INFO - Train: [109/120][1800/3907]	eta 0:06:53 lr 0.00097887	time 0.1881 (0.1961)	loss 2.2580 (3.1476)	acc@1: 87.6236	acc@5: 92.8984	
2023-03-22 07:11:37,845 - INFO - Train: [109/120][2100/3907]	eta 0:05:54 lr 0.00097887	time 0.2115 (0.1960)	loss 2.1246 (3.1425)	acc@1: 87.5516	acc@5: 93.6421	
2023-03-22 07:12:35,366 - INFO - Train: [109/120][2400/3907]	eta 0:04:54 lr 0.00097887	time 0.1777 (0.1955)	loss 2.5759 (3.1500)	acc@1: 85.5784	acc@5: 89.2022	
2023-03-22 07:13:30,373 - INFO - Train: [109/120][2700/3907]	eta 0:03:54 lr 0.00097887	time 0.1722 (0.1941)	loss 1.7811 (3.1484)	acc@1: 91.1194	acc@5: 97.3522	
2023-03-22 07:14:25,208 - INFO - Train: [109/120][3000/3907]	eta 0:02:55 lr 0.00097887	time 0.1824 (0.1930)	loss 4.4162 (3.1550)	acc@1: 46.1656	acc@5: 59.6155	
2023-03-22 07:15:20,186 - INFO - Train: [109/120][3300/3907]	eta 0:01:56 lr 0.00097887	time 0.1879 (0.1921)	loss 2.6788 (3.1553)	acc@1: 79.2602	acc@5: 87.9861	
2023-03-22 07:16:14,667 - INFO - Train: [109/120][3600/3907]	eta 0:00:58 lr 0.00097887	time 0.1863 (0.1912)	loss 4.4946 (3.1568)	acc@1: 50.3092	acc@5: 61.2467	
2023-03-22 07:17:09,779 - INFO - Train: [109/120][3900/3907]	eta 0:00:01 lr 0.00097887	time 0.1730 (0.1906)	loss 1.9275 (3.1568)	acc@1: 90.2754	acc@5: 96.5042	
2023-03-22 07:17:11,118 - INFO - EPOCH 109 training takes 0:12:25
2023-03-22 07:17:12,526 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Latest.pth saved !!!
2023-03-22 07:17:12,527 - INFO - **********Latest test***********
2023-03-22 07:17:12,527 - INFO - eval epoch 109
2023-03-22 07:17:13,454 - INFO - Test: [0/782]	Time 0.925 (0.925)	Loss 2.2363 (2.2363)	Acc@1 81.250 (81.250)	Acc@5 96.875 (96.875)
2023-03-22 07:20:02,264 - INFO - Test: [200/782]	Time 0.886 (0.844)	Loss 2.4964 (2.5292)	Acc@1 71.094 (74.238)	Acc@5 89.062 (90.454)
2023-03-22 07:22:50,779 - INFO - Test: [400/782]	Time 0.786 (0.844)	Loss 2.4324 (2.5025)	Acc@1 80.469 (75.094)	Acc@5 89.844 (90.781)
2023-03-22 07:25:38,057 - INFO - Test: [600/782]	Time 0.908 (0.841)	Loss 2.5392 (2.4721)	Acc@1 75.000 (75.833)	Acc@5 88.281 (91.146)
2023-03-22 07:28:02,807 - INFO -  * Acc@1 76.268 Acc@5 91.480
2023-03-22 07:28:02,808 - INFO - Max accuracy: 77.5810%
2023-03-22 07:28:02,808 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-22 07:28:05,622 - INFO - Train: [110/120][0/3907]	eta 3:02:55 lr 0.00082361	time 2.8091 (2.8091)	loss 2.5438 (2.5438)	acc@1: 80.0263	acc@5: 88.9974	
2023-03-22 07:29:04,029 - INFO - Train: [110/120][300/3907]	eta 0:12:13 lr 0.00082361	time 0.1931 (0.2034)	loss 3.7666 (3.0676)	acc@1: 65.2283	acc@5: 75.1407	
2023-03-22 07:30:02,850 - INFO - Train: [110/120][600/3907]	eta 0:11:00 lr 0.00082361	time 0.1912 (0.1997)	loss 2.5090 (3.0878)	acc@1: 86.0209	acc@5: 89.6910	
2023-03-22 07:31:01,766 - INFO - Train: [110/120][900/3907]	eta 0:09:57 lr 0.00082361	time 0.2061 (0.1986)	loss 2.3880 (3.0848)	acc@1: 84.3767	acc@5: 88.8531	
2023-03-22 07:32:00,683 - INFO - Train: [110/120][1200/3907]	eta 0:08:56 lr 0.00082361	time 0.2041 (0.1981)	loss 4.6980 (3.0957)	acc@1: 37.0055	acc@5: 56.2926	
2023-03-22 07:32:59,675 - INFO - Train: [110/120][1500/3907]	eta 0:07:56 lr 0.00082361	time 0.2114 (0.1978)	loss 4.7594 (3.0959)	acc@1: 41.7149	acc@5: 59.2010	
2023-03-22 07:33:58,728 - INFO - Train: [110/120][1800/3907]	eta 0:06:56 lr 0.00082361	time 0.2128 (0.1976)	loss 4.6066 (3.1172)	acc@1: 45.4387	acc@5: 62.0013	
2023-03-22 07:34:57,743 - INFO - Train: [110/120][2100/3907]	eta 0:05:56 lr 0.00082361	time 0.1874 (0.1975)	loss 2.3830 (3.1336)	acc@1: 85.1463	acc@5: 91.8479	
2023-03-22 07:35:56,405 - INFO - Train: [110/120][2400/3907]	eta 0:04:57 lr 0.00082361	time 0.1879 (0.1972)	loss 1.9229 (3.1502)	acc@1: 93.2035	acc@5: 97.0549	
2023-03-22 07:36:51,560 - INFO - Train: [110/120][2700/3907]	eta 0:03:56 lr 0.00082361	time 0.1815 (0.1958)	loss 1.9624 (3.1548)	acc@1: 87.8811	acc@5: 96.4355	
2023-03-22 07:37:46,501 - INFO - Train: [110/120][3000/3907]	eta 0:02:56 lr 0.00082361	time 0.1764 (0.1945)	loss 2.1315 (3.1647)	acc@1: 83.1074	acc@5: 95.4297	
2023-03-22 07:38:41,174 - INFO - Train: [110/120][3300/3907]	eta 0:01:57 lr 0.00082361	time 0.1827 (0.1934)	loss 3.1937 (3.1667)	acc@1: 71.9522	acc@5: 80.9349	
2023-03-22 07:39:35,744 - INFO - Train: [110/120][3600/3907]	eta 0:00:59 lr 0.00082361	time 0.1937 (0.1924)	loss 2.3381 (3.1640)	acc@1: 83.2394	acc@5: 90.0438	
2023-03-22 07:40:30,388 - INFO - Train: [110/120][3900/3907]	eta 0:00:01 lr 0.00082361	time 0.1765 (0.1916)	loss 4.4854 (3.1679)	acc@1: 49.0315	acc@5: 64.7072	
2023-03-22 07:40:31,774 - INFO - EPOCH 110 training takes 0:12:28
2023-03-22 07:40:33,221 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Latest.pth saved !!!
2023-03-22 07:40:33,222 - INFO - **********Latest test***********
2023-03-22 07:40:33,222 - INFO - eval epoch 110
2023-03-22 07:40:34,004 - INFO - Test: [0/782]	Time 0.781 (0.781)	Loss 2.1600 (2.1600)	Acc@1 78.906 (78.906)	Acc@5 96.094 (96.094)
2023-03-22 07:43:21,692 - INFO - Test: [200/782]	Time 0.892 (0.838)	Loss 2.4236 (2.4727)	Acc@1 71.094 (75.237)	Acc@5 90.625 (90.757)
2023-03-22 07:46:08,143 - INFO - Test: [400/782]	Time 0.728 (0.835)	Loss 2.3657 (2.4485)	Acc@1 78.125 (75.807)	Acc@5 92.969 (91.137)
2023-03-22 07:48:54,240 - INFO - Test: [600/782]	Time 0.881 (0.834)	Loss 2.5019 (2.4174)	Acc@1 75.000 (76.581)	Acc@5 89.844 (91.592)
2023-03-22 07:51:27,235 - INFO -  * Acc@1 77.005 Acc@5 91.899
2023-03-22 07:51:27,235 - INFO - Max accuracy: 77.5810%
2023-03-22 07:51:27,235 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-22 07:51:30,121 - INFO - Train: [111/120][0/3907]	eta 3:07:35 lr 0.00068148	time 2.8808 (2.8808)	loss 1.8868 (1.8868)	acc@1: 88.8689	acc@5: 95.1053	
2023-03-22 07:52:28,659 - INFO - Train: [111/120][300/3907]	eta 0:12:15 lr 0.00068148	time 0.2103 (0.2040)	loss 2.1701 (3.1633)	acc@1: 88.5811	acc@5: 94.5845	
2023-03-22 07:53:27,722 - INFO - Train: [111/120][600/3907]	eta 0:11:02 lr 0.00068148	time 0.2004 (0.2005)	loss 4.8559 (3.0697)	acc@1: 33.9498	acc@5: 56.4489	
2023-03-22 07:54:26,653 - INFO - Train: [111/120][900/3907]	eta 0:09:58 lr 0.00068148	time 0.2056 (0.1991)	loss 2.4788 (3.0961)	acc@1: 84.3390	acc@5: 90.2450	
2023-03-22 07:55:25,638 - INFO - Train: [111/120][1200/3907]	eta 0:08:57 lr 0.00068148	time 0.1953 (0.1985)	loss 3.2890 (3.1109)	acc@1: 72.3201	acc@5: 77.4919	
2023-03-22 07:56:24,770 - INFO - Train: [111/120][1500/3907]	eta 0:07:57 lr 0.00068148	time 0.2013 (0.1982)	loss 4.6881 (3.0894)	acc@1: 43.3637	acc@5: 60.0605	
2023-03-22 07:57:22,862 - INFO - Train: [111/120][1800/3907]	eta 0:06:56 lr 0.00068148	time 0.1838 (0.1974)	loss 4.0427 (3.1053)	acc@1: 58.1616	acc@5: 69.7796	
2023-03-22 07:58:21,299 - INFO - Train: [111/120][2100/3907]	eta 0:05:56 lr 0.00068148	time 0.1940 (0.1971)	loss 2.6980 (3.1086)	acc@1: 82.1556	acc@5: 87.1825	
2023-03-22 07:59:18,632 - INFO - Train: [111/120][2400/3907]	eta 0:04:55 lr 0.00068148	time 0.1780 (0.1963)	loss 2.2130 (3.1037)	acc@1: 89.3338	acc@5: 93.1491	
2023-03-22 08:00:13,384 - INFO - Train: [111/120][2700/3907]	eta 0:03:55 lr 0.00068148	time 0.1753 (0.1948)	loss 2.4512 (3.0964)	acc@1: 84.9342	acc@5: 90.0535	
2023-03-22 08:01:08,476 - INFO - Train: [111/120][3000/3907]	eta 0:02:55 lr 0.00068148	time 0.1808 (0.1937)	loss 3.5235 (3.1064)	acc@1: 70.0242	acc@5: 77.0037	
2023-03-22 08:02:03,342 - INFO - Train: [111/120][3300/3907]	eta 0:01:56 lr 0.00068148	time 0.1792 (0.1927)	loss 4.4114 (3.1098)	acc@1: 47.9627	acc@5: 65.1656	
2023-03-22 08:02:58,208 - INFO - Train: [111/120][3600/3907]	eta 0:00:58 lr 0.00068148	time 0.1804 (0.1919)	loss 3.0357 (3.1169)	acc@1: 80.0752	acc@5: 82.9250	
2023-03-22 08:03:53,168 - INFO - Train: [111/120][3900/3907]	eta 0:00:01 lr 0.00068148	time 0.1763 (0.1912)	loss 2.0263 (3.1293)	acc@1: 88.7326	acc@5: 94.1839	
2023-03-22 08:03:54,453 - INFO - EPOCH 111 training takes 0:12:27
2023-03-22 08:03:55,815 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Latest.pth saved !!!
2023-03-22 08:03:55,816 - INFO - **********Latest test***********
2023-03-22 08:03:55,816 - INFO - eval epoch 111
2023-03-22 08:03:56,605 - INFO - Test: [0/782]	Time 0.788 (0.788)	Loss 2.1597 (2.1597)	Acc@1 82.031 (82.031)	Acc@5 96.094 (96.094)
2023-03-22 08:06:48,823 - INFO - Test: [200/782]	Time 0.797 (0.861)	Loss 2.4186 (2.4528)	Acc@1 73.438 (75.381)	Acc@5 91.406 (90.955)
2023-03-22 08:09:34,168 - INFO - Test: [400/782]	Time 0.912 (0.844)	Loss 2.3397 (2.4275)	Acc@1 79.688 (76.011)	Acc@5 92.969 (91.358)
2023-03-22 08:12:30,265 - INFO - Test: [600/782]	Time 0.899 (0.856)	Loss 2.4791 (2.3971)	Acc@1 77.344 (76.695)	Acc@5 89.844 (91.759)
2023-03-22 08:15:06,477 - INFO -  * Acc@1 77.104 Acc@5 92.058
2023-03-22 08:15:06,477 - INFO - Max accuracy: 77.5810%
2023-03-22 08:15:06,477 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-22 08:15:09,188 - INFO - Train: [112/120][0/3907]	eta 2:56:15 lr 0.00055260	time 2.7067 (2.7067)	loss 2.4414 (2.4414)	acc@1: 85.7819	acc@5: 90.9112	
2023-03-22 08:16:08,134 - INFO - Train: [112/120][300/3907]	eta 0:12:18 lr 0.00055260	time 0.1903 (0.2048)	loss 1.9717 (3.0437)	acc@1: 86.7107	acc@5: 96.0848	
2023-03-22 08:17:07,259 - INFO - Train: [112/120][600/3907]	eta 0:11:04 lr 0.00055260	time 0.1922 (0.2010)	loss 2.0163 (3.1322)	acc@1: 90.5374	acc@5: 95.1803	
2023-03-22 08:18:05,860 - INFO - Train: [112/120][900/3907]	eta 0:09:58 lr 0.00055260	time 0.1883 (0.1991)	loss 2.9386 (3.1357)	acc@1: 80.0313	acc@5: 85.1078	
2023-03-22 08:19:04,554 - INFO - Train: [112/120][1200/3907]	eta 0:08:56 lr 0.00055260	time 0.1979 (0.1982)	loss 4.8258 (3.1033)	acc@1: 32.1224	acc@5: 57.1224	
2023-03-22 08:20:03,829 - INFO - Train: [112/120][1500/3907]	eta 0:07:56 lr 0.00055260	time 0.2145 (0.1981)	loss 2.2944 (3.1003)	acc@1: 86.5898	acc@5: 92.5591	
2023-03-22 08:21:02,934 - INFO - Train: [112/120][1800/3907]	eta 0:06:56 lr 0.00055260	time 0.1935 (0.1979)	loss 3.2237 (3.1272)	acc@1: 76.3379	acc@5: 80.0072	
2023-03-22 08:22:02,353 - INFO - Train: [112/120][2100/3907]	eta 0:05:57 lr 0.00055260	time 0.1926 (0.1979)	loss 3.3879 (3.1243)	acc@1: 72.3299	acc@5: 79.1437	
2023-03-22 08:23:01,656 - INFO - Train: [112/120][2400/3907]	eta 0:04:58 lr 0.00055260	time 0.1936 (0.1979)	loss 2.9787 (3.1166)	acc@1: 81.0392	acc@5: 85.8410	
2023-03-22 08:24:00,086 - INFO - Train: [112/120][2700/3907]	eta 0:03:58 lr 0.00055260	time 0.1756 (0.1976)	loss 3.0092 (3.1334)	acc@1: 76.8505	acc@5: 85.9302	
2023-03-22 08:24:55,058 - INFO - Train: [112/120][3000/3907]	eta 0:02:57 lr 0.00055260	time 0.1776 (0.1961)	loss 4.1256 (3.1379)	acc@1: 56.6414	acc@5: 68.8358	
2023-03-22 08:25:50,100 - INFO - Train: [112/120][3300/3907]	eta 0:01:58 lr 0.00055260	time 0.1836 (0.1950)	loss 4.7391 (3.1365)	acc@1: 40.8456	acc@5: 56.4527	
2023-03-22 08:26:45,088 - INFO - Train: [112/120][3600/3907]	eta 0:00:59 lr 0.00055260	time 0.1742 (0.1940)	loss 2.7653 (3.1362)	acc@1: 79.4740	acc@5: 85.9765	
2023-03-22 08:27:40,358 - INFO - Train: [112/120][3900/3907]	eta 0:00:01 lr 0.00055260	time 0.1746 (0.1932)	loss 3.7809 (3.1381)	acc@1: 65.2718	acc@5: 71.8686	
2023-03-22 08:27:41,650 - INFO - EPOCH 112 training takes 0:12:35
2023-03-22 08:27:42,986 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Latest.pth saved !!!
2023-03-22 08:27:42,987 - INFO - **********Latest test***********
2023-03-22 08:27:42,987 - INFO - eval epoch 112
2023-03-22 08:27:43,902 - INFO - Test: [0/782]	Time 0.914 (0.914)	Loss 2.1632 (2.1632)	Acc@1 80.469 (80.469)	Acc@5 96.875 (96.875)
2023-03-22 08:30:33,191 - INFO - Test: [200/782]	Time 0.752 (0.847)	Loss 2.4204 (2.4530)	Acc@1 72.656 (75.544)	Acc@5 89.062 (91.014)
2023-03-22 08:33:25,460 - INFO - Test: [400/782]	Time 0.940 (0.854)	Loss 2.3508 (2.4273)	Acc@1 80.469 (76.276)	Acc@5 92.969 (91.412)
2023-03-22 08:36:20,816 - INFO - Test: [600/782]	Time 0.728 (0.862)	Loss 2.4600 (2.3972)	Acc@1 77.344 (77.038)	Acc@5 89.844 (91.790)
2023-03-22 08:38:51,583 - INFO -  * Acc@1 77.415 Acc@5 92.088
2023-03-22 08:38:51,583 - INFO - Max accuracy: 77.5810%
2023-03-22 08:38:53,274 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Best.pth saved !!!
2023-03-22 08:38:53,275 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-22 08:38:56,259 - INFO - Train: [113/120][0/3907]	eta 3:14:02 lr 0.00043705	time 2.9799 (2.9799)	loss 1.8821 (1.8821)	acc@1: 91.3655	acc@5: 96.0509	
2023-03-22 08:39:55,847 - INFO - Train: [113/120][300/3907]	eta 0:12:29 lr 0.00043705	time 0.1915 (0.2079)	loss 1.8833 (3.0157)	acc@1: 89.6083	acc@5: 95.8416	
2023-03-22 08:40:55,057 - INFO - Train: [113/120][600/3907]	eta 0:11:10 lr 0.00043705	time 0.1905 (0.2026)	loss 3.8093 (3.0635)	acc@1: 65.4205	acc@5: 73.0542	
2023-03-22 08:41:53,950 - INFO - Train: [113/120][900/3907]	eta 0:10:02 lr 0.00043705	time 0.1943 (0.2005)	loss 2.4970 (3.0646)	acc@1: 85.6373	acc@5: 89.2970	
2023-03-22 08:42:53,167 - INFO - Train: [113/120][1200/3907]	eta 0:09:00 lr 0.00043705	time 0.1921 (0.1997)	loss 3.8904 (3.0884)	acc@1: 64.5637	acc@5: 71.8888	
2023-03-22 08:43:52,040 - INFO - Train: [113/120][1500/3907]	eta 0:07:59 lr 0.00043705	time 0.2030 (0.1990)	loss 3.2062 (3.0987)	acc@1: 73.4947	acc@5: 82.7491	
2023-03-22 08:44:50,960 - INFO - Train: [113/120][1800/3907]	eta 0:06:58 lr 0.00043705	time 0.1934 (0.1986)	loss 4.5608 (3.0957)	acc@1: 41.5379	acc@5: 60.4367	
2023-03-22 08:45:49,847 - INFO - Train: [113/120][2100/3907]	eta 0:05:58 lr 0.00043705	time 0.1894 (0.1983)	loss 2.2860 (3.0933)	acc@1: 85.9274	acc@5: 92.7711	
2023-03-22 08:46:48,790 - INFO - Train: [113/120][2400/3907]	eta 0:04:58 lr 0.00043705	time 0.1814 (0.1980)	loss 4.8706 (3.0993)	acc@1: 34.7274	acc@5: 52.4117	
2023-03-22 08:47:47,774 - INFO - Train: [113/120][2700/3907]	eta 0:03:58 lr 0.00043705	time 0.1876 (0.1979)	loss 4.8476 (3.0997)	acc@1: 34.5113	acc@5: 52.8289	
2023-03-22 08:48:46,845 - INFO - Train: [113/120][3000/3907]	eta 0:02:59 lr 0.00043705	time 0.2076 (0.1978)	loss 3.6335 (3.1067)	acc@1: 68.5444	acc@5: 75.4341	
2023-03-22 08:49:45,041 - INFO - Train: [113/120][3300/3907]	eta 0:01:59 lr 0.00043705	time 0.1964 (0.1974)	loss 3.3547 (3.0950)	acc@1: 70.0794	acc@5: 80.0743	
2023-03-22 08:50:42,059 - INFO - Train: [113/120][3600/3907]	eta 0:01:00 lr 0.00043705	time 0.1790 (0.1968)	loss 4.0499 (3.1127)	acc@1: 59.7801	acc@5: 74.0428	
2023-03-22 08:51:36,973 - INFO - Train: [113/120][3900/3907]	eta 0:00:01 lr 0.00043705	time 0.1831 (0.1958)	loss 1.8322 (3.1205)	acc@1: 93.4819	acc@5: 98.8894	
2023-03-22 08:51:38,373 - INFO - EPOCH 113 training takes 0:12:45
2023-03-22 08:51:39,752 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Latest.pth saved !!!
2023-03-22 08:51:39,753 - INFO - **********Latest test***********
2023-03-22 08:51:39,753 - INFO - eval epoch 113
2023-03-22 08:51:40,674 - INFO - Test: [0/782]	Time 0.919 (0.919)	Loss 2.1512 (2.1512)	Acc@1 79.688 (79.688)	Acc@5 96.875 (96.875)
2023-03-22 08:54:37,190 - INFO - Test: [200/782]	Time 0.881 (0.883)	Loss 2.3823 (2.4393)	Acc@1 73.438 (75.595)	Acc@5 91.406 (91.115)
2023-03-22 08:57:32,075 - INFO - Test: [400/782]	Time 0.916 (0.879)	Loss 2.3288 (2.4146)	Acc@1 78.906 (76.292)	Acc@5 92.188 (91.478)
2023-03-22 09:00:23,163 - INFO - Test: [600/782]	Time 0.836 (0.871)	Loss 2.4811 (2.3835)	Acc@1 74.219 (77.088)	Acc@5 89.844 (91.874)
2023-03-22 09:03:02,255 - INFO -  * Acc@1 77.509 Acc@5 92.174
2023-03-22 09:03:02,255 - INFO - Max accuracy: 77.5810%
2023-03-22 09:03:03,821 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Best.pth saved !!!
2023-03-22 09:03:03,821 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-22 09:03:06,628 - INFO - Train: [114/120][0/3907]	eta 3:02:27 lr 0.00033490	time 2.8021 (2.8021)	loss 2.3557 (2.3557)	acc@1: 86.1654	acc@5: 93.5901	
2023-03-22 09:04:05,419 - INFO - Train: [114/120][300/3907]	eta 0:12:18 lr 0.00033490	time 0.1944 (0.2046)	loss 3.0516 (3.1837)	acc@1: 77.8674	acc@5: 82.9675	
2023-03-22 09:05:04,800 - INFO - Train: [114/120][600/3907]	eta 0:11:05 lr 0.00033490	time 0.1830 (0.2013)	loss 4.6181 (3.1412)	acc@1: 44.2318	acc@5: 59.5514	
2023-03-22 09:06:04,156 - INFO - Train: [114/120][900/3907]	eta 0:10:01 lr 0.00033490	time 0.2088 (0.2001)	loss 2.2127 (3.0927)	acc@1: 83.4423	acc@5: 92.6269	
2023-03-22 09:07:03,264 - INFO - Train: [114/120][1200/3907]	eta 0:08:59 lr 0.00033490	time 0.1891 (0.1994)	loss 3.8303 (3.1319)	acc@1: 63.9788	acc@5: 72.6136	
2023-03-22 09:08:02,655 - INFO - Train: [114/120][1500/3907]	eta 0:07:59 lr 0.00033490	time 0.1862 (0.1991)	loss 2.1076 (3.1323)	acc@1: 87.7241	acc@5: 95.3506	
2023-03-22 09:09:01,964 - INFO - Train: [114/120][1800/3907]	eta 0:06:58 lr 0.00033490	time 0.2078 (0.1988)	loss 3.2005 (3.1306)	acc@1: 75.7766	acc@5: 81.4439	
2023-03-22 09:10:01,639 - INFO - Train: [114/120][2100/3907]	eta 0:05:59 lr 0.00033490	time 0.2051 (0.1989)	loss 4.7408 (3.1292)	acc@1: 38.4346	acc@5: 59.6709	
2023-03-22 09:11:00,259 - INFO - Train: [114/120][2400/3907]	eta 0:04:59 lr 0.00033490	time 0.1901 (0.1984)	loss 1.7804 (3.1214)	acc@1: 92.0808	acc@5: 98.3234	
2023-03-22 09:12:00,048 - INFO - Train: [114/120][2700/3907]	eta 0:03:59 lr 0.00033490	time 0.1848 (0.1985)	loss 1.6714 (3.1328)	acc@1: 92.9687	acc@5: 96.8750	
2023-03-22 09:12:59,560 - INFO - Train: [114/120][3000/3907]	eta 0:03:00 lr 0.00033490	time 0.1897 (0.1985)	loss 2.4471 (3.1249)	acc@1: 86.1279	acc@5: 91.2372	
2023-03-22 09:13:59,242 - INFO - Train: [114/120][3300/3907]	eta 0:02:00 lr 0.00033490	time 0.1847 (0.1985)	loss 2.2480 (3.1157)	acc@1: 89.3383	acc@5: 93.8404	
2023-03-22 09:14:58,864 - INFO - Train: [114/120][3600/3907]	eta 0:01:00 lr 0.00033490	time 0.1969 (0.1986)	loss 4.1424 (3.1159)	acc@1: 56.7902	acc@5: 69.1516	
2023-03-22 09:15:58,183 - INFO - Train: [114/120][3900/3907]	eta 0:00:01 lr 0.00033490	time 0.1883 (0.1985)	loss 2.3187 (3.1180)	acc@1: 86.1108	acc@5: 92.8499	
2023-03-22 09:15:59,568 - INFO - EPOCH 114 training takes 0:12:55
2023-03-22 09:16:01,074 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Latest.pth saved !!!
2023-03-22 09:16:01,074 - INFO - **********Latest test***********
2023-03-22 09:16:01,074 - INFO - eval epoch 114
2023-03-22 09:16:02,124 - INFO - Test: [0/782]	Time 1.048 (1.048)	Loss 2.1714 (2.1714)	Acc@1 79.688 (79.688)	Acc@5 96.094 (96.094)
2023-03-22 09:18:54,063 - INFO - Test: [200/782]	Time 0.839 (0.861)	Loss 2.3838 (2.4403)	Acc@1 75.000 (75.680)	Acc@5 91.406 (91.115)
2023-03-22 09:21:45,044 - INFO - Test: [400/782]	Time 0.873 (0.858)	Loss 2.3404 (2.4153)	Acc@1 79.688 (76.352)	Acc@5 92.188 (91.508)
2023-03-22 09:24:39,606 - INFO - Test: [600/782]	Time 0.920 (0.863)	Loss 2.4839 (2.3857)	Acc@1 77.344 (77.147)	Acc@5 89.844 (91.886)
2023-03-22 09:27:14,593 - INFO -  * Acc@1 77.550 Acc@5 92.164
2023-03-22 09:27:14,594 - INFO - Max accuracy: 77.5810%
2023-03-22 09:27:16,057 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Best.pth saved !!!
2023-03-22 09:27:16,058 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-22 09:27:18,927 - INFO - Train: [115/120][0/3907]	eta 3:06:27 lr 0.00024623	time 2.8633 (2.8633)	loss 4.9541 (4.9541)	acc@1: 35.7880	acc@5: 51.0443	
2023-03-22 09:28:18,044 - INFO - Train: [115/120][300/3907]	eta 0:12:22 lr 0.00024623	time 0.1929 (0.2059)	loss 1.9445 (3.1646)	acc@1: 89.9879	acc@5: 96.9091	
2023-03-22 09:29:17,724 - INFO - Train: [115/120][600/3907]	eta 0:11:09 lr 0.00024623	time 0.1952 (0.2024)	loss 2.9159 (3.1273)	acc@1: 79.6531	acc@5: 83.8975	
2023-03-22 09:30:17,761 - INFO - Train: [115/120][900/3907]	eta 0:10:06 lr 0.00024623	time 0.2219 (0.2017)	loss 3.6641 (3.1481)	acc@1: 66.1124	acc@5: 73.9954	
2023-03-22 09:31:17,558 - INFO - Train: [115/120][1200/3907]	eta 0:09:04 lr 0.00024623	time 0.1920 (0.2011)	loss 5.1958 (3.1569)	acc@1: 27.8257	acc@5: 47.8389	
2023-03-22 09:32:16,058 - INFO - Train: [115/120][1500/3907]	eta 0:08:01 lr 0.00024623	time 0.1931 (0.1999)	loss 2.8135 (3.1508)	acc@1: 82.1970	acc@5: 85.7801	
2023-03-22 09:33:15,856 - INFO - Train: [115/120][1800/3907]	eta 0:07:00 lr 0.00024623	time 0.1894 (0.1998)	loss 1.8464 (3.1498)	acc@1: 90.6233	acc@5: 97.6545	
2023-03-22 09:34:15,848 - INFO - Train: [115/120][2100/3907]	eta 0:06:01 lr 0.00024623	time 0.1951 (0.1998)	loss 2.1361 (3.1435)	acc@1: 86.5417	acc@5: 94.9646	
2023-03-22 09:35:15,769 - INFO - Train: [115/120][2400/3907]	eta 0:05:01 lr 0.00024623	time 0.2171 (0.1998)	loss 1.9870 (3.1368)	acc@1: 89.8324	acc@5: 93.7045	
2023-03-22 09:36:15,656 - INFO - Train: [115/120][2700/3907]	eta 0:04:01 lr 0.00024623	time 0.1940 (0.1998)	loss 1.9324 (3.1297)	acc@1: 90.5379	acc@5: 92.8793	
2023-03-22 09:37:15,678 - INFO - Train: [115/120][3000/3907]	eta 0:03:01 lr 0.00024623	time 0.2153 (0.1998)	loss 1.8791 (3.1227)	acc@1: 90.8086	acc@5: 96.2416	
2023-03-22 09:38:15,441 - INFO - Train: [115/120][3300/3907]	eta 0:02:01 lr 0.00024623	time 0.1939 (0.1997)	loss 3.3705 (3.1142)	acc@1: 75.6419	acc@5: 80.3294	
2023-03-22 09:39:15,347 - INFO - Train: [115/120][3600/3907]	eta 0:01:01 lr 0.00024623	time 0.1911 (0.1997)	loss 4.5627 (3.1200)	acc@1: 47.7187	acc@5: 60.7445	
2023-03-22 09:40:15,249 - INFO - Train: [115/120][3900/3907]	eta 0:00:01 lr 0.00024623	time 0.1918 (0.1997)	loss 3.3174 (3.1213)	acc@1: 74.5377	acc@5: 79.9981	
2023-03-22 09:40:16,697 - INFO - EPOCH 115 training takes 0:13:00
2023-03-22 09:40:18,208 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Latest.pth saved !!!
2023-03-22 09:40:18,210 - INFO - **********Latest test***********
2023-03-22 09:40:18,210 - INFO - eval epoch 115
2023-03-22 09:40:19,124 - INFO - Test: [0/782]	Time 0.912 (0.912)	Loss 2.2346 (2.2346)	Acc@1 80.469 (80.469)	Acc@5 96.094 (96.094)
2023-03-22 09:43:13,510 - INFO - Test: [200/782]	Time 0.916 (0.872)	Loss 2.4425 (2.5035)	Acc@1 73.438 (74.992)	Acc@5 91.406 (90.734)
2023-03-22 09:46:12,366 - INFO - Test: [400/782]	Time 0.906 (0.883)	Loss 2.3963 (2.4786)	Acc@1 77.344 (75.727)	Acc@5 92.188 (91.095)
2023-03-22 09:49:12,728 - INFO - Test: [600/782]	Time 0.878 (0.889)	Loss 2.5340 (2.4485)	Acc@1 74.219 (76.526)	Acc@5 89.062 (91.505)
2023-03-22 09:51:51,995 - INFO -  * Acc@1 76.899 Acc@5 91.819
2023-03-22 09:51:51,996 - INFO - Max accuracy: 77.5810%
2023-03-22 09:51:51,996 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-22 09:51:54,928 - INFO - Train: [116/120][0/3907]	eta 3:10:39 lr 0.00017110	time 2.9279 (2.9279)	loss 3.0794 (3.0794)	acc@1: 75.8361	acc@5: 82.8221	
2023-03-22 09:52:54,334 - INFO - Train: [116/120][300/3907]	eta 0:12:26 lr 0.00017110	time 0.1895 (0.2071)	loss 1.8961 (3.0420)	acc@1: 90.0211	acc@5: 96.2291	
2023-03-22 09:53:52,959 - INFO - Train: [116/120][600/3907]	eta 0:11:05 lr 0.00017110	time 0.2120 (0.2013)	loss 1.9195 (3.0750)	acc@1: 91.0060	acc@5: 96.4540	
2023-03-22 09:54:52,762 - INFO - Train: [116/120][900/3907]	eta 0:10:03 lr 0.00017110	time 0.1912 (0.2006)	loss 2.7261 (3.1078)	acc@1: 79.7394	acc@5: 85.5345	
2023-03-22 09:55:52,745 - INFO - Train: [116/120][1200/3907]	eta 0:09:02 lr 0.00017110	time 0.1909 (0.2004)	loss 3.0096 (3.1080)	acc@1: 77.6182	acc@5: 83.3388	
2023-03-22 09:56:52,424 - INFO - Train: [116/120][1500/3907]	eta 0:08:01 lr 0.00017110	time 0.1921 (0.2001)	loss 3.6938 (3.0855)	acc@1: 69.1930	acc@5: 76.0484	
2023-03-22 09:57:52,472 - INFO - Train: [116/120][1800/3907]	eta 0:07:01 lr 0.00017110	time 0.2233 (0.2001)	loss 2.8392 (3.0725)	acc@1: 79.8911	acc@5: 87.0600	
2023-03-22 09:58:52,350 - INFO - Train: [116/120][2100/3907]	eta 0:06:01 lr 0.00017110	time 0.1965 (0.2001)	loss 2.4086 (3.0738)	acc@1: 87.3878	acc@5: 91.7545	
2023-03-22 09:59:52,163 - INFO - Train: [116/120][2400/3907]	eta 0:05:01 lr 0.00017110	time 0.1995 (0.2000)	loss 4.5024 (3.0719)	acc@1: 44.9967	acc@5: 59.1423	
2023-03-22 10:00:52,151 - INFO - Train: [116/120][2700/3907]	eta 0:04:01 lr 0.00017110	time 0.1980 (0.2000)	loss 2.0300 (3.0739)	acc@1: 86.6246	acc@5: 92.8677	
2023-03-22 10:01:51,771 - INFO - Train: [116/120][3000/3907]	eta 0:03:01 lr 0.00017110	time 0.2147 (0.1998)	loss 2.5717 (3.0672)	acc@1: 81.4543	acc@5: 90.2302	
2023-03-22 10:02:51,282 - INFO - Train: [116/120][3300/3907]	eta 0:02:01 lr 0.00017110	time 0.2118 (0.1997)	loss 4.8566 (3.0842)	acc@1: 38.6914	acc@5: 56.5184	
2023-03-22 10:03:50,882 - INFO - Train: [116/120][3600/3907]	eta 0:01:01 lr 0.00017110	time 0.1808 (0.1996)	loss 4.7820 (3.0851)	acc@1: 35.9770	acc@5: 54.3166	
2023-03-22 10:04:49,566 - INFO - Train: [116/120][3900/3907]	eta 0:00:01 lr 0.00017110	time 0.1873 (0.1993)	loss 3.0001 (3.0852)	acc@1: 77.7547	acc@5: 86.0386	
2023-03-22 10:04:50,999 - INFO - EPOCH 116 training takes 0:12:58
2023-03-22 10:04:52,629 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Latest.pth saved !!!
2023-03-22 10:04:52,631 - INFO - **********Latest test***********
2023-03-22 10:04:52,631 - INFO - eval epoch 116
2023-03-22 10:04:53,534 - INFO - Test: [0/782]	Time 0.900 (0.900)	Loss 2.1378 (2.1378)	Acc@1 80.469 (80.469)	Acc@5 96.094 (96.094)
2023-03-22 10:07:49,051 - INFO - Test: [200/782]	Time 0.885 (0.878)	Loss 2.3631 (2.4097)	Acc@1 75.000 (76.166)	Acc@5 92.188 (91.391)
2023-03-22 10:10:45,962 - INFO - Test: [400/782]	Time 0.915 (0.881)	Loss 2.3201 (2.3855)	Acc@1 80.469 (76.812)	Acc@5 91.406 (91.708)
2023-03-22 10:13:47,741 - INFO - Test: [600/782]	Time 0.923 (0.890)	Loss 2.4577 (2.3553)	Acc@1 75.000 (77.570)	Acc@5 90.625 (92.102)
2023-03-22 10:16:22,027 - INFO -  * Acc@1 77.955 Acc@5 92.409
2023-03-22 10:16:22,028 - INFO - Max accuracy: 77.9550%
2023-03-22 10:16:23,436 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Best.pth saved !!!
2023-03-22 10:16:23,437 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-22 10:16:26,275 - INFO - Train: [117/120][0/3907]	eta 3:04:20 lr 0.00010956	time 2.8308 (2.8308)	loss 1.8398 (1.8398)	acc@1: 94.4504	acc@5: 96.7728	
2023-03-22 10:17:25,328 - INFO - Train: [117/120][300/3907]	eta 0:12:21 lr 0.00010956	time 0.1937 (0.2056)	loss 3.8194 (3.1841)	acc@1: 60.9691	acc@5: 74.5954	
2023-03-22 10:18:24,961 - INFO - Train: [117/120][600/3907]	eta 0:11:08 lr 0.00010956	time 0.1919 (0.2022)	loss 3.5491 (3.1823)	acc@1: 68.1253	acc@5: 76.4272	
2023-03-22 10:19:24,758 - INFO - Train: [117/120][900/3907]	eta 0:10:05 lr 0.00010956	time 0.2018 (0.2012)	loss 1.8538 (3.1741)	acc@1: 90.4599	acc@5: 97.4782	
2023-03-22 10:20:24,451 - INFO - Train: [117/120][1200/3907]	eta 0:09:03 lr 0.00010956	time 0.1994 (0.2007)	loss 1.8372 (3.1423)	acc@1: 89.7607	acc@5: 97.5667	
2023-03-22 10:21:24,032 - INFO - Train: [117/120][1500/3907]	eta 0:08:02 lr 0.00010956	time 0.1940 (0.2003)	loss 2.1617 (3.1207)	acc@1: 92.3461	acc@5: 93.8587	
2023-03-22 10:22:23,528 - INFO - Train: [117/120][1800/3907]	eta 0:07:01 lr 0.00010956	time 0.1993 (0.1999)	loss 1.7274 (3.1214)	acc@1: 94.3185	acc@5: 98.2159	
2023-03-22 10:23:23,044 - INFO - Train: [117/120][2100/3907]	eta 0:06:00 lr 0.00010956	time 0.1895 (0.1997)	loss 4.0964 (3.0977)	acc@1: 55.0098	acc@5: 70.6187	
2023-03-22 10:24:19,284 - INFO - Train: [117/120][2400/3907]	eta 0:04:58 lr 0.00010956	time 0.1756 (0.1982)	loss 4.4115 (3.1057)	acc@1: 47.5097	acc@5: 61.6192	
2023-03-22 10:25:14,057 - INFO - Train: [117/120][2700/3907]	eta 0:03:57 lr 0.00010956	time 0.1712 (0.1964)	loss 4.6702 (3.1127)	acc@1: 40.6374	acc@5: 59.3874	
2023-03-22 10:26:08,774 - INFO - Train: [117/120][3000/3907]	eta 0:02:56 lr 0.00010956	time 0.1997 (0.1950)	loss 3.8094 (3.1177)	acc@1: 64.3206	acc@5: 70.5444	
2023-03-22 10:27:04,155 - INFO - Train: [117/120][3300/3907]	eta 0:01:57 lr 0.00010956	time 0.2002 (0.1941)	loss 5.0273 (3.1232)	acc@1: 32.8385	acc@5: 53.9322	
2023-03-22 10:27:59,275 - INFO - Train: [117/120][3600/3907]	eta 0:00:59 lr 0.00010956	time 0.1874 (0.1932)	loss 1.8493 (3.1277)	acc@1: 91.7932	acc@5: 97.2384	
2023-03-22 10:28:54,433 - INFO - Train: [117/120][3900/3907]	eta 0:00:01 lr 0.00010956	time 0.1824 (0.1925)	loss 1.9689 (3.1351)	acc@1: 88.5720	acc@5: 93.2335	
2023-03-22 10:28:55,718 - INFO - EPOCH 117 training takes 0:12:32
2023-03-22 10:28:57,209 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Latest.pth saved !!!
2023-03-22 10:28:57,210 - INFO - **********Latest test***********
2023-03-22 10:28:57,211 - INFO - eval epoch 117
2023-03-22 10:28:58,129 - INFO - Test: [0/782]	Time 0.916 (0.916)	Loss 2.1743 (2.1743)	Acc@1 80.469 (80.469)	Acc@5 96.875 (96.875)
2023-03-22 10:31:46,398 - INFO - Test: [200/782]	Time 0.880 (0.842)	Loss 2.4007 (2.4525)	Acc@1 73.438 (75.517)	Acc@5 92.188 (91.053)
2023-03-22 10:34:36,599 - INFO - Test: [400/782]	Time 0.922 (0.846)	Loss 2.3640 (2.4278)	Acc@1 79.688 (76.249)	Acc@5 92.188 (91.397)
2023-03-22 10:37:24,799 - INFO - Test: [600/782]	Time 0.827 (0.845)	Loss 2.4981 (2.3976)	Acc@1 72.656 (77.023)	Acc@5 89.844 (91.813)
2023-03-22 10:39:55,396 - INFO -  * Acc@1 77.432 Acc@5 92.120
2023-03-22 10:39:55,396 - INFO - Max accuracy: 77.9550%
2023-03-22 10:39:55,396 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-22 10:39:58,008 - INFO - Train: [118/120][0/3907]	eta 2:49:47 lr 0.00006165	time 2.6074 (2.6074)	loss 3.8961 (3.8961)	acc@1: 60.4994	acc@5: 73.2024	
2023-03-22 10:40:56,749 - INFO - Train: [118/120][300/3907]	eta 0:12:15 lr 0.00006165	time 0.2165 (0.2038)	loss 5.0391 (3.0739)	acc@1: 29.2826	acc@5: 51.6188	
2023-03-22 10:41:55,659 - INFO - Train: [118/120][600/3907]	eta 0:11:01 lr 0.00006165	time 0.1880 (0.2001)	loss 4.3506 (3.0809)	acc@1: 50.8621	acc@5: 65.3243	
2023-03-22 10:42:54,350 - INFO - Train: [118/120][900/3907]	eta 0:09:57 lr 0.00006165	time 0.2091 (0.1986)	loss 3.8834 (3.0846)	acc@1: 64.1563	acc@5: 71.4306	
2023-03-22 10:43:53,505 - INFO - Train: [118/120][1200/3907]	eta 0:08:56 lr 0.00006165	time 0.1893 (0.1982)	loss 1.8353 (3.0795)	acc@1: 90.2635	acc@5: 97.2664	
2023-03-22 10:44:52,619 - INFO - Train: [118/120][1500/3907]	eta 0:07:56 lr 0.00006165	time 0.1912 (0.1980)	loss 2.7725 (3.1013)	acc@1: 84.8376	acc@5: 87.6105	
2023-03-22 10:45:51,440 - INFO - Train: [118/120][1800/3907]	eta 0:06:56 lr 0.00006165	time 0.2045 (0.1977)	loss 1.7151 (3.1183)	acc@1: 92.1603	acc@5: 99.1895	
2023-03-22 10:46:49,245 - INFO - Train: [118/120][2100/3907]	eta 0:05:55 lr 0.00006165	time 0.2021 (0.1970)	loss 2.2489 (3.0995)	acc@1: 87.8532	acc@5: 92.3974	
2023-03-22 10:47:48,345 - INFO - Train: [118/120][2400/3907]	eta 0:04:56 lr 0.00006165	time 0.1860 (0.1970)	loss 2.0466 (3.1037)	acc@1: 91.5267	acc@5: 95.3088	
2023-03-22 10:48:45,493 - INFO - Train: [118/120][2700/3907]	eta 0:03:56 lr 0.00006165	time 0.1827 (0.1962)	loss 2.1224 (3.1029)	acc@1: 87.4479	acc@5: 93.5298	
2023-03-22 10:49:40,542 - INFO - Train: [118/120][3000/3907]	eta 0:02:56 lr 0.00006165	time 0.1928 (0.1950)	loss 3.4054 (3.1020)	acc@1: 68.3666	acc@5: 77.8725	
2023-03-22 10:50:35,430 - INFO - Train: [118/120][3300/3907]	eta 0:01:57 lr 0.00006165	time 0.1989 (0.1939)	loss 2.0565 (3.0878)	acc@1: 88.1117	acc@5: 94.9480	
2023-03-22 10:51:30,257 - INFO - Train: [118/120][3600/3907]	eta 0:00:59 lr 0.00006165	time 0.1776 (0.1930)	loss 3.5768 (3.0883)	acc@1: 66.6342	acc@5: 77.2165	
2023-03-22 10:52:25,061 - INFO - Train: [118/120][3900/3907]	eta 0:00:01 lr 0.00006165	time 0.1805 (0.1922)	loss 5.0274 (3.0986)	acc@1: 31.1823	acc@5: 49.3278	
2023-03-22 10:52:26,337 - INFO - EPOCH 118 training takes 0:12:30
2023-03-22 10:52:27,732 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Latest.pth saved !!!
2023-03-22 10:52:27,733 - INFO - **********Latest test***********
2023-03-22 10:52:27,733 - INFO - eval epoch 118
2023-03-22 10:52:28,700 - INFO - Test: [0/782]	Time 0.966 (0.966)	Loss 2.1588 (2.1588)	Acc@1 80.469 (80.469)	Acc@5 96.094 (96.094)
2023-03-22 10:55:20,057 - INFO - Test: [200/782]	Time 0.892 (0.857)	Loss 2.3917 (2.4365)	Acc@1 74.219 (75.867)	Acc@5 92.969 (91.192)
2023-03-22 10:58:06,447 - INFO - Test: [400/782]	Time 0.885 (0.845)	Loss 2.3418 (2.4127)	Acc@1 80.469 (76.502)	Acc@5 92.188 (91.548)
2023-03-22 11:00:57,204 - INFO - Test: [600/782]	Time 0.735 (0.848)	Loss 2.4846 (2.3825)	Acc@1 75.000 (77.287)	Acc@5 89.844 (91.974)
2023-03-22 11:03:30,853 - INFO -  * Acc@1 77.695 Acc@5 92.284
2023-03-22 11:03:30,854 - INFO - Max accuracy: 77.9550%
2023-03-22 11:03:30,854 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-22 11:03:33,569 - INFO - Train: [119/120][0/3907]	eta 2:56:20 lr 0.00002741	time 2.7080 (2.7080)	loss 2.1888 (2.1888)	acc@1: 90.7218	acc@5: 94.4694	
2023-03-22 11:04:31,784 - INFO - Train: [119/120][300/3907]	eta 0:12:10 lr 0.00002741	time 0.1956 (0.2024)	loss 2.4538 (3.0063)	acc@1: 85.4652	acc@5: 91.3090	
2023-03-22 11:05:30,844 - INFO - Train: [119/120][600/3907]	eta 0:11:00 lr 0.00002741	time 0.1945 (0.1996)	loss 4.8096 (2.9996)	acc@1: 35.8038	acc@5: 55.1286	
2023-03-22 11:06:29,941 - INFO - Train: [119/120][900/3907]	eta 0:09:57 lr 0.00002741	time 0.1992 (0.1988)	loss 2.8284 (3.0085)	acc@1: 81.7159	acc@5: 85.2999	
2023-03-22 11:07:27,756 - INFO - Train: [119/120][1200/3907]	eta 0:08:53 lr 0.00002741	time 0.1876 (0.1972)	loss 4.8635 (3.0112)	acc@1: 39.1254	acc@5: 53.0782	
2023-03-22 11:08:26,842 - INFO - Train: [119/120][1500/3907]	eta 0:07:54 lr 0.00002741	time 0.1973 (0.1972)	loss 3.6061 (3.0270)	acc@1: 71.0251	acc@5: 76.6148	
2023-03-22 11:09:25,939 - INFO - Train: [119/120][1800/3907]	eta 0:06:55 lr 0.00002741	time 0.1895 (0.1971)	loss 3.2921 (3.0474)	acc@1: 73.6590	acc@5: 79.8667	
2023-03-22 11:10:25,063 - INFO - Train: [119/120][2100/3907]	eta 0:05:56 lr 0.00002741	time 0.1934 (0.1971)	loss 3.6905 (3.0567)	acc@1: 64.0840	acc@5: 75.3792	
2023-03-22 11:11:24,107 - INFO - Train: [119/120][2400/3907]	eta 0:04:57 lr 0.00002741	time 0.1895 (0.1971)	loss 1.8347 (3.0769)	acc@1: 92.1140	acc@5: 97.5325	
2023-03-22 11:12:22,760 - INFO - Train: [119/120][2700/3907]	eta 0:03:57 lr 0.00002741	time 0.2040 (0.1969)	loss 4.6648 (3.0880)	acc@1: 43.5814	acc@5: 59.4855	
2023-03-22 11:13:21,774 - INFO - Train: [119/120][3000/3907]	eta 0:02:58 lr 0.00002741	time 0.2071 (0.1969)	loss 3.6026 (3.0970)	acc@1: 67.3003	acc@5: 76.5380	
2023-03-22 11:14:20,816 - INFO - Train: [119/120][3300/3907]	eta 0:01:59 lr 0.00002741	time 0.1947 (0.1969)	loss 1.8367 (3.1016)	acc@1: 90.5407	acc@5: 96.7849	
2023-03-22 11:15:20,042 - INFO - Train: [119/120][3600/3907]	eta 0:01:00 lr 0.00002741	time 0.1911 (0.1969)	loss 2.0805 (3.1043)	acc@1: 89.7580	acc@5: 93.5613	
2023-03-22 11:16:19,004 - INFO - Train: [119/120][3900/3907]	eta 0:00:01 lr 0.00002741	time 0.1949 (0.1969)	loss 1.9528 (3.1050)	acc@1: 92.3200	acc@5: 96.8978	
2023-03-22 11:16:20,328 - INFO - EPOCH 119 training takes 0:12:49
2023-03-22 11:16:21,683 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Latest.pth saved !!!
2023-03-22 11:16:21,684 - INFO - **********Latest test***********
2023-03-22 11:16:21,684 - INFO - eval epoch 119
2023-03-22 11:16:22,442 - INFO - Test: [0/782]	Time 0.757 (0.757)	Loss 2.1318 (2.1318)	Acc@1 80.469 (80.469)	Acc@5 96.875 (96.875)
2023-03-22 11:19:06,370 - INFO - Test: [200/782]	Time 0.762 (0.819)	Loss 2.3656 (2.4119)	Acc@1 75.000 (76.166)	Acc@5 92.188 (91.356)
2023-03-22 11:21:54,239 - INFO - Test: [400/782]	Time 0.858 (0.829)	Loss 2.3261 (2.3881)	Acc@1 79.688 (76.863)	Acc@5 92.188 (91.708)
2023-03-22 11:24:44,294 - INFO - Test: [600/782]	Time 0.850 (0.836)	Loss 2.4718 (2.3576)	Acc@1 76.562 (77.621)	Acc@5 90.625 (92.104)
2023-03-22 11:27:14,809 - INFO -  * Acc@1 77.999 Acc@5 92.370
2023-03-22 11:27:14,810 - INFO - Max accuracy: 77.9990%
2023-03-22 11:27:16,152 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Best.pth saved !!!
2023-03-22 11:27:16,153 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-22 11:27:18,740 - INFO - Train: [120/120][0/3907]	eta 2:48:13 lr 0.00000685	time 2.5834 (2.5834)	loss 2.0746 (2.0746)	acc@1: 90.1772	acc@5: 94.0304	
2023-03-22 11:28:16,534 - INFO - Train: [120/120][300/3907]	eta 0:12:03 lr 0.00000685	time 0.1885 (0.2006)	loss 2.5145 (3.1663)	acc@1: 86.2066	acc@5: 90.5820	
2023-03-22 11:29:15,456 - INFO - Train: [120/120][600/3907]	eta 0:10:56 lr 0.00000685	time 0.1926 (0.1985)	loss 3.7145 (3.1100)	acc@1: 64.9974	acc@5: 75.1822	
2023-03-22 11:30:14,748 - INFO - Train: [120/120][900/3907]	eta 0:09:56 lr 0.00000685	time 0.1913 (0.1982)	loss 3.3874 (3.1164)	acc@1: 74.4962	acc@5: 80.0077	
2023-03-22 11:31:13,739 - INFO - Train: [120/120][1200/3907]	eta 0:08:55 lr 0.00000685	time 0.2167 (0.1978)	loss 4.8423 (3.1032)	acc@1: 37.5369	acc@5: 54.3021	
2023-03-22 11:32:12,525 - INFO - Train: [120/120][1500/3907]	eta 0:07:55 lr 0.00000685	time 0.1951 (0.1974)	loss 1.9503 (3.1073)	acc@1: 84.7756	acc@5: 96.4446	
2023-03-22 11:33:11,527 - INFO - Train: [120/120][1800/3907]	eta 0:06:55 lr 0.00000685	time 0.1901 (0.1973)	loss 2.0278 (3.1116)	acc@1: 90.6546	acc@5: 95.2642	
2023-03-22 11:34:10,307 - INFO - Train: [120/120][2100/3907]	eta 0:05:56 lr 0.00000685	time 0.1903 (0.1971)	loss 5.0263 (3.1146)	acc@1: 34.4078	acc@5: 53.5872	
2023-03-22 11:35:09,325 - INFO - Train: [120/120][2400/3907]	eta 0:04:56 lr 0.00000685	time 0.1913 (0.1971)	loss 4.3219 (3.1196)	acc@1: 53.4124	acc@5: 65.1749	
2023-03-22 11:36:08,823 - INFO - Train: [120/120][2700/3907]	eta 0:03:58 lr 0.00000685	time 0.1888 (0.1972)	loss 1.8289 (3.1133)	acc@1: 91.1445	acc@5: 95.8186	
2023-03-22 11:37:04,672 - INFO - Train: [120/120][3000/3907]	eta 0:02:57 lr 0.00000685	time 0.1918 (0.1961)	loss 3.8310 (3.1161)	acc@1: 60.5101	acc@5: 70.6111	
2023-03-22 11:37:59,633 - INFO - Train: [120/120][3300/3907]	eta 0:01:58 lr 0.00000685	time 0.1992 (0.1949)	loss 4.3407 (3.1138)	acc@1: 50.4247	acc@5: 62.4221	
2023-03-22 11:38:54,054 - INFO - Train: [120/120][3600/3907]	eta 0:00:59 lr 0.00000685	time 0.1746 (0.1938)	loss 4.2704 (3.1153)	acc@1: 53.7605	acc@5: 64.1568	
2023-03-22 11:39:49,184 - INFO - Train: [120/120][3900/3907]	eta 0:00:01 lr 0.00000685	time 0.1747 (0.1930)	loss 2.2303 (3.1154)	acc@1: 87.2024	acc@5: 92.5090	
2023-03-22 11:39:50,426 - INFO - EPOCH 120 training takes 0:12:34
2023-03-22 11:39:51,642 - INFO - ./outputs/inat21_mini/res50_dynamic_mlp_d/res50_dynamic_mlp_d-Latest.pth saved !!!
2023-03-22 11:39:51,643 - INFO - **********Latest test***********
2023-03-22 11:39:51,643 - INFO - eval epoch 120
2023-03-22 11:39:52,526 - INFO - Test: [0/782]	Time 0.882 (0.882)	Loss 2.1803 (2.1803)	Acc@1 81.250 (81.250)	Acc@5 96.094 (96.094)
2023-03-22 11:42:48,100 - INFO - Test: [200/782]	Time 0.761 (0.878)	Loss 2.3922 (2.4536)	Acc@1 73.438 (75.649)	Acc@5 92.188 (91.056)
2023-03-22 11:45:42,095 - INFO - Test: [400/782]	Time 0.929 (0.874)	Loss 2.3568 (2.4294)	Acc@1 79.688 (76.374)	Acc@5 92.188 (91.465)
2023-03-22 11:48:39,016 - INFO - Test: [600/782]	Time 0.812 (0.877)	Loss 2.4985 (2.3993)	Acc@1 75.000 (77.162)	Acc@5 90.625 (91.876)
2023-03-22 11:51:12,707 - INFO -  * Acc@1 77.562 Acc@5 92.176
2023-03-22 11:51:12,708 - INFO - Max accuracy: 77.9990%
2023-03-22 11:51:12,708 - INFO - Exp path: ./outputs/inat21_mini/res50_dynamic_mlp_d
2023-03-22 11:51:12,708 - INFO - Training time 10:41:24